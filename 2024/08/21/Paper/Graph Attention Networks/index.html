<!DOCTYPE html><html lang="zh" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Graph Attention Networks | 遗世独立</title><meta name="author" content="神火不知灭"><meta name="copyright" content="神火不知灭"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="图形注意力网络 会议: ICLR 2018 论文地址：https:&#x2F;&#x2F;paperswithcode.com&#x2F;paper&#x2F;graph-attention-networks github: https:&#x2F;&#x2F;github.com&#x2F;PetarV-&#x2F;GAT 开源库：PyG  [TOC] 摘要 本文提出一种新的神经网络架构——图注意力网络（GAT），该网络可以处理具有图形结构的数据，并利用掩码自注意层来解决基">
<meta property="og:type" content="article">
<meta property="og:title" content="Graph Attention Networks">
<meta property="og:url" content="http://blog.sunlingzhang.com/2024/08/21/Paper/Graph%20Attention%20Networks/index.html">
<meta property="og:site_name" content="遗世独立">
<meta property="og:description" content="图形注意力网络 会议: ICLR 2018 论文地址：https:&#x2F;&#x2F;paperswithcode.com&#x2F;paper&#x2F;graph-attention-networks github: https:&#x2F;&#x2F;github.com&#x2F;PetarV-&#x2F;GAT 开源库：PyG  [TOC] 摘要 本文提出一种新的神经网络架构——图注意力网络（GAT），该网络可以处理具有图形结构的数据，并利用掩码自注意层来解决基">
<meta property="og:locale">
<meta property="og:image" content="http://blog.sunlingzhang.com/admin_head.jpg">
<meta property="article:published_time" content="2024-08-21T09:21:00.000Z">
<meta property="article:modified_time" content="2026-02-12T10:34:06.980Z">
<meta property="article:author" content="神火不知灭">
<meta property="article:tag" content="GAN">
<meta property="article:tag" content="ICLR 2018">
<meta property="article:tag" content="paper">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://blog.sunlingzhang.com/admin_head.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Graph Attention Networks",
  "url": "http://blog.sunlingzhang.com/2024/08/21/Paper/Graph%20Attention%20Networks/",
  "image": "http://blog.sunlingzhang.com/admin_head.jpg",
  "datePublished": "2024-08-21T09:21:00.000Z",
  "dateModified": "2026-02-12T10:34:06.980Z",
  "author": [
    {
      "@type": "Person",
      "name": "神火不知灭",
      "url": "http://blog.sunlingzhang.com"
    }
  ]
}</script><link rel="shortcut icon" href="/favicon.ico"><link rel="canonical" href="http://blog.sunlingzhang.com/2024/08/21/Paper/Graph%20Attention%20Networks/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=5.5.4"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.13.0/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Graph Attention Networks',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 8.1.1"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/admin_head.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">64</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">64</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">3</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/"><i class="fa-fw fas fa-keyboard"></i><span> 入门实践</span></a></div><div class="menus_item"><a class="site-page" href="/tags/%E9%9A%8F%E7%AC%94/"><i class="fa-fw fas fa-edit"></i><span> 随笔</span></a></div><div class="menus_item"><a class="site-page" href="/tags/paper/"><i class="fa-fw fal fa-paperclip"></i><span> 论文解读</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-book"></i><span> 计算机</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/algorithm/"><i class="fa-fw fas fa-code"></i><span> 算法</span></a></li><li><a class="site-page child" href="/data-structure/"><i class="fa-fw fas fa-terminal"></i><span> 数据结构</span></a></li><li><a class="site-page child" href="/operation-system/"><i class="fa-fw fas fa-desktop"></i><span> 操作系统</span></a></li><li><a class="site-page child" href="/computer-composition/"><i class="fa-fw fas fa-microchip"></i><span> 计算机组成原理</span></a></li><li><a class="site-page child" href="/network/"><i class="fa-fw fas fa-network-wired"></i><span> 计算机网络</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-book"></i><span> 页面</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 编程语言</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/tags/Java/"><i class="fa-fw fas fa-music"></i><span> Java</span></a></li><li><a class="site-page child" href="/tags/Python/"><i class="fa-fw fas fa-video"></i><span> Python</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">遗世独立</span></a><a class="nav-page-title" href="/"><span class="site-name">Graph Attention Networks</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/"><i class="fa-fw fas fa-keyboard"></i><span> 入门实践</span></a></div><div class="menus_item"><a class="site-page" href="/tags/%E9%9A%8F%E7%AC%94/"><i class="fa-fw fas fa-edit"></i><span> 随笔</span></a></div><div class="menus_item"><a class="site-page" href="/tags/paper/"><i class="fa-fw fal fa-paperclip"></i><span> 论文解读</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-book"></i><span> 计算机</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/algorithm/"><i class="fa-fw fas fa-code"></i><span> 算法</span></a></li><li><a class="site-page child" href="/data-structure/"><i class="fa-fw fas fa-terminal"></i><span> 数据结构</span></a></li><li><a class="site-page child" href="/operation-system/"><i class="fa-fw fas fa-desktop"></i><span> 操作系统</span></a></li><li><a class="site-page child" href="/computer-composition/"><i class="fa-fw fas fa-microchip"></i><span> 计算机组成原理</span></a></li><li><a class="site-page child" href="/network/"><i class="fa-fw fas fa-network-wired"></i><span> 计算机网络</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-book"></i><span> 页面</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 编程语言</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/tags/Java/"><i class="fa-fw fas fa-music"></i><span> Java</span></a></li><li><a class="site-page child" href="/tags/Python/"><i class="fa-fw fas fa-video"></i><span> Python</span></a></li></ul></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">Graph Attention Networks</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2024-08-21T09:21:00.000Z" title="Created 2024-08-21 17:21:00">2024-08-21</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2026-02-12T10:34:06.980Z" title="Updated 2026-02-12 18:34:06">2026-02-12</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><h2 id="图形注意力网络">图形注意力网络</h2>
<p>会议: ICLR 2018</p>
<p>论文地址：<a target="_blank" rel="noopener" href="https://paperswithcode.com/paper/graph-attention-networks">https://paperswithcode.com/paper/graph-attention-networks</a></p>
<p>github: <a target="_blank" rel="noopener" href="https://github.com/PetarV-/GAT">https://github.com/PetarV-/GAT</a></p>
<p>开源库：<a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/">PyG</a></p>
<hr>
<p>[TOC]</p>
<h2 id="摘要">摘要</h2>
<p>本文提出一种新的神经网络架构——图注意力网络（GAT），该网络可以处理具有图形结构的数据，并利用掩码自注意层来解决基于图卷积或其近似方法的先前方法的不足之处。通过将节点能够关注邻居特征的层堆叠起来，我们可以隐式地为邻居中的不同节点指定不同的权重，而无需进行任何昂贵的矩阵操作（如求逆）或依赖于事先知道图结构。这样，我们同时解决了谱基图神经网络模型的一些关键挑战，并使我们的模型适用于归纳和推断问题。实验结果表明，在四个已建立的归纳和推断图基准数据集上，GAT模型已经达到了或匹配了最先进的结果：Cora、Citeseer和Pubmed引用网络数据集以及一个蛋白质相互作用数据集（其中测试图在训练期间未被看到）。</p>
<span id="more"></span>
<h2 id="1-简介">1 简介</h2>
<p>卷积神经网络（CNN）已成功应用于诸如图像分类，语义分割或机器翻译等问题，在这些问题中，底层数据表示具有网格状结构。 这些架构通过将其应用于所有输入位置来有效地重复使用可学习参数的本地滤波器。</p>
<p>然而，许多有趣的任务涉及的数据不能用网格结构来表示，而是在不规则域中。这种情况包括三维网格、社交网络、电信网络、生物网络或大脑连接组。这种数据通常可以以图形的形式呈现。</p>
<p>在文献中已经有过一些尝试，将神经网络扩展到处理任意结构的图。早期的工作使用循环神经网络来处理以有向无环图表示的数据领域。图神经网络（GNN）由Gori等人（2005）、Scarselli等人（2009）引入，作为循环神经网络的一般化，可以直接处理更一般的图类型，例如循环、有向和无向图。图神经网络包括一个迭代过程，该过程传播节点状态直到达到平衡；然后通过神经网络基于每个节点的状态为每个节点产生输出 。李等人(2016)采纳并改进了这一想法，建议在传播步骤中使用门控循环单元(Cho等人，2014)。</p>
<p>然而，人们越来越有兴趣将卷积推广到图领域。这方面的进展通常被归类为谱方法和非谱方法。</p>
<p>一方面，谱方法使用图的谱表示，并已成功应用于节点分类。在 Bruna等人（2014）的工作中，卷积操作是在傅里叶域中定义的，通过计算图拉普拉斯矩阵的特征分解来实现，这可能导致大量的计算和非空间局部滤波器。后来的研究解决了这些问题。Henaff 等人。（2015）引入了具有平滑系数的谱滤波器参数化，以使它们在空间上局部化。随后，Defferrard 等人。（2016）提出通过图拉普拉斯矩阵的 Chebyshev 展开近似滤波器，从而避免了计算拉普拉斯特征向量的需求，并产生了空间局部化的滤波器。最后，Kipf 和 Welling（2017）通过限制滤波器仅在每个节点周围的一个步骤内运行来简化了此先前的方法。然而，在上述所有谱方法中，学习到的滤波器依赖于拉普拉斯本征基，而拉普拉斯本征基又取决于图结构。因此，基于特定结构训练的模型不能直接应用于具有不同结构的图。</p>
<p>另一方面，我们有非频谱方法（Duvenaud et al.，2015；Atwood &amp; Towsley，2016；Hamilton et al.，2017），它在图上直接定义卷积操作，在空间接近邻居组上进行操作。这些方法中的一些挑战包括如何为不同的大小邻域定义一个算子，并保持卷积神经网络的权重共享特性。在某些情况下，这需要为每个节点度数学习一个特定的权重矩阵（Duvenaud et al.，2015），使用过渡矩阵的幂来定义邻域，同时为每个输入通道和邻域度数学习权重（Atwood &amp; Towsley，2016），或者提取并归一化包含固定数量节点的邻域（Niepert et al.，2016）。Monti等人（2016）提出了混合模型CNN（MoNet），这是一种为空间提供CNN架构统一泛化的空间方法。最近，Hamilton等人（2017）引入了GraphSAGE，这是一种用于递归采样的归纳近似的方法。该技术通过从每个节点采样一个固定大小的邻域，然后对其进行聚合（例如对所有采样邻居特征向量求平均值或将它们馈送到循环神经网络中）来实现。这种方法在几个大规模递归样本基准测试中表现出色。</p>
<p>注意力机制已成为许多基于序列的任务的事实标准（Bahdanau等，2015年；Gehring等，2016年）。注意力机制的一个好处是它允许处理可变大小的输入，并关注输入中产生决策的相关部分。当使用注意力机制来计算单个序列的表示时，通常称为自注意或内注意。与递归神经网络（RNN）或卷积一起，自注意已被证明对于机器阅读理解（Cheng等，2016年）和学习句子嵌入（Lin等，2017年）等任务很有用。然而，Vaswani等人。 (2017) 表明，不仅自我注意可以改进基于循环神经网络或卷积的方法，而且自我注意足以构建一个强大的模型，在机器翻译任务上达到最先进的性能。</p>
<p>受最近这项工作的启发，我们提出了一种基于注意力机制的架构来对图结构数据进行节点分类。其思想是在遵循自注意力策略的情况下，通过关注每个图中节点的邻居来计算它们的隐藏表示。这种注意力架构有几个有趣的性质：（1）操作效率高，因为可以在节点邻居对之间并行化；（2）可以通过为邻居指定任意权重来应用于具有不同度数的图节点；以及（3）该模型可以直接应用于归纳学习问题，包括模型必须推广到完全未见过的图的任务。我们在四个具有挑战性的基准测试集上验证了所提出的方案：Cora、Citeseer 和 Pubmed 引用网络，以及一个归纳蛋白质相互作用数据集，并取得了与最先进的结果相媲美的效果，这突显了当处理任意结构的图时，基于注意力的模型的潜力。</p>
<p>值得注意的是，我们的工作也可以被重新解释为MoNet（Monti等人，2016）的一个特例。此外，我们共享神经网络边计算的方法类似于关系网络 (Santoro 等人，2017) 和 VAIN（Hoshen，2017） 的公式化方法，其中通过使用共享机制对对象或代理之间的关系进行逐对聚合。同样，我们提出的注意力模型可以与 Duan 等人的工作（2017）和 Denil 等人的工作（2017）相连接，这些工作使用邻域注意力操作来计算环境中不同对象之间的注意力系数。其他相关方法包括局部线性嵌入（LLE）(Roweis &amp; Saul, 2000) 和记忆网络（Weston et al.，2014）。LLE 在每个数据点周围选择固定数量的邻居，并为每个邻居学习一个权重系数以将其重建为邻居的加权总和。第二个优化步骤提取该点的特征嵌入。记忆网络也与我们的工作有一些联系，特别是如果我们将节点的邻域解释为其内存，则可以使用它来计算节点功能，通过对它的值进行关注，然后通过将其新特性存储在同一位置来进行更新。</p>
<h2 id="2-GAT-架构">2. GAT 架构</h2>
<p>在这一部分，我们将介绍用于构建任意图注意力网络的基础层（通过堆叠该层），并直接概述它与神经图处理领域中现有工作的理论和实际好处和局限性。</p>
<h3 id="2-1-图注意力层">2.1 图注意力层</h3>
<p>我们将从描述单个图注意力层开始，该层在整个实验中用于所有GAT架构。我们使用的特定注意力设置与Bahdanau等人（2015）的工作非常相似——但框架对选择的注意力机制不敏感。</p>
<p>我们的层输入是一组节点特征，即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mo>=</mo><mrow><msub><mover accent="true"><mi>h</mi><mo>⃗</mo></mover><mn>1</mn></msub><mo separator="true">,</mo><msub><mover accent="true"><mi>h</mi><mo>⃗</mo></mover><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mover accent="true"><mi>h</mi><mo>⃗</mo></mover><mi>N</mi></msub></mrow></mrow><annotation encoding="application/x-tex">h = {\vec{h}_1, \vec{h}_2,..., \vec{h}_N}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1719em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9774em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">h</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2355em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"/></svg></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9774em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">h</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2355em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"/></svg></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9774em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">h</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2355em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"/></svg></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>i</mi></msub><mo>∈</mo><msup><mi>R</mi><mi>F</mi></msup></mrow><annotation encoding="application/x-tex">h_i \in R^F</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">F</span></span></span></span></span></span></span></span></span></span></span>，N是节点数，F是每个节点的功能数。该层产生一个新的节点特征（可能具有不同的基F’），<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>h</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>=</mo><mrow><msub><mover accent="true"><msup><mi>h</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>⃗</mo></mover><mn>1</mn></msub><mo separator="true">,</mo><msub><mover accent="true"><msup><mi>h</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>⃗</mo></mover><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mover accent="true"><msup><mi>h</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>⃗</mo></mover><mi>N</mi></msub></mrow></mrow><annotation encoding="application/x-tex">h&#x27;={\vec{h&#x27;}_1, \vec{h&#x27;}_2,..., \vec{h&#x27;}_N}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1719em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9774em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6779em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2355em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"/></svg></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9774em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6779em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2355em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"/></svg></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9774em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6779em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2355em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"/></svg></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>， <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><msup><mi>h</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>⃗</mo></mover><mi>i</mi></msub><mo>∈</mo><msup><mi>R</mi><msup><mi>F</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msup></mrow><annotation encoding="application/x-tex">\vec{h&#x27;}_i∈R^{F&#x27;}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1274em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9774em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6779em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2355em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"/></svg></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9425em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9425em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8278em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span> 作为输出。</p>
<p>为了获得足够的表达能力，以将输入特征转换为更高层次的特征，至少需要一个可学习的线性变换。为此，在初始步骤中，对每个节点应用共享的线性变换，由权重矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>∈</mo><msup><mi>R</mi><mrow><msup><mi>F</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>×</mo><mi>F</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W∈R^{F&#x27;×F}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9425em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9425em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8278em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">F</span></span></span></span></span></span></span></span></span></span></span></span>参数化。然后在节点上执行自注意力——共享注意机制a：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>R</mi><msup><mi>F</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msup><mo>×</mo><msup><mi>R</mi><msup><mi>F</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msup><mo>→</mo><mi>R</mi></mrow><annotation encoding="application/x-tex">R^{F&#x27;}×R^{F&#x27;}→R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0258em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9425em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8278em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9425em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9425em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8278em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> 计算注意力系数:</p>
<p><img src="/img/gan/image-20240827201542709.png" alt="image-20240827201542709"></p>
<p>这表明节点 j 的特性对节点 i 有多么重要。在最一般的形式中，模型允许每个节点关注其他所有节点，放弃所有结构信息。我们通过执行遮蔽注意力来注入图结构到机制中——我们只计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">N_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 中的节点 j 对应的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">e_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> ，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">N_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是图中节点 i 的一些邻居。在我们的所有实验中，这些将是节点 i（包括 i）的 首先邻域。为了使系数在不同节点之间易于比较，我们使用 softmax 函数在所有选择 j 上对其进行归一化：</p>
<p><img src="/img/gan/image-20240827201725207.png" alt="image-20240827201725207"></p>
<p>在我们的实验中，注意机制 是一个单层前馈神经网络，由权重向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>a</mi><mo>⃗</mo></mover><mo>∈</mo><msup><mi>R</mi><mrow><mn>2</mn><msup><mi>F</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow></msup></mrow><annotation encoding="application/x-tex">\vec{a}∈R^{2F&#x27;}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7531em;vertical-align:-0.0391em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">a</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2355em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"/></svg></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9425em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9425em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8278em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span> ，并应用LeakyReLU （负输入斜率α=0.2 ）作为非线性激活函数。展开后，注意力机制计算出的系数（如图 1 (左) 所示）可以表示为：</p>
<p><img src="/img/gan/image-20240827201739320.png" alt="image-20240827201739320"></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> 代表转置，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">||</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣∣</span></span></span></span> 是拼接运算。</p>
<p>一旦获得，归一化的注意力系数被用来计算它们对应的特征的线性组合，作为每个节点的最终输出特征（在潜空间应用非线性函数σ之后）：</p>
<p><img src="/img/gan/image-20240827201846655.png" alt="image-20240827201846655"></p>
<p>为了稳定自注意力学习过程，我们发现将其扩展到多头注意力机制中是有益的，就像 Vaswani等人（2017）所做的那样。具体来说，K个独立的注意力机制执行方程4中的变换，然后它们的特征被连接起来，得到下面的输出特征表示：</p>
<p><img src="/img/gan/image-20240827201855208.png" alt="image-20240827201855208"></p>
<p>其中，||表示连接操作，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>α</mi><mrow><mi>i</mi><mi>j</mi></mrow><mi>k</mi></msubsup></mrow><annotation encoding="application/x-tex">α^k_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2439em;vertical-align:-0.3948em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-2.4413em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3948em;"><span></span></span></span></span></span></span></span></span></span> 是由第 k 个注意力机制（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mi>k</mi></msup></mrow><annotation encoding="application/x-tex">a^k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span></span></span></span>）计算得到的归一化注意力系数，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>k</mi></msup></mrow><annotation encoding="application/x-tex">W^k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span></span></span></span> 是对应的输入线性变换权重矩阵。请注意，在这种设置下，每个节点的最终返回输出 h’ 将包含 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><msup><mi>F</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">KF&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> 个特征（而不是 F’）。 特别地，如果我们在网络的最后一层（预测）上执行多头注意力，那么了连接操作就不再有意义了——相反，我们使用平均值，并且在那时才应用最终的非线性函数（通常为分类问题的softmax或logistic sigmoid）：</p>
<p><img src="/img/gan/image-20240827201908060.png" alt="image-20240827201908060"></p>
<p>图 1 （右）显示了多头注意力层的聚合过程。</p>
<p><img src="/img/gan/image-20240827201832774.png" alt="image-20240827201832774"></p>
<p>图1：左：我们的模型中采用的注意力机制a（Whhi，Whhj），由权重向量a∈R2F参数化，并应用LeakyReLU激活。右：节点1在其邻域上的多头注意力（K = 3个头）。不同的箭头样式和颜色表示独立的注意力计算。每个头的聚合特征通过连接或平均来获得h。1。</p>
<h3 id="2-2-与相关工作的比较">2.2 与相关工作的比较</h3>
<p>本节 2.1 中描述的图注意力层直接解决了神经网络处理图形结构数据时遇到的一些问题：</p>
<ul>
<li>从计算的角度来看，它非常有效率：自注意力层的操作可以并行化到所有边缘上，输出特征的计算也可以并行化到 所有节点。不需要特征值分解或类似的昂贵矩阵操作。单个GAT注意力头计算’F’功能的时间复杂度可以表示为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi mathvariant="normal">∣</mi><mi>v</mi><mi mathvariant="normal">∣</mi><mi>F</mi><msup><mi>F</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>+</mo><mi mathvariant="normal">∣</mi><mi>E</mi><mi mathvariant="normal">∣</mi><msup><mi>F</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mtext>）</mtext></mrow><annotation encoding="application/x-tex">O(|v|FF&#x27;+|E|F&#x27;）</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mord cjk_fallback">）</span></span></span></span>，其中F是输入特征的数量，|V|和|E|分别是图中节点和边的数量。这种复杂性与基线方法相同，例如图形卷积网络（GCNs）(kipf &amp; welling, 2017)。应用多头注意力会将存储和参数要求乘以一个因子K，而各个头部的计算完全独立，并且可以并行化。</li>
<li>与GCN不同，我们的模型允许（隐式）为同一邻域中的节点分配不同的重要性，从而提高了模型的能力。此外，分析学习到的注意力权重可能会带来可解释性的优势，就像在机器翻译领域一样（例如Bahdanau等人对2015年的定性分析）。</li>
<li>注意力机制以共享的方式应用于图中的所有边，因此它不依赖于提前访问全局图结构或其所有节点（许多先前技术的局限性）。这有几个可取之处：
<ul>
<li>图不一定要是有向的（如果不存在从顶点 j 到顶点 i 的边，我们可以简单地忽略计算αij）。</li>
<li>它使我们的技术可以直接应用于 <em>归纳</em> 学习，包括模型在训练过程中完全没有见过的图上进行评估的任务。</li>
</ul>
</li>
<li>最近由汉密尔顿等人(2017)提出的方法对每个节点采样一个固定大小的邻域，以保持计算开销一致；这使得在推理过程中无法访问整个邻域。此外，当使用基于LSTM (Hochreiter &amp; Schmidhuber, 1997) 的邻居聚合器时，该技术取得了最强的结果。这假设了不同邻域之间存在一致的时间顺序节点排列，并且作者通过始终向 LSTM 提供随机排序的序列来纠正这一点。我们的方法不会受到这两种问题的影响——它会处理所有邻域（代价是在可变计算开销的情况下），并且不假定其中任何一种顺序。</li>
<li>正如第 1 节所述，GAT 可以被重新表述为 MoNet 的一个特例（Monti 等人，2016）。具体来说，将伪坐标函数设置为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>f</mi><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">u(x,y)=f(x)||f(y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">u</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mord">∣∣</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span>  表示节点 x 的特征 (潜在地通过 MLP 进行变换)，|| 是连接操作；权重函数设为$w_j(u) = softmax(MLP(u)) $（对整个节点邻域进行 softmax 操作），这会使 MoNet 的patch算子与我们的相似。然而，需要注意的是，与之前考虑过的 MoNet 实例相比，我们的模型使用了节点特征来进行相似性计算，而不是节点的结构属性（即假设提前知道了图结构）。</li>
</ul>
<p>我们能够构建一个版本的GAT层，它利用稀疏矩阵操作，将存储复杂性降低到与节点数和边数线性相关的，并使GAT模型能够在更大的图数据集上运行。然而，我们使用的张量操纵框架只支持对阶数为2的张量进行稀疏矩阵乘法，这限制了该层的批量处理能力（尤其是对于包含多个图的数据集）。适当地解决这一约束是未来工作的重要方向。根据图结构的规律性，GPU在这些稀疏情况下可能无法比CPU提供显著的性能提升。还应该注意的是，我们的模型的“感受野”的大小由网络深度所界定（与GCN和类似的模型相似）。可以很容易地应用诸如跳过连接（He等人，2016）等技术来适当扩展深度。最后，在所有图边缘上并行化，特别是在分布式方式下，可能会涉及大量冗余计算，因为感兴趣的图中邻域通常高度重叠。</p>
<h2 id="3-实验评估">3 实验评估</h2>
<p>我们在四个基于图的标准基准任务（推断）上，对 GAT 模型进行了与多种强大的基线和先前方法的比较评估。 以及归纳法)，在所有这些方法中实现或匹配最先进的性能。 本节总结了我们的实验设置、结果，以及对 GAT 模型提取特征表示的大致定性分析。</p>
<h3 id="3-1-数据集">3.1 数据集</h3>
<p><strong>传导学习</strong>  我们使用三个标准引用网络基准数据集——Cora、Citeseer 和 Pubmed（Sen 等，2008 年）——并密切遵循 Yang 等人（2016 年）的传导实验设置。在所有这些数据集中，节点对应于文档，边对应于（无向）引文。节点特征对应于文档的词袋表示中的元素。每个节点都有一个类别标签。我们只允许每类使用 20 个训练节点，但是为了遵守传导设置，训练算法可以访问所有节点的功能向量。对经过训练的模型的预测能力是在 1000 个测试节点上评估的，我们在验证目的时使用了另外 500 个节点（与 Kipf 和 Welling（2017）所使用的相同）。 Cora 数据集包含 2708 个节点、5429 条边、7 类和每个节点 1433 个特征。Citeseer 数据集包含 3327 个节点、4732 条边、6 类和每个节点 3703 个特征。Pubmed 数据集包含 19717 个节点、44338 条边、3 类和每个节点 500 个特征。</p>
<p><strong>归纳学习</strong>  我们使用了蛋白质相互作用 (PPI) 数据集，其中包含对应于不同人类组织的图（Zitnik 和 Leskovec，2017）。该数据集包含 20 个训练图、2 个验证图和 2 个测试图。在训练过程中，测试图保持完全不可见。为了构造这些图，我们使用了 Hamilton 等人（2017）提供的预处理数据。每个图中的平均节点数为 2,372。每个节点有 50 个特征，由基因组定位集合、模式基因集和免疫学标签组成。来自分子签名数据库(Molecular Signatures Database)的基因本体(Gene Ontology)中每个节点集有 121 个标签收集自Subramanian等人，2005)，一个节点可以同时具有多个标签。 表 1 提供了数据集有趣特征的概述。</p>
<p>表1：我们实验中使用的数据集摘要。</p>
<table>
<thead>
<tr>
<th></th>
<th>Cora</th>
<th>Citeseer</th>
<th>Pubmed</th>
<th>PPI</th>
</tr>
</thead>
<tbody>
<tr>
<td>Task</td>
<td>Transductive</td>
<td>Transductive</td>
<td>Transductive  19717(1  graph)</td>
<td>Inductive</td>
</tr>
<tr>
<td>#  Nodes</td>
<td>2708(1  graph)</td>
<td>3327(1  graph)</td>
<td></td>
<td>56944(24  graphs)</td>
</tr>
<tr>
<td>#  Edges</td>
<td>5429</td>
<td>4732</td>
<td>44338</td>
<td>818716</td>
</tr>
<tr>
<td>#  Features/Node</td>
<td>1433</td>
<td>3703</td>
<td>500</td>
<td>50</td>
</tr>
<tr>
<td>#  Classes</td>
<td>7</td>
<td>6</td>
<td>3</td>
<td>121(multilabel)</td>
</tr>
<tr>
<td>#  Training Nodes</td>
<td>140</td>
<td>120</td>
<td>60</td>
<td>44906(20  graphs)</td>
</tr>
<tr>
<td>#  Validation Nodes</td>
<td>500</td>
<td>500</td>
<td>500</td>
<td>6514(2  graphs)</td>
</tr>
<tr>
<td>#  Test Nodes</td>
<td>1000</td>
<td>1000</td>
<td>1000</td>
<td>5524(2  graphs)</td>
</tr>
</tbody>
</table>
<h3 id="3-2-目前最先进的方法">3.2 目前最先进的方法</h3>
<p><strong>传导学习</strong>  在传导学习任务中，我们使用与Kipf＆Welling（2017）指定的一致的相同强大的基线和最先进的方法进行比较。 这包括标签传播 (LP) (Zhu 等人，2003)，半监督嵌入 (SemiEmb) (Weston 等人，2012)，流形正则化 (ManiReg) (Belkin 等人，2006)，基于skip-gram 的图嵌入 (DeepWalk) (Perozzi 等人，2014)，迭代分类算法 (ICA) (Lu 和Getoor，2003) 和Planetoid (Yang 等人，2016)。 我们还将我们的模型直接与GCN (Kipf 和Welling, 2017) 进行比较，以及使用高阶Chebyshev滤波器的图卷积模型(Deferrard等人，2016)，以及在Monti等人(2016)中介绍的MoNet模型。</p>
<p><strong>归纳学习</strong>  在归纳学习任务中，我们比较了四种不同的监督式GraphSAGE归纳方法，这些方法在Hamilton等人，(2017)年提出。这些方法提供了多种方法来聚合采样邻居内的特征： GraphSAGE-GCN（将图卷积风格的操作扩展到归纳设置）, GraphSAGE-mean（取 GraphSAGE-GCN（通过GCN聚合邻居特征向量）、GraphSAGE-LSTM（通过将邻居功能馈入LSTM进行聚合）和GraphSAGE-pool（对共享非线性多层感知器转换后的特征向量执行元素最大操作）。其他归纳方法要么在归纳设置中完全不适用，要么假设节点按顺序添加到单个图中，使其无法用于测试图在训练期间完全不可见的情况（例如PPI数据集）。</p>
<p>此外，对于这两个任务，我们提供了每个节点共享多层感知器（MLP）分类器的性能（根本没有包含图形结构）。</p>
<h3 id="3-3-实验装置">3.3 实验装置</h3>
<p><strong>传导学习</strong>  在传导学习任务中，我们使用了两层的GAT模型。其结构超参数已在 Cora 数据集上进行了优化，并在 CiteSeer 上重复使用。第一层由 K=8 个注意力头组成，每个头计算 F’=8 个特征（总计 64 个特征），后面跟着一个指数线性单元 (ELU) 非线性函数(Clevert 等人，2016)。第二层用于分类：一个单一的注意力头来计算 C 个特征（其中 C 是类的数量），后面跟着一个 softmax 激活。为了应对小规模训练集，我们在模型中广泛地应用正则化。在训练过程中，我们对 λ=0.0005 的 L2 正则化进行应用。此外，在两个层的输入以及归一化的注意力权重（这一点至关重要）处都应用了概率为 0.6 的dropout (Srivastava 等人，2014)。与 Monti 等人（2016 年）观察到的结果类似，我们发现在 PubMed 的训练数据大小（60 个示例）需要对 GAT 架构进行一些修改：我们应用了 K=8 个输出注意力头（而不是一个），并将 L2 正则化加强至 λ=0.001。否则，架构与用于 Cora 和 CiteSeer 的架构相同。</p>
<p><strong>归纳学习</strong>  对于归纳学习任务，我们使用了三层 GAT 模型。前两层每层包含 K=4 个注意力头来计算 F’=256维 特征（总共 1024 维特征），后面跟着一个 ELU 非线性函数。最后一层用于 (多标签) 分类：有 K=6 个注意力头，每个头计算 121维 特征，然后求平均值并接上逻辑sigmoid 激活。这个任务的数据集足够大，因此我们发 现没有必要应用 L2 正则化或丢弃法——然而，我们在中间注意层之间成功地应用了跳 跃连接（He等人，2016）。在训练过程中，我们使用了包含 2 个图的批次大小。为了严格评估在这种情况下应用注意力机制的好处（即与近似 GCN 相比），当使用恒 定注意力机制a(x,y)=1时，我们也提供了相同结构的结果——这将为每个邻居分配相同的权重。</p>
<p>两个模型都使用 Glorot 初始化（Glorot 和 Bengio，2010 年）进行初始化，并使用 Adam SGD 优化器 (Kingma 和 Ba，2014 年) 在训练节点上最小化交叉熵。在PubMed中初始学习率为0.01，在所有其他数据集上的初始学习率为0.005。我们在验证节点上对交叉熵损失和准确度（推断）或微 F1 分数（归纳）采用早期停止策略，每个周期为100个时期。</p>
<h3 id="3-4-结果">3.4 结果</h3>
<p>我们的比较评估实验的结果总结在表2和表3中。<br>
对于<em>传导任务</em>，我们在 100 次运行后报告了我们方法在测试节点上的平均分类精度（标准差），并为最先进的技术重用了已在Kipf＆Welling（2017）和Monti等人（2016）中报道的指标。具体而言，对于基于Chebyshev滤波器的方法（Deferrard等人，2016），我们提供了最大报告性能，用于滤波器阶数K = 2和K = 3。为了公平地评估注意力机制的好处，我们进一步评估了一个计算64个隐藏特征的GCN模型，并尝试使用ReLU和ELU激活，并在100次运行后报告结果（作为GCN-64* ），这是所有三种情况下ReLU的结果。</p>
<p>表2:Cora、Citseeer和Pubmed的分类准确率结果总结。GCN-64*对应于计算64个隐藏特征的最佳GCN结果（使用ReLU或ELU）。</p>
<p>Transductive</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Cora</th>
<th>Citeseer</th>
<th>Pubmed</th>
</tr>
</thead>
<tbody>
<tr>
<td>MLP</td>
<td>55.1%</td>
<td>46.5%</td>
<td>71.4%</td>
</tr>
<tr>
<td>ManiReg(Belkin  et al., 2006)</td>
<td>59.5%</td>
<td>60.1%</td>
<td>70.7%</td>
</tr>
<tr>
<td>SemiEmb(Weston  et al., 2012)</td>
<td>59.0%</td>
<td>59.6%</td>
<td>71.7%</td>
</tr>
<tr>
<td>LP(Zhu  et al., 2003)</td>
<td>68.0%</td>
<td>45.3%</td>
<td>63.0%</td>
</tr>
<tr>
<td>DeepWalk(Perozzi  et al., 2014)</td>
<td>67.2%</td>
<td>43.2%</td>
<td>65.3%</td>
</tr>
<tr>
<td>ICA(Lu&amp;  Getoor, 2003)</td>
<td>75.1%</td>
<td>69.1%</td>
<td>73.9%</td>
</tr>
<tr>
<td>Planetoid(Yang  et al., 2016)</td>
<td>75.7%</td>
<td>64.7%</td>
<td>77.2%</td>
</tr>
<tr>
<td>Chebyshev(Defferrard  et al., 2016)</td>
<td>81.2%</td>
<td>69.8%</td>
<td>74.4%</td>
</tr>
<tr>
<td>GCN(Kipf&amp;  Welling, 2017)</td>
<td>81.5%</td>
<td>70.3%</td>
<td>79.0%</td>
</tr>
<tr>
<td>MoNet(Monti  et al., 2016)</td>
<td>81.7  ± 0.5%</td>
<td>—</td>
<td>78.8  ± 0.3%</td>
</tr>
<tr>
<td>GCN-64∗</td>
<td>81.4  ± 0.5%</td>
<td>70.9  ± 0.5%</td>
<td>79.0  ± 0.3%</td>
</tr>
<tr>
<td>GAT(ours)</td>
<td>83.0  ± 0.7%</td>
<td>72.5  ± 0.7%</td>
<td>79.0  ± 0.3%</td>
</tr>
</tbody>
</table>
<p>对于<em>归纳任务</em>，我们在两个未见过的测试图中的节点上报告了微观平均F1分数， 平均10次运行后，复现Hamilton等人（2017）中已经报告的指标用于其他技术。具体来说，由于我们的设置是监督式的，我们与 监督式GraphSAGE方法 进行了比较。为了评估在所有邻居中聚合的好处，我们进一步提供了 (作为GraphSAGE*) 我们通过简单修改其体系结构(这是使用具有 [512, 512, 726] 特征的三层GraphSAGE-LSTM在每个层中计算，并且用于聚合邻居的128个特征)所能实现的最佳结果。最后，我们报告了我们恒定注意力GAT模型 (作为Const-GAT) 的10次运行的结果，以公平地评估注意机制相对于GCN类聚合方案的优势（具有相同架构）。</p>
<p>表3：以微平均F1分数为指标，对PPI数据集的结果进行总结。GraphSAGE∗ 是通过修改其架构可以获得的最佳 GraphSAGE 结果。Const-GAT 是一个与 GAT 架构相同的模型，但具有恒定注意力机制（为每个邻居分配相同的重要性；类似于 GCN 的归纳算子）。</p>
<p>Inductive</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>PPI</th>
</tr>
</thead>
<tbody>
<tr>
<td>Random</td>
<td>0.396</td>
</tr>
<tr>
<td>MLP</td>
<td>0.422</td>
</tr>
<tr>
<td>GraphSAGE-GCN(Hamilton  et al., 2017)</td>
<td>0.500</td>
</tr>
<tr>
<td>GraphSAGE-mean(Hamilton  et al., 2017)</td>
<td>0.598</td>
</tr>
<tr>
<td>GraphSAGE-LSTM(Hamilton  et al., 2017)</td>
<td>0.612</td>
</tr>
<tr>
<td>GraphSAGE-pool(Hamilton  et al., 2017)</td>
<td>0.600</td>
</tr>
<tr>
<td>GraphSAGE∗</td>
<td>0.768</td>
</tr>
<tr>
<td>Const-GAT(ours)</td>
<td>0.934  ± 0.006</td>
</tr>
<tr>
<td>GAT(ours)</td>
<td>0.973  ± 0.002</td>
</tr>
</tbody>
</table>
<p>我们的结果成功地在所有四个数据集上实现了最先进的性能——这与我们在第2.2节中的讨论一致。具体来说，我们能够以1.5%和1.6%的差距提高GCN在Cora和Citeseer上的表现，表明给同一邻域的不同节点分配不同的权重可能是有益的。值得注意的是，在PPI数据集上取得的进步：我们的GAT模型比我们能够获得的最佳GraphSAGE结果提高了20.5%，证明了我们的模型具有归纳能力，并且可以通过观察整个邻域来利用更大的预测能力。此外，它比恒定注意力机制（Const-GAT，具有相同架构但具有常数注意力机制）改进了3.9%，再次直接证明了能够为不同的邻居分配不同权重的重要性。</p>
<p>我们还可以从定性的角度来研究学习到的特征表示的有效性——为此，我们在图 2 中展示了使用 t-SNE (Maaten &amp; Hinton, 2008) 对 Cora 数据集预训练的 GAT 模型的第一层提取的特征表示进行变换后的结果。该表示在投影的二维空间中显示了可识别的聚类。请注意，这些聚类对应于数据集中的七个标签，验证了模型在 Cora 的七个主题类别上的判别能力。此外，我们还可视化了归一化注意力系数（所有八个注意力头平均）的相对强度。要正确解释这些系数（例如，Bahdanau 等人。2015年），需要对所研究的数据集有进一步的领域知识，并留给未来的工作。</p>
<p><img src="/img/gan/image-20240827202313901.png" alt="image-20240827202313901"></p>
<p>图2: Cora数据集上预训练GAT模型第一个隐藏层的计算特征表示的t-SNE图。节点颜色表示类。边缘厚度表示所有八个注意力头（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup><msubsup><mi>α</mi><mrow><mi>i</mi><mi>j</mi></mrow><mi>k</mi></msubsup><mo>+</mo><msubsup><mi>α</mi><mrow><mi>j</mi><mi>i</mi></mrow><mi>k</mi></msubsup></mrow><annotation encoding="application/x-tex">\sum^K_{k=1}α^k_{ij}+α^k_{ji}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.376em;vertical-align:-0.3948em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-2.4413em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3948em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2439em;vertical-align:-0.3948em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-2.4413em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ji</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3948em;"><span></span></span></span></span></span></span></span></span></span>）节点i和j之间的聚集归一化注意力系数。</p>
<h2 id="4-结论">4 结论</h2>
<p>我们提出了图注意力网络（GAT），这是一种新颖的卷积神经网络架构，用于处理图形数据，它利用了掩码自我关注层。这些模型中使用的所有图注意力层都具有计算效率（不需要昂贵的矩阵操作，并且可以在图的所有节点上并行计算），可以为同一邻域内不同大小的邻域分配不同的重要性，并且无需提前知道整个图结构——从而解决了许多先前谱方法中的理论问题。我们的注意力模型在四个公认的节点分类基准测试中成功实现了最先进的性能或匹配性能，包括归纳和推断（特别是当完全未见过的图用于测试时）。</p>
<p>有几个潜在的改进和扩展图注意力网络可以作为未来的工作，比如克服子节2.2中描述的实际问题，能够处理更大的批量大小。一个特别有趣的 研究方向 将是利用注意机制对模型进行深入分析，以提高其可解释性。此外，从应用的角度来看，将方法扩展到 图分类 而不是节点分类也是相关的。最后，将模型扩展到包含边特征（可能指示节点之间的关系）将使我们能够解决更广泛的问题。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="http://blog.sunlingzhang.com">神火不知灭</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="http://blog.sunlingzhang.com/2024/08/21/Paper/Graph%20Attention%20Networks/">http://blog.sunlingzhang.com/2024/08/21/Paper/Graph%20Attention%20Networks/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/paper/">paper</a><a class="post-meta__tags" href="/tags/GAN/">GAN</a><a class="post-meta__tags" href="/tags/ICLR-2018/">ICLR 2018</a></div><div class="post-share"><div class="social-share" data-image="/admin_head.jpg" data-sites="facebook,x,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2024/08/27/Paper/Rethinking%20Table%20Recognition%20using%20%20GNN/" title="Rethinking Table Recognitionusing Graph Neural Networks"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">Rethinking Table Recognitionusing Graph Neural Networks</div></div><div class="info-2"><div class="info-item-1">Rethinking Table Recognitionusing Graph Neural Networks 会议: ICDAR 2019 论文地址：https://arxiv.org/abs/1905.13391 github: https://github.com/shahrukhqasim/TIES-2.0 [TOC] 摘要 文档结构分析，例如区域分割和表格识别，是文档处理中的复杂问题，并且是一个活跃的研究领域。深度学习在解决各种计算机视觉和机器学习问题方面的近期成功尚未反映在文档结构分析中，因为传统的神经网络不适合该问题的输入结构。本文提出了一种基于图网络的架构作为标准神经网络更好的替代方案来识别表格。我们主张图网络对于这些问题是一种更自然的选择，并探索了两种基于梯度的图神经网络。我们的提出的架构结合了卷积神经网络用于视觉特征提取以及图网络用于处理问题结构的好处。我们在实验上证明，与基线相比，我们的方法具有显著的优势。此外，我们还指出大规模数据集缺乏是结构分析领域深度学习研究的主要障碍，并提出了一个针对表格识别的新大规模合成数据集。最后，我们开源了我们的数据生成和图网络...</div></div></div></a><a class="pagination-related" href="/2024/08/21/Paper/GCN_Semi-Supervised%20Classification%20with%20Graph%20Convolutional%20Networks/" title="Semi-Supervised Classification with Graph Convolutional Networks"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">Semi-Supervised Classification with Graph Convolutional Networks</div></div><div class="info-2"><div class="info-item-1">基于图卷积网络的半监督分类（GCN） 会议: ICLR 2017 论文地址：https://arxiv.org/abs/1609.02907 github: https://github.com/tkipf/pygcn  [TOC] 摘要 本文提出了一种可扩展的方法来处理图结构数据上的半监督学习，该方法基于一种高效的卷积神经网络变体，它直接在图上操作。本文通过局部一阶近似谱图卷积，优化我们的卷积架构的选择。我们的模型与图中边的数量线性相关，并且可以学习编码了图的局部结构和节点特征的隐藏层表示。我们在引用网络和知识图数据库上的一系列实验中展示了我们的方法相比其他相关方法具有显著优势。  1 简介 我们考虑在图（如文献引用网络）中对节点（如文档）进行分类的问题，其中仅有一小部分节点有标签。这个问题可以被看作基于图的半监督学习，通过某种显式的基于图的正则化形式来平滑（迁移）标签信息到图中，例如，在损失函数中使用图拉普拉斯正则化项：  式中，$L_0 $ 表示与图中带标签部分相关的监督损失。f(⋅)f(·)f(⋅)可以是类似于神经网络的可微函数，λλλ 是一个权重因子，XXX 是节点特征...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2021/05/21/Paper/Attention%20Is%20All%20You%20Need/" title="Attention Is All You Need"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2021-05-21</div><div class="info-item-2">Attention Is All You Need</div></div><div class="info-2"><div class="info-item-1">Transformer 注意力就是您所需要的 [TOC] 会议： NeurIPS 2017 论文地址：https://arxiv.org/abs/1706.03762 摘要 主流的序列转换模型多是基于复杂的循环或卷积神经网络，网络包括编码器和解码器。性能最好的模型还通过注意机制连接编码器和解码器。我们提出了一个新的简单且完全基于注意力机制的网络结构，Transformer，摒弃了循环和卷积。在两个机器翻译任务上的实验表明，这些模型具有更高的并行性，更少的训练时间。我们的模型在WMT 2014 Englishto-German 的翻译任务中达到28.4 BLEU，比现有的最佳结果（包括集成模型）提高了2 BLEU以上。在WMT 2014 English-to-French翻译任务中，我们的模型在8个GPU上训练3.5天后，达到了新的单模型BLEU 41.8的最新分数，这只相当于文献中最佳模型训练成本的一小部分。通过将Transformer成功地应用于大规模和有限训练数据下的英语选区分析，证明了Transformer具有良好的泛化能力。  1 简介 循环神经网络，特别是长-短期记忆(...</div></div></div></a><a class="pagination-related" href="/2025/04/22/Paper/CTPN_Detecting%20Text%20in%20Natural%20Image%20with%20Connectionist%20Text%20Proposal%20Network/" title="Detecting Text in Natural Image with Connectionist Text Proposal Network"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-22</div><div class="info-item-2">Detecting Text in Natural Image with Connectionist Text Proposal Network</div></div><div class="info-2"><div class="info-item-1">名称：Detecting Text in Natural Image with Connectionist Text Proposal Network 论文：https://arxiv.org/abs/1609.03605 会议：ECCV 2016 github: https://github.com/tianzhi0549/CTPN  CTPN（Connectionist Text Proposal Network）是一种基于深度学习的文本检测算法，擅长在自然场景图像中定位文本行。其核心思想是将文本行分解为多个小文本段（text proposals），再通过序列连接形成完整文本行 。以下从算法流程、关键技术、优缺点及改进方向展开详解：  一、算法流程  特征提取 使用预训练的CNN（如VGG16）提取图像特征，得到高维特征图（如conv5层输出）。 双向LSTM序列建模 在特征图上滑动窗口（如3×3），每个窗口生成固定高度（如11px）的锚点（anchors），覆盖不同宽度（如16px、32px等）。通过双向LSTM捕捉水平方向的文本序列上下文信息，增强对长文本的建模能力。 文...</div></div></div></a><a class="pagination-related" href="/2026/02/04/Paper/YOLOv10/" title="YOLOv10技术文档"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-02-04</div><div class="info-item-2">YOLOv10技术文档</div></div><div class="info-2"><div class="info-item-1">[TOC] 核心摘要   端到端革命: 通过无NMS训练策略，彻底消除后处理，实现真正的端到端实时检测，显著降低延迟。   效率与精度: 通过轻量化模型设计，在保持高精度的同时，参数量和计算量显著降低，实现双赢。   硬件适配: 提供从边缘设备到高性能GPU服务器的全系列预训练模型，满足不同硬件的部署需求。   1. 概述 YOLOv10（You Only Look Once v10）是清华大学THU-MIG团队与Ultralytics合作开发的新一代实时端到端目标检测框架，于2024年5月正式发布。作为YOLO系列的里程碑式迭代，YOLOv10通过创新性的无NMS（非极大值抑制）训练策略和效率-精度驱动的模型设计，在保持高精度的同时显著降低了计算复杂度，实现了真正的端到端实时检测。 YOLOv10的核心突破在于：  完全消除NMS后处理：通过&quot;一致双分配&quot;策略，使模型在训练时利用多标签监督，推理时直接输出最终检测框，无需依赖后处理 全面优化计算路径：通过轻量化分类头、空间-通道解耦下采样、基于秩的块设计等技术，实现参数与计算量的显著降低 多硬件适配：从边缘设...</div></div></div></a><a class="pagination-related" href="/2025/04/16/Paper/CRNN_An%20End-to-End%20Trainable%20Neural%20Network%20for%20Image-based%20Sequence%20Recognition%20and%20Its%20Application%20to%20Scene%20Text%20Recognition/" title="CRNN: An End-to-End Trainable Neural Network for Image-based Sequence Recognition and Its Application to Scene Text Recognition"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-16</div><div class="info-item-2">CRNN: An End-to-End Trainable Neural Network for Image-based Sequence Recognition and Its Application to Scene Text Recognition</div></div><div class="info-2"><div class="info-item-1">CRNN详解 名称：An End-to-End Trainable Neural Network for Image-based Sequence Recognition and Its Application to Scene Text Recognition 论文：https://arxiv.org/abs/1507.05717 会议：ICDAR 2015 github: https://github.com/meijieru/crnn.pytorch 一、网络结构 CRNN整体架构包含三部分：  CNN特征提取层 输入图像通过多层卷积和池化操作提取局部特征，生成特征图（Feature Map）。例如，采用类似VGG的卷积层结构，逐步缩小空间维度并增加通道数，最终输出特征序列‌12。 RNN序列建模层 将CNN输出的特征序列转化为时序相关的序列特征。通常采用双向LSTM（BLSTM），捕捉前后文信息，解决传统RNN的梯度消失问题‌35。 CTC转录层 将RNN输出的概率序列映射为最终字符序列。CTC通过动态规划合并重复字符和空白标签，解决输入输出序列长度不一致的问题    二...</div></div></div></a><a class="pagination-related" href="/2025/04/22/Paper/ABINet_Autonomous,%20Bidirectional%20and%20Iterative%20Language%20Modeling%20for%20Scene%20Text%20Recognition/" title="ABINet: Autonomous, Bidirectional and Iterative Language Modeling for Scene Text Recognition"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-22</div><div class="info-item-2">ABINet: Autonomous, Bidirectional and Iterative Language Modeling for Scene Text Recognition</div></div><div class="info-2"><div class="info-item-1">[TOC]  名称：Read Like Humans: Autonomous, Bidirectional and Iterative Language Modeling for Scene Text Recognition 论文：https://arxiv.org/abs/2103.06495 会议：AAAI2020 Github: https://github.com/FangShancheng/ABINet  ABINet（Attention-based Bidirectional Network）是一种用于场景文本识别（Scene Text Recognition, STR）的深度学习模型。它在处理复杂背景、噪声干扰以及弯曲或倾斜文本时表现出色。ABINet 的核心创新点是引入了 双向注意力机制 和 迭代优化策略 ，从而显著提升了文本识别的准确性和鲁棒性。 以下是 ABINet 的详细解析，包括其架构设计、工作原理、优势和实现细节。  1. ABINet 的背景 问题  自然场景中的文本通常具有复杂的形状（如弯曲、倾斜等），并且背景可能包含大量噪声。 传统的基于分类的方法...</div></div></div></a><a class="pagination-related" href="/2024/08/27/Paper/Rethinking%20Table%20Recognition%20using%20%20GNN/" title="Rethinking Table Recognitionusing Graph Neural Networks"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-27</div><div class="info-item-2">Rethinking Table Recognitionusing Graph Neural Networks</div></div><div class="info-2"><div class="info-item-1">Rethinking Table Recognitionusing Graph Neural Networks 会议: ICDAR 2019 论文地址：https://arxiv.org/abs/1905.13391 github: https://github.com/shahrukhqasim/TIES-2.0 [TOC] 摘要 文档结构分析，例如区域分割和表格识别，是文档处理中的复杂问题，并且是一个活跃的研究领域。深度学习在解决各种计算机视觉和机器学习问题方面的近期成功尚未反映在文档结构分析中，因为传统的神经网络不适合该问题的输入结构。本文提出了一种基于图网络的架构作为标准神经网络更好的替代方案来识别表格。我们主张图网络对于这些问题是一种更自然的选择，并探索了两种基于梯度的图神经网络。我们的提出的架构结合了卷积神经网络用于视觉特征提取以及图网络用于处理问题结构的好处。我们在实验上证明，与基线相比，我们的方法具有显著的优势。此外，我们还指出大规模数据集缺乏是结构分析领域深度学习研究的主要障碍，并提出了一个针对表格识别的新大规模合成数据集。最后，我们开源了我们的数据生成和图网络...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/admin_head.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">神火不知灭</div><div class="author-info-description">日常记录学习用博客，仅用来练习使用</div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">64</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">64</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/dollarser"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">技术笔记，日常记录</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE%E5%BD%A2%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%BD%91%E7%BB%9C"><span class="toc-number">1.</span> <span class="toc-text">图形注意力网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">2.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E7%AE%80%E4%BB%8B"><span class="toc-number">3.</span> <span class="toc-text">1 简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-GAT-%E6%9E%B6%E6%9E%84"><span class="toc-number">4.</span> <span class="toc-text">2. GAT 架构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E5%9B%BE%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%B1%82"><span class="toc-number">4.1.</span> <span class="toc-text">2.1 图注意力层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E4%B8%8E%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C%E7%9A%84%E6%AF%94%E8%BE%83"><span class="toc-number">4.2.</span> <span class="toc-text">2.2 与相关工作的比较</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E5%AE%9E%E9%AA%8C%E8%AF%84%E4%BC%B0"><span class="toc-number">5.</span> <span class="toc-text">3 实验评估</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">5.1.</span> <span class="toc-text">3.1 数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E7%9B%AE%E5%89%8D%E6%9C%80%E5%85%88%E8%BF%9B%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">5.2.</span> <span class="toc-text">3.2 目前最先进的方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E5%AE%9E%E9%AA%8C%E8%A3%85%E7%BD%AE"><span class="toc-number">5.3.</span> <span class="toc-text">3.3 实验装置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-%E7%BB%93%E6%9E%9C"><span class="toc-number">5.4.</span> <span class="toc-text">3.4 结果</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E7%BB%93%E8%AE%BA"><span class="toc-number">6.</span> <span class="toc-text">4 结论</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/12/Python/Claude_Code/" title="Claude Code应用指南">Claude Code应用指南</a><time datetime="2026-02-12T09:30:00.000Z" title="Created 2026-02-12 17:30:00">2026-02-12</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/12/Python/MuSGD/" title="MuSGD优化器">MuSGD优化器</a><time datetime="2026-02-12T09:00:00.000Z" title="Created 2026-02-12 17:00:00">2026-02-12</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/11/Python/pytorch-%E5%B8%B8%E7%94%A8%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" title="深度学习常用损失函数">深度学习常用损失函数</a><time datetime="2026-02-11T10:00:00.000Z" title="Created 2026-02-11 18:00:00">2026-02-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/10/Python/%E4%BD%8E%E7%A7%A9%E8%BF%91%E4%BC%BC/" title="矩阵相关">矩阵相关</a><time datetime="2026-02-10T10:00:00.000Z" title="Created 2026-02-10 18:00:00">2026-02-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/10/Python/Muon%E4%BC%98%E5%8C%96%E5%99%A8/" title="Muon优化器">Muon优化器</a><time datetime="2026-02-10T09:00:00.000Z" title="Created 2026-02-10 17:00:00">2026-02-10</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 - 2026 By 神火不知灭</span><span class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 8.1.1</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.5.4</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=5.5.4"></script><script src="/js/main.js?v=5.5.4"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex@0.16.28/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex@0.16.28/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>