---
title: CRNN: An End-to-End Trainable Neural Network for Image-based Sequence Recognition and Its Application to Scene Text Recognition
date: 2025-04-16 19:00:00
tags:
 - PyTorch
 - 深度学习
 - CRNN
typora-root-url: ..
typora-copy-images-to: ../img/ocr
---

# CRNN详解

名称：An End-to-End Trainable Neural Network for Image-based Sequence Recognition and Its Application to Scene Text Recognition

论文：https://arxiv.org/abs/1507.05717

会议：ICDAR 2015

github: https://github.com/meijieru/crnn.pytorch



## 一、网络结构

CRNN整体架构包含三部分：

1. CNN特征提取层
   输入图像通过多层卷积和池化操作提取局部特征，生成特征图（Feature Map）。例如，采用类似VGG的卷积层结构，逐步缩小空间维度并增加通道数，最终输出特征序列‌12。
2. RNN序列建模层
   将CNN输出的特征序列转化为时序相关的序列特征。通常采用双向LSTM（BLSTM），捕捉前后文信息，解决传统RNN的梯度消失问题‌35。
3. CTC转录层
   将RNN输出的概率序列映射为最终字符序列。CTC通过动态规划合并重复字符和空白标签，解决输入输出序列长度不一致的问题

 <!--more-->

## 二、核心模块详解

1. CNN部分

- 卷积层通过滑动窗口提取图像纹理、边缘等低级特征，池化层降低维度并增强平移不变性。
- 输出特征图需通过Map-to-Sequence操作，将二维特征按列或行展开为时间序列，便于输入RNN。

2. RNN部分

- 双向LSTM分别从前向和后向处理序列，融合上下文信息。例如，第t时刻的输出依赖于t−1和t+1时刻的隐含状态。

3. RNN层输出每个时间步对应字符的概率分布，形成字符候选序列。

4. CTC损失函数

- 定义所有可能的字符对齐路径，通过求和路径概率计算损失值，训练时最大化正确路径的概率。
- 解码阶段采用贪心算法或束搜索（Beam Search）选择最优路径，合并重复字符并去除空白标签。

 

## 三、训练与优化

- 训练流程：采用端到端训练方式，通过反向传播和随机梯度下降（SGD）优化参数。CNN和RNN联合优化，避免分阶段训练的误差累积。
- 损失函数：使用CTC Loss，直接最小化预测序列与真实标签的差异。
- 数据预处理：对输入图像进行归一化和尺寸调整，通常将高度固定为32像素，宽度按比例缩放。

 

## 四、特点与优势

1. 端到端可训练：CNN、RNN和CTC统一优化，无需字符分割或单独训练组件。
2. 处理任意长度文本：输入图像宽度可变，输出序列长度自适应，支持中英文、数字混合识别。
3. 无需预定义词典：可直接输出字符序列，适用于无词典场景（如生僻字识别）。
4. 轻量化模型：参数量较小，适合移动端部署。



# Map to Sequence详解

CRNN中的‌**Map-to-Sequence**‌是将卷积神经网络（CNN）输出的二维特征图转化为适合循环神经网络（RNN）处理的一维序列数据的关键步骤，其核心作用是为后续的序列建模提供时序依赖特征。具体实现过程如下：

------

### 一、Map-to-Sequence的结构与作用

1. ‌**输入特征图**‌
   CNN输出的特征图尺寸通常为 `H×W×C`（高度×宽度×通道数）。例如，输入图像高度归一化为32像素时，经过多层卷积和池化后，特征图高度可能压缩至1，宽度保留较多（如100列）。
2. ‌**特征序列转换**‌
   将特征图按‌**宽度方向（W维度）切分**‌，每一列（尺寸为 `H×C`）作为一个时间步的特征向量。最终得到长度为 `W` 的序列，每个时间步的特征维度为 `H×C`（如512维）‌。
   *示例*：若特征图尺寸为 `1×100×512`，则转换为100个时间步，每个时间步的特征为512维的向量序列‌。
3. ‌**适配RNN输入**‌
   转换后的序列输入到双向LSTM中，利用RNN捕捉序列的上下文依赖关系，完成对文本字符的时序预测‌。

------

### 二、关键技术细节

1. ‌**特征图尺寸设计**‌
   - 通过调整池化层参数（如使用 `1×2` 池化窗口）减少高度压缩，保留宽度方向信息，适应文本水平排列的特点‌。
   - 最终特征图高度通常压缩为1，宽度与输入图像的文本长度成比例‌48。
2. ‌**序列顺序对齐**‌
   - 特征图按‌**从左到右的列顺序**‌切分，与文本阅读方向一致，确保RNN能正确建模字符顺序‌。
3. ‌**支持变长输入**‌
   - 宽度 `W` 可变，支持不同长度的文本识别，避免固定尺寸输入的限制‌。

------

### 三、与CRNN整体架构的关系

1. ‌**CNN特征提取阶段**‌
   CNN通过多层卷积提取局部特征，输出高语义级别的特征图，为Map-to-Sequence提供基础‌。
2. ‌**RNN时序建模阶段**‌
   双向LSTM对序列化特征进行编码，捕捉字符间的前后依赖关系，提升对相似字符（如"i"和"l"）的区分能力‌。
3. ‌**CTC解码阶段**‌
   将RNN输出的序列概率分布通过CTC算法解码，解决字符对齐问题，实现端到端训练‌。

------

### 四、总结

Map-to-Sequence通过‌**空间特征序列化**‌，将CNN的视觉特征与RNN的时序建模能力结合，是CRNN实现端到端不定长文本识别的核心模块。其设计兼顾了文本图像的空间特性和序列特性，解决了传统方法需字符切割的局限性‌。