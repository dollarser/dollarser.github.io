<!DOCTYPE html><html lang="zh" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Unifying Deep Local and Global Features for Image Search | 遗世独立</title><meta name="author" content="神火不知灭"><meta name="copyright" content="神火不知灭"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="统一局部和全局特征进行图像搜索的深层(网络) ​    本文使用机翻，稍加润色，主要用于个人理解，不恰当之处请看客见谅。 摘要 图像检索是在图像数据库中搜索与查询图像相似的项的问题。为了解决这一问题，研究了两种主要的图像表示方法：全局图像特征和局部图像特征。在这项工作中，我们的主要贡献是将全局和局部特征统一到一个单一的深度模型中，从而实现精确的检索和高效的特征提取。我们将新模型称为DELG，代表了">
<meta property="og:type" content="article">
<meta property="og:title" content="Unifying Deep Local and Global Features for Image Search">
<meta property="og:url" content="http://blog.sunlingzhang.com/2020/07/02/Paper/Unifying%20Deep%20Local%20and%20Global%20Features%20for%20Image%20Search/index.html">
<meta property="og:site_name" content="遗世独立">
<meta property="og:description" content="统一局部和全局特征进行图像搜索的深层(网络) ​    本文使用机翻，稍加润色，主要用于个人理解，不恰当之处请看客见谅。 摘要 图像检索是在图像数据库中搜索与查询图像相似的项的问题。为了解决这一问题，研究了两种主要的图像表示方法：全局图像特征和局部图像特征。在这项工作中，我们的主要贡献是将全局和局部特征统一到一个单一的深度模型中，从而实现精确的检索和高效的特征提取。我们将新模型称为DELG，代表了">
<meta property="og:locale">
<meta property="og:image" content="http://blog.sunlingzhang.com/admin_head.jpg">
<meta property="article:published_time" content="2020-07-02T10:36:45.000Z">
<meta property="article:modified_time" content="2026-02-12T10:34:06.980Z">
<meta property="article:author" content="神火不知灭">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="cv">
<meta property="article:tag" content="paper">
<meta property="article:tag" content="论文翻译">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://blog.sunlingzhang.com/admin_head.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Unifying Deep Local and Global Features for Image Search",
  "url": "http://blog.sunlingzhang.com/2020/07/02/Paper/Unifying%20Deep%20Local%20and%20Global%20Features%20for%20Image%20Search/",
  "image": "http://blog.sunlingzhang.com/admin_head.jpg",
  "datePublished": "2020-07-02T10:36:45.000Z",
  "dateModified": "2026-02-12T10:34:06.980Z",
  "author": [
    {
      "@type": "Person",
      "name": "神火不知灭",
      "url": "http://blog.sunlingzhang.com"
    }
  ]
}</script><link rel="shortcut icon" href="/favicon.ico"><link rel="canonical" href="http://blog.sunlingzhang.com/2020/07/02/Paper/Unifying%20Deep%20Local%20and%20Global%20Features%20for%20Image%20Search/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=5.5.4"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.13.0/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Unifying Deep Local and Global Features for Image Search',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 8.1.1"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/admin_head.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">64</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">64</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">3</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/"><i class="fa-fw fas fa-keyboard"></i><span> 入门实践</span></a></div><div class="menus_item"><a class="site-page" href="/tags/%E9%9A%8F%E7%AC%94/"><i class="fa-fw fas fa-edit"></i><span> 随笔</span></a></div><div class="menus_item"><a class="site-page" href="/tags/paper/"><i class="fa-fw fal fa-paperclip"></i><span> 论文解读</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-book"></i><span> 计算机</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/algorithm/"><i class="fa-fw fas fa-code"></i><span> 算法</span></a></li><li><a class="site-page child" href="/data-structure/"><i class="fa-fw fas fa-terminal"></i><span> 数据结构</span></a></li><li><a class="site-page child" href="/operation-system/"><i class="fa-fw fas fa-desktop"></i><span> 操作系统</span></a></li><li><a class="site-page child" href="/computer-composition/"><i class="fa-fw fas fa-microchip"></i><span> 计算机组成原理</span></a></li><li><a class="site-page child" href="/network/"><i class="fa-fw fas fa-network-wired"></i><span> 计算机网络</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-book"></i><span> 页面</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 编程语言</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/tags/Java/"><i class="fa-fw fas fa-music"></i><span> Java</span></a></li><li><a class="site-page child" href="/tags/Python/"><i class="fa-fw fas fa-video"></i><span> Python</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">遗世独立</span></a><a class="nav-page-title" href="/"><span class="site-name">Unifying Deep Local and Global Features for Image Search</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/"><i class="fa-fw fas fa-keyboard"></i><span> 入门实践</span></a></div><div class="menus_item"><a class="site-page" href="/tags/%E9%9A%8F%E7%AC%94/"><i class="fa-fw fas fa-edit"></i><span> 随笔</span></a></div><div class="menus_item"><a class="site-page" href="/tags/paper/"><i class="fa-fw fal fa-paperclip"></i><span> 论文解读</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-book"></i><span> 计算机</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/algorithm/"><i class="fa-fw fas fa-code"></i><span> 算法</span></a></li><li><a class="site-page child" href="/data-structure/"><i class="fa-fw fas fa-terminal"></i><span> 数据结构</span></a></li><li><a class="site-page child" href="/operation-system/"><i class="fa-fw fas fa-desktop"></i><span> 操作系统</span></a></li><li><a class="site-page child" href="/computer-composition/"><i class="fa-fw fas fa-microchip"></i><span> 计算机组成原理</span></a></li><li><a class="site-page child" href="/network/"><i class="fa-fw fas fa-network-wired"></i><span> 计算机网络</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-book"></i><span> 页面</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 编程语言</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/tags/Java/"><i class="fa-fw fas fa-music"></i><span> Java</span></a></li><li><a class="site-page child" href="/tags/Python/"><i class="fa-fw fas fa-video"></i><span> Python</span></a></li></ul></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">Unifying Deep Local and Global Features for Image Search</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-07-02T10:36:45.000Z" title="Created 2020-07-02 18:36:45">2020-07-02</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2026-02-12T10:34:06.980Z" title="Updated 2026-02-12 18:34:06">2026-02-12</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><h2 id="统一局部和全局特征进行图像搜索的深层-网络">统一局部和全局特征进行图像搜索的深层(网络)</h2>
<p>​    本文使用机翻，稍加润色，主要用于个人理解，不恰当之处请看客见谅。</p>
<h3 id="摘要">摘要</h3>
<p>图像检索是在图像数据库中搜索与查询图像相似的项的问题。为了解决这一问题，研究了两种主要的图像表示方法：全局图像特征和局部图像特征。在这项工作中，我们的主要贡献是将全局和局部特征统一到一个单一的深度模型中，从而实现精确的检索和高效的特征提取。我们将新模型称为DELG，代表了深层网络的本地和全局特性。我们利用最近特征学习工作的经验教训，提出了一个将全局特征的广义均值池和局部特征的注意选择相结合的模型。通过仔细平衡两部分之间的梯度流，整个网络可以端到端地学习——只需要图像级别的标签。我们还引入了一种基于自动编码器的局部特征降维技术，并将其集成到模型中，提高了训练效率和匹配性能。在重新修改的牛津和巴黎数据集上的实验表明，我们共同学习的基于ResNet-50的特征优于使用深层全局特征（大多数具有更重量级的主干）和那些进一步使用局部特征重新排序的结果。代码和模型将被发布。</p>
<p><strong>关键词：deep features，image retrieval，unified model，深度特征，图像检索，统一模型</strong></p>
<span id="more"></span>
<h3 id="1-介绍">1. 介绍</h3>
<p>大规模图像检索是计算机视觉中一个长期存在的问题，甚至在深度学习革命之前，计算机视觉就已经取得了很好的结果。这个问题的核心是用来 描述 图像及其相似性 的表示。</p>
<p>为了获得高的图像检索性能，需要两种图像表示方法：全局特征和局部特征。全局特征，也称为“全局描述符”或“嵌入”，总结图像的内容，通常导致紧凑的表示；同时有关视觉元素的空间排列的信息丢失。另一方面，局部特征包括关于特定图像区域的描述符和几何信息；它们对于匹配描述刚性对象的图像特别有用。一般来说，全局特征的召回率较高，而局部特征的准确率较高。全局特征可以在局部特征无法找到对应关系的非常不同的姿势中学习相似性；相反，基于局部特征的几何验证提供的分数通常能很好地反映图像相似性，比全局特征距离更可靠。一个常见的检索系统设置是首先按全局特征进行搜索，然后使用局部特征匹配对顶级数据库图像进行重新排序，以获得两个特征字的最佳结果。这种混合方法得到普及的一个突出应用是视觉定位。</p>
<p>如今，大多数依赖于这两种特性的系统都需要使用不同的模型分别提取每种特性。这是不可取的，因为它可能导致高内存使用率和增加延迟，例如，如果两个模型都需要使用专用和有限的硬件（如gpu）运行。此外，在许多情况下，对两者执行类似类型的计算，导致冗余处理和不必要的复杂性。</p>
<p><img src="/img/vision-locallization/1593687410536.png" alt="视觉定位总图"></p>
<p>图1. 我们提出的**DELG(Deep Local and Global features) **模型（左）联合提取了深层的局部和全局特征。全局特征可用于检索系统的第一阶段，以便有效地选择最相似的图像（底部）。然后，可以使用局部特征对上面的结果重新排序，从而提高检索结果的精度（右上角）。统一模型利用卷积神经网络诱导的层次图像表示来学习局部和全局表示，结合全局特征池和注意局部特征检测的最新进展。</p>
<p>贡献:（1）我们的第一个贡献是使用卷积神经网络（CNN）表示局部和全局特征的统一模型，称为DELG（深层局部和全局特征），如图1所示。这允许通过提取图像的全局特征、检测到的关键点和单个模型中的局部描述符进行有效的推断。我们的模型是通过利用CNNs中出现的分层图像表示来实现的，我们将其与广义均值池和注意局部特征检测相结合。（2）其次，我们采用卷积式自动编码模块，可以成功地学习低维的局部描述子。这可以很容易地集成到统一的模型中，并且避免了通常使用的后处理学习步骤（如PCA）的需要。（3）最后，我们设计了一个程序，使得只使用图像级监控的端到端的训练模型。这需要在反向传播过程中仔细控制全局和本地网络头之间的梯度流，以避免破坏所需的表示。通过系统的实验，我们证明我们的联合模型在仅使用全局特征进行检索或使用局部特征对这些结果重新排序时，在重新访问的ROxford和RParis数据集上取得了最新的性能。</p>
<h3 id="2-相关工作">2. 相关工作</h3>
<p>我们回顾了局部和全局特征的相关工作，主要集中在与图像检索相关的方法上。</p>
<p><em>局部特征</em>：手工（特征）的技术，如<strong>SIFT</strong>和<strong>SURF</strong>已经被广泛用于检索问题。早期的系统[32,28,39]的工作方式是根据一个包含局部描述符的大型数据库搜索查询局部描述符，然后用足够数量的对应关系对数据库图像进行几何验证。随后，根据通过局部描述符聚类获得的视觉单词，结合TF-IDF评分，采用<strong>Bag-of-Words</strong>[52]和相关方法[42,43,24]。与全局特征相比，局部特征用于检索的关键优势在于能够执行空间匹配，通常使用<strong>RANSAC</strong>。这已经被广泛使用，因为它取得了可靠和可解释的分数。最近，一些基于深度学习的局部特征被提出。与我们工作最相关的是DELF；我们提出的统一模型包含了DELF的注意力模块，但是除了支持全局特征提取之外，还有一个更简单的训练流程。</p>
<p><em>全局特征</em>：全局特征在提供紧凑表示的高图像检索性能方面表现突出。在深度学习在计算机视觉中流行之前，它们主要是通过聚集手工制作的局部描述符来开发的。如今，大多数高性能的全局特征都是基于深层卷积神经网络，这些神经网络通过基于<strong>ranking-loss</strong>或<strong>classification loss</strong>进行训练。我们的工作利用了最近在全局特性设计方面的经验教训，通过采用<strong>GeM</strong>池化和<strong>ArcFace loss</strong>。这使得全局特征检索性能比以往的方法有了很大的提高，而基于同一模型的局部特征的几何重排序进一步提高了全局特征检索性能。</p>
<p><em>联合本地和全局CNN特征</em>：以前的工作考虑卷积神经网络联合提取全局和局部图像特征。对于室内定位应用程序，Taira[53]等人使用预先训练的基于<strong>VGG</strong>的<strong>NetVLAD</strong>模型提取全局特征用于候选姿态检索，然后使用来自同一网络的特征映射进行密集的局部特征匹配。Simeoni[51]等人的<strong>DSM</strong>利用预先训练的全局特征模型，提出使用<strong>MSER</strong>检测深度激活映射中的关键点；激活通道被解释为视觉词义，可用于提出一对图像之间的暂定对应关系。我们的工作与[53,51]有很大的不同，因为它们只对经过预训练的全局特征模型进行后期处理以生成局部特征，而我们则联合训练局部和全局特征。Sarlin等人[48]提取预先训练好的局部SuperPoint[12]和全局NetVLAD[1]功能整合到单个模型中，以视觉定位应用为目标。相比之下，我们的模型是端到端的图像检索训练，并且不限于模拟单独的预先训练的局部和全局模型。据我们所知，我们是第一个研究 学习一个既能产生局部图像特征又能产生全局图像特征的非分离模型。</p>
<p><em>图像检索的降维方法</em>：<strong>PCA</strong>和<strong>whitening</strong>（白化）技术广泛应用于图像检索中局部和全局特征的降维。正如在[23]中所讨论的那样，白化权重同时作用于局部特征，这通常有利于检索应用。Mukundan等人[35]进一步引入一个收缩参数，该参数控制应用白花的程度。如果有匹配对或类别标签形式的监督，可以使用更复杂的方法。最近，Gordo等人[16] 提出用一个完全连通的层来代替PCA/白化，该层与全局描述符一起学习。</p>
<p>在本文中，我们的目标是构建一个可以端到端学习的系统，只使用图像级标签，不需要使训练更复杂的后处理阶段。此外，由于我们从常见CNN主干网的特征图中提取局部特征，它们往往是高维的，不适用于大规模问题。所有上述方法要么需要一个单独的后处理步骤来降低特征的维数，要么需要在本地补丁的级别上进行监督，导致它们不适合我们的需要。因此，我们在我们的模型中引入了一个自动编码器，它可以与网络的其他部分共同有效地学习。它不需要额外的监督，因为它可以训练与重建损失。</p>
<h3 id="3-DELG">3. DELG</h3>
<h4 id="3-1-设计注意事项">3.1 设计注意事项</h4>
<p>为了获得最佳性能，图像检索需要对用户可能感兴趣的对象类型进行语义理解，以便系统能够区分相关对象与杂波/背景。因此，局部和全局特征都应该只关注图像中最具鉴别能力的信息。然而，在这两种特征模式的期望行为方面存在着实质性的差异，这对共同学习它们构成了相当大的挑战。</p>
<p>对于描绘同一感兴趣对象的图像，全局特征应该相似，否则应该不同。这需要对视点和光度变换保持不变的高级抽象表示。另一方面，局部特征需要对基于特定图像区域的表示进行编码；特别是，关键点检测器对于视点应该是等价的，并且关键点描述符需要对局部视觉信息进行编码。这对于在图像检索系统中广泛应用的查询图像和数据库图像之间进行几何一致性检查至关重要。</p>
<p>此外，我们的目标是设计一个可以端到端学习的模型，具有局部和全局特性，而不需要额外的学习阶段。这简化了训练流程，允许更快的迭代和更广泛的适用性。相比之下，以往的特征学习工作通常需要几个学习阶段：专注的局部特征深度学习[38]需要3个学习阶段（微调、注意力、主成分分析）；全局特征深度通常需要两个阶段，例如区域建议和Siamese训练[17]，或Siamese训练和监督白化[45]，或者ranking loss 训练和主成分分析[46]。</p>
<h4 id="3-2-模型">3.2 模型</h4>
<p>我们设计DELG模型，如图1所示，以满足上述要求。我们建议利用CNNs[60]中的层次表示来表示要学习的不同类型的特征。虽然全局特征可以与表示高级线索的深层关联，但局部特征更适合于编码局部信息的中间层。</p>
<p>给定一幅图像，我们应用卷积神经网络主干来获得两个特征映射：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>∈</mo><msup><mi>R</mi><mo stretchy="false">(</mo></msup><msub><mi>H</mi><mi>S</mi></msub><mo>×</mo><msub><mi>W</mi><mi>S</mi></msub><mo>×</mo><msub><mi>C</mi><mi>S</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">S\in R^(H_S \times W_S \times C_S)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.038em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mopen mtight">(</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi><mo>∈</mo><msup><mi>R</mi><mo stretchy="false">(</mo></msup><msub><mi>H</mi><mi>D</mi></msub><mo>×</mo><msub><mi>W</mi><mi>D</mi></msub><mo>×</mo><msub><mi>C</mi><mi>D</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">D\in R^(H_D \times W_D \times C_D)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.038em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mopen mtight">(</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，分别代表浅激活和深激活，式中H，W，C对应于每种情况下的高度、宽度和通道数量。对于通常的卷积网络，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mi>D</mi></msub><mo>&lt;</mo><mo>=</mo><msub><mi>H</mi><mi>S</mi></msub></mrow><annotation encoding="application/x-tex">H_D &lt;= H_S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>D</mi></msub><mo>&lt;</mo><mo>=</mo><msub><mi>W</mi><mi>S</mi></msub></mrow><annotation encoding="application/x-tex">W_D &lt;= W_S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mi>D</mi></msub><mo>&gt;</mo><mo>=</mo><msub><mi>C</mi><mi>S</mi></msub></mrow><annotation encoding="application/x-tex">C_D &gt;=C_S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>；较深的层具有空间上较小的映射，具有较大数量的通道。设<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>h</mi><mo separator="true">,</mo><mi>w</mi></mrow></msub><mo>∈</mo><msup><mi>R</mi><msub><mi>C</mi><mi>S</mi></msub></msup></mrow><annotation encoding="application/x-tex">s_{h,w}\in R^{C_S}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8252em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3567em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1433em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mrow><mi>h</mi><mo separator="true">,</mo><mi>w</mi></mrow></msub><mo>∈</mo><msup><mi>R</mi><msub><mi>C</mi><mi>D</mi></msub></msup></mrow><annotation encoding="application/x-tex">d_{h,w} ∈R^{C_D}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3567em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1433em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span> 表示这些映射中h，w位置的特征。对于一般的网络设计，这些特征是非负的，因为它们是在ReLU非线性之后获得的，我们的方法就是这样。</p>
<p>为了聚合深度激活值为全局特征，我们采用了广义平均池化（GeM）[45]，它有效地加权了每个特征的贡献。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="http://blog.sunlingzhang.com">神火不知灭</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="http://blog.sunlingzhang.com/2020/07/02/Paper/Unifying%20Deep%20Local%20and%20Global%20Features%20for%20Image%20Search/">http://blog.sunlingzhang.com/2020/07/02/Paper/Unifying%20Deep%20Local%20and%20Global%20Features%20for%20Image%20Search/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/AI/">AI</a><a class="post-meta__tags" href="/tags/paper/">paper</a><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/">论文翻译</a><a class="post-meta__tags" href="/tags/cv/">cv</a></div><div class="post-share"><div class="social-share" data-image="/admin_head.jpg" data-sites="facebook,x,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2020/07/03/Paper/Large-Scale%20Image%20Retrieval%20with%20Attentive%20Deep%20Local%20Features/" title="Large-Scale Image Retrieval with Attentive Deep Local Features"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">Large-Scale Image Retrieval with Attentive Deep Local Features</div></div><div class="info-2"><div class="info-item-1">注意力深层局部特征的大规模图像检索 摘要 提出了一种适合于大规模图像检索的局部特征描述器，称为Deep-local-feature。新的特征是基于卷积神经网络，它只在地标图像数据集上使用图像级注释进行训练。为了识别在语义上有用的图像检索局部特征，我们还提出了一种用于关键点选择的注意机制，该机制与描述符共享大部分网络层。该框架可用于图像检索，作为其他关键点检测器和描述符的替代品，实现更精确的特征匹配和几何匹配验证。我们的系统产生可信的分数拒绝误报(FP)，尤其是它的健壮性针对数据库中没有正确匹配的查询。为了评估所提出的描述符，我们引入了一个新的大规模数据集，被称为谷歌地标(GLD)数据集，包括数据库和 查询搜索作为背景杂波，部分遮挡，多个地标、可变尺度的物体等DELF的成绩超过了全球和当地最先进的水平(SOTA)在大范围数据集中的描述符。可在以下网页找到项目代码：https://github.com/tensorflow/models/tree/master/research/delf。  1. 介绍 大规模图像检索是计算机视觉中的一项基本任务，它直接关系到目标检测、视觉位置识别、...</div></div></div></a><a class="pagination-related" href="/2020/03/28/default/%E6%95%B0%E6%8D%AE%E6%B5%81%E9%87%8F%E8%AF%B7%E6%B1%82%E5%A4%B4%E5%88%86%E6%9E%90/" title="移动数据流量请求头分析"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">移动数据流量请求头分析</div></div><div class="info-2"><div class="info-item-1">1. http协议请求头 12345[method] [uri] [version]\r\nHost: www.example.com\r\nConnection: keep-alive\r\n...\r\n 1.1 第一行的字段为请求的：方法，资源地址，协议版本 http协议常用的请求方法[method]为  GET：用于向服务器请求数据； POST: 用于向服务器提交数据； CONNECT: 用于隧道代理; HEAD: 用于向服务器请求报头;  资源地址[uri]：一般为URL中去掉域名后剩下的那部分，即浏览器地址栏网址中域名之后的内容。 http协议版本[version]: 目前主流版本有HTTP/1.0和HTTP/1.1。 http请求头中的的换行用的是\r\n, 而非Linux中的换行符\n。以下为一个真实请求头的示例  GET /index.html HTTP/1.1 Host: www.example.com Connection: keep-alive   1.2 Host字段为请求的主机域名 早期没有虚拟主机的概念，一台服务器有一个主机名。因此规定在请求头的第一...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2024/08/05/Paper/Hierarchical%20Graph%20Pooling%20with%20Structure%20Learning/" title="Hierarchical Graph Pooling with Structure Learning"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-05</div><div class="info-item-2">Hierarchical Graph Pooling with Structure Learning</div></div><div class="info-2"><div class="info-item-1">Hierarchical Graph Pooling with Structure Learning 会议: AAAI 2020(疑似撤稿) 论文地址：https://arxiv.org/abs/1911.05954 github: https://github.com/cszhangzhen/HGP-SL DGL开源库：https://github.com/dmlc/dgl/tree/master/examples/pytorch/hgp_sl [TOC] 摘要 图神经网络 (GNN) 将深度神经网络扩展到图结构数据，在许多图相关任务中取得了最先进的性能。然而，现有的 GNN 模型主要关注设计图卷积操作。图池化 (或下采样) 操作在分层表示学习中发挥着重要作用，通常被忽视。在这篇论文中，我们提出了一种新的图池化操作符，称为具有结构学习的分层图池化 (HGP-SL)，它可以集成到各种图神经网络架构中。HGP-SL 将图池化和结构学习集成到一个统一的模块中，以生成图的分层表示。具体来说，图池化操作根据我们定义的节点信息分数自适应地选择一组节点来形成一个诱导子图，用于后续层。为了保留...</div></div></div></a><a class="pagination-related" href="/2024/11/05/Paper/GraphSAGE_Inductive%20Representation%20Learning%20on%20Large%20Graphs/" title="Graph SAGE: Inductive Representation Learning on Large Graphs"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-05</div><div class="info-item-2">Graph SAGE: Inductive Representation Learning on Large Graphs</div></div><div class="info-2"><div class="info-item-1">Inductive Representation Learning on Large Graphs </div></div></div></a><a class="pagination-related" href="/2024/12/05/Paper/Mask2Former_Masked-attention%20Mask%20Transformer%20for%20Universal%20Image%20Segmentation/" title="Mask2Former: Masked-attention Mask Transformer for Universal Image Segmentation"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-05</div><div class="info-item-2">Mask2Former: Masked-attention Mask Transformer for Universal Image Segmentation</div></div><div class="info-2"><div class="info-item-1">摘要 图像分割将具有不同语义（如类别或实例成员关系）的像素分组，每种语义选择定义了一项任务。虽然各项任务仅在语义上有所不同，但当前研究主要集中于为每个任务设计专门的架构。我们提出了掩码注意力掩码变换器（Mask2Former），这是一种能够处理任何图像分割任务（全景、实例或语义）的新架构。其关键组件包括掩码注意力，它通过将交叉注意力约束在预测掩码区域内来提取局部特征。除了将研究工作量至少减少三倍外，它在四个流行数据集上显著优于最佳专用架构。最值得注意的是，Mask2Former 在全景分割（COCO 上的 57.8 PQ）、实例分割（COCO 上的 50.1 AP）和语义分割（ADE20K 上的 57.7 mIoU）方面设定了新的最先进水平。  1. 引言 图像分割研究像素分组问题。像素分组的不同语义，例如类别或实例成员关系，导致了不同类型的分割任务，如全景、实例或语义分割。虽然这些任务仅在语义上有所不同，但当前方法为每个任务开发专门的架构。基于全卷积网络（FCN）的逐像素分类架构用于语义分割，而预测一组与单个类别相关联的二进制掩码的掩码分类架构在实例级分割中占主导地位。尽管这些...</div></div></div></a><a class="pagination-related" href="/2025/04/22/Paper/ABINet_Autonomous,%20Bidirectional%20and%20Iterative%20Language%20Modeling%20for%20Scene%20Text%20Recognition/" title="ABINet: Autonomous, Bidirectional and Iterative Language Modeling for Scene Text Recognition"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-22</div><div class="info-item-2">ABINet: Autonomous, Bidirectional and Iterative Language Modeling for Scene Text Recognition</div></div><div class="info-2"><div class="info-item-1">[TOC]  名称：Read Like Humans: Autonomous, Bidirectional and Iterative Language Modeling for Scene Text Recognition 论文：https://arxiv.org/abs/2103.06495 会议：AAAI2020 Github: https://github.com/FangShancheng/ABINet  ABINet（Attention-based Bidirectional Network）是一种用于场景文本识别（Scene Text Recognition, STR）的深度学习模型。它在处理复杂背景、噪声干扰以及弯曲或倾斜文本时表现出色。ABINet 的核心创新点是引入了 双向注意力机制 和 迭代优化策略 ，从而显著提升了文本识别的准确性和鲁棒性。 以下是 ABINet 的详细解析，包括其架构设计、工作原理、优势和实现细节。  1. ABINet 的背景 问题  自然场景中的文本通常具有复杂的形状（如弯曲、倾斜等），并且背景可能包含大量噪声。 传统的基于分类的方法...</div></div></div></a><a class="pagination-related" href="/2020/07/03/Paper/Large-Scale%20Image%20Retrieval%20with%20Attentive%20Deep%20Local%20Features/" title="Large-Scale Image Retrieval with Attentive Deep Local Features"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2020-07-03</div><div class="info-item-2">Large-Scale Image Retrieval with Attentive Deep Local Features</div></div><div class="info-2"><div class="info-item-1">注意力深层局部特征的大规模图像检索 摘要 提出了一种适合于大规模图像检索的局部特征描述器，称为Deep-local-feature。新的特征是基于卷积神经网络，它只在地标图像数据集上使用图像级注释进行训练。为了识别在语义上有用的图像检索局部特征，我们还提出了一种用于关键点选择的注意机制，该机制与描述符共享大部分网络层。该框架可用于图像检索，作为其他关键点检测器和描述符的替代品，实现更精确的特征匹配和几何匹配验证。我们的系统产生可信的分数拒绝误报(FP)，尤其是它的健壮性针对数据库中没有正确匹配的查询。为了评估所提出的描述符，我们引入了一个新的大规模数据集，被称为谷歌地标(GLD)数据集，包括数据库和 查询搜索作为背景杂波，部分遮挡，多个地标、可变尺度的物体等DELF的成绩超过了全球和当地最先进的水平(SOTA)在大范围数据集中的描述符。可在以下网页找到项目代码：https://github.com/tensorflow/models/tree/master/research/delf。  1. 介绍 大规模图像检索是计算机视觉中的一项基本任务，它直接关系到目标检测、视觉位置识别、...</div></div></div></a><a class="pagination-related" href="/2025/04/21/Paper/DBNet_Real-time%20Scene%20Text%20Detection%20with%20Differentiable%20Binarization/" title="DBNet: Real-time Scene Text Detection with Differentiable Binarization"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-21</div><div class="info-item-2">DBNet: Real-time Scene Text Detection with Differentiable Binarization</div></div><div class="info-2"><div class="info-item-1">[TOC] 名称：DBNet: Real-time Scene Text Detection with Differentiable Binarization 论文：https://arxiv.org/abs/1911.08947 会议：AAAI2020 V2：Real-Time Scene Text Detection with Differentiable Binarization and Adaptive Scale Fusion V2：https://arxiv.org/abs/2202.10304 顶刊：TPAMI 2022  DBNet（Differentiable Binarization Network）是一种用于文本检测的深度学习模型，特别适用于自然场景中的文本检测任务。它在处理弯曲、倾斜或复杂背景中的文本时表现出色。DBNet 的核心创新点是引入了 可微分二值化（Differentiable Binarization, DB） 模块，使得模型能够在训练过程中直接优化分割掩码的二值化效果。 以下是 DBNet 的详细解析，包括其架构设计、工作原理、优势和实现细节...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/admin_head.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">神火不知灭</div><div class="author-info-description">日常记录学习用博客，仅用来练习使用</div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">64</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">64</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/dollarser"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">技术笔记，日常记录</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%9F%E4%B8%80%E5%B1%80%E9%83%A8%E5%92%8C%E5%85%A8%E5%B1%80%E7%89%B9%E5%BE%81%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E6%90%9C%E7%B4%A2%E7%9A%84%E6%B7%B1%E5%B1%82-%E7%BD%91%E7%BB%9C"><span class="toc-number">1.</span> <span class="toc-text">统一局部和全局特征进行图像搜索的深层(网络)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">1.1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.2.</span> <span class="toc-text">1. 介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C"><span class="toc-number">1.3.</span> <span class="toc-text">2. 相关工作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-DELG"><span class="toc-number">1.4.</span> <span class="toc-text">3. DELG</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-%E8%AE%BE%E8%AE%A1%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"><span class="toc-number">1.4.1.</span> <span class="toc-text">3.1 设计注意事项</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.4.2.</span> <span class="toc-text">3.2 模型</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/12/Python/Claude_Code/" title="Claude Code应用指南">Claude Code应用指南</a><time datetime="2026-02-12T09:30:00.000Z" title="Created 2026-02-12 17:30:00">2026-02-12</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/12/Python/MuSGD/" title="MuSGD优化器">MuSGD优化器</a><time datetime="2026-02-12T09:00:00.000Z" title="Created 2026-02-12 17:00:00">2026-02-12</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/11/Python/pytorch-%E5%B8%B8%E7%94%A8%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" title="深度学习常用损失函数">深度学习常用损失函数</a><time datetime="2026-02-11T10:00:00.000Z" title="Created 2026-02-11 18:00:00">2026-02-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/10/Python/%E4%BD%8E%E7%A7%A9%E8%BF%91%E4%BC%BC/" title="矩阵相关">矩阵相关</a><time datetime="2026-02-10T10:00:00.000Z" title="Created 2026-02-10 18:00:00">2026-02-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/10/Python/Muon%E4%BC%98%E5%8C%96%E5%99%A8/" title="Muon优化器">Muon优化器</a><time datetime="2026-02-10T09:00:00.000Z" title="Created 2026-02-10 17:00:00">2026-02-10</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 - 2026 By 神火不知灭</span><span class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 8.1.1</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.5.4</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=5.5.4"></script><script src="/js/main.js?v=5.5.4"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex@0.16.28/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex@0.16.28/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>