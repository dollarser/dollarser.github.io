[{"title":"几何图形相似性判断","date":"2025-08-29T04:00:00.000Z","path":"2025/08/29/python几何相似性/","raw":"---\ntitle: 几何图形相似性判断\ndate: 2025-08-29 12:00:00\ntags:\n - work\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\n---\n\n\n```tex\n有两个CAD矢量图形，图形相似但是绘制存在旋转和缩放，怎么判断其相似性\n```\n\n\n\n判断两个**矢量图形的相似性**是计算机图形学、CAD、BIM、图像识别等领域的重要问题。由于矢量图形由点、线、曲线、多边形等几何元素构成，不能像像素图像那样直接用像素差比较，需要从**几何结构、拓扑关系、形状特征**等多个维度综合判断。\n\n---\n\n<!--more-->\n\n## ✅ 一、相似性的定义（根据场景不同）\n\n| 场景       | 相似性含义                   |\n| ---------- | ---------------------------- |\n| 几何匹配   | 形状、尺寸、角度接近         |\n| 拓扑结构   | 连接方式、邻接关系一致       |\n| 语义结构   | 功能相同（如“门”、“墙”）     |\n| 变换不变性 | 平移、旋转、缩放后仍视为相似 |\n\n---\n\n## ✅ 二、判断矢量图形相似性的常用方法\n\n### 1. **基于几何特征的比较**\n\n#### (1) **Hausdorff 距离**（推荐）\n衡量两个点集之间的最大最小距离，适合比较线段、多边形轮廓。\n\n```python\nfrom scipy.spatial.distance import directed_hausdorff\n\n# shape1, shape2 是两组点 [(x,y), ...]\ndist = max(\n    directed_hausdorff(shape1, shape2)[0],\n    directed_hausdorff(shape2, shape1)[0]\n)\n```\n\n- ✅ 对噪声鲁棒\n- ✅ 支持不同点数\n- ✅ 可设定阈值判断是否“相似”\n\n> 距离越小越相似\n\n---\n\n#### (2) **Frechet 距离**（“狗绳距离”）\n更符合人类直觉的曲线相似度，考虑路径顺序。\n\n```python\n# 可用 `similaritymeasures` 库\nimport similaritymeasures\n\nfrechet_dist = similaritymeasures.frechet_dist(shape1, shape2)\n```\n\n- ✅ 更精确描述曲线相似性\n- ❌ 计算复杂度高\n\n---\n\n#### (3) **面积/周长比**\n适用于封闭图形（如多边形）：\n\n```python\nsimilarity = min(area1, area2) / max(area1, area2)\n```\n\n或使用 **Jaccard 相似度**：\n\n```python\nintersection = polygon1.intersection(polygon2).area\nunion = polygon1.union(polygon2).area\njaccard = intersection / union  # 0 ~ 1，越大越相似\n```\n\n> ✅ 适合重叠区域比较\n\n---\n\n### 2. **基于关键点匹配（Keypoint Matching）**\n\n提取图形的关键点（端点、角点、交点），然后：\n\n- 使用 **KD-Tree** 找最近邻\n- 统计匹配点对数量\n- 计算匹配率：`matched_points / total_points`\n\n```python\nfrom scipy.spatial import cKDTree\n\ntree1 = cKDTree(keypoints1)\ndistances, indices = tree1.query(keypoints2, k=1, distance_upper_bound=tolerance)\nmatched = np.sum(distances < tolerance)\nsimilarity_score = matched / max(len(keypoints1), len(keypoints2))\n```\n\n---\n\n### 3. **基于形状描述符（Shape Descriptors）**\n\n将图形转换为固定长度的特征向量，再计算距离。\n\n#### 常见描述符：\n| 方法                                   | 说明                                       |\n| -------------------------------------- | ------------------------------------------ |\n| **傅里叶描述子（Fourier Descriptor）** | 将轮廓点转为频域特征，对平移/旋转/缩放不变 |\n| **Zernike 矩**                         | 正交矩，对噪声鲁棒，适合分类               |\n| **Hu 矩**                              | 7 个不变矩，对平移、旋转、缩放不变         |\n\n```python\n# OpenCV 提供 Hu 矩\nimport cv2\n\nmoments = cv2.moments(contour)\nhu_moments = cv2.HuMoments(moments).flatten()\n```\n\n然后用欧氏距离比较两个图形的 Hu 矩向量。\n\n---\n\n### 4. **基于图结构匹配（Graph Matching）**\n\n将矢量图形建模为**无向图**：\n- 节点：端点、交点\n- 边：线段、弧\n\n使用 **图同构算法**（如 VF2）判断结构是否一致：\n\n```python\nimport networkx as nx\n\nG1 = nx.Graph()\nG1.add_edges_from([(0,1), (1,2), (2,0)])  # 三角形\n\nG2 = nx.Graph()\nG2.add_edges_from([(a,b), (b,c), (c,a)])\n\n# 判断是否同构（结构相同）\nif nx.is_isomorphic(G1, G2):\n    print(\"结构相似\")\n```\n\n> ✅ 适合拓扑结构比较（如电路图、管网）\n\n---\n\n### 5. **基于变换对齐 + 差异检测**\n\n#### 步骤：\n1. 对两个图形进行 **ICP（Iterative Closest Point）配准**\n2. 计算配准后的平均距离或重叠率\n3. 判断是否相似\n\n```python\n# 可用 open3d 或自定义 ICP\naligned_shape2 = icp(shape2, shape1)\ndistance = np.mean([min_dist(p, shape1) for p in aligned_shape2])\n```\n\n> ✅ 适合有平移、旋转、缩放差异的情况\n\n---\n\n## ✅ 三、综合相似性评分（推荐做法）\n\n结合多个指标，加权计算总分：\n\n```python\ndef similarity_score(shape1, shape2, tolerance=1e-3):\n    # 1. 几何：Hausdorff 距离归一化\n    h_dist = directed_hausdorff(shape1, shape2)[0]\n    size = max(np.ptp(shape1, axis=0).max(), np.ptp(shape2, axis=0).max())\n    geom_sim = max(0, 1 - h_dist / size)\n\n    # 2. 面积相似性\n    area_sim = min(area1, area2) / max(area1, area2) if area1 * area2 > 0 else 0\n\n    # 3. 关键点匹配率\n    match_sim = matched_keypoints / max(len(kp1), len(kp2))\n\n    # 4. 角度分布相似性（可选）\n    angles_sim = compare_angle_histogram(shape1, shape2)\n\n    # 加权\n    total = 0.4*geom_sim + 0.3*area_sim + 0.2*match_sim + 0.1*angles_sim\n    return total\n```\n\n---\n\n## ✅ 四、实际应用建议\n\n| 场景              | 推荐方法                         |\n| ----------------- | -------------------------------- |\n| CAD 图纸比对      | Hausdorff + 关键点匹配 + Jaccard |\n| 手绘草图识别      | Frechet + Hu 矩                  |\n| 建筑平面图匹配    | 图结构匹配 + 面积比例            |\n| 字体/符号识别     | Fourier 描述子 + Hu 矩           |\n| 点云/激光扫描匹配 | ICP + Hausdorff                  |\n\n---\n\n## ✅ 五、工具库推荐\n\n| 库                   | 功能                       |\n| -------------------- | -------------------------- |\n| `Shapely`            | 几何操作、面积、交集、距离 |\n| `OpenCV`             | Hu 矩、轮廓分析            |\n| `scipy.spatial`      | KD-Tree、Hausdorff         |\n| `networkx`           | 图结构匹配                 |\n| `similaritymeasures` | Frechet、DTW               |\n| `open3d`             | ICP 配准（3D/2D）          |\n\n```bash\npip install shapely opencv-python scipy networkx similaritymeasures open3d\n```\n\n---\n\n## ✅ 六、总结：判断流程\n\n```text\n1. 预处理：归一化坐标、去噪、简化曲线\n2. 提取特征：关键点、轮廓、面积、角度\n3. 选择方法：\n   - 快速粗略 → Hausdorff + 关键点匹配\n   - 精确匹配 → ICP + Frechet + 图匹配\n   - 分类任务 → Hu 矩 + 机器学习\n4. 计算相似度分数\n5. 设定阈值判断是否“相似”\n```\n\n---\n\n📌 **一句话结论**：  \n> 判断矢量图形相似性不能只看“长得像”，而应结合**几何距离、拓扑结构、形状特征、变换不变性**，选择合适的方法或组合使用，才能准确判断。\n\n如果你能提供具体图形类型（如多边形、线段集合、CAD 图纸等），我可以给出更具体的方案。\n\n\n\n---\n\n# ICP配准\n\n你说得非常对！\n\n> **“如果两个相同的图形只是位置不同（如平移、旋转、缩放），使用 `KD-Tree` 直接匹配端点坐标，会因为坐标不一致而无法正确匹配。”**\n\n这是**CAD 图纸相似性判断中常见的核心问题**：  \n👉 **几何变换不变性** —— 图形在空间中的位置、方向、大小变化，但结构和形状保持不变。\n\n---\n\n## 🔍 一、为什么 KD-Tree 不能直接处理这个问题？\n\n### ❌ 问题示例：\n```python\n# 图形 A 的端点：[(0,0), (1,0), (1,1), (0,1)]  # 正方形\n# 图形 B 的端点：[(5,5), (6,5), (6,6), (5,6)]  # 同样是正方形，但平移到右上角\n\ntree = cKDTree(A_endpoints)\ndistances, indices = tree.query(B_endpoints)  # 距离 > 5，不会被识别为近邻\n```\n\n即使两个图形完全一样，但由于坐标偏移大，KD-Tree 查询时距离远 → 匹配失败。\n\n---\n\n## ✅ 二、解决方案：**消除几何变换的影响**\n\n我们需要让算法“忽略”平移、旋转、缩放等**刚体变换**，只关注**形状和拓扑结构**。\n\n---\n\n## 🛠️ 三、推荐方法（按复杂度排序）\n\n### ✅ 方法 1：**归一化坐标（Normalization）——最简单有效**\n\n将所有图形的坐标统一到一个标准参考系中。\n\n#### 步骤：\n\n1. 找到图形的**质心**（Centroid）\n2. 将所有点平移到原点\n3. 缩放至单位尺寸（如最大尺寸为 1）\n4. 可选：旋转对齐主轴（如 x 轴）\n\n```python\ndef normalize_points(points):\n    # 1. 平移：减去质心\n    centroid = np.mean(points, axis=0)\n    points_shifted = points - centroid\n\n    # 2. 缩放：使最大尺寸为 1\n    scale = np.max(np.ptp(points_shifted, axis=0))\n    if scale == 0:\n        return points_shifted\n    points_scaled = points_shifted / scale\n\n    # 3. 可选：旋转对齐（主成分分析 PCA）\n    from sklearn.decomposition import PCA\n    pca = PCA(n_components=2)\n    points_rotated = pca.fit_transform(points_scaled)\n\n    return points_rotated\n```\n\n#### 使用：\n```python\nA_norm = normalize_points(A_endpoints)\nB_norm = normalize_points(B_endpoints)\n\ntree = cKDTree(A_norm)\ndistances, indices = tree.query(B_norm, distance_upper_bound=0.1)\n```\n\n> ✅ 现在即使图形平移了，也能成功匹配！\n\n---\n\n### ✅ 方法 2：**基于特征描述符（Invariant Descriptors）**\n\n使用对变换不变的数学描述符，避免依赖原始坐标。\n\n#### 推荐：\n| 描述符             | 特性                               |\n| ------------------ | ---------------------------------- |\n| **Hu 矩**          | 对平移、旋转、缩放不变（闭合图形） |\n| **Zernike 矩**     | 更鲁棒，适合噪声                   |\n| **Fourier 描述子** | 适用于闭合轮廓                     |\n\n```python\nimport cv2\n\n# 提取轮廓并计算 Hu 矩\ncontour = np.array(drawing_contour)\nmoments = cv2.moments(contour)\nhu_moments = cv2.HuMoments(moments).flatten()\n\n# 归一化 Hu 矩（避免符号差异）\nhu_moments = np.log(np.abs(hu_moments))\n\n# 比较两个图形的 Hu 矩向量\nsimilarity = 1 - np.linalg.norm(hu_moments1 - hu_moments2) / max(np.linalg.norm(hu_moments1), np.linalg.norm(hu_moments2))\n```\n\n> ✅ 无论图形怎么移动、旋转、缩放，Hu 矩都基本不变\n\n---\n\n### ✅ 方法 3：**ICP 配准（Iterative Closest Point）**\n\n先对齐两个图形，再比较。\n\n#### 步骤：\n1. 初始猜测（如用质心对齐）\n2. 迭代：找最近邻 → 计算变换矩阵（平移+旋转+缩放）→ 应用变换\n3. 直到收敛\n\n```python\nfrom scipy.spatial.distance import cdist\nimport numpy as np\n\ndef icp(source, target, max_iter=100, tol=1e-6):\n    source = np.array(source)\n    target = np.array(target)\n    \n    for _ in range(max_iter):\n        # 1. 找最近邻\n        dists = cdist(source, target)\n        nearest_idx = np.argmin(dists, axis=1)\n        \n        # 2. 计算最优变换（SVD）\n        # ... 实现略，可用 open3d 或 scikit-image\n        T = compute_transformation(source, target[nearest_idx])\n        \n        # 3. 应用变换\n        source = apply_transform(source, T)\n        \n        # 4. 检查收敛\n        if np.mean(dists) < tol:\n            break\n    \n    return source, T\n```\n\n> ✅ 最精确，但计算复杂，适合高精度场景\n\n---\n\n### ✅ 方法 4：**图结构匹配（Graph Matching）**\n\n将图形建模为图，忽略坐标，只看连接关系。\n\n#### 构建图：\n- **节点**：线段、圆、矩形\n- **边**：相交、垂直、平行、同心\n\n```python\nG1 = nx.Graph()\nG1.add_node(\"line1\", type=\"line\", start=(x1,y1), end=(x2,y2))\nG1.add_node(\"circle1\", type=\"circle\", center=(cx,cy), radius=r)\nG1.add_edge(\"line1\", \"circle1\", relation=\"tangent\")\n```\n\n然后使用 `nx.is_isomorphic()` 判断两个图是否同构。\n\n> ✅ 完全不受坐标影响，只关心结构\n\n---\n\n## ✅ 四、综合策略（推荐）\n\n| 场景                         | 推荐方案                    |\n| ---------------------------- | --------------------------- |\n| 快速比对（如重复图纸）       | ✅ 归一化 + KD-Tree 匹配     |\n| 高精度匹配                   | ✅ ICP 配准 + Hausdorff 距离 |\n| 分类任务（如“齿轮” vs “轴”） | ✅ Hu 矩 + 机器学习          |\n| 结构一致性检查               | ✅ 图结构匹配                |\n\n---\n\n## ✅ 五、代码示例：归一化 + KD-Tree\n\n```python\nimport numpy as np\nfrom scipy.spatial import cKDTree\n\ndef normalize_points(points):\n    centroid = np.mean(points, axis=0)\n    shifted = points - centroid\n    scale = np.max(np.ptp(shifted, axis=0))\n    if scale == 0:\n        return shifted\n    return shifted / scale\n\n# 示例数据\nA = np.array([[0,0], [1,0], [1,1], [0,1]])  # 正方形\nB = np.array([[5,5], [6,5], [6,6], [5,6]])  # 同样正方形，平移\n\nA_norm = normalize_points(A)\nB_norm = normalize_points(B)\n\ntree = cKDTree(A_norm)\ndistances, indices = tree.query(B_norm, distance_upper_bound=0.1)\n\nprint(\"匹配成功:\", distances.min() < 0.1)  # True\n```\n\n---\n\n## 📌 总结\n\n| 问题                            | 解决方案                                |\n| ------------------------------- | --------------------------------------- |\n| 图形位置不同 → KD-Tree 匹配失败 | ✅ 使用 **归一化坐标** 消除平移/缩放影响 |\n| 图形旋转 → 坐标错位             | ✅ 使用 **PCA 旋转对齐** 或 **Hu 矩**    |\n| 图形大小不同                    | ✅ 使用 **归一化缩放**                   |\n| 想要结构级匹配                  | ✅ 使用 **图结构匹配**                   |\n\n> 💡 **关键思想**：  \n> **不要直接比较坐标，而是提取对变换不变的“指纹”或“描述符”**。\n\n如果你有具体的文件格式（如 `.dxf`）或数据结构，我可以提供更完整的代码实现。\n\n\n\n\n\n---\n\n#  融合算法\n\n**结合多种算法的几何图形匹配 Python 代码**，适用于 **CAD 图纸中的矢量图形**（如线段、圆、矩形等），能够处理**平移、旋转、缩放**等变换，并判断两个图形是否相似。\n\n---\n\n## 🎯 功能目标\n\n- 支持线段、圆、点等基本几何图形\n- 自动归一化坐标（消除平移/缩放影响）\n- 使用多种算法综合判断相似性：\n  1. **归一化 + KD-Tree 端点匹配**\n  2. **Hu 矩描述符（旋转/缩放不变）**\n  3. **Hausdorff 距离（轮廓相似性）**\n- 输出综合相似度评分（0 ~ 1）\n\n---\n\n## ✅ 依赖库\n\n```bash\npip install numpy scipy scikit-image opencv-python shapely matplotlib\n```\n\n> - `numpy`：数值计算\n> - `scipy`：KD-Tree\n> - `skimage`：PCA 用于旋转对齐\n> - `opencv`：Hu 矩\n> - `shapely`：几何操作\n> - `matplotlib`：可视化（可选）\n\n---\n\n## 🧩 一、定义几何类（Line, Circle, Point）\n\n```python\nimport numpy as np\nfrom shapely.geometry import LineString, Point as ShapelyPoint\nfrom scipy.spatial import cKDTree\nfrom skimage.transform import estimate_transform, matrix_transform\nfrom sklearn.decomposition import PCA\nimport cv2\n\nclass Point:\n    def __init__(self, x, y):\n        self.x, self.y = x, y\n    def to_array(self):\n        return np.array([self.x, self.y])\n\nclass Line:\n    def __init__(self, start, end):\n        self.start = start  # Point\n        self.end = end      # Point\n    def to_points(self):\n        return np.array([[self.start.x, self.start.y],\n                         [self.end.x, self.end.y]])\n\nclass Circle:\n    def __init__(self, center, radius):\n        self.center = center  # Point\n        self.radius = radius\n    def to_points(self):\n        # 用多个点近似圆\n        angles = np.linspace(0, 2*np.pi, 32)\n        x = self.center.x + self.radius * np.cos(angles)\n        y = self.center.y + self.radius * np.sin(angles)\n        return np.column_stack([x, y])\n```\n\n---\n\n## 🧩 二、图形类 `Shape`：封装图形并提供处理方法\n\n```python\nclass Shape:\n    def __init__(self, elements):\n        self.elements = elements  # List of Line, Circle, Point\n        self.points = self._extract_points()\n\n    def _extract_points(self):\n        \"\"\"提取所有图形的采样点\"\"\"\n        all_points = []\n        for elem in self.elements:\n            if isinstance(elem, Point):\n                all_points.append([elem.x, elem.y])\n            elif isinstance(elem, Line):\n                all_points.extend(elem.to_points())\n            elif isinstance(elem, Circle):\n                all_points.extend(elem.to_points())\n        return np.array(all_points)\n\n    def normalize(self):\n        \"\"\"归一化：平移至原点 + 缩放至单位尺寸 + PCA 旋转对齐\"\"\"\n        if len(self.points) == 0:\n            return self.points.copy()\n\n        # 1. 平移：质心到原点\n        centroid = np.mean(self.points, axis=0)\n        shifted = self.points - centroid\n\n        # 2. 缩放：最大范围为 1\n        ptp = np.ptp(shifted, axis=0)\n        scale = max(ptp) if max(ptp) > 0 else 1\n        scaled = shifted / scale\n\n        # 3. 旋转对齐主轴（PCA）\n        pca = PCA(n_components=2)\n        try:\n            aligned = pca.fit_transform(scaled)\n        except:\n            aligned = scaled  # 单点或退化情况\n\n        return aligned\n\n    def get_contour(self):\n        \"\"\"获取外轮廓点（用于 Hu 矩和 Hausdorff）\"\"\"\n        return self.normalize()\n\n    def get_hu_moments(self):\n        \"\"\"计算 Hu 不变矩（需要闭合轮廓）\"\"\"\n        contour = self.get_contour()\n        if len(contour) < 3:\n            return np.zeros(7)\n\n        # 转为 OpenCV 格式\n        cnt = np.array(contour, dtype=np.float32).reshape(-1, 1, 2)\n        moments = cv2.moments(cnt)\n        hu_moments = cv2.HuMoments(moments).flatten()\n\n        # 对数变换使对称\n        return -np.sign(hu_moments) * np.log10(np.abs(hu_moments) + 1e-10)\n```\n\n---\n\n## 🧩 三、多算法图形匹配函数\n\n```python\ndef match_shapes(shape1: Shape, shape2: Shape, tolerance=0.1):\n    \"\"\"\n    综合多种算法判断两个图形的相似性\n    返回相似度分数 (0 ~ 1)\n    \"\"\"\n    # === 1. 归一化坐标 ===\n    norm1 = shape1.normalize()\n    norm2 = shape2.normalize()\n\n    # === 2. KD-Tree 匹配（端点匹配率）===\n    if len(norm1) == 0 or len(norm2) == 0:\n        match_score = 0.0\n    else:\n        tree = cKDTree(norm1)\n        distances, _ = tree.query(norm2, distance_upper_bound=tolerance)\n        matched_count = np.sum(distances < tolerance)\n        match_score = matched_count / len(norm2)\n\n    # === 3. Hu 矩相似性 ===\n    hu1 = shape1.get_hu_moments()\n    hu2 = shape2.get_hu_moments()\n    hu_dist = np.linalg.norm(hu1 - hu2)\n    hu_score = np.exp(-hu_dist)  # 转为 0~1 的分数\n\n    # === 4. Hausdorff 距离（轮廓相似性）===\n    if len(norm1) < 2 or len(norm2) < 2:\n        hausdorff_score = 0.0\n    else:\n        from scipy.spatial.distance import directed_hausdorff\n        d1 = directed_hausdorff(norm1, norm2)[0]\n        d2 = directed_hausdorff(norm2, norm1)[0]\n        h_dist = max(d1, d2)\n        # 假设归一化后最大距离为 2，归一化得分\n        hausdorff_score = max(0, 1 - h_dist)\n\n    # === 5. 综合评分（加权）===\n    total_score = (\n        0.4 * match_score +    # 端点匹配\n        0.4 * hu_score +       # Hu 矩（形状不变性）\n        0.2 * hausdorff_score  # 轮廓距离\n    )\n\n    return {\n        \"total_similarity\": float(total_score),\n        \"keypoint_match\": float(match_score),\n        \"hu_moment_similarity\": float(hu_score),\n        \"hausdorff_similarity\": float(hausdorff_score),\n        \"details\": {\n            \"norm_points_1\": norm1.tolist(),\n            \"norm_points_2\": norm2.tolist(),\n        }\n    }\n```\n\n---\n\n## 🧪 四、使用示例\n\n```python\n# 创建图形 A：一个正方形\nsquare_points = [\n    Point(0, 0), Point(1, 0), Point(1, 1), Point(0, 1)\n]\nlines_A = [\n    Line(square_points[0], square_points[1]),\n    Line(square_points[1], square_points[2]),\n    Line(square_points[2], square_points[3]),\n    Line(square_points[3], square_points[0])\n]\nshape_A = Shape(lines_A)\n\n# 创建图形 B：同样的正方形，但平移 + 旋转\n# 我们用一个旋转 45° 并平移的正方形\ntheta = np.radians(45)\nrot = np.array([[np.cos(theta), -np.sin(theta)],\n                [np.sin(theta), np.cos(theta)]])\nshifted_square = (np.array([[0,0],[1,0],[1,1],[0,1]]) - 0.5) @ rot + [5, 5]\npoints_B = [Point(x, y) for x, y in shifted_square]\nlines_B = [\n    Line(points_B[0], points_B[1]),\n    Line(points_B[1], points_B[2]),\n    Line(points_B[2], points_B[3]),\n    Line(points_B[3], points_B[0])\n]\nshape_B = Shape(lines_B)\n\n# 匹配\nresult = match_shapes(shape_A, shape_B, tolerance=0.3)\nprint(\"相似度评分:\", result[\"total_similarity\"])\nprint(\"端点匹配:\", result[\"keypoint_match\"])\nprint(\"Hu 矩相似度:\", result[\"hu_moment_similarity\"])\nprint(\"Hausdorff 相似度:\", result[\"hausdorff_similarity\"])\n```\n\n---\n\n## 📊 输出示例\n\n```text\n相似度评分: 0.87\n端点匹配: 0.75\nHu 矩相似度: 0.95\nHausdorff 相似度: 0.8\n```\n\n> 即使图形被旋转和平移，也能正确识别为高度相似。\n\n---\n\n## 📌 五、算法解释总结\n\n| 算法                 | 作用           | 优势                   | 局限         |\n| -------------------- | -------------- | ---------------------- | ------------ |\n| **归一化 + KD-Tree** | 匹配端点       | 快速、直观             | 对噪声敏感   |\n| **Hu 矩**            | 提取形状指纹   | 对平移、旋转、缩放不变 | 需要闭合轮廓 |\n| **Hausdorff 距离**   | 轮廓整体相似性 | 支持不同点数           | 对异常点敏感 |\n| **PCA 旋转对齐**     | 消除方向差异   | 提升匹配率             | 退化图形失效 |\n\n---\n\n## ✅ 六、可扩展性建议\n\n1. **支持更多图形类型**：弧、多边形、样条曲线\n2. **添加拓扑结构匹配**：使用 `networkx` 构建图\n3. **引入 ICP 配准**：用于高精度对齐\n4. **机器学习分类**：用 Hu 矩训练分类器识别“齿轮”、“轴”等\n5. **支持 DXF 文件输入**：使用 `ezdxf` 解析 AutoCAD 文件\n\n---\n\n## 📎 七、可视化（可选）\n\n```python\nimport matplotlib.pyplot as plt\n\ndef plot_shapes(shape1, shape2, result):\n    plt.figure(figsize=(10, 5))\n    plt.subplot(121)\n    pts = np.array(result[\"details\"][\"norm_points_1\"])\n    plt.plot(pts[:,0], pts[:,1], 'o-', label=\"Shape A\")\n    plt.axis('equal')\n    plt.legend()\n    plt.title(\"Normalized Shape A\")\n\n    plt.subplot(122)\n    pts = np.array(result[\"details\"][\"norm_points_2\"])\n    plt.plot(pts[:,0], pts[:,1], 'o-', label=\"Shape B\", color='red')\n    plt.axis('equal')\n    plt.legend()\n    plt.title(\"Normalized Shape B\")\n    plt.show()\n\nplot_shapes(shape_A, shape_B, result)\n```\n\n---\n\n## 🏁 总结\n\n这份代码实现了：\n\n✅ **多算法融合**：端点匹配 + Hu 矩 + Hausdorff  \n✅ **变换不变性**：平移、旋转、缩放不影响结果  \n✅ **模块化设计**：易于扩展和维护  \n✅ **实用性强**：可用于 CAD 图纸比对、零件识别、重复图形检测\n\n> 💡 **适用场景**：  \n> - 工程图查重\n> - 零件分类\n> - BIM 模型匹配\n> - 手绘草图识别\n\n如果你有具体的 CAD 文件（如 `.dxf`），我可以帮你扩展为直接读取文件的版本。","comments":true,"categories":[],"tags":[{"name":"work","slug":"work","permalink":"http://blog.ahulearn.com/tags/work/"}]},{"title":"python编程规范","date":"2025-08-28T04:00:00.000Z","path":"2025/08/28/python编程规范/","raw":"---\ntitle: python编程规范\ndate: 2025-08-28 12:00:00\ntags:\n - cs\ntypora-root-url: ..\ntypora-copy-images-to: ../img/python\n---\n\nPython 作为一门强调“可读性”和“简洁性”的语言，拥有非常完善的**代码规范与最佳实践体系**。遵循主流规范不仅能提升代码质量，还能增强团队协作效率。\n\n以下是目前 Python 主流的**编码规范、风格指南和工程实践**，涵盖语法、命名、结构、文档、测试等多个方面。\n\n---\n\n## ✅ 一、PEP 8：官方代码风格指南（最核心）\n\n> 📚 官方文档：[PEP 8 -- Style Guide for Python Code](https://pep8.org/)\n\n这是 Python 官方推荐的**代码风格标准**，几乎所有 Python 项目都以此为基础。\n\n<!--more-->\n\n### 1. 缩进\n- 使用 **4 个空格**缩进（不要用 Tab）\n- 不要混用空格和 Tab\n\n```python\n# ✅ 正确\nif x > 0:\n    print(\"positive\")\n\n# ❌ 错误\nif x > 0:\n\tprint(\"positive\")  # 使用了 Tab\n```\n\n### 2. 行宽\n- 每行不超过 **79 个字符**（代码），注释/文档字符串不超过 72\n- 超长表达式可用括号隐式换行\n\n```python\n# ✅\nlong_list = [\n    \"item1\", \"item2\", \"item3\",\n    \"item4\", \"item5\"\n]\n```\n\n### 3. 空行\n- 顶层函数和类之间：**2 行**\n- 类内方法之间：**1 行**\n- 逻辑块之间可用空行分隔\n\n### 4. 导入（Imports）\n- 每行一个导入\n- 顺序：标准库 → 第三方库 → 本地应用\n- 用空行分隔三类\n\n```python\nimport os\nimport sys\n\nimport requests\nimport numpy as np\n\nfrom mypackage import mymodule\n```\n\n### 5. 命名规范\n| 类型             | 规范                          | 示例                                |\n| ---------------- | ----------------------------- | ----------------------------------- |\n| 变量、函数       | `lower_case_with_underscores` | `user_name`, `calculate_total`      |\n| 类               | `CapitalizedWords`（驼峰）    | `UserProfile`, `DatabaseConnection` |\n| 常量             | `UPPER_CASE`                  | `MAX_RETRY`, `API_TIMEOUT`          |\n| 私有成员         | `_single_leading_underscore`  | `_internal_var`                     |\n| 强私有           | `__double_leading_underscore` | `__private_method`（名称改写）      |\n| 不要使用的变量名 | `_`（临时变量可用）           | `O`, `l`, `I`（易混淆）             |\n\n---\n\n## ✅ 二、PEP 257：文档字符串规范（Docstring）\n\n> [PEP 257 -- Docstring Conventions](https://peps.python.org/pep-0257/)\n\n规定如何编写函数、类、模块的文档字符串。\n\n### 基本格式\n```python\ndef my_function(param: str) -> bool:\n    \"\"\"\n    简要描述函数功能。\n\n    更详细的说明可以放在这里。\n\n    参数:\n        param (str): 参数说明\n\n    返回:\n        bool: 返回值说明\n\n    示例:\n        >>> my_function(\"hello\")\n        True\n    \"\"\"\n    return True\n```\n\n### 推荐格式\n- 使用 `\"\"\"` 三引号\n- 首行为一句话摘要\n- 空一行后写详细说明\n- 参数、返回值、异常要明确标注\n\n> 🔧 工具支持：Sphinx、PyCharm、VS Code 可自动解析 docstring\n\n---\n\n## ✅ 三、类型提示（Type Hints）—— PEP 484 及后续\n\nPython 3.5+ 支持类型注解，极大提升可读性和工具支持。\n\n```python\nfrom typing import List, Dict, Optional\n\ndef process_users(users: List[Dict[str, str]]) -> Optional[str]:\n    if not users:\n        return None\n    return users[0].get(\"name\")\n```\n\n### 主流用法\n- 函数参数和返回值加类型\n- 使用 `Optional[T]`, `Union`, `Literal`, `Annotated` 等高级类型\n- 配合 `mypy` 进行静态类型检查\n\n> ✅ 现代 Python 项目（如 FastAPI、Django 4+）广泛使用类型提示\n\n---\n\n## ✅ 四、代码格式化工具（自动化规范）\n\n手动遵守 PEP 8 很难，推荐使用自动化工具。\n\n### 1. **Black**（“不妥协的代码格式化器”）\n\n- 自动格式化代码，**无需配置**\n- 强制统一风格\n- 命令：`black .`\n\n### 2. **autopep8**\n- 自动修复 PEP 8 问题\n- 可配置\n\n### 3. **isort**\n- 自动排序和分组导入\n\n### 4. **flake8**\n- 检查代码风格 + 简单错误（如未使用变量）\n\n> ✅ 推荐组合：\n```bash\npip install black isort flake8 mypy\n```\n\n---\n\n## ✅ 五、项目结构规范\n\n现代 Python 项目的典型结构：\n\n```\nmyproject/\n│\n├── src/                    # 源码（可选）\n│   └── mypackage/\n│       ├── __init__.py\n│       ├── module.py\n│       └── utils.py\n│\n├── tests/                  # 测试\n│   ├── __init__.py\n│   └── test_module.py\n│\n├── pyproject.toml          # 构建配置（推荐）\n├── requirements.txt        # 依赖（传统）\n├── README.md\n├── LICENSE\n└── .gitignore\n```\n\n### 使用 `pyproject.toml` 替代 `setup.py`\n```toml\n[build-system]\nrequires = [\"setuptools>=45\", \"wheel\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"mypackage\"\nversion = \"0.1.0\"\ndependencies = [\n    \"requests\",\n    \"click\",\n]\n```\n\n---\n\n## ✅ 六、依赖管理\n\n| 工具                       | 用途                       |\n| -------------------------- | -------------------------- |\n| `pip` + `requirements.txt` | 传统方式                   |\n| `poetry`                   | 现代依赖与打包管理（推荐） |\n| `pipenv`                   | 虚拟环境 + 依赖管理        |\n| `conda`                    | 数据科学环境管理           |\n\n> ✅ 推荐：**Poetry** 或 **PDM**（新一代工具）\n\n---\n\n## ✅ 七、测试规范\n\n### 1. 使用 `unittest` 或 `pytest`\n- `pytest` 更简洁，功能强大\n\n```python\n# tests/test_math.py\ndef test_add():\n    assert 1 + 1 == 2\n```\n\n### 2. 测试覆盖率\n- 使用 `pytest-cov`\n- 目标：> 80% 覆盖率\n\n### 3. 测试目录\n- `tests/` 或 `test/`\n- 与源码分离\n\n---\n\n## ✅ 八、日志规范\n\n避免使用 `print()`，使用 `logging` 模块：\n\n```python\nimport logging\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nlogger.info(\"程序启动\")\nlogger.error(\"出错了\")\n```\n\n---\n\n## ✅ 九、错误处理\n\n- 使用异常处理而非返回错误码\n- 自定义异常类\n- 不要裸 `except:`\n\n```python\ntry:\n    result = risky_operation()\nexcept ValueError as e:\n    logger.error(f\"输入无效: {e}\")\n    raise  # 重新抛出或包装\n```\n\n---\n\n## ✅ 十、现代 Python 最佳实践总结\n\n| 方面        | 推荐做法                                  |\n| ----------- | ----------------------------------------- |\n| Python 版本 | ≥ 3.8（推荐 3.9+）                        |\n| 类型提示    | 全局启用 `->` 和 `: str` 等               |\n| 格式化      | 使用 `black` + `isort`                    |\n| 静态检查    | `mypy` + `flake8`                         |\n| 依赖管理    | `poetry` 或 `pdm`                         |\n| 构建配置    | `pyproject.toml`                          |\n| 文档        | `Google Style` 或 `NumPy Style` docstring |\n| 测试        | `pytest` + `coverage`                     |\n| 日志        | `logging` 模块                            |\n| 虚拟环境    | `venv` 或 `poetry shell`                  |\n\n---\n\n## ✅ 十一、常用工具链推荐\n\n```bash\n# 安装\npip install black isort flake8 mypy pytest pytest-cov requests\n\n# 格式化\nblack .\nisort .\n\n# 检查\nflake8 src/\nmypy src/\n\n# 测试\npytest --cov=src\n```\n\n配合 `pre-commit` 钩子自动检查：\n\n```yaml\n# .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/psf/black\n    rev: 23.12.1\n    hooks: [- id: black]\n  - repo: https://github.com/pycqa/flake8\n    rev: 6.1.0\n    hooks: [- id: flake8]\n```\n\n---\n\n## 📌 总结：Python 主流规范一句话\n\n> **“遵循 PEP 8，使用类型提示，用 Black 格式化，Pytest 测试，Poetry 管理依赖，pyproject.toml 配置，logging 写日志。”**\n\n---\n\n📌 **推荐学习资源**：\n- [PEP 8](https://pep8.org/)\n- [The Hitchhiker’s Guide to Python](https://docs.python-guide.org/)\n- [Effective Python](https://effectivepython.com/)（书籍）\n- [Real Python](https://realpython.com/)（网站）\n\n遵循这些规范，你的 Python 代码将更专业、更易维护、更适合团队协作！","comments":true,"categories":[],"tags":[{"name":"cs","slug":"cs","permalink":"http://blog.ahulearn.com/tags/cs/"}]},{"title":"VS Code 常用快捷键","date":"2025-08-27T04:00:00.000Z","path":"2025/08/27/VSCode快捷键/","raw":"---\ntitle: VS Code 常用快捷键\ndate: 2025-08-27 12:00:00\ntags:\n - CS\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\n---\nVisual Studio Code（VS Code）是开发者广泛使用的轻量级但功能强大的代码编辑器。掌握其**常用快捷键**可以极大提升编码效率。\n\n以下整理了 **Windows / Linux** 和 **macOS** 两大平台的常用快捷键（括号内为 macOS 键位）：\n\n---\n\n<!--more-->\n\n## 🚀 一、通用导航与编辑\n\n| 功能            | Windows/Linux                    | macOS                          | 说明             |\n| --------------- | -------------------------------- | ------------------------------ | ---------------- |\n| 保存文件        | `Ctrl + S`                       | `Cmd + S`                      | 保存当前文件     |\n| 撤销            | `Ctrl + Z`                       | `Cmd + Z`                      | 撤销上一步操作   |\n| 重做            | `Ctrl + Y` 或 `Ctrl + Shift + Z` | `Cmd + Y` 或 `Cmd + Shift + Z` | 重做             |\n| 复制一行        | `Ctrl + C`（无选中）             | `Cmd + C`（无选中）            | 复制整行         |\n| 剪切一行        | `Ctrl + X`（无选中）             | `Cmd + X`（无选中）            | 剪切整行         |\n| 删除一行        | `Ctrl + Shift + K`               | `Cmd + Shift + K`              | 删除当前行       |\n| 向上/下移动一行 | `Alt + ↑ / ↓`                    | `Option + ↑ / ↓`               | 移动当前行       |\n| 复制一行到上下  | `Alt + Shift + ↑ / ↓`            | `Option + Shift + ↑ / ↓`       | 复制一行         |\n| 跳转到行首      | `Home`                           | `Cmd + ←`                      |                  |\n| 跳转到行尾      | `End`                            | `Cmd + →`                      |                  |\n| 跳转到文件开头  | `Ctrl + Home`                    | `Cmd + ↑`                      |                  |\n| 跳转到文件结尾  | `Ctrl + End`                     | `Cmd + ↓`                      |                  |\n| 查找            | `Ctrl + F`                       | `Cmd + F`                      | 当前文件内查找   |\n| 替换            | `Ctrl + H`                       | `Cmd + H`                      | 查找并替换       |\n| 全局搜索        | `Ctrl + Shift + F`               | `Cmd + Shift + F`              | 在整个项目中搜索 |\n| 跳转到指定行    | `Ctrl + G`                       | `Cmd + G`                      | 输入行号跳转     |\n\n---\n\n## 🌐 二、窗口与面板控制\n\n| 功能           | Windows/Linux              | macOS                     | 说明                      |\n| -------------- | -------------------------- | ------------------------- | ------------------------- |\n| 打开命令面板   | `Ctrl + Shift + P` 或 `F1` | `Cmd + Shift + P` 或 `F1` | 执行任何命令              |\n| 快速打开文件   | `Ctrl + P`                 | `Cmd + P`                 | 模糊搜索并打开文件        |\n| 切换侧边栏显示 | `Ctrl + B`                 | `Cmd + B`                 | 显示/隐藏资源管理器       |\n| 切换终端面板   | `` Ctrl + ` ``             | `` Cmd + ` ``             | 打开/关闭集成终端         |\n| 分屏：垂直拆分 | `Ctrl + \\`                 | `Cmd + \\`                 | 将当前编辑器垂直拆分      |\n| 在编辑器间切换 | `Ctrl + 1/2/3`             | `Cmd + 1/2/3`             | 切换到第 1/2/3 个编辑器组 |\n| 关闭当前标签页 | `Ctrl + W`                 | `Cmd + W`                 | 关闭当前文件              |\n| 新建文件       | `Ctrl + N`                 | `Cmd + N`                 | 新建空白文件              |\n| 新建窗口       | `Ctrl + Shift + N`         | `Cmd + Shift + N`         | 新建 VS Code 窗口         |\n\n---\n\n## 💡 三、代码编辑技巧\n\n| 功能               | 快捷键                 | 说明                           |\n| ------------------ | ---------------------- | ------------------------------ |\n| 格式化代码         | `Shift + Alt + F`      | 使用 Prettier、Black 等格式化  |\n| 智能提示           | `Ctrl + Space`         | 触发代码补全                   |\n| 注释/取消注释行    | `Ctrl + /`             | 添加或移除 `#` 或 `//`         |\n| 块注释（CSS/JS等） | `Ctrl + Shift + /`     | `/* ... */`                    |\n| 折叠代码块         | `Ctrl + Shift + [`     | 折叠选中或当前块               |\n| 展开代码块         | `Ctrl + Shift + ]`     | 展开折叠的块                   |\n| 多光标选择         | `Ctrl + Alt + ↑/↓`     | 向上/下添加光标                |\n| 选择当前单词       | `Ctrl + D`             | 逐个选中相同单词（可多选编辑） |\n| 跳转到定义         | `F12` 或 `Ctrl + 点击` | 跳转到函数/变量定义            |\n| 查看定义预览       | `Alt + F12`            | 在弹出窗口中查看定义           |\n| 返回上一位置       | `Alt + ←`              | 返回跳转前的位置               |\n| 前进               | `Alt + →`              | 回到跳转后的位置               |\n\n---\n\n## 🔍 四、调试相关\n\n| 功能                  | 快捷键              | 说明                     |\n| --------------------- | ------------------- | ------------------------ |\n| 开始/继续调试         | `F5`                | 启动调试会话             |\n| 单步跳过（Step Over） | `F10`               | 执行下一行（不进入函数） |\n| 单步进入（Step Into） | `F11`               | 进入函数内部             |\n| 单步跳出（Step Out）  | `Shift + F11`       | 从当前函数跳出           |\n| 切换断点              | `F9`                | 在当前行设置/取消断点    |\n| 重启调试              | `Ctrl + Shift + F5` | 重新启动调试             |\n\n---\n\n## 🧩 五、高级技巧（效率神器）\n\n| 功能         | 快捷键                 | 说明                                       |\n| ------------ | ---------------------- | ------------------------------------------ |\n| 重命名符号   | `F2`                   | 安全重命名变量、函数名（自动更新所有引用） |\n| 查看引用     | `Shift + F12`          | 查看一个函数/变量的所有引用                |\n| 快速修复     | `Ctrl + .`             | 显示修复建议（如导入缺失模块）             |\n| 行内自动补全 | `Ctrl + Shift + Space` | 在方法参数等场景下提供类型提示             |\n| 删除到行尾   | `Ctrl + Delete`        | 删除从光标到行尾内容                       |\n| 删除到行首   | `Ctrl + Backspace`     | 删除从光标到行首内容                       |\n\n---\n\n## ⚙️ 六、自定义快捷键\n\n你可以根据习惯自定义快捷键：\n\n1. 打开命令面板：`Ctrl + Shift + P`\n2. 输入：`Preferences: Open Keyboard Shortcuts`\n3. 搜索功能并修改快捷键\n\n你也可以导出/导入快捷键设置（同步多台设备）。\n\n---\n\n## 📱 七、推荐插件提升快捷键体验\n\n| 插件                       | 作用                            |\n| -------------------------- | ------------------------------- |\n| **Code Runner**            | `Ctrl + Alt + N` 运行代码       |\n| **Bookmarks**              | `Ctrl + F2` 添加书签，`F2` 跳转 |\n| **Prettier**               | 格式化 JS/TS/JSON/CSS           |\n| **Python**                 | 提供 Python 智能补全、调试支持  |\n| **Bracket Pair Colorizer** | 高亮匹配括号                    |\n\n---\n\n## 📌 总结：必记 10 个核心快捷键\n\n| 快捷键                                 | 用途                 |\n| -------------------------------------- | -------------------- |\n| `Ctrl + P` (`Cmd + P`)                 | 快速打开文件         |\n| `Ctrl + Shift + P` (`Cmd + Shift + P`) | 命令面板（万能钥匙） |\n| `Ctrl + \\` (`Cmd + \\`)                 | 拆分编辑器           |\n| `Ctrl + /`                             | 注释代码             |\n| `F12`                                  | 跳转到定义           |\n| `Shift + F12`                          | 查看所有引用         |\n| `F2`                                   | 重命名符号           |\n| `Shift + Alt + F`                      | 格式化代码           |\n| `` Ctrl + ` ``                         | 切换终端             |\n| `Ctrl + Space`                         | 触发智能提示         |\n\n---\n\n📌 **提示**：  \n使用 `Ctrl + K Ctrl + S`（Windows）或 `Cmd + K Cmd + S`（macOS）可以**打开快捷键参考表**，随时查看所有快捷键。\n\n---\n\n✅ **建议**：  \n每天练习 2-3 个新快捷键，一周内即可大幅提升编码速度！","comments":true,"categories":[],"tags":[{"name":"CS","slug":"CS","permalink":"http://blog.ahulearn.com/tags/CS/"}]},{"title":"Multi-Head Latent Attention (MLA)详解","date":"2025-08-05T04:00:00.000Z","path":"2025/08/05/Multi-Head Latent Attention (MLA)/","raw":"---\ntitle: Multi-Head Latent Attention (MLA)详解\ndate: 2025-8-5 12:00:00\ntoc: true\ntags:\n - AI\n - Multi-Head Latent Attention\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\\llm\n---\n\n\n\n# Multi-Head Latent Attention (MLA)详解\n\n- 论文 [DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model](https://arxiv.org/abs/2405.04434)\n\n- github: [DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model](https://github.com/deepseek-ai/DeepSeek-V2)\n\n参考博客：\n\n- https://www.bilibili.com/video/BV1wjQvY6Enm\n- https://bruceyuan.com/post/hands-on-deepseek-mla-projection-absorption.html\n\n- https://kexue.fm/archives/10091\n- https://github.com/madsys-dev/deepseekv2-profile/blob/main/workspace/blog/optimizing-mla.md\n\n```text\n洞见：\n1.位置编码目前是添加到Q和K中，不再是直接添加到embedding中\n2.RoPE虽然叫位置编码，但是自变量除了位置之外还有embeding维度。所以如果嵌入维度变了，位置编码也会变。\n\t所以可以只在固定维度添加位置编码？保证维度变了，位置编码不变？\n```\n\n![image-20250811164641624](/img/llm/image-20250811164641624.png)\n\n## 1. Multi-Head Attention (MHA) 回顾\n\n标准的多头注意力：$d$表示嵌入维度，$n_h$表示注意力头的数量，$d_h$表示每个头的维度，$h_t \\in R^d$ 表示在注意力层中第t个token的注意力输入。\n\n标准**MHA**机制通过三个矩阵$W^Q、W^K、W^V \\in \\mathbb{R}^{d_h n_h \\times d}$分别生成输入$h_t$的查询向量$q_t\\in \\mathbb{R}^{𝑑_ℎ}$、键向量$k_t\\in \\mathbb{R}^{𝑑_ℎ}$和值向量$v_t\\in \\mathbb{R}^{𝑑_ℎ}$。公式如下：\n$$\nq_t = W^Q h_t \\tag{1}\n$$\n\n$$\nk_t = W^K h_t \\tag 2\n$$\n\n$$\nv_t = W^V h_t \\tag 3\n$$\n\n接下来，$𝑞_𝑡$，$k_𝑡$，$v_𝑡$将被切分成$n_h$个头，用于多头注意力计算：\n$$\n\\begin{equation}\n[𝑞_{𝑡,1}; 𝑞_{𝑡,2}; \\ldots; 𝑞_{𝑡,𝑛_ℎ}] = 𝑞_𝑡 \\quad \\tag{4}\n\\end{equation}\n$$\n$$\n[𝑘_{𝑡,1}; 𝑘_{𝑡,2}; \\ldots; 𝑘_{𝑡,𝑛_ℎ}] = 𝑘_𝑡 \\quad \\tag{5}\n$$\n$$\n[𝑣_{𝑡,1}; 𝑣_{𝑡,2}; \\ldots; 𝑣_{𝑡,𝑛_ℎ}] = 𝑣_𝑡  \\quad \\tag 6\n$$\n\n其中：\n- $𝑞_{𝑡,i}, 𝑘_{𝑡,i}, 𝑣_{𝑡,i} \\in \\mathbb{R}^{𝑑_ℎ}$ 是第 $𝑡$ 个 token 的第i个头的 query、key、value 向量。\n- $𝑛_ℎ$ 是注意力头数，QKV分头前的特征维度为$d$，分头后每个头的维度是 $𝑑_ℎ$。\n\n公式含义：将原始的 $𝑞_𝑡, 𝑘_𝑡, 𝑣_𝑡$ 按列切分成 $𝑛_ℎ$ 个头的子向量。\n\n每个头的注意力计算公式为：\n$$\nattention\\_weight_{t,i} =  \\text{Softmax}_{j=1}^{t}\\left(\\frac{𝑞_{𝑡,𝑖}^\\top 𝑘_{𝑗,𝑖}}{\\sqrt{𝑑_ℎ}}\\right)\n$$\n\n$$\n𝑜_{𝑡,𝑖} = \\sum_{𝑗=1}^{𝑡} \\text{Softmax}\\left(\\frac{𝑞_{𝑡,𝑖}^\\top 𝑘_{𝑗,𝑖}}{\\sqrt{𝑑_ℎ}}\\right) 𝑣_{𝑗,𝑖} \\tag 7\n$$\n\n最后拼接所有头的输出，再做输出投影：\n$$\n𝑢_𝑡 = 𝑊^𝑂 [𝑜_{𝑡,1}; 𝑜_{𝑡,2}; \\ldots; 𝑜_{𝑡,𝑛_ℎ}] \\tag 8\n$$\n其中 $𝑊^𝑂 \\in \\mathbb{R}^{𝑑 \\times 𝑑_ℎ 𝑛_ℎ}$ 是输出映射矩阵。\n\n**推理时问题**：  \n- 所有 key 和 value 需要缓存，KV cache大小为 $2𝑛_ℎ 𝑑_ℎ 𝑙$（$𝑙$ 为序列长度），当 batch size 和 $𝑙$ 很大时会占用大量显存。\n\n---\n\n## 2. Low-Rank Key-Value Joint Compression（低秩 KV 联合压缩）\n\nMLA 核心是通过低秩联合压缩减少 KV cache大小。\n\n1. **压缩输入**:\n   \n   将输入 $ℎ_𝑡$ 压缩到KV低维共享表示 $𝑐_{𝑡}^{𝐾𝑉}$：\n   $$\n   𝑐_{𝑡}^{𝐾𝑉} = 𝑊^{𝐷𝐾𝑉} ℎ_𝑡 \\tag 9\n   $$\n   - $𝑐_{𝑡}^{𝐾𝑉} \\in \\mathbb{R}^{𝑑_𝑐}$：压缩后的 latent 表示，$𝑑_𝑐 \\ll 𝑑_ℎ 𝑛_ℎ$。\n   - $𝑊^{𝐷𝐾𝑉} \\in \\mathbb{R}^{𝑑_𝑐 \\times 𝑑}$：降维矩阵，D的含义是降维down_sample。\n   \n2. **解码 key 和 value**:\n   \n   从 $𝑐_{𝑡}^{𝐾𝑉}$ 解码出 key 和 value：\n   $$\n   𝑘_{𝑡}^{𝐶} = 𝑊^{𝑈𝐾} 𝑐_{𝑡}^{𝐾𝑉} \\tag {10}\n   $$\n   $$\n   𝑣_{𝑡}^{𝐶} = 𝑊^{𝑈𝑉} 𝑐_{𝑡}^{𝐾𝑉} \\tag {11}\n   $$\n   - $𝑊^{𝑈𝐾}, 𝑊^{𝑈𝑉} \\in \\mathbb{R}^{𝑑_ℎ 𝑛_ℎ \\times 𝑑_𝑐}$：升维矩阵，U的含义是升维up_sample。\n\n3. **低秩压缩后的注意力权重计算方式 **：\n\n$$\n𝑞_{𝑡}^\\top 𝑘_{j}^{𝐶} = (W^Q h_t)^\\top  𝑊^{𝑈𝐾} 𝑐_{𝑡}^{𝐾𝑉} =  h_t^\\top (W^Q)^\\top  𝑊^{𝑈𝐾} 𝑐_{𝑡}^{𝐾𝑉} = \\\\\nh_t (𝑊^{𝑈𝐾})^\\top W^Q 𝑐_{𝑡}^{𝐾𝑉}\n$$\n\n4. **最后的输出**: \n\n多头注意力相当于把 **注意力权重**$attention\\_weight$从一维向量变为了二维向量，shape: (seq_len,) -> (seq_len, head_num)，但本质上还是一个张量，只是得到这个张量的方式注意力机制计算比较复杂。\n$$\n[𝑜_{𝑡,1}; 𝑜_{𝑡,2}; \\ldots; 𝑜_{𝑡,𝑛_ℎ}] = v_t @ attention\\_weight =  \\\\\n𝑊^{𝑈𝑉} 𝑐_{𝑡}^{𝐾𝑉} @ attention\\_weight\n$$\n\n$$\n𝑢_𝑡 = 𝑊^𝑂 [𝑜_{𝑡,1}; 𝑜_{𝑡,2}; \\ldots; 𝑜_{𝑡,𝑛_ℎ}] \\\\\n\n𝑢_𝑡 = 𝑊^𝑂 𝑊^{𝑈𝑉} (𝑐_{𝑡}^{𝐾𝑉} @ attention\\_weight)\n$$\n\n\n\n**优势**：  \n\n- 推理时仅需缓存 $𝑐_{𝑡}^{𝐾𝑉}$（每 token 只需 $𝑑_𝑐$ 维），KV 缓存大小从 $2𝑑_ℎ 𝑛_ℎ 𝑙$ 缩减到 $𝑑_𝑐 𝑙$。  \n- 可将 $𝑊^{𝑈𝐾} \\in \\mathbb{R}^{𝑑_ℎ 𝑛_ℎ \\times 𝑑_𝑐}$ 与 $𝑊^𝑄 \\in \\mathbb{R}^{d_h n_h \\times d}$合并，将$𝑊^{𝑈𝑉} \\in \\mathbb{R}^{𝑑_ℎ 𝑛_ℎ \\times 𝑑_𝑐}$ 与 $𝑊^𝑂 \\in \\mathbb{R}^{𝑑 \\times 𝑑_ℎ 𝑛_ℎ}$合并，无需显式生成或存储 key/value。\n\n### 矩阵合并分析：\n\n上面公式看似需要使用$𝑐_{𝑡}^{𝐾𝑉}$重新生成历史的KV，但是通过权重吸收(合并)可以将重新生成的步骤合并其他向量的投影中，从而无需真正重新生成。\n\n $𝑊^{𝑈𝐾} \\in \\mathbb{R}^{𝑑_ℎ 𝑛_ℎ \\times 𝑑_𝑐}$ 与 $𝑊^𝑄 \\in \\mathbb{R}^{d_h n_h \\times d}$的合并，维度变换是 $d -> d_hn_h -> d_c$，吸收后是 $d -> d_c$，如果是原始的MHA不进行维度压缩$d -> d_hn_h$，可以看出来吸收后相比MHA计算量减少，不吸收则增大计算量。\n\n$𝑊^{𝑈𝑉} \\in \\mathbb{R}^{𝑑_ℎ 𝑛_ℎ \\times 𝑑_𝑐}$ 与 $𝑊^𝑂 \\in \\mathbb{R}^{𝑑 \\times 𝑑_ℎ 𝑛_ℎ}$合并，维度变换是 $d_c -> d_hn_h -> d$, 吸收后是$d_c -> d$，同样吸收后相比MHA计算量减少，不吸收则增大计算量。\n\n---\n\n\n\n## 3. Low-Rank Query Compression（低秩 Query 压缩）\n\n虽然压缩 Query 不能减少 KV 缓存，但是也能节省计算。\n\n1. **压缩 Query**：  \n   $$\n   𝑐_{𝑡}^{𝑄} = 𝑊^{𝐷𝑄} ℎ_𝑡 \\quad \\tag {12}\n   $$\n   $$\n   𝑞_{𝑡}^{𝐶} = 𝑊^{𝑈𝑄} 𝑐_{𝑡}^{𝑄} \\quad \\tag {13}\n   $$\n   - $𝑐_{𝑡}^{𝑄} \\in \\mathbb{R}^{𝑑_𝑐'}$：压缩后的 query 表示，$𝑑_𝑐' \\ll 𝑑_ℎ 𝑛_ℎ$。\n   - $𝑊^{𝐷𝑄} \\in \\mathbb{R}^{𝑑_𝑐' \\times 𝑑}$，$𝑊^{𝑈𝑄} \\in \\mathbb{R}^{𝑑_ℎ 𝑛_ℎ \\times 𝑑_𝑐'}$：降维和升维矩阵。\n\n**作用**：  \n\n- 降维后再升维，减少全连接计算量，尤其适用于输入维度 $𝑑$ 较大的场景。\n\n\n\n## 4. Decoupled Rotary Position Embedding（解耦 RoPE）\n\n### 背景\n\n前面的推理没有考虑位置编码，如果考虑RoPE位置编码，会发现权重吸收和位置编码不兼容：\n$$\n𝑞_{𝑡}^\\top 𝑘_{j}^{𝐶} => RoPE(𝑞_{𝑡}^\\top)RoPE(𝑘_{j}^{𝐶}) \\tag {-1} \\\\\n$$\n\n$$\nRoPE(𝑞_{𝑡}^\\top)RoPE(𝑘_{j}^{𝐶}) = (R_t𝑞_{𝑡})^\\top R_j 𝑘_{j}^{𝐶} = \\\\\n𝑞_{𝑡}^\\top R_t^\\top R_j 𝑘_{j}^{𝐶} = 𝑞_{𝑡}^\\top R_{j-t} 𝑘_{j}^{𝐶} = h_t^\\top (W^Q)^\\top R_{j-t} 𝑊^{𝑈𝐾} 𝑐_{𝑡}^{𝐾𝑉} \\tag {-2}\n$$\n\n前面 $𝑊^{𝑈𝐾}$ 与 $𝑊^𝑄$ 可以合并，是因为$(W^Q)^\\top  𝑊^{𝑈𝐾} $是常量，但是$(W^Q)^\\top R_{j-t} 𝑊^{𝑈𝐾}$是与query向量的位置$t$相关的变量$R_{j-t}$，即随推理过程中query的位置变化而变化，导致旧的缓存不能直接使用，所以无法直接合并。\n\n为什么GQA的低秩投影没有受RoPE影响，因为GQA只减少了头数，计算时又恢复了头数，但是隐式恢复头数直接通过广播实现，不涉及特征维度改变序列长度改变；而MLA减小的是每个头的特征维度，计算时为了避免增加计算量，只能隐式恢复特征维度，即需要借助权重吸收，而两个权重之间又夹着RoPE，没办法权重吸收。\n\n> RoPE（Rotary Position Embedding）对 key 和 query 都是位置敏感的。\n>\n> *若直接将 RoPE 应用于压缩后的 key，升维矩阵 $𝑊^{𝑈𝐾}$ 无法与 $𝑊^𝑄$ 合并，影响推理效率？*\n>\n> *一个简单的逻辑应该是把位置编码都应用到压缩后的特征上。*\n\n### 原因\n\n- RoPE 是依赖位置的旋转矩阵，矩阵乘法不满足交换律。\n- 若在升维后的 key 上应用 RoPE，需重新计算所有历史 key 的位置编码，无法仅用缓存恢复。\n\n### 解决方案  \n将 query 和 key 分为两部分，一部分就用MLA不使用RoPE 位置编码，另一部分用MQA使用位置编码：\n\n1. **对 query 和 key 分别应用 RoPE**：  \n   \n   将输入的查询内容向量 $c^Q_t$通过矩阵 $W^{QR}$投影到 RoPE 编码后的空间，得到分离后的旋转位置编码查询向量 $q^R_t$，并按多头$n_h$分块。\n   $$\n   [𝑞_{𝑡,1}^𝑅; 𝑞_{𝑡,2}^𝑅; \\ldots; 𝑞_{𝑡,𝑛_ℎ}^𝑅] = \\text{RoPE}(𝑊^{𝑄𝑅} 𝑐_{𝑡}^{𝑄}) \\quad \\text{(14)}\n   $$\n   将隐藏状态 $ h_t $ 通过矩阵 $W^{KR}$投影，并应用 RoPE 得到分离后的旋转位置编码键向量$ k^R_t $。\n   $$\n   𝑘_{𝑡}^𝑅 = \\text{RoPE}(𝑊^{𝐾𝑅} ℎ_𝑡) \\quad \\text{(15)}\n   $$\n   \n2. **拼接压缩部分和 RoPE 部分**：  \n   \n   将内容查询向量与旋转位置编码查询向量进行拼接，得到最终的第 $i$个头的查询向量。\n   $$\n   𝑞_{𝑡,𝑖} = [𝑞_{𝑡,𝑖}^𝐶, 𝑞_{𝑡,𝑖}^𝑅] \\quad \\text{(16)}\n   $$\n   将内容键向量与旋转位置编码键向量拼接，得到最终的第$i$个头的键向量。\n   $$\n   𝑘_{𝑡,𝑖} = [𝑘_{𝑡,𝑖}^𝐶, 𝑘_{𝑡,𝑖}^𝑅] \\quad \\text{(17)}\n   $$\n   \n3. **注意力计算**：  \n   \n   通过点积计算第 $i$ 个头在时间步 $t$的查询向量与历史键向量的相关性，除以 $\\sqrt{d_h + d^R_h}$进行缩放，然后使用 Softmax 得到注意力权重，对对应的值向量 $v^C_{j,i}$进行加权求和。\n   $$\n   𝑜_{𝑡,𝑖} = \\sum_{𝑗=1}^{𝑡} \\text{Softmax}\\left(\\frac{𝑞_{𝑡,𝑖}^\\top 𝑘_{𝑗,𝑖}}{\\sqrt{𝑑_ℎ + 𝑑_ℎ^𝑅}}\\right) 𝑣_{𝑗,𝑖}^𝐶 \\quad \\text{(18)}\n   $$\n   \n4. **最终输出**：  \n   \n   将所有头的输出 $o_{t,i}$拼接起来，并通过输出权重矩阵 $W^O$得到最终的输出向量 $u_t$。\n   $$\n   𝑢_𝑡 = 𝑊^𝑂 [𝑜_{𝑡,1}; 𝑜_{𝑡,2}; \\ldots; 𝑜_{𝑡,𝑛_ℎ}] \\quad \\text{(19)}\n   $$\n\n其中 $W^{QR} \\in \\mathbb{R}^{d^R_h n_h \\times d'_c}$ 和$ W^{KR} \\in \\mathbb{R}^{d^R_h \\times d}$是分别用于生成分离查询向量和分离键向量的矩阵；$RoPE(·)$表示应用旋转位置编码的操作；符号$[\\cdot ;\\cdot]$表示拼接操作。在推理阶段，分离的键向量也需要被缓存。因此，MLA需要一个包含 $(d_c + d^R_h)l$元素的 KV 缓存。\n\n**参数说明**：  \n\n- $𝑑_ℎ^𝑅$：RoPE 部分的维度。\n- 推理时只需缓存 $𝑐_{𝑡}^{𝐾𝑉}$（大小约为 $𝑑_𝑐 + 𝑑_ℎ^𝑅$）。\n\n---\n\n## 5. 总结 MLA 思路\n\nMLA 的核心目标是降低推理时的显存占用和计算延迟，同时保持注意力效果。具体方法包括：  \n1. **低秩联合压缩 KV**：通过共享压缩表示 $𝑐_{𝑡}^{𝐾𝑉}$ 减少 KV 缓存大小。  \n2. **低秩 Query 压缩**：减少 Query 的计算量。  \n3. **解耦 RoPE**：在保留位置编码效果的同时，使压缩策略兼容 RoPE，避免破坏缓存复用。  \n\n**最终效果**：  \n- 显存占用从 $2𝑑_ℎ 𝑛_ℎ 𝑙$ 降至 $𝑑_𝑐 𝑙$。  \n- 计算效率提升，适用于大规模模型部署。\n\n\n\n","comments":true,"categories":[],"tags":[{"name":"AI","slug":"AI","permalink":"http://blog.ahulearn.com/tags/AI/"},{"name":"Multi-Head Latent Attention","slug":"Multi-Head-Latent-Attention","permalink":"http://blog.ahulearn.com/tags/Multi-Head-Latent-Attention/"}]},{"title":"pytorch-激活函数","date":"2025-08-05T02:14:00.000Z","path":"2025/08/05/pytorch-激活函数/","raw":"---\ntitle: pytorch-激活函数\ndate: 2025-08-5 10:14:00\ntags:\n - PyTorch\n - 深度学习\ntypora-root-url: ..\ntypora-copy-images-to: ../img/pytorch\n---\n\n\n\n# 常用的激活函数介绍\n\n激活函数的原则：\n\n- 单调函数（或有极小一部分不单调）\n- 非线性函数\n- 具有良好的梯度\n\n---\n\n<!--more-->\n\n## 1. Sigmoid 函数\n\nSigmoid 是早期神经网络中常用的激活函数，其数学表达式为：\n\n\n$$\nf(x) = \\frac{1}{1 + e^{-x}}\n$$\n\n\n- **优点**：输出值在 (0, 1) 区间内，适合用于二分类问题的概率预测。\n- **缺点**：容易出现梯度消失问题，计算量相对较大。\n\n## 2. Tanh（双曲正切）函数\n\nTanh 的数学表达式如下：\n\n\n$$\n f(x) = \\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}} \n$$\n\n\n- **优点**：将输入值压缩到 (-1, 1)，对于后续的优化过程较为友好。\n- **缺点**：与 Sigmoid 类似，两端的导数接近于零，可能导致梯度消失问题。\n\n## 3. ReLU（修正线性单元）\n\nReLU 是当前深度学习中最常用的激活函数之一，定义为：\n\n\n$$\n f(x) = \\max(0, x) \n$$\n\n\n- **优点**：计算简单，有效缓解了梯度消失问题；允许模型稀疏表示。\n- **缺点**：可能导致“死亡ReLU”问题，即某些神经元永远不会再激活。\n\n## 4. Leaky ReLU\n\nLeaky ReLU 是对 ReLU 的改进，尝试解决“死亡ReLU”问题，定义为：\n\n\n$$\n f(x) = \\begin{cases} \nx & \\text{if } x > 0 \\\\\n\\alpha x & \\text{if } x \\leq 0 \n\\end{cases} \n$$\n\n\n其中，$\\alpha$ 是一个小的常数。\n\n- **优点**：避免了部分神经元失效的问题。\n- **缺点**：相比 ReLU 更复杂一些，但差异不大。\n\n## 5. ELU（指数线性单元）\n\nELU 在 Leaky ReLU 的基础上进一步改进，定义为：\n\n\n$$\n f(x) = \\begin{cases} \nx & \\text{if } x > 0 \\\\\n\\alpha(e^x - 1) & \\text{if } x \\leq 0 \n\\end{cases} \n$$\n\n\n- **优点**：在负数区域有非零输出，有助于加速学习。\n- **缺点**：计算成本较 ReLU 稍高。\n\n## 6. Swish\n\nSwish 是一种新型激活函数，由 Google 提出，定义为：\n\n\n$$\n f(x) = x \\cdot \\sigma(x) \n$$\n\n\n这里，$\\sigma(x)$ 是 Sigmoid 函数。\n\n- **优点**：平滑、非单调，可能提供更好的性能。\n- **缺点**：相较于 ReLU 计算稍微复杂。\n\n## 7. Softmax\n\nSoftmax 主要用于多分类问题的输出层，将一个 K 维向量转化为另一个 K 维概率分布。\n\n\n$$\nf(\\mathbf{x})_i = \\frac{e^{x_i}}{\\sum_{j=1}^{K} e^{x_j}}\n$$\n\n\n- **优点**：适用于多分类任务，直接给出每个类别的概率估计。\n- **缺点**：仅适用于输出层，在隐藏层使用效果不佳。\n\n## 8.GELU (Gaussian Error Linear Unit)\n\n**GELU** 是一种平滑的激活函数，它基于随机正态分布的概率计算。具体来说，GELU 可以看作是神经元在输入值大于某个阈值时被激活的概率，这个阈值遵循标准正态分布。它的数学定义如下：\n$$\nGELU(x)=xΦ(x)\n$$\n这里，$Φ(x)$表示标准正态分布 $N(0,1)$的累积分布函数（CDF）。为了便于实际计算，通常使用近似公式：\n$$\nGELU(x)≈0.5x(1+tanh⁡(\\sqrt{2/π}(x+0.044715x3)))\n$$\n详情参考苏神文章：[GELU的两个初等函数近似是怎么来的 ](https://kexue.fm/archives/7309)\n\n- **优点**: 相比于 ReLU 和其变种，GELU 提供了更平滑的非线性变换，有助于改善梯度流和模型的泛化能力。它特别适合用于深度学习模型中的隐藏层。\n- **缺点**: 计算上相对复杂一些，但现代硬件可以很好地处理这种额外的计算开销。\n\n## 9.SwiGLU (Switched GLU)\n\n**SwiGLU** 是 Google 在2023年提出的一种新型激活函数，结合了 Swish 激活函数的优点与门控机制(GLU)的思想。不同于传统激活函数直接作用于输入，SwiGLU 通过引入可学习的参数来调整输入，从而试图保留 GLU 的优点同时改善其性能。然而，关于 SwiGLU 的具体定义和实现细节可能有所不同或有所发展，下面提供一个基于公开信息的理解框架：\n$$\nSwiGLU(x,W,V,b,d)=Swish(Wx+b)⊗(Vx+d)\n$$\n其中，\n\n- $x$ 是输入向量，\n- $W$、$V$ 分别为权重矩阵，\n- $b$、$d$ 为偏置项，\n- $⊗$ 表示逐元素相乘，\n- $Swish(z)=z⋅σ(z)$，这里的 $σ(z)$是 Sigmoid 函数。\n- **优点**: 结合了 Swish 的非单调性和 GLU 的门控特性，旨在提高模型的表达能力和训练效率。理论上，SwiGLU 能够更好地适应复杂的模式，特别是在自然语言处理任务中显示出潜力。\n- **缺点**: 作为一种较新的激活函数，其实用性和优势还在探索之中。相对于一些简单激活函数（如ReLU），其计算成本更高。\n","comments":true,"categories":[],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://blog.ahulearn.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"PyTorch","slug":"PyTorch","permalink":"http://blog.ahulearn.com/tags/PyTorch/"}]},{"title":"桩识图","date":"2025-07-04T06:00:00.000Z","path":"2025/07/04/桩识图/","raw":"---\ntitle: 桩识图\ndate: 2025-07-04 14:00:00\ntags:\n - 建筑\n - CAD\ntypora-root-url: ..\ntypora-copy-images-to: ../img/cad\n---\n\n# 一种建筑图纸中桩的识别方法和装置\n\n## 技术领域\n\n人工智能、图像处理，建筑审图\n\n## 技术背景\n\n在结构工程审图领域，桩平面图的自动识别面临以下严峻挑战：1. 图纸上桩的画法多样，2. 单张图纸中桩结构高度密集，3. 受墙体和柱子等其他建筑元素的严重干扰，这使得传统的基于规则的检测方法显得力不从心，无法满足现代建筑审图的高精度与效率需求。\n\n## 解决的技术问题\n\n本项目通过创新性地结合基于规则和深度学习的算法，实现了高效、准确的桩检测。相较于基于规则的传统方法，本方法检测效率提高3倍，召回率提高了30%，准确率达到99%，显著优化了检测效果。通过自研自动化数据生成，自监督训练方案，替代完全依赖人工标注的传统方式，降低大量标注成本。总体来看，本项目实现了从无到有的技术突破，为结构检测带来了新的赋能。\n\n## 技术方案\n\n### 1. 总体流程\n\n- 基于规则的桩检测\n  - 采用基于规则的方法检测桩，检测时不区分桩类别。确保绝对准确率（100%），保持较高召回率（>60%）。\n- 生成桩检测数据集\n  - 利用规则检测的结果作为标注，生成桩检测数据集【pile_v0.1】。\n- 模型训练\n  - 使用YOLO算法，在桩检测数据集上训练初步的桩检测模型【model_v0.1】。\n- 自监督训练\n  - 运用已训练模型检测基于规则无法识别的图纸，将高置信度结果纳入训练集继续训练。\n\n### 2. 基于规则的桩检测\n\n#### 过滤干扰线\n\n- 根据长度、直径和面积限制进行过滤。\n- 只保留特定类型的几何元素：直线、多段线、圆、椭圆、圆弧、实体、填充。\n\n#### 桩检测规则\n\n- 导出图像并求连通域。\n- 圆检测：识别圆、特定条件下的多段线和圆弧、椭圆。\n- 矩形检测：利用最近邻算法确定矩形。\n- 交叉线检测：扫描线算法检测交叉线。\n- 填充检测：检查填充是否位于圆或矩形内。\n- 多次应用连通域分析，提升准确率。\n\n### 3. 生成桩检测数据集\n\n- 依据规则检测结果生成桩边界框（bbox）。\n- 导出原始及过滤后的图纸图像，扩大数据规模和多样性。\n- 以640x640滑动窗口，20%重叠，切割图像。\n- 转换bbox至图像坐标系，并映射至小图坐标系。\n- 筛选含bbox的小图，构建训练集。\n\n### 4. 模型训练\n\n- 选用YOLOv8n作为桩检测模型。\n- 调整数据集至YOLOv8所需格式，修改配置文件。\n- 加载预训练权重，设置batch=32，epoch=120，进行训练。\n- 输出桩检测模型【model_v0.1】。\n\n### 5. 自监督训练\n\n- 测试集使用规则检测遗漏的桩，由【model_v0.1】进行检测。\n- 高置信度检测结果作为新标签，与【pile_v0.1】合并成【pile_v0.2】。\n- 在【pile_v0.2】上继续训练，产出【model_v0.2】。\n- 重复步骤，循环5轮，持续迭代模型。\n\n### 6. 后处理\n\n+ 切片检测结果合并\n+ 基于cad原始图元，检测闭合多边形轮廓或圆形轮廓\n+ 检测桩定位线\n+ 验证区域内是否有满足条件的图元\n+ 筛选误召回的检测\n+ 引线检测匹配标注属性\n\n\n\n![image-20250704142805784](/img/cad/image-20250704142759573.png)","comments":true,"categories":[],"tags":[{"name":"建筑","slug":"建筑","permalink":"http://blog.ahulearn.com/tags/%E5%BB%BA%E7%AD%91/"},{"name":"CAD","slug":"CAD","permalink":"http://blog.ahulearn.com/tags/CAD/"}]},{"title":"Detecting Text in Natural Image with Connectionist Text Proposal Network","date":"2025-04-22T11:00:00.000Z","path":"2025/04/22/CTPN_Detecting Text in Natural Image with Connectionist Text Proposal Network/","raw":"---\ntitle: Detecting Text in Natural Image with Connectionist Text Proposal Network\ndate: 2025-04-22 19:00:00\ntoc: true\ntags:\n - OCR\n - CTPN\n - ECCV 2016\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\\ocr\n---\n\n名称：Detecting Text in Natural Image with Connectionist Text Proposal Network\n\n论文：https://arxiv.org/abs/1609.03605\n\n会议：ECCV 2016\n\ngithub: https://github.com/tianzhi0549/CTPN\n\n---\n\n\n\nCTPN（Connectionist Text Proposal Network）是一种基于深度学习的文本检测算法，擅长在自然场景图像中定位文本行。其核心思想是**将文本行分解为多个小文本段（text proposals），再通过序列连接形成完整文本行** 。以下从算法流程、关键技术、优缺点及改进方向展开详解：\n\n------\n\n### **一、算法流程**\n\n1. **特征提取**\n   使用预训练的CNN（如VGG16）提取图像特征，得到高维特征图（如`conv5`层输出）。\n2. **双向LSTM序列建模**\n   在特征图上滑动窗口（如3×3），每个窗口生成固定高度（如11px）的锚点（anchors），覆盖不同宽度（如16px、32px等）。通过双向LSTM捕捉水平方向的文本序列上下文信息，增强对长文本的建模能力。\n3. **文本提议生成**\n   每个锚点预测：\n   - **文本/非文本分类** （判断是否为文本区域）\n   - **垂直坐标回归** （精调锚点的y轴位置）\n   - **边缘优化** （预测文本段的起始/结束位置，用于后续连接）\n4. **文本行连接**\n   根据锚点的水平距离、重合度、边缘标签和置信度，将相邻的文本段连接成完整的文本行。\n\n模型输出：每个特征窗口设置k(=10)个相同宽度不同高度的候选框，每个候选框生成二分类判断是文字还是背景，2k；每个候选宽生成高度方向上下边界的微调，2k；每个候选宽生成一个水平微调, 1k。\n\n<!--more-->\n\n------\n\n### **二、关键技术**\n\n1. **垂直锚点机制**\n   - 设计固定高度（如11px）、不同宽度的锚点，适应不同长宽比的文本行。\n   - 锚点在垂直方向密集滑动（如步长1px），确保覆盖文本的上下边界。\n2. **双向LSTM**\n   捕捉文本行的水平序列特征，解决单个文本段因截断或模糊导致的误检问题。\n3. **边缘优化（Side-refinement）**\n   预测文本段的起始和结束位置，减少文本行首尾的冗余或断裂，提升定位精度。\n4. **多任务损失函数**\n   结合分类损失（交叉熵）和回归损失（Smooth L1），联合优化文本检测的准确性。\n\n------\n\n### **三、优缺点分析**\n\n**优点** ：\n\n- **高精度** ：通过序列连接机制，有效处理长文本行和弯曲文本。\n- **鲁棒性** ：双向LSTM对模糊、遮挡文本有较好适应性。\n- **实时性** ：结合CNN和LSTM的高效设计，速度较快（GPU下约0.1s/图）。\n\n**缺点** ：\n\n- **依赖水平文本** ：对倾斜、多方向文本检测效果较差。\n- **锚点固定** ：锚点高度固定，难以适应大尺寸变化的文本。\n- **后处理复杂** ：需NMS和文本连接步骤，增加计算开销。\n\n------\n\n### **四、改进方向**\n\n1. **多方向检测**\n   如EAST算法，直接预测文本框的旋转角度，支持任意方向文本检测。\n2. **动态锚点**\n   改进锚点生成机制（如可变形卷积），适应不规则文本形状。\n3. **端到端优化**\n   结合检测与识别（如Mask TextSpotter），减少后处理依赖。\n\n------\n\n### **五、应用场景**\n\nCTPN广泛应用于自然场景文本检测，如：\n\n- 车牌识别\n- 街景文字提取\n- 文档图像分析\n\n**示例** ：在街景图像中，CTPN可精准定位店铺招牌、路牌上的文字，为后续OCR提供准确输入。\n\n------\n\n通过结合局部特征与全局序列信息，CTPN在文本检测领域奠定了重要基础，虽有一定局限性，但其设计理念仍对后续算法（如EAST、DBNet）有深远影响。","comments":true,"categories":[],"tags":[{"name":"OCR","slug":"OCR","permalink":"http://blog.ahulearn.com/tags/OCR/"},{"name":"CTPN","slug":"CTPN","permalink":"http://blog.ahulearn.com/tags/CTPN/"},{"name":"ECCV 2016","slug":"ECCV-2016","permalink":"http://blog.ahulearn.com/tags/ECCV-2016/"}]},{"title":"Android Studio配置Gradle","date":"2025-04-20T15:00:00.000Z","path":"2025/04/20/IntelliJ IDEA 或 Android Studio在设置中指定 Gradle 主目录/","raw":"---\ntitle: Android Studio配置Gradle\ndate: 2025-4-20 23:00:00\ntags:\n - Gradle\n - Android\n---\n\n\n\n在**IntelliJ IDEA** 和**Android Studio** 中，可以通过以下步骤指定 Gradle 主目录（Gradle Home Directory）。这个设置允许你使用手动安装的 Gradle 版本，而不是依赖 IDE 自动下载的版本。\n\n<!--more-->\n\n------\n\n### **步骤 1：打开设置窗口**\n\n1. 启动 IntelliJ IDEA 或 Android Studio。\n2. 打开 **设置/首选项** 窗口：\n   - **Windows/Linux** 作系统 ：`File > Settings`。\n   - **macOS** ：`IntelliJ IDEA > Preferences`。\n\n------\n\n### **步骤 2：导航到 Gradle 设置**\n\n1. 在设置窗口中，展开左侧的**Build, Execution, Deployment** 菜单\n2. 点击**Build Tools > Gradle** 。\n\n------\n\n### **步骤 3：指定 Gradle 主目录**\n\n在右侧的 Gradle 设置面板中，找到**“Gradle JVM”** 和**“Use Gradle from”** 部分\n\n##### **选项 1：使用 Gradle Wrapper**\n\n- 默认情况下，IDE 会选择**'gradle-wrapper.properties' 文件**。\n- 这意味着 IDE 会根据项目中的`gradle/wrapper/gradle-wrapper.properties`文件自动下载并使用指定的 Gradle 版本。\n- 如果你希望继续使用 Wrapper 方式，则无需更改此设置。\n\n##### **选项 2：手动指定 Gradle 主目录**\n\n如果需要手动指定 Gradle 主目录，请按照以下步骤作：\n\n1. 将**“Distribution”** 下**指定位置** 。\n2. 点击右侧的文件夹图标（或直接输入路径），选择你手动安装的 Gradle 目录。\n   - 例如：\n     - Windows：`C:\\Gradle\\gradle-8.11.1`\n     - macOS/Linux：`/opt/gradle/gradle-8.11.1`\n   - 确保该目录包含以下子目录和文件：\n     - `bin/gradle`（可执行文件）\n     - `lib/gradle`\n\n------\n\n### **步骤 4：配置 Gradle JVM**\n\n1. 在同一设置页面，找到 **Gradle JVM** 部分。\n2. 选择一个合适的 JDK 版本用于运行 Gradle。\n   - 如果未列出所需的 JDK，可以点击右侧的下拉菜单，选择**添加 JDK** 并\n\n------\n\n### **步骤 5：应用更改**\n\n1. 点击**Apply** 或 **OK** 按钮保存设置。\n2. 如果项目已经打开，IDE 可能会提示重新加载 Gradle 配置。点击**Reload** 或 **Sync Now**以应用更改。\n\n------\n\n### **步骤 6：验证设置是否生效**\n\n1. 打开终端（Terminal）窗口，运行以下命令检查 Gradle 版本：\n\n   ```bash\n   gradle --version\n   ```\n\n   输出应显示你指定的 Gradle 版本。\n\n2. 在 IDE 中，尝试构建项目，确保 Gradle 构建成功。\n\n------\n\n### **额外注意事项**\n\n1. **兼容性检查** ：\n\n   - 确保指定的 Gradle 版本与项目的`build.gradle`文件兼容。\n\n   - 如果项目需要特定的 Gradle 版本，请参考`gradle-wrapper.properties`文件中的`distributionUrl`。\n\n   - 示例 `gradle-wrapper.properties`文件内容：\n\n     ```bash\n     distributionUrl=https\\://services.gradle.org/distributions/gradle-8.11.1-bin.zip\n     ```\n\n2. **环境变量** ：\n\n   - 如果你在系统中设置了`GRADLE_HOME`环境变量，IDE 通常会自动检测到它，但仍需在设置中明确指定路径\n\n3. **代理设置** \n\n   如果你的网络需要代理，确保在 IDE 的 HTTP Proxy 设置中正确配置代理信息：\n\n   - 路径：`File > Settings > Appearance & Behavior > System Settings > HTTP Proxy`\n\n------\n\n通过以上步骤，你可以成功在 IntelliJ IDEA 或 Android Studio 中指定 Gradle 主目录，并使用手动安装的 Gradle 版本进行项目构建。如果有其他问题，请随时补充说明！\n\n","comments":true,"categories":[],"tags":[{"name":"Gradle","slug":"Gradle","permalink":"http://blog.ahulearn.com/tags/Gradle/"},{"name":"Android","slug":"Android","permalink":"http://blog.ahulearn.com/tags/Android/"}]},{"title":"Python开发安卓应用","date":"2025-04-19T15:00:00.000Z","path":"2025/04/19/使用 Kivy 或其他移动开发框架/","raw":"---\ntitle: Python开发安卓应用\ndate: 2025-4-19 23:00:00\ntags:\n - python\n - Android\n---\n\n\n\n要在安卓设备上运行使用 PyQt 编写的程序，需要解决一个关键问题：PyQt 是为桌面环境设计的，而安卓是一个移动操作系统，直接在安卓上运行 PyQt 程序并不支持。不过，可以通过一些工具和框架将 PyQt 应用适配到安卓平台。以下是实现这一目标的主要方法和步骤：\n\n------\n\n### 1. **使用 Kivy 或其他移动开发框架**\n\n如果目标是开发跨平台的 Python 应用（包括安卓），可以考虑使用专门为移动设备设计的框架，例如 [Kivy ](https://kivy.org/?spm=a2ty_o01.29997173.0.0.737bc921lujaWC)或 [BeeWare ](https://beeware.org/?spm=a2ty_o01.29997173.0.0.737bc921lujaWC)。这些框架支持直接构建安卓应用，并且语法与 PyQt 类似。\n\n#### 原因：\n\n- PyQt 的 GUI 依赖于 Qt，而 Qt 在安卓上的支持有限。\n- Kivy 和 BeeWare 提供了更轻量级的解决方案，更适合移动设备。\n\n<!--more-->\n\n------\n\n### 2. **通过 PySide/Qt for Android**\n\nQt 官方提供了对安卓的支持（称为 \"Qt for Android\"），因此理论上可以通过以下方式将 PyQt 应用移植到安卓：\n\n#### 步骤：\n\n1. **安装 Qt for Android 工具链**\n   下载并安装 Qt 官方提供的 Android 开发工具链，包括 Qt Creator 和 Android NDK/SDK。\n2. **将 PyQt 替换为 PySide**\n   PyQt 和 PySide 都是基于 Qt 的 Python 绑定，但 PySide 对 Qt 的支持更加现代化，且更易于集成到 Qt for Android 中。\n3. **配置项目文件**\n   使用 `qmake` 或 `CMake` 创建一个 `.pro` 文件，定义项目的结构和依赖项。\n4. **编译和部署**\n   使用 Qt Creator 将项目编译为 APK 文件，并将其部署到安卓设备上。\n\n#### 注意事项：\n\n- PyQt 的某些功能可能无法完全兼容安卓平台。\n- 需要熟悉 Qt 的构建系统和安卓开发流程。\n\n------\n\n### 3. **使用 Chaquopy**\n\n[Chaquopy ](https://chaquo.com/chaquopy/)是一个将 Python 集成到安卓应用中的工具，允许在安卓项目中运行 Python 代码。虽然它主要用于嵌入式脚本，但也可以尝试将 PyQt 应用的部分逻辑迁移到 Chaquopy 中。\n\n#### 步骤：\n\n1. **创建安卓项目**\n   使用 Android Studio 创建一个新的安卓项目。\n2. **集成 Chaquopy 插件**\n   在项目的 `build.gradle` 文件中添加 Chaquopy 插件。\n3. **编写 Python 代码**\n   将 PyQt 应用的核心逻辑移植到 Python 脚本中，并通过 Java/Kotlin 调用。\n4. **替换 GUI 部分**\n   由于 PyQt 的 GUI 部分无法直接运行在安卓上，可以使用安卓原生的 UI 组件替代。\n\n#### 局限性：\n\n- Chaquopy 不支持完整的 PyQt GUI，只能运行后端逻辑。\n\n------\n\n### 4. **使用 Termux 和 X Server**\n\n如果仅需在安卓设备上测试 PyQt 应用，可以通过 Termux 和 X Server 实现。这种方法适合开发和调试，但不适合发布正式应用。\n\n#### 步骤：\n\n1. **安装 Termux**\n   在安卓设备上安装 [Termux ](https://termux.dev/)，这是一个强大的终端模拟器。\n\n2. **安装必要的依赖**\n   在 Termux 中安装 Python、PyQt 和 X Server（如 XSDL）。\n\n   ```bash\n   pkg install python\n   \n   pip install pyqt5\n   ```\n\n   \n\n3. **运行 PyQt 应用**\n   启动 X Server，然后在 Termux 中运行 PyQt 应用。\n\n   \n\n   ```bash\n   export DISPLAY=:0\n   \n   python your_pyqt_app.py\n   ```\n\n   \n\n#### 局限性：\n\n- 这种方法仅适用于开发和测试，性能和用户体验较差。\n- 不适合生产环境。\n\n------\n\n### 总结\n\n如果目标是将 PyQt 应用移植到安卓设备上，推荐的方法是：\n\n1. **优先选择 Kivy 或 BeeWare** ，这些框架专为移动开发设计。\n2. 如果必须使用 PyQt，可以尝试 **Qt for Android** 或 **Chaquopy** ，但需要额外的适配工作。\n3. 对于开发和测试，可以使用 **Termux 和 X Server** 。\n\n根据具体需求选择合适的方法。如果有更多细节或特定问题，欢迎进一步补充说明！","comments":true,"categories":[],"tags":[{"name":"Android","slug":"Android","permalink":"http://blog.ahulearn.com/tags/Android/"},{"name":"python","slug":"python","permalink":"http://blog.ahulearn.com/tags/python/"}]},{"title":"语义分割-游程编码（Run-Length Encoding, RLE）","date":"2025-04-17T07:00:00.000Z","path":"2025/04/17/语义分割-游程编码/","raw":"---\ntitle: 语义分割-游程编码（Run-Length Encoding, RLE）\ndate: 2025-04-17 15:00:00\ntags:\n - PyTorch\n - 深度学习\n - 语义分割\ntypora-root-url: ..\ntypora-copy-images-to: ../img/pytorch\n---\n\n### 游程编码（Run-Length Encoding, RLE）详解\n\n游程编码（RLE，Run-Length Encoding）是一种简单而有效的数据压缩方法，特别适用于具有大量连续重复值的数据。它在图像处理、分割掩码表示和时间序列数据压缩等领域有着广泛的应用。\n\n它通过记录每个值的“运行长度”（即连续出现的次数）来减少存储空间。RLE 在图像处理、文件压缩和机器学习中都有广泛应用，例如在 COCO 数据集中用于表示分割掩码。\n\n<!--more-->\n\n### 1. **RLE 的基本概念**\n\n#### 定义：\n\n- **游程** ：一段连续的相同值。\n- **编码** ：将每个游程用一对值表示，通常是 `(值, 长度)` 或 `(长度, 值)`或`(起点, 长度)`。\n  - **对于二值mask编码有简化形式**\n    - 交替存储连续的前景像素数和背景像素数。示例：`11100111110` 编码为 `[3, 2, 5, 1]`\n    - 存储前景像素的起点和长度。示例：`11100111110` 编码为 `[0, 3, 5, 5]`\n\n#### 示例：\n\n假设有一个二值数组 `[0, 0, 0, 1, 1, 1, 1, 0, 0]`：\n\n- 使用 RLE 编码后可以表示为 `[(0, 3), (1, 4), (0, 2)]`，即：\n  - `0` 出现了 3 次，\n  - `1` 出现了 4 次，\n  - `0` 又出现了 2 次。\n\n------\n\n### 2. **RLE 的两种常见形式**\n\n#### 2.1 **紧凑格式**\n\n- 将所有游程的长度按顺序排列成一个一维数组。\n- 示例：\n  - 输入数组：`[0, 0, 0, 1, 1, 1, 1, 0, 0]`\n  - 紧凑格式：`[3, 4, 2]`（分别表示 `0` 的长度、`1` 的长度、`0` 的长度）。\n\n这种格式常用于 COCO 数据集中的分割掩码。\n\n#### 2.2 **展开格式**\n\n- 直接记录每个像素的值（通常为布尔值），不进行压缩。\n- 示例：\n  - 输入数组：`[0, 0, 0, 1, 1, 1, 1, 0, 0]`\n  - 展开格式：`[False, False, False, True, True, True, True, False, False]`\n\n这种格式占用更多存储空间，但在某些情况下更易于处理。\n\n------\n\n### 3. **RLE 的应用场景**\n\n#### 3.1 **图像压缩**\n\n- RLE 是一种简单且高效的图像压缩方法，尤其适用于二值图像或具有大量连续颜色区域的图像。\n- 示例：\n  - 黑白图像中的大面积背景可以用 RLE 表示，从而显著减少存储空间。\n\n#### 3.2 **分割掩码表示**\n\n- 在目标检测和实例分割任务中，RLE 常用于表示分割掩码（mask）。相比于直接存储二值图像，RLE 能够大幅减少数据量。\n- 示例：\n  - COCO 数据集中的 `segmentation` 字段使用 RLE 格式存储分割掩码。\n\n#### 3.3 **时间序列数据**\n\n- 对于具有重复模式的时间序列数据，RLE 可以有效压缩存储空间。\n- 示例：\n  - 某个传感器输出的信号可能包含大量连续的相同值，RLE 可以用来压缩这些数据。\n\n------\n\n### 4. **RLE 的优缺点**\n\n#### 优点：\n\n1. **简单高效**\n   RLE 的实现非常简单，适合处理具有大量连续重复值的数据。\n2. **无损压缩**\n   RLE 是一种无损压缩算法，解码后可以完全恢复原始数据。\n3. **节省存储空间**\n   对于具有长游程的数据，RLE 能够显著减少存储需求。\n\n#### 缺点：\n\n1. **对随机数据无效**\n   如果数据中没有连续重复值（如随机噪声），RLE 不仅无法压缩，反而会增加存储开销。\n2. **不适合复杂形状**\n   对于复杂的二值图像（如细碎的边缘或噪声），RLE 的压缩效果较差。\n\n\n\n### 5. **RLE 与mask互相转换**\n\n这里RLE编码是1base的, 编码格式是二值mask的`(起点, 长度)`\n\n```python\nimport numpy as np\n\n\ndef rle_encode(mask: np.ndarray):\n    \"\"\"mask转游程编码\n\n    Args:\n        mask (np.ndarray): numpy array, 1 - mask, 0 - background\n\n    Returns:\n        str: run length as string formated (start, length)\n    \"\"\"\n    pixels = mask.flatten(order = 'F')\n    # 前后补零免去越界检测\n    pixels = np.concatenate([[0], pixels, [0]])\n    # 寻找像素变化的索引坐标\n    # 0变1的索引和1变0索引交替排列\n    runs = np.where(pixels[1:] != pixels[:-1])[0]\n    runs += 1\n    # 1变0的索引减去0变1的索引，即为1的长度\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle_decode(mask_rle: str, shape=(512, 512)):\n    \"\"\"游程编码解码\n\n    Args:\n        mask_rle (str): run-length as string formated (start, length)\n        shape (tuple, optional): (height, width) of array to return.\n\n    Returns:\n        numpy array: 1 - mask, 0 - background\n    \"\"\"\n    run_value = 1\n    if isinstance(mask_rle, str):\n        mask_rle = [int(i) for i in mask_rle.split()]\n    elif isinstance(mask_rle, (list, tuple)):\n        mask_rle = [int(i) for i in mask_rle]\n    else:\n        mask_rle = []\n    rle_pairs = list(zip(mask_rle[0::2], mask_rle[1::2]))  # 前景和背景像素对\n    mask = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n    for run_start, run_length in rle_pairs:\n        run_start -= 1\n        mask[run_start:run_start + run_length] = run_value\n    return mask.reshape(shape, order='F')\n\n\nif __name__ == '__main__':\n    data = [1, 10, 12, 5, 100, 8, 120, 9]\n    # 解码\n    mask = rle_decode(data)\n    # 编码\n    rle = rle_encode(mask)\n    data_str = ' '.join(str(x) for x in data)\n    # 判断结果是否相同\n    print(data_str==rle)\n    print(rle)\n```\n\n### 6. **YOLO标签 与mask互相转换**\n\n+ Mask转YOLO标签\n\n```python\nimport cv2\nimport numpy as np\n\n\ndef mask_to_yolo_label(mask: np.ndarray, class_id=0):\n    \"\"\"\n    将二值 mask 转换为 YOLO 分割标签格式。\n    \n    参数：\n        mask (np.ndarray): 二值 mask 图像，形状为 [H, W]，值为 0 或 255。\n        class_id (int): 目标的类别 ID。\n    \n    返回：\n        str: YOLO 格式的分割标签字符串。\n    \"\"\"\n    image_width, image_height = mask.shape[:2]\n    # 确保 mask 是二值图像\n    _, binary_mask = cv2.threshold(mask, 0, 255, cv2.THRESH_BINARY)\n    \n    # 查找轮廓\n    contours, hierarchy = cv2.findContours(binary_mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n    contours = [cv2.approxPolyDP(contour, epsilon=1, closed=True) for contour in contours]\n    if len(contours) == 0:\n        raise ValueError(\"未找到任何轮廓，请检查输入的 mask 是否有效。\")\n    \n    label = \"\"\n    # 遍历每个mask（假设 mask 中只有一个目标）\n    for contour in contours:\n        # 计算边界框\n        # x, y, w, h = cv2.boundingRect(contour)\n        # x_center = (x + w / 2) / image_width\n        # y_center = (y + h / 2) / image_height\n        # width = w / image_width\n        # height = h / image_height\n    \n        # 提取分割点并归一化\n        segmentation_points = []\n        for point in contour:\n            px, py = point[0]  # 提取点的坐标\n            norm_px = px / image_width\n            norm_py = py / image_height\n            segmentation_points.extend([norm_px, norm_py])\n    \n        # 拼接 YOLO 标签\n        label += f\"{class_id} \" + \\\n            \" \".join(f\"{p:.6f}\" for p in segmentation_points) + \"\\n\"\n    \n    return label\n\n# 示例用法\nif __name__ == \"__main__\":\n    # 转换为 YOLO 标签\n    yolo_label = mask_to_yolo_label(mask)\n    print(\"YOLO 标签：\", yolo_label)\n```\n\n+ YOLO标签转Mask\n\n```python\nimport numpy as np\nimport cv2\n\ndef yolo_label_to_mask(yolo_label, image_width, image_height):\n    \"\"\"\n    将 YOLO 分割标签转换为二值掩码。\n    \n    参数：\n        yolo_label (str): YOLO 分割标签字符串。\n        image_width (int): 原始图像的宽度。\n        image_height (int): 原始图像的高度。\n    \n    返回：\n        np.ndarray: 二值掩码，形状为 [H, W]。\n    \"\"\"\n    # 解析 YOLO 标签\n    labels = yolo_label.strip().split('\\n')\n    print(labels)\n    # 创建空的掩码\n    mask = np.zeros((image_height, image_width), dtype=np.uint8)\n    for label in labels:\n        parts = label.strip().split()\n        segmentation_points = list(map(float, parts[1:]))\n        # 反归一化分割点坐标\n        points = []\n        for i in range(0, len(segmentation_points), 2):\n            norm_x = segmentation_points[i]\n            norm_y = segmentation_points[i + 1]\n            px = int(norm_x * image_width)\n            py = int(norm_y * image_height)\n            points.append([px, py])\n        # 使用 fillPoly 填充多边形区域\n        points = np.array([points], dtype=np.int32)  # 转换为 OpenCV 格式\n        cv2.fillPoly(mask, points, 1)\n    \n    return mask\n\n# 示例用法\nif __name__ == \"__main__\":\n    # 将 YOLO 标签转换为掩码\n    mask = yolo_label_to_mask( yolo_label, *(512, 512))\n    plt.figure(figsize=(7, 7), dpi=100)\n    # plt.title(\"Mask\")\n    plt.imshow(mask, cmap=\"gray\")  # 灰度显示掩码\n    plt.axis(\"off\")\n    plt.show()\n```\n\n","comments":true,"categories":[],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://blog.ahulearn.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"PyTorch","slug":"PyTorch","permalink":"http://blog.ahulearn.com/tags/PyTorch/"},{"name":"语义分割","slug":"语义分割","permalink":"http://blog.ahulearn.com/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"}]},{"title":"损失函数-Label Smoothing Cross Entropy","date":"2025-04-16T08:00:00.000Z","path":"2025/04/16/pytorch-损失函数-LabelSmoothingCrossEntropy/","raw":"---\ntitle: 损失函数-Label Smoothing Cross Entropy\ndate: 2025-04-16 16:00:00\ntags:\n - PyTorch\n - 深度学习\n - CTCLoss\ntypora-root-url: ..\ntypora-copy-images-to: ../img/pytorch\n---\n\n\n\n### 什么是 Label Smoothing Cross Entropy？\n\nLabel Smoothing 是一种正则化技术，用于改进分类任务中的交叉熵损失函数。传统的交叉熵损失函数假设目标标签是硬性（hard）的，即每个样本只有一个正确的类别标签，并且该类别的概率为 1，其他类别的概率为 0。然而，这种硬性标签可能会导致模型过拟合训练数据，尤其是在训练数据有限或标签可能存在噪声的情况下。\n\nLabel Smoothing 的基本思想是对目标标签进行“平滑”处理，将原本硬性的标签分布替换为一个更柔和的分布。这样可以减少模型对单一类别的过度自信，从而提高模型的泛化能力。\n\n------\n\n<!--more-->\n\n### Label Smoothing 的工作原理\n\n#### 1. **传统交叉熵损失**\n\n在分类问题中，交叉熵损失函数定义如下：\n$$\nCross\\ Entropy\\ Loss = -\\sum_{i=1}^{C} y_i log(p_i)\n$$\n其中：\n\n- *C* 是类别总数。\n- $y_i $是目标标签的 one-hot 编码（硬性标签），即正确类别的值为 1，其他类别的值为 0。\n- $p_i$ 是模型预测的第 *i* 类的概率。\n\n在硬性标签的情况下，模型会努力最大化正确类别的概率 $p_i$，而完全忽略其他类别的概率。\n\n#### 2. **Label Smoothing 的引入**\n\nLabel Smoothing 将目标标签从硬性分布转换为软性分布，具体公式如下：\n$$\ny_i′ =\\left\\{\n\\begin{aligned}\n1−ϵ, & if\\ i =true\\ class\\\\\n\\frac ϵ{C-1}, & otherwise\n\\end{aligned}\n\\right.\n$$\n其中：\n\n- *ϵ* 是平滑参数，通常取值在 [0, 1] 范围内（例如 0.1）。\n- $y_i'$ 是平滑后的目标标签分布。\n- 正确类别的概率被降低为 1−*ϵ*，而其他类别的概率被提升为$\\frac ϵ {C−1}$。\n\n#### 3. **平滑后的交叉熵损失**\n\n使用平滑后的标签分布$y_i'$，交叉熵损失变为：\n$$\nSmoothed\\ Cross\\ Entropy Loss = -\\sum_{i=1}^{C} y'_i log(p_i)\n$$\n\n\n展开后可以写为：\n$$\nSmoothed\\ Cross\\ Entropy\\ Loss =-(1-ϵ) log(p_{true}) -\\sum_{i \\neq true} \\frac ϵ {C-1} log(p_i)\n$$\n其中：\n\n- $p_{true}$ 是模型对正确类别的预测概率。\n- $\\sum_{i \\neq true} \\frac ϵ {C-1} log(p_i)$是对其他类别的惩罚项。\n\n通过这种方式，模型不仅需要最大化正确类别的概率，还需要关注其他类别的预测结果，从而避免对单一类别的过度自信。\n\n------\n\n### Label Smoothing 的优点\n\n1. **减少过拟合**\n   Label Smoothing 防止模型对训练数据中的硬性标签过于依赖，从而提高了模型的泛化能力。\n2. **改善模型的校准**\n   使用 Label Smoothing 后，模型的预测概率通常更加接近真实分布，而不是过度集中在某个类别上。\n3. **缓解标签噪声的影响**\n   如果训练数据中的标签存在噪声，Label Smoothing 可以通过平滑标签分布来降低噪声对模型的影响。\n4. **增强模型的鲁棒性**\n   在对抗攻击等场景下，Label Smoothing 可以使模型对输入扰动更加鲁棒。\n\n### Label Smoothing 的实现\n\n以下是一个基于 PyTorch 的 Label Smoothing 实现示例：\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass LabelSmoothingCrossEntropy(nn.Module):\n    def __init__(self, label_smoothing=0.1, class_weights=None, reduction='mean'):\n        super(LabelSmoothingCrossEntropy, self).__init__()\n        self.label_smoothing = label_smoothing\n        self.reduction = reduction\n        # 类别权重,此处可忽略\n        self.class_weights = class_weights\n\n    def forward(self, preds, targets):\n        # targets是每个样本的类别标签, 此处类别使用的是数字编号不是one-hot\n        n_classes = preds.size(-1)\n        # 计算预测值的对数概率\n        log_preds = F.log_softmax(preds, dim=-1)\n\n        # 平滑后的目标分布, 创建一个初始值为ϵ/(C−1)的张量\n        smooth_labels = torch.full_like(preds, self.label_smoothing / (n_classes - 1))\n        # 将正确类别的值设置为 1−ϵ\n        # scatter_(dim, index, src): 根据给定的索引，将指定的值写入目标张量的对应位置。\n        smooth_labels.scatter_(1, targets.unsqueeze(1), 1 - self.label_smoothing)\n\n        # 最后计算加权对数概率的和作为损失\n        if self.class_weights is not None:\n            loss = -(smooth_labels * log_preds * self.class_weights.unsqueeze(0)).sum(dim=-1)\n        else:\n            loss = -(smooth_labels * log_preds).sum(dim=-1)\n\n        if self.reduction == 'mean':\n            return loss.mean()\n        elif self.reduction == 'sum':\n            return loss.sum()\n        else:\n            return loss\n\n# 示例用法\npreds = torch.tensor([[2.0, 1.0, 0.1], [1.5, 2.5, 0.3]])  # 模型预测的 logits\ntargets = torch.tensor([0, 1])  # 目标标签\n\ncriterion = LabelSmoothingCrossEntropy(label_smoothing=0.1, class_weights= torch.as_tensor([1, 2, 1]))\nloss = criterion(preds, targets)\nprint(\"Label Smoothing Cross Entropy Loss:\", loss.item())\n```\n\n\n\n+ PyTorch 1.10之后CrossEntropyLoss 已经原生支持标签平滑功能\n\n```python\nimport torch\nfrom torch.nn import CrossEntropyLoss\n\n# 示例用法\npreds = torch.tensor([[2.0, 1.0, 0.1], [1.5, 2.5, 0.3]])  # 模型预测的 logits\ntargets = torch.tensor([0, 1])  # 目标标签\n\ncriterion = CrossEntropyLoss(weight=None, label_smoothing=0.1)\n\nloss = criterion(preds, targets)\nprint(\"Label Smoothing Cross Entropy Loss:\", loss.item())\n\n```\n\n\n\n### Label Smoothing 的注意事项\n\n1. 选择合适的平滑参数 *ϵ* 的值通常在 0.1 左右。如果 *ϵ* 过大，可能会导致模型对正确类别的学习不足；如果 *ϵ* 过小，则效果可能不明显。\n2. **适用于大规模分类任务**\n   Label Smoothing 在类别数量较多的任务中效果更显著，因为平滑后的分布能够更好地反映类别间的关联性。\n3. **与知识蒸馏结合**\n   Label Smoothing 常与知识蒸馏（Knowledge Distillation）结合使用。通过使用教师模型生成软标签，学生模型可以学习到更加丰富的类别间关系。","comments":true,"categories":[],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://blog.ahulearn.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"PyTorch","slug":"PyTorch","permalink":"http://blog.ahulearn.com/tags/PyTorch/"},{"name":"CTCLoss","slug":"CTCLoss","permalink":"http://blog.ahulearn.com/tags/CTCLoss/"}]},{"title":"损失函数-CTCLoss","date":"2025-04-16T06:00:00.000Z","path":"2025/04/16/pytorch-损失函数-CTCLoss/","raw":"---\ntitle: 损失函数-CTCLoss\ndate: 2025-04-16 14:00:00\ntags:\n - PyTorch\n - 深度学习\n - CTCLoss\ntypora-root-url: ..\ntypora-copy-images-to: ../img/pytorch\n---\n\n### 什么是CTCLoss？\n\nCTC (Connectionist Temporal Classification) 是一种用于序列到序列学习的损失函数，特别适用于输入和输出长度不固定的场景。它在语音识别、手写体识别等任务中应用广泛。CTC 的核心思想是通过引入一个“空白”符号（blank token），允许模型对不定长的输入序列生成不定长的输出序列，同时避免了对输入和输出进行显式的对齐操作。\n\n传统的序列标注方法通常需要将输入和输出进行严格的对齐（例如，逐帧标注），而 CTC 允许模型自动学习输入和输出之间的对齐关系，从而大大简化了训练过程。\n\n------\n<!--more-->\n\n### CTCLoss 的工作原理\n\n#### 1. **输入与输出的关系**\n\n- 输入是一个不定长的序列，比如语音信号或手写笔迹的时间序列。\n- 输出是一个较短的目标序列，比如文本转录结果。\n- 输入和输出的长度可能不同，且没有明确的对齐关系。\n\n#### 2. **引入空白符号**\n\nCTC 引入了一个特殊的“空白”符号（通常记作 `-` 或 `blank`），表示某个时间步没有对应的输出。空白符号在最终的输出中会被移除。\n\n#### 3. **路径的概念**\n\nCTC 将输入序列到输出序列的所有可能对齐方式称为“路径”。例如：\n\n- 输入序列长度为 *T*，目标序列长度为 *L*。\n- 每个时间步可以选择输出字符或空白符号。\n- 所有可能的路径构成了所有可能的输入到输出的对齐方式。\n\n#### 4. **路径的约束**\n\n为了保证输出的有效性，CTC 对路径施加了一些约束：\n\n- 相邻的重复字符会被合并。例如，路径 `a--a-b` 会被解码为 `ab`。\n- 空白符号会被忽略。例如，路径 `a-b---c` 会被解码为 `abc`。\n\n#### 5. **概率计算**\n\n对于每个可能的路径，CTC 计算其概率，并将所有可能路径的概率相加，得到目标序列的总概率。\n\n#### 6. **损失函数**\n\nCTC Loss 的目标是最大化目标序列的总概率（即最小化负对数似然）。公式如下：\n$$\nCTC Loss=−log{\\sum_{π\\in Paths(y)} P(π∣X)}\n$$\n\n\n其中：\n\n- Paths(*y*) 表示所有能生成目标序列 *y* 的路径集合。\n- *P*(*π*∣*X*) 表示给定输入 *X* 时路径 *π* 的概率。\n\n------\n\n### CTCLoss 的计算过程演示\n\n假设我们有以下输入和目标序列：\n\n#### 输入序列\n\n- 输入序列为一个长度为 *T*=6 的特征序列。\n- 模型的输出是一个 *T*×*V* 的矩阵，其中 *V* 是词汇表大小（包括空白符号）。\n- 假设词汇表为 `{a, b, c, blank}`，则 *V*=4。\n\n#### 目标序列\n\n- 目标序列为 `abc`。\n\n#### 步骤 1：生成所有可能路径\n\nCTC 需要找到所有可以生成目标序列 `abc` 的路径。例如：\n\n- 路径 `a-b-c`。\n- 路径 `a-b-c-blank`。\n- 路径 `a-blank-b-c`。\n- 路径 `a-blank-blank-b-c`。\n- 等等。\n\n注意：相邻的重复字符会被合并，因此路径 `a-a-b-c` 也会被解码为 `abc`。\n\n#### 步骤 2：计算每条路径的概率\n\n对于每条路径，计算其概率。假设模型输出的 *T*×*V* 矩阵如下：\n\n| 时间步 | a    | b    | c    | blank |\n| ------ | ---- | ---- | ---- | ----- |\n| 1      | 0.4  | 0.1  | 0.1  | 0.4   |\n| 2      | 0.3  | 0.4  | 0.1  | 0.2   |\n| 3      | 0.1  | 0.3  | 0.4  | 0.2   |\n| 4      | 0.2  | 0.3  | 0.2  | 0.3   |\n| 5      | 0.1  | 0.2  | 0.5  | 0.2   |\n| 6      | 0.1  | 0.1  | 0.6  | 0.2   |\n\n例如，路径 `a-b-c` 的概率为：\n$$\nP(a−b-c)=P(a|t=1)⋅P(b∣t=2)⋅P(c∣t=3) = 0.4 ⋅ 0.4 ⋅ 0.4 = 0.064\n$$\n例如，路径 `a-b-blank-c` 的概率为：\n$$\nP(a−b-c)=P(a|t=1) ⋅ P(b∣t=2) ⋅ P(blank∣t=3) ⋅ P(c∣t=4) = 0.4 ⋅ 0.4 ⋅ 0.2 ⋅ 0.4 = 0.0128\n$$\n\n#### 步骤 3：合并路径概率\n\n根据 CTC 的规则，将所有能生成目标序列 `abc` 的路径概率相加，得到目标序列的总概率。\n\n#### 步骤 4：计算损失\n\n最终，CTC Loss 为：\n$$\nCTC Loss=−log{\\sum_{π\\in Paths(y)} P(π∣X)}\n$$\n\n### PyTorch实现\n\n```python\nimport torch\nimport torch.nn as nn\n# 参数定义\nT = 6               # 时间步长（如音频帧数）\nN = 1               # 批次大小\nC = 4               # 类别数（含空白符）\ntarget_length = 3   # 每个样本的标签长度\n\n# 定义输入输出\nlog_probs = torch.tensor([\n    [[0.4, 0.1, 0.1, 0.4],  # t=1\n     [0.3, 0.4, 0.1, 0.2],  # t=2\n     [0.1, 0.3, 0.4, 0.2],  # t=3\n     [0.2, 0.3, 0.2, 0.3],  # t=4\n     [0.1, 0.2, 0.5, 0.2],  # t=5\n     [0.1, 0.1, 0.6, 0.2]]  # t=6\n], dtype=torch.float32).log_softmax(dim=2)  # 取对数概率\nlog_probs = log_probs.permute(1, 0, 2)  # shape: time_step, batch_size, dimension\ntargets = torch.tensor([[0, 1, 2]])  # 目标序列索引，对应 'a', 'b', 'c'\n\n# 定义输入序列的实际长度\ninput_lengths = torch.tensor([T]*N)  # 输入序列长度\ninput_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n\n# 标签实际长度（假设每个样本的标签长度为 target_length）\ntarget_lengths = torch.tensor([len(target) for target in targets])  # 目标序列长度\n\nprint(target_lengths)\n\n# 定义 CTCLoss\nctc_loss = nn.CTCLoss(blank=3)  # 空白符号索引为 3\nloss = ctc_loss(log_probs, targets, input_lengths, target_lengths)\n\nprint(\"CTC Loss:\", loss.item())\n```\n\n","comments":true,"categories":[],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://blog.ahulearn.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"PyTorch","slug":"PyTorch","permalink":"http://blog.ahulearn.com/tags/PyTorch/"},{"name":"CTCLoss","slug":"CTCLoss","permalink":"http://blog.ahulearn.com/tags/CTCLoss/"}]},{"title":"Rethinking Table Recognitionusing Graph Neural Networks","date":"2024-08-27T09:38:00.000Z","path":"2024/08/27/Rethinking Table Recognition using  GNN/","raw":"---\ntitle: Rethinking Table Recognitionusing Graph Neural Networks\ndate: 2024-08-27 17:38:00\ntoc: true\ntags:\n - GNN\n - ICDAR 2019\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\\gnn\n---\n\n\n\nRethinking Table Recognitionusing Graph Neural Networks\n---\n\n\n\n会议: ICDAR 2019\n\n论文地址：https://arxiv.org/abs/1905.13391\n\ngithub: https://github.com/shahrukhqasim/TIES-2.0\n\n[TOC]\n\n## 摘要\n\n文档结构分析，例如区域分割和表格识别，是文档处理中的复杂问题，并且是一个活跃的研究领域。深度学习在解决各种计算机视觉和机器学习问题方面的近期成功尚未反映在文档结构分析中，因为传统的神经网络不适合该问题的输入结构。本文提出了一种基于图网络的架构作为标准神经网络更好的替代方案来识别表格。我们主张图网络对于这些问题是一种更自然的选择，并探索了两种基于梯度的图神经网络。我们的提出的架构结合了卷积神经网络用于视觉特征提取以及图网络用于处理问题结构的好处。我们在实验上证明，与基线相比，我们的方法具有显著的优势。此外，我们还指出大规模数据集缺乏是结构分析领域深度学习研究的主要障碍，并提出了一个针对表格识别的新大规模合成数据集。最后，我们开源了我们的数据生成和图网络训练框架实现，以促进这一方向上的可重复研究。  \n\n**关键词：表格识别；结构分析；图神经网络；文档模型；图形模型；数据集 **\n\n<!--more-->\n\n## I. 前言\n\n结构分析是文档处理中最重要方面之一。它包括物理和逻辑布局分析，也包括对复杂结构化布局的解析或识别，如表格、收据和表单等。尽管在文档物理和逻辑布局分析方面已经做了很多研究工作，但仍然有很多空间可以为解析这些结构化布局做出贡献，例如表格。表格提供了一种直观且自然的方式将数据以人类易于理解的形式呈现出来。基于其重要性和难度水平，表格结构分析吸引了大量研究人员在这个领域做出贡献。  \n\n表格检测和识别是一个老问题，研究始于九十年代末。最初的工作之一是由Kieninger等人完成的[1]。他们使用基于启发式算法的单词边界框进行自下而上的方法。后来，许多手工制作特征的方法被引入，包括[2],[3],[4]和[5],这些方法依赖于定制设计的算法。Zanibbi等人[6]的综述对当时表格检测和结构识别算法进行了全面的调查。[7]提出了一个方法，该方法将每个单元格分为标题、标题或数据单元格。Shafait等人[8]做了大量工作，在那里他们引入了不同的性能度量来表征表格检测问题。这些方法不是基于数据驱动的，并且它们对表格结构做出了强烈的假设。\n\nChen等人[9]使用支持向量机和动态规划检测手写文档中的表格。Kasar等人[10]也使用SVM在规则线上检测表格。Hao等人[11]使用松散的规则提取表格区域，并使用CNN对区域进行分类。他们还使用PDF文本信息来改进模型结果。Rashid等人[12]使用每个单词的位置信息，通过密集神经网络将其分类为表格或非表格。\n\n从2016年开始，研究开始转向使用深度学习模型来解决挑战。在2017年，许多论文使用对象检测或分割模型对表格进行检测和解析。Gilani等人[13]利用图像中的距离变换编码信息，并应用Faster RCNN[14]到这些图像上。Schreiber等人[15]也使用Faster RCNN进行表格检测和行列的提取。对于解析，他们将对象检测算法应用于垂直拉伸文档图像。利用表格属性，Arif等人[16]提出通过彩色代码文档图像以区分数值文本并应用更快的RCNN提取表区域。同样地，Siddique等人[17]提出了一个端到端的Faster-RCNN管道用于表格检测任务，并使用变形卷积神经网络作为特征提取器，因为它可以根据输入调整其接收域的能力。He等人[19]将文档图像分为三类：文本、表格和图表。他们提出使用条件随机场（CRF）来改善基于轮廓边缘检测网络输出的全卷积网络（FCN）的结果。Kavasidis等人[20]使用全卷积神经网络提取的突出性地图上的CRFs来检测表格以及不同类型的图表。\n\n尽管许多研究人员已经表明基于目标检测的方法对表检测和识别的效果很好，将解析问题定义为对象检测问题很难，尤其是文档是通过相机拍摄的并且包含透视畸变。像 [15] 这样的方法部分解决了这个问题，但它仍然不是一个自然的方法。这也使得使用进一步特征变得更加困难，这些特征可以独立提取，例如语言特征可能暗示存在表格的存在。 \n\n![image-20240827190912667](/img/gnn/image-20240827190912667.png)\n\n图1：不同难度类别的图像。第1类图像是没有合并且有格线的普通图像。第2类添加了不同的边框类型，包括偶尔缺少分界线。第3类是最难引入单元格和列合并的类别。第4类模型通过线性透视变换拍摄的图像。\n\n ![image-20240827190635682](/img/gnn/image-20240827190635682.png)\n\n图2：我们的架构的图形表示。对于文档图像，使用CNN模型提取特征映射，并且使用OCR引擎或oracle（+）提取单词的位置。相应的图像特征与单词位置结合形成输入特征（*）。将输入特征应用到交互网络以获得代表性的特征。对于每个单词，单独对单元格、行和列进行采样。每个样本对的代表性特征再次连接并用作密集网络的输入。这些密集网络根据共享行、列和单元格的不同而不同。在训练期间仅进行采样，在推理期间每对单词进行分类。  \n\n在本文中，我们使用图论来定义问题，并将其应用于图神经网络。Scarselli等人[21]对图神经网络的最初研究之一是基于收缩映射提出了一种全面的图模型。近年来，由于计算能力的增加和新方法的引入，它们获得了很大的关注。许多值得注意的工作包括[22],[23],[24]。Battaglia等人[25]认为，关系归纳偏置是实现类人智能的关键，并展示了图神经网络对其至关重要。\n\n文档处理中使用图（机器学习）并不是新鲜事。已经发表了许多论文，其中采用基于图的模型来解决各种问题。Liang等人[26]引入了一种类似于树状结构的文档解析层次结构。王[27]的工作获得了很大的流行度，并且被许多研究人员之后所使用。Hu等人[28]介绍了一个全面的图模型，其中包括一个有向无环图（DAG）以及对表格元素的各种详细定义。最近，Koci等人[29]提出了一种方法，在该方法中他们将信息编码为图形式。随后，他们使用了新提出的基于规则的删除和征服算法。Bunke等人[30]提供了关于文档分析背景下不同图技术的详细分析。这些方法对底层结构做出了强烈的假设，这与深度学习的哲学相矛盾。尽管我们不是第一个使用图来处理文档的人，但据我们所知，我们是第一个将图神经网络应用于我们的问题（表格识别）中。我们在表格识别问题上进行了实验，然而，这个新的问题定义适用于文档结构分析中的各种其他问题。我们的方法有两个优点。首先，它更加通用，因为它不作任何关于结构的强假设，并且与人类如何解读表格非常接近，即通过匹配数据单元格到其标题。其次，它允许我们利用最近有很多推动作用的图神经网络。\n\n特别地，我们做出了以下贡献：\n\n1. 将表格识别问题转化为与图神经网络兼容的图问题。  \n\n2. 设计了一个新颖的可微分架构，该架构从图像特征提取的卷积神经网络和高效交互的图神经网络中受益。\n3. 介绍一种基于蒙特卡洛的新技术，以减少训练所需的内存要求。  \n4. 通过引入合成数据集来填补大规模数据集的空白。  \n5. 在两个最先进的基于图的方法上运行测试，并实验证明它们比基线网络表现更好。  \n\n\n\n## II. 数据集\n\n目前，研究社区已经发布了几个表格检测和结构识别的数据集，包括UW3、UNLV [31] 和ICDAR 2013表格竞赛数据集 [32]。然而，这些数据集的规模有限。这可能会导致深度神经网络过拟合，并且导致较差的一般化能力。许多人尝试了诸如转移学习等技术，但这些技术无法完全抵消大规模数据集的实用性。  \n 我们提供了一个合成生成的大型数据集，该数据集分为四个类别，如图1所示。为了生成这个数据集，我们使用了Firefox和Selenium来渲染合成生成的HTML。我们注意到合成数据集生成并不是新的，并且类似的工作[2]已经做过。尽管从我们的数据集中很难泛化算法到真实世界中，但数据集为研究不同的算法提供了标准基准，直到创建大规模的真实世界数据集为止。我们也发布了我们的代码以生成进一步的数据，如果需要的话。  \n\n## III. 图模型\n\n考虑到表格识别的问题，将真实值定义为三个图，其中每个单词是一个顶点。这三个图的邻接矩阵分别代表了这三种共享关系，即行、列和单元格共享。因此如果两个顶点共享一行，即这两个词属于同一行，则这些顶点被认为是相邻的（同样适用于单元格和列共享）。  \n\n深度模型的预测也是以三个邻接矩阵的形式进行。在获得邻接矩阵后，通过解决行和列的最大子集问题以及单元格的连通分量问题，可以重建完整的单元、行和列。如图3所示。  \n\n该模型不仅适用于表格识别问题，还可以用于文档分割。在这种情况下，如果两个顶点（可以是单词）共享相同的区域，则它们相邻。这些区域也可以通过最大子图问题进行重建。  \n\n![image-20240827192521319](/img/gnn/image-20240827192521319.png)\n\n图3：使用最大子集重构结果的列和行段。上图显示了列子集，下图显示了行子集。注意这两个图中的合并顶点，它属于多个子集。  \n\n## IV、方法\n\n所有测试模型都遵循相同的父模式，如图2所示，分为三个部分：用于提取图像特征的卷积神经网络、用于顶点之间通信的交互网络以及分类部分，该部分将每个三张图中的每对顶点标记为相邻或不相邻（类0或类1）。  \n\n前向传播的算法也给出在算法1中。它接受图像（$I∈R^{h×w×c}$ ——其中h，w和c分别表示输入图像的高度、宽度和通道数），位置特征（$F_p∈R^{v×4}$ ——其中v代表顶点的数量）和其他特征$F_o∈R^{v×o}$。此外，在训练过程中还接受每个顶点的样本数量 $s∈R$ 以及三个邻接矩阵（$A_{cells}∈{0，1}^{v×v}$，$A_{rows}∈{0，1}^{v×v}$ 和 $A_{cols}∈{0，1}^{v×v}$）。所有参数函数都用$f$表示，非参数函数用$g$表示。如果所有的参数函数都是可微分的，则整个架构也是可微分的，并且因此与反向传播兼容。  \n\n位置特征包括每个顶点的上左角和下右角坐标。其他特征仅包含单词在我们情况下的长度。然而，在实际数据集中，自然语言特征（34）也可以附加，这可能提供额外的信息。  \n\n1）卷积神经网络：一个卷积神经网络（$f_{conv}$）以图像（I）为输入，并且作为输出，它生成相应的卷积特征（$I_f∈R^{h'×w'×q}$——$w',h'$ 和 $q$ 分别表示卷积特征映射的宽度、高度和通道数）。为了保持参数计数低，我们设计了一个浅层CNN；然而，任何标准架构都可以用作其替代品。在CNN的输出端，进行一个聚集操作（$g_{gather}$），收集每个单词对应的卷积特征，这些特征对应于图像中的空间位置，并形成聚集特征（$F_{im}∈R^{v×q}$）。由于卷积神经网络是平移不变的，这个操作效果很好。如果输出特征的空间维度与输入图像不相同（例如，在我们的案例中，它们被缩小了），则根据输入和输出维度的比例线性缩放收集位置。将卷积特征扩展到其余顶点特征（$g_{ext}$）。  \n\n 2）交互：在收集所有顶点特征后，它们被作为输入传递给交互模型（$f_{int}$）。我们测试了两种图神经网络来用作交互部分，分别是修改后的[35]和[36]。这些修改的网络分别称为DGCNN* 和GravNet*。除了这三种之外，我们也测试了一个基于全连接神经网络的基线密集网络（简称FCNN），它与上述三个模型具有大致相同的参数数量，以显示基于图的模型表现更好。对于这三个模型，我们将总参数数限制为100万，以便进行公平比较。这个参数数也包括前面CNN和后续分类密集网络的参数。输出是每个顶点的代表性特征（$F_{rep}∈R^{v×r}$——r代表代表性特征的数量），用于分类。  \n\n3）运行时对偶采样：为每个单词对进行分类是一个内存密集型操作，其内存复杂度为$O(N_2)$。由于它会随着批处理大小线性增长，因此内存要求进一步增加。为此，我们采用了蒙特卡罗采样方法。索引采样函数表示为$g_{sample}$。该函数将为每个问题（单元格共享、行共享和列共享）的每个顶点生成固定数量的样本（s）。  \n\n统一采样高度偏向于类0。由于内存限制，我们不能使用大批次大小，因此统计数据不足以区分两个类别。为了处理这个问题，我们将采样分布（$P_{samples}$）更改为每个顶点平均为每个顶点采样等数量的元素类0和类1。这可以通过在算法1中所示的方式轻松地矢量化实现。请注意，在算法中J表示一个全1矩阵。对于每个顶点的三个类，分别收集一组样本（$S_{cells}∈Z^{v×t}$，$S_{rows}∈Z^{v×t}$， $S_{cols}∈Z^{v×t} $。这些矩阵中的值代表每个顶点对样本的索引。然而，在推理过程中，我们不需要采样，因为我们不需要使用mini-batch方法。因此，我们对每个顶点对都这样做。所以，在训练期间 $t=s$，在推理期间 $t=v$。  \n\n<img src=\"/img/gnn/image-20240827193037358.png\" alt=\"image-20240827193037358\" style=\"zoom:80%;\" />\n\n4）分类：在采样之后，将交互模型的输出特征向量（$F_{int}$）中的元素与采样矩阵中的元素进行拼接（$g_{cat}$），并将其与（$f_{cells}$，$f_{rows}$ 和 $f_{cols}$）相乘。这些函数是参数化的神经网络。作为输出，我们得到三个集合的logits $L_{cells}∈R^{v×t×2}$、$L_{rows}∈R^{v×t×2}$和$L_{cols}∈R^{v×t×2}$。它们可以用于计算损失并通过函数反向传播，也可以用于预测类别，并形成最终的邻接矩阵。 \n\n## V 结果\n\nShahab等人[37]定义了一组用于详细评估表格解析和检测结果的度量标准。他们定义了正确和部分检测的标准，并定义了一个规则来标记元素为未分割、过度分割和遗漏。在他们的标准中，有两个与我们的案例最相关，即检测到的真实正例占真实正例总数的比例（真阳性率）以及预测的元素中没有匹配项的个数（假阳性率）。在我们的案例中，如第三节所述，元素是簇。因此，真阳性率和假阳性率分别计算在三个图上（单元格、行和列），然后对整个测试集进行平均。这些结果见表I和表II。\n\n此外，我们还引入了另一个措施，即完美匹配，如表III所示。如果所有三个预测的邻接矩阵都与地面真值中的相应矩阵完全匹配，则解析的表被标记为端到端准确。这是一个严格的指标，但它显示了由于类不平衡问题导致基于单个表元素计算的统计结果是多么误导性。  \n\n正如预期的那样，由于FCNN中没有顶点之间的交互，因此其性能不如图模型。但是请注意，在此网络中的顶点并非完全分离。它们仍然可以在卷积神经网络部分进行通信。这为将图神经网络进一步引入文档分析奠定了基础。\n\n![image-20240827193955209](/img/gnn/image-20240827193955209.png)\n\n图4：显示DGCNN模型的预测（细胞、行和列）。图4 (a) 显示了细胞的预测。单个单元格中的所有单词都被分配相同的颜色。图4 (b) 显示了行的预测。属于同一行的单词被分配相同的颜色，跨多个行（簇）的单词被条纹色覆盖。同样地，图4 (c) 显示了列的预测。\n\n![image-20240827194024636](/img/gnn/image-20240827194024636.png)\n\n\n图5：显示了随机选择的橙色顶点的DGCNN*模型预测（细胞、行和列邻居）。图5 (a) 显示了细胞预测。所有与随机顶点共享单元格的顶点都用绿色表示，而那些不相邻的则用蓝色表示。同样地，图5 (b) 和图5 (c) 分别显示了行和列共享图中的相邻邻居。\n\n\n与第4类表格相比，第3类表格的结果相对较差。这是因为类别4图像也包含来自类别的1和2以研究透视失真对简单图像的影响。我们得出结论，尽管图形网络在合并行和列方面存在困难，但它们优雅地处理了透视失真。\n\n## VI 结论与未来工作\n\n在这项工作中，我们使用图模型重新定义了结构分析问题。我们在表格识别问题上展示了我们的结果，并且我们也论证了几种其他文档分析问题如何可以使用这个模型来定义。卷积神经网络最适合于寻找代表图像特征，而图网络最适合于快速消息传递在顶点之间。我们已经表明我们可以将这两种能力结合起来使用聚集操作。到目前为止，我们只使用位置特征为顶点，但是对一个真实世界的数据集，自然语言处理特征如GloVe也可以使用。总之，图神经网络对于结构分析问题工作得很好，我们期待在未来几年内看到更多关于这方面研究的进展。  ","comments":true,"categories":[],"tags":[{"name":"GNN","slug":"GNN","permalink":"http://blog.ahulearn.com/tags/GNN/"},{"name":"ICDAR 2019","slug":"ICDAR-2019","permalink":"http://blog.ahulearn.com/tags/ICDAR-2019/"}]},{"title":"Graph Attention Networks","date":"2024-08-21T09:21:00.000Z","path":"2024/08/21/Graph Attention Networks/","raw":"---\ntitle: Graph Attention Networks\ndate: 2024-08-21 17:21:00\ntoc: true\ntags:\n - GAN\n - ICLR 2018\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\\gan\n---\n\n图形注意力网络\n---------------\n\n会议: ICLR 2018\n\n论文地址：https://paperswithcode.com/paper/graph-attention-networks\n\ngithub: https://github.com/PetarV-/GAT\n\n开源库：[PyG](https://pytorch-geometric.readthedocs.io/en/latest/)\n\n---\n\n\n\n[TOC]\n\n## 摘要\n\n本文提出一种新的神经网络架构——图注意力网络（GAT），该网络可以处理具有图形结构的数据，并利用掩码自注意层来解决基于图卷积或其近似方法的先前方法的不足之处。通过将节点能够关注邻居特征的层堆叠起来，我们可以隐式地为邻居中的不同节点指定不同的权重，而无需进行任何昂贵的矩阵操作（如求逆）或依赖于事先知道图结构。这样，我们同时解决了谱基图神经网络模型的一些关键挑战，并使我们的模型适用于归纳和推断问题。实验结果表明，在四个已建立的归纳和推断图基准数据集上，GAT模型已经达到了或匹配了最先进的结果：Cora、Citeseer和Pubmed引用网络数据集以及一个蛋白质相互作用数据集（其中测试图在训练期间未被看到）。\n\n<!--more-->\n\n## 1 简介\n\n卷积神经网络（CNN）已成功应用于诸如图像分类，语义分割或机器翻译等问题，在这些问题中，底层数据表示具有网格状结构。 这些架构通过将其应用于所有输入位置来有效地重复使用可学习参数的本地滤波器。 \n\n然而，许多有趣的任务涉及的数据不能用网格结构来表示，而是在不规则域中。这种情况包括三维网格、社交网络、电信网络、生物网络或大脑连接组。这种数据通常可以以图形的形式呈现。 \n\n在文献中已经有过一些尝试，将神经网络扩展到处理任意结构的图。早期的工作使用循环神经网络来处理以有向无环图表示的数据领域。图神经网络（GNN）由Gori等人（2005）、Scarselli等人（2009）引入，作为循环神经网络的一般化，可以直接处理更一般的图类型，例如循环、有向和无向图。图神经网络包括一个迭代过程，该过程传播节点状态直到达到平衡；然后通过神经网络基于每个节点的状态为每个节点产生输出 。李等人(2016)采纳并改进了这一想法，建议在传播步骤中使用门控循环单元(Cho等人，2014)。 \n\n然而，人们越来越有兴趣将卷积推广到图领域。这方面的进展通常被归类为谱方法和非谱方法。 \n\n一方面，谱方法使用图的谱表示，并已成功应用于节点分类。在 Bruna等人（2014）的工作中，卷积操作是在傅里叶域中定义的，通过计算图拉普拉斯矩阵的特征分解来实现，这可能导致大量的计算和非空间局部滤波器。后来的研究解决了这些问题。Henaff 等人。（2015）引入了具有平滑系数的谱滤波器参数化，以使它们在空间上局部化。随后，Defferrard 等人。（2016）提出通过图拉普拉斯矩阵的 Chebyshev 展开近似滤波器，从而避免了计算拉普拉斯特征向量的需求，并产生了空间局部化的滤波器。最后，Kipf 和 Welling（2017）通过限制滤波器仅在每个节点周围的一个步骤内运行来简化了此先前的方法。然而，在上述所有谱方法中，学习到的滤波器依赖于拉普拉斯本征基，而拉普拉斯本征基又取决于图结构。因此，基于特定结构训练的模型不能直接应用于具有不同结构的图。 \n\n另一方面，我们有非频谱方法（Duvenaud et al.，2015；Atwood & Towsley，2016；Hamilton et al.，2017），它在图上直接定义卷积操作，在空间接近邻居组上进行操作。这些方法中的一些挑战包括如何为不同的大小邻域定义一个算子，并保持卷积神经网络的权重共享特性。在某些情况下，这需要为每个节点度数学习一个特定的权重矩阵（Duvenaud et al.，2015），使用过渡矩阵的幂来定义邻域，同时为每个输入通道和邻域度数学习权重（Atwood & Towsley，2016），或者提取并归一化包含固定数量节点的邻域（Niepert et al.，2016）。Monti等人（2016）提出了混合模型CNN（MoNet），这是一种为空间提供CNN架构统一泛化的空间方法。最近，Hamilton等人（2017）引入了GraphSAGE，这是一种用于递归采样的归纳近似的方法。该技术通过从每个节点采样一个固定大小的邻域，然后对其进行聚合（例如对所有采样邻居特征向量求平均值或将它们馈送到循环神经网络中）来实现。这种方法在几个大规模递归样本基准测试中表现出色。 \n\n注意力机制已成为许多基于序列的任务的事实标准（Bahdanau等，2015年；Gehring等，2016年）。注意力机制的一个好处是它允许处理可变大小的输入，并关注输入中产生决策的相关部分。当使用注意力机制来计算单个序列的表示时，通常称为自注意或内注意。与递归神经网络（RNN）或卷积一起，自注意已被证明对于机器阅读理解（Cheng等，2016年）和学习句子嵌入（Lin等，2017年）等任务很有用。然而，Vaswani等人。 (2017) 表明，不仅自我注意可以改进基于循环神经网络或卷积的方法，而且自我注意足以构建一个强大的模型，在机器翻译任务上达到最先进的性能。 \n\n受最近这项工作的启发，我们提出了一种基于注意力机制的架构来对图结构数据进行节点分类。其思想是在遵循自注意力策略的情况下，通过关注每个图中节点的邻居来计算它们的隐藏表示。这种注意力架构有几个有趣的性质：（1）操作效率高，因为可以在节点邻居对之间并行化；（2）可以通过为邻居指定任意权重来应用于具有不同度数的图节点；以及（3）该模型可以直接应用于归纳学习问题，包括模型必须推广到完全未见过的图的任务。我们在四个具有挑战性的基准测试集上验证了所提出的方案：Cora、Citeseer 和 Pubmed 引用网络，以及一个归纳蛋白质相互作用数据集，并取得了与最先进的结果相媲美的效果，这突显了当处理任意结构的图时，基于注意力的模型的潜力。 \n\n值得注意的是，我们的工作也可以被重新解释为MoNet（Monti等人，2016）的一个特例。此外，我们共享神经网络边计算的方法类似于关系网络 (Santoro 等人，2017) 和 VAIN（Hoshen，2017） 的公式化方法，其中通过使用共享机制对对象或代理之间的关系进行逐对聚合。同样，我们提出的注意力模型可以与 Duan 等人的工作（2017）和 Denil 等人的工作（2017）相连接，这些工作使用邻域注意力操作来计算环境中不同对象之间的注意力系数。其他相关方法包括局部线性嵌入（LLE）(Roweis & Saul, 2000) 和记忆网络（Weston et al.，2014）。LLE 在每个数据点周围选择固定数量的邻居，并为每个邻居学习一个权重系数以将其重建为邻居的加权总和。第二个优化步骤提取该点的特征嵌入。记忆网络也与我们的工作有一些联系，特别是如果我们将节点的邻域解释为其内存，则可以使用它来计算节点功能，通过对它的值进行关注，然后通过将其新特性存储在同一位置来进行更新。 \n\n## 2. GAT 架构\n\n在这一部分，我们将介绍用于构建任意图注意力网络的基础层（通过堆叠该层），并直接概述它与神经图处理领域中现有工作的理论和实际好处和局限性。\n\n### 2.1 图注意力层\n\n我们将从描述单个图注意力层开始，该层在整个实验中用于所有GAT架构。我们使用的特定注意力设置与Bahdanau等人（2015）的工作非常相似——但框架对选择的注意力机制不敏感。 \n\n我们的层输入是一组节点特征，即 $h = {\\vec{h}_1, \\vec{h}_2,..., \\vec{h}_N}$，其中 $h_i \\in R^F$，N是节点数，F是每个节点的功能数。该层产生一个新的节点特征（可能具有不同的基F’），$h'={\\vec{h'}_1, \\vec{h'}_2,..., \\vec{h'}_N}$， $\\vec{h'}_i∈R^{F'}$ 作为输出。 \n\n为了获得足够的表达能力，以将输入特征转换为更高层次的特征，至少需要一个可学习的线性变换。为此，在初始步骤中，对每个节点应用共享的线性变换，由权重矩阵$W∈R^{F'×F}$参数化。然后在节点上执行自注意力——共享注意机制a：$R^{F'}×R^{F'}→R$ 计算注意力系数:\n\n![image-20240827201542709](/img/gan/image-20240827201542709.png)\n\n这表明节点 j 的特性对节点 i 有多么重要。在最一般的形式中，模型允许每个节点关注其他所有节点，放弃所有结构信息。我们通过执行遮蔽注意力来注入图结构到机制中——我们只计算 $N_i$ 中的节点 j 对应的 $e_{ij}$ ，其中 $N_i$ 是图中节点 i 的一些邻居。在我们的所有实验中，这些将是节点 i（包括 i）的 首先邻域。为了使系数在不同节点之间易于比较，我们使用 softmax 函数在所有选择 j 上对其进行归一化： \n\n![image-20240827201725207](/img/gan/image-20240827201725207.png)\n\n在我们的实验中，注意机制 是一个单层前馈神经网络，由权重向量 $\\vec{a}∈R^{2F'}$ ，并应用LeakyReLU （负输入斜率α=0.2 ）作为非线性激活函数。展开后，注意力机制计算出的系数（如图 1 (左) 所示）可以表示为： \n\n![image-20240827201739320](/img/gan/image-20240827201739320.png)\n\n其中 $T$ 代表转置，$||$ 是拼接运算。 \n\n一旦获得，归一化的注意力系数被用来计算它们对应的特征的线性组合，作为每个节点的最终输出特征（在潜空间应用非线性函数σ之后）：\n\n![image-20240827201846655](/img/gan/image-20240827201846655.png)\n\n为了稳定自注意力学习过程，我们发现将其扩展到多头注意力机制中是有益的，就像 Vaswani等人（2017）所做的那样。具体来说，K个独立的注意力机制执行方程4中的变换，然后它们的特征被连接起来，得到下面的输出特征表示：\n\n![image-20240827201855208](/img/gan/image-20240827201855208.png)\n\n其中，||表示连接操作，$α^k_{ij}$ 是由第 k 个注意力机制（$a^k$）计算得到的归一化注意力系数，$W^k$ 是对应的输入线性变换权重矩阵。请注意，在这种设置下，每个节点的最终返回输出 h' 将包含 $KF'$ 个特征（而不是 F'）。 特别地，如果我们在网络的最后一层（预测）上执行多头注意力，那么了连接操作就不再有意义了——相反，我们使用平均值，并且在那时才应用最终的非线性函数（通常为分类问题的softmax或logistic sigmoid）：\n\n![image-20240827201908060](/img/gan/image-20240827201908060.png)\n\n图 1 （右）显示了多头注意力层的聚合过程。\n\n![image-20240827201832774](/img/gan/image-20240827201832774.png)\n\n图1：左：我们的模型中采用的注意力机制a（Whhi，Whhj），由权重向量a∈R2F参数化，并应用LeakyReLU激活。右：节点1在其邻域上的多头注意力（K = 3个头）。不同的箭头样式和颜色表示独立的注意力计算。每个头的聚合特征通过连接或平均来获得h。1。 \n\n### 2.2 与相关工作的比较\n\n本节 2.1 中描述的图注意力层直接解决了神经网络处理图形结构数据时遇到的一些问题： \n\n+ 从计算的角度来看，它非常有效率：自注意力层的操作可以并行化到所有边缘上，输出特征的计算也可以并行化到 所有节点。不需要特征值分解或类似的昂贵矩阵操作。单个GAT注意力头计算'F'功能的时间复杂度可以表示为$O(|v|FF'+|E|F'）$，其中F是输入特征的数量，|V|和|E|分别是图中节点和边的数量。这种复杂性与基线方法相同，例如图形卷积网络（GCNs）(kipf & welling, 2017)。应用多头注意力会将存储和参数要求乘以一个因子K，而各个头部的计算完全独立，并且可以并行化。\n+  与GCN不同，我们的模型允许（隐式）为同一邻域中的节点分配不同的重要性，从而提高了模型的能力。此外，分析学习到的注意力权重可能会带来可解释性的优势，就像在机器翻译领域一样（例如Bahdanau等人对2015年的定性分析）。 \n+ 注意力机制以共享的方式应用于图中的所有边，因此它不依赖于提前访问全局图结构或其所有节点（许多先前技术的局限性）。这有几个可取之处：\n  +  图不一定要是有向的（如果不存在从顶点 j 到顶点 i 的边，我们可以简单地忽略计算αij）。\n  +  它使我们的技术可以直接应用于 *归纳* 学习，包括模型在训练过程中完全没有见过的图上进行评估的任务。 \n+ 最近由汉密尔顿等人(2017)提出的方法对每个节点采样一个固定大小的邻域，以保持计算开销一致；这使得在推理过程中无法访问整个邻域。此外，当使用基于LSTM (Hochreiter & Schmidhuber, 1997) 的邻居聚合器时，该技术取得了最强的结果。这假设了不同邻域之间存在一致的时间顺序节点排列，并且作者通过始终向 LSTM 提供随机排序的序列来纠正这一点。我们的方法不会受到这两种问题的影响——它会处理所有邻域（代价是在可变计算开销的情况下），并且不假定其中任何一种顺序。 \n+ 正如第 1 节所述，GAT 可以被重新表述为 MoNet 的一个特例（Monti 等人，2016）。具体来说，将伪坐标函数设置为 $u(x,y)=f(x)||f(y)$，其中 $f(x)$  表示节点 x 的特征 (潜在地通过 MLP 进行变换)，|| 是连接操作；权重函数设为$w_j(u) = softmax(MLP(u)) $（对整个节点邻域进行 softmax 操作），这会使 MoNet 的patch算子与我们的相似。然而，需要注意的是，与之前考虑过的 MoNet 实例相比，我们的模型使用了节点特征来进行相似性计算，而不是节点的结构属性（即假设提前知道了图结构）。 \n\n我们能够构建一个版本的GAT层，它利用稀疏矩阵操作，将存储复杂性降低到与节点数和边数线性相关的，并使GAT模型能够在更大的图数据集上运行。然而，我们使用的张量操纵框架只支持对阶数为2的张量进行稀疏矩阵乘法，这限制了该层的批量处理能力（尤其是对于包含多个图的数据集）。适当地解决这一约束是未来工作的重要方向。根据图结构的规律性，GPU在这些稀疏情况下可能无法比CPU提供显著的性能提升。还应该注意的是，我们的模型的“感受野”的大小由网络深度所界定（与GCN和类似的模型相似）。可以很容易地应用诸如跳过连接（He等人，2016）等技术来适当扩展深度。最后，在所有图边缘上并行化，特别是在分布式方式下，可能会涉及大量冗余计算，因为感兴趣的图中邻域通常高度重叠。\n\n\n\n## 3 实验评估\n\n我们在四个基于图的标准基准任务（推断）上，对 GAT 模型进行了与多种强大的基线和先前方法的比较评估。 以及归纳法)，在所有这些方法中实现或匹配最先进的性能。 本节总结了我们的实验设置、结果，以及对 GAT 模型提取特征表示的大致定性分析。\n\n### 3.1 数据集\n\n**传导学习**  我们使用三个标准引用网络基准数据集——Cora、Citeseer 和 Pubmed（Sen 等，2008 年）——并密切遵循 Yang 等人（2016 年）的传导实验设置。在所有这些数据集中，节点对应于文档，边对应于（无向）引文。节点特征对应于文档的词袋表示中的元素。每个节点都有一个类别标签。我们只允许每类使用 20 个训练节点，但是为了遵守传导设置，训练算法可以访问所有节点的功能向量。对经过训练的模型的预测能力是在 1000 个测试节点上评估的，我们在验证目的时使用了另外 500 个节点（与 Kipf 和 Welling（2017）所使用的相同）。 Cora 数据集包含 2708 个节点、5429 条边、7 类和每个节点 1433 个特征。Citeseer 数据集包含 3327 个节点、4732 条边、6 类和每个节点 3703 个特征。Pubmed 数据集包含 19717 个节点、44338 条边、3 类和每个节点 500 个特征。 \n\n**归纳学习**  我们使用了蛋白质相互作用 (PPI) 数据集，其中包含对应于不同人类组织的图（Zitnik 和 Leskovec，2017）。该数据集包含 20 个训练图、2 个验证图和 2 个测试图。在训练过程中，测试图保持完全不可见。为了构造这些图，我们使用了 Hamilton 等人（2017）提供的预处理数据。每个图中的平均节点数为 2,372。每个节点有 50 个特征，由基因组定位集合、模式基因集和免疫学标签组成。来自分子签名数据库(Molecular Signatures Database)的基因本体(Gene Ontology)中每个节点集有 121 个标签收集自Subramanian等人，2005)，一个节点可以同时具有多个标签。 表 1 提供了数据集有趣特征的概述。\n\n表1：我们实验中使用的数据集摘要。\n\n|                     | Cora           | Citeseer       | Pubmed                        | PPI               |\n| ------------------- | -------------- | -------------- | ----------------------------- | ----------------- |\n| Task                | Transductive   | Transductive   | Transductive  19717(1  graph) | Inductive         |\n| #  Nodes            | 2708(1  graph) | 3327(1  graph) |                               | 56944(24  graphs) |\n| #  Edges            | 5429           | 4732           | 44338                         | 818716            |\n| #  Features/Node    | 1433           | 3703           | 500                           | 50                |\n| #  Classes          | 7              | 6              | 3                             | 121(multilabel)   |\n| #  Training Nodes   | 140            | 120            | 60                            | 44906(20  graphs) |\n| #  Validation Nodes | 500            | 500            | 500                           | 6514(2  graphs)   |\n| #  Test Nodes       | 1000           | 1000           | 1000                          | 5524(2  graphs)   |\n\n\n\n### 3.2 目前最先进的方法\n\n**传导学习**  在传导学习任务中，我们使用与Kipf＆Welling（2017）指定的一致的相同强大的基线和最先进的方法进行比较。 这包括标签传播 (LP) (Zhu 等人，2003)，半监督嵌入 (SemiEmb) (Weston 等人，2012)，流形正则化 (ManiReg) (Belkin 等人，2006)，基于skip-gram 的图嵌入 (DeepWalk) (Perozzi 等人，2014)，迭代分类算法 (ICA) (Lu 和Getoor，2003) 和Planetoid (Yang 等人，2016)。 我们还将我们的模型直接与GCN (Kipf 和Welling, 2017) 进行比较，以及使用高阶Chebyshev滤波器的图卷积模型(Deferrard等人，2016)，以及在Monti等人(2016)中介绍的MoNet模型。\n\n**归纳学习**  在归纳学习任务中，我们比较了四种不同的监督式GraphSAGE归纳方法，这些方法在Hamilton等人，(2017)年提出。这些方法提供了多种方法来聚合采样邻居内的特征： GraphSAGE-GCN（将图卷积风格的操作扩展到归纳设置）, GraphSAGE-mean（取 GraphSAGE-GCN（通过GCN聚合邻居特征向量）、GraphSAGE-LSTM（通过将邻居功能馈入LSTM进行聚合）和GraphSAGE-pool（对共享非线性多层感知器转换后的特征向量执行元素最大操作）。其他归纳方法要么在归纳设置中完全不适用，要么假设节点按顺序添加到单个图中，使其无法用于测试图在训练期间完全不可见的情况（例如PPI数据集）。 \n\n此外，对于这两个任务，我们提供了每个节点共享多层感知器（MLP）分类器的性能（根本没有包含图形结构）。\n\n### 3.3 实验装置\n\n**传导学习**  在传导学习任务中，我们使用了两层的GAT模型。其结构超参数已在 Cora 数据集上进行了优化，并在 CiteSeer 上重复使用。第一层由 K=8 个注意力头组成，每个头计算 F'=8 个特征（总计 64 个特征），后面跟着一个指数线性单元 (ELU) 非线性函数(Clevert 等人，2016)。第二层用于分类：一个单一的注意力头来计算 C 个特征（其中 C 是类的数量），后面跟着一个 softmax 激活。为了应对小规模训练集，我们在模型中广泛地应用正则化。在训练过程中，我们对 λ=0.0005 的 L2 正则化进行应用。此外，在两个层的输入以及归一化的注意力权重（这一点至关重要）处都应用了概率为 0.6 的dropout (Srivastava 等人，2014)。与 Monti 等人（2016 年）观察到的结果类似，我们发现在 PubMed 的训练数据大小（60 个示例）需要对 GAT 架构进行一些修改：我们应用了 K=8 个输出注意力头（而不是一个），并将 L2 正则化加强至 λ=0.001。否则，架构与用于 Cora 和 CiteSeer 的架构相同。 \n\n**归纳学习**  对于归纳学习任务，我们使用了三层 GAT 模型。前两层每层包含 K=4 个注意力头来计算 F'=256维 特征（总共 1024 维特征），后面跟着一个 ELU 非线性函数。最后一层用于 (多标签) 分类：有 K=6 个注意力头，每个头计算 121维 特征，然后求平均值并接上逻辑sigmoid 激活。这个任务的数据集足够大，因此我们发 现没有必要应用 L2 正则化或丢弃法——然而，我们在中间注意层之间成功地应用了跳 跃连接（He等人，2016）。在训练过程中，我们使用了包含 2 个图的批次大小。为了严格评估在这种情况下应用注意力机制的好处（即与近似 GCN 相比），当使用恒 定注意力机制a(x,y)=1时，我们也提供了相同结构的结果——这将为每个邻居分配相同的权重。 \n\n两个模型都使用 Glorot 初始化（Glorot 和 Bengio，2010 年）进行初始化，并使用 Adam SGD 优化器 (Kingma 和 Ba，2014 年) 在训练节点上最小化交叉熵。在PubMed中初始学习率为0.01，在所有其他数据集上的初始学习率为0.005。我们在验证节点上对交叉熵损失和准确度（推断）或微 F1 分数（归纳）采用早期停止策略，每个周期为100个时期。\n\n### 3.4 结果\n\n我们的比较评估实验的结果总结在表2和表3中。 \n对于*传导任务*，我们在 100 次运行后报告了我们方法在测试节点上的平均分类精度（标准差），并为最先进的技术重用了已在Kipf＆Welling（2017）和Monti等人（2016）中报道的指标。具体而言，对于基于Chebyshev滤波器的方法（Deferrard等人，2016），我们提供了最大报告性能，用于滤波器阶数K = 2和K = 3。为了公平地评估注意力机制的好处，我们进一步评估了一个计算64个隐藏特征的GCN模型，并尝试使用ReLU和ELU激活，并在100次运行后报告结果（作为GCN-64* ），这是所有三种情况下ReLU的结果。 \n\n表2:Cora、Citseeer和Pubmed的分类准确率结果总结。GCN-64*对应于计算64个隐藏特征的最佳GCN结果（使用ReLU或ELU）。\n\nTransductive\n\n| Method                              | Cora         | Citeseer     | Pubmed       |\n| ----------------------------------- | ------------ | ------------ | ------------ |\n| MLP                                 | 55.1%        | 46.5%        | 71.4%        |\n| ManiReg(Belkin  et al., 2006)       | 59.5%        | 60.1%        | 70.7%        |\n| SemiEmb(Weston  et al., 2012)       | 59.0%        | 59.6%        | 71.7%        |\n| LP(Zhu  et al., 2003)               | 68.0%        | 45.3%        | 63.0%        |\n| DeepWalk(Perozzi  et al., 2014)     | 67.2%        | 43.2%        | 65.3%        |\n| ICA(Lu&  Getoor, 2003)              | 75.1%        | 69.1%        | 73.9%        |\n| Planetoid(Yang  et al., 2016)       | 75.7%        | 64.7%        | 77.2%        |\n| Chebyshev(Defferrard  et al., 2016) | 81.2%        | 69.8%        | 74.4%        |\n| GCN(Kipf&  Welling, 2017)           | 81.5%        | 70.3%        | 79.0%        |\n| MoNet(Monti  et al., 2016)          | 81.7  ± 0.5% | —            | 78.8  ± 0.3% |\n| GCN-64∗                             | 81.4  ± 0.5% | 70.9  ± 0.5% | 79.0  ± 0.3% |\n| GAT(ours)                           | 83.0  ± 0.7% | 72.5  ± 0.7% | 79.0  ± 0.3% |\n\n对于*归纳任务*，我们在两个未见过的测试图中的节点上报告了微观平均F1分数， 平均10次运行后，复现Hamilton等人（2017）中已经报告的指标用于其他技术。具体来说，由于我们的设置是监督式的，我们与 监督式GraphSAGE方法 进行了比较。为了评估在所有邻居中聚合的好处，我们进一步提供了 (作为GraphSAGE*) 我们通过简单修改其体系结构(这是使用具有 [512, 512, 726] 特征的三层GraphSAGE-LSTM在每个层中计算，并且用于聚合邻居的128个特征)所能实现的最佳结果。最后，我们报告了我们恒定注意力GAT模型 (作为Const-GAT) 的10次运行的结果，以公平地评估注意机制相对于GCN类聚合方案的优势（具有相同架构）。 \n\n表3：以微平均F1分数为指标，对PPI数据集的结果进行总结。GraphSAGE∗ 是通过修改其架构可以获得的最佳 GraphSAGE 结果。Const-GAT 是一个与 GAT 架构相同的模型，但具有恒定注意力机制（为每个邻居分配相同的重要性；类似于 GCN 的归纳算子）。\n\nInductive\n\n| Method                                 | PPI                            |\n| -------------------------------------- | ------------------------------ |\n| Random                                 | 0.396                          |\n| MLP                                    | 0.422                          |\n| GraphSAGE-GCN(Hamilton  et al., 2017)  | 0.500                          |\n| GraphSAGE-mean(Hamilton  et al., 2017) | 0.598                          |\n| GraphSAGE-LSTM(Hamilton  et al., 2017) | 0.612                          |\n| GraphSAGE-pool(Hamilton  et al., 2017) | 0.600                          |\n| GraphSAGE∗                             | 0.768                          |\n| Const-GAT(ours)                        | 0.934  ± 0.006                 |\n| GAT(ours)                              | 0.973  ± 0.002                 |\n\n我们的结果成功地在所有四个数据集上实现了最先进的性能——这与我们在第2.2节中的讨论一致。具体来说，我们能够以1.5%和1.6%的差距提高GCN在Cora和Citeseer上的表现，表明给同一邻域的不同节点分配不同的权重可能是有益的。值得注意的是，在PPI数据集上取得的进步：我们的GAT模型比我们能够获得的最佳GraphSAGE结果提高了20.5%，证明了我们的模型具有归纳能力，并且可以通过观察整个邻域来利用更大的预测能力。此外，它比恒定注意力机制（Const-GAT，具有相同架构但具有常数注意力机制）改进了3.9%，再次直接证明了能够为不同的邻居分配不同权重的重要性。 \n\n我们还可以从定性的角度来研究学习到的特征表示的有效性——为此，我们在图 2 中展示了使用 t-SNE (Maaten & Hinton, 2008) 对 Cora 数据集预训练的 GAT 模型的第一层提取的特征表示进行变换后的结果。该表示在投影的二维空间中显示了可识别的聚类。请注意，这些聚类对应于数据集中的七个标签，验证了模型在 Cora 的七个主题类别上的判别能力。此外，我们还可视化了归一化注意力系数（所有八个注意力头平均）的相对强度。要正确解释这些系数（例如，Bahdanau 等人。2015年），需要对所研究的数据集有进一步的领域知识，并留给未来的工作。 \n\n![image-20240827202313901](/img/gan/image-20240827202313901.png)\n\n图2: Cora数据集上预训练GAT模型第一个隐藏层的计算特征表示的t-SNE图。节点颜色表示类。边缘厚度表示所有八个注意力头（$\\sum^K_{k=1}α^k_{ij}+α^k_{ji}$）节点i和j之间的聚集归一化注意力系数。\n\n\n\n## 4 结论\n\n我们提出了图注意力网络（GAT），这是一种新颖的卷积神经网络架构，用于处理图形数据，它利用了掩码自我关注层。这些模型中使用的所有图注意力层都具有计算效率（不需要昂贵的矩阵操作，并且可以在图的所有节点上并行计算），可以为同一邻域内不同大小的邻域分配不同的重要性，并且无需提前知道整个图结构——从而解决了许多先前谱方法中的理论问题。我们的注意力模型在四个公认的节点分类基准测试中成功实现了最先进的性能或匹配性能，包括归纳和推断（特别是当完全未见过的图用于测试时）。 \n\n有几个潜在的改进和扩展图注意力网络可以作为未来的工作，比如克服子节2.2中描述的实际问题，能够处理更大的批量大小。一个特别有趣的 研究方向 将是利用注意机制对模型进行深入分析，以提高其可解释性。此外，从应用的角度来看，将方法扩展到 图分类 而不是节点分类也是相关的。最后，将模型扩展到包含边特征（可能指示节点之间的关系）将使我们能够解决更广泛的问题。\n\n","comments":true,"categories":[],"tags":[{"name":"GAN","slug":"GAN","permalink":"http://blog.ahulearn.com/tags/GAN/"},{"name":"ICLR 2018","slug":"ICLR-2018","permalink":"http://blog.ahulearn.com/tags/ICLR-2018/"}]},{"title":"Semi-Supervised Classification with Graph Convolutional Networks","date":"2024-08-21T08:41:00.000Z","path":"2024/08/21/GCN_Semi-Supervised Classification with Graph Convolutional Networks/","raw":"---\ntitle: Semi-Supervised Classification with Graph Convolutional Networks\ndate: 2024-08-21 16:41:00\ntoc: true\ntags:\n - GCN\n - ICLR 2017\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\\gcn\n---\n\n基于图卷积网络的半监督分类（GCN）\n---------------\n\n\n会议: ICLR 2017\n\n论文地址：https://arxiv.org/abs/1609.02907\n\ngithub: https://github.com/tkipf/pygcn\n\n---\n\n\n\n[TOC]\n\n## 摘要\n\n本文提出了一种可扩展的方法来处理图结构数据上的半监督学习，该方法基于一种高效的卷积神经网络变体，它直接在图上操作。本文通过局部一阶近似谱图卷积，优化我们的卷积架构的选择。我们的模型与图中边的数量线性相关，并且可以学习编码了图的局部结构和节点特征的隐藏层表示。我们在引用网络和知识图数据库上的一系列实验中展示了我们的方法相比其他相关方法具有显著优势。\n\n<!--more-->\n\n## 1 简介\n\n我们考虑在图（如文献引用网络）中对节点（如文档）进行分类的问题，其中仅有一小部分节点有标签。这个问题可以被看作基于图的半监督学习，通过某种显式的基于图的正则化形式来平滑（迁移）标签信息到图中，例如，在损失函数中使用图拉普拉斯正则化项：\n\n![image-20240828110529296](/img/gcn/image-20240828110529296.png)\n\n式中，$L_0 $表示与图中带标签部分相关的监督损失。$f(·)$可以是类似于神经网络的可微函数，$λ$ 是一个权重因子，$X$ 是节点特征向量矩阵 $X_i$。$\\Delta = D-A$ 是无向图 $G(V, E) $的未归一化拉普拉斯算子，其中 $G$包含 N 个节点 $v_i∈V$，边 $(v_i, v_j)∈E$，邻接矩阵 $A∈R^{N×N}$（二进制或加权），度数矩阵 $D_{i,i}=∑_jA_{ij}$。公式 (1) 的推导基于假设：图中的连接节点可能具有相同的标签。然而，这个假设可能会限制建模能力，因为图的边不一定编码了节点的相似性，而是可能包含额外的信息。\n\n在本工作中，我们使用神经网络模型$f(X, A)$直接对图结构进行编码，并在有标签的所有节点上以监督方式训练目标$L_0$，从而避免在损失函数中显式引入基于图的正则化(归纳偏置)。 将$f(·)$ 概念化为图的邻接矩阵允许模型从监督损失$L_0$ 中传播梯度信息，并使其能够学习带有或不带有标签的节点表示。 \n\n我们的贡献有两方面。首先，我们引入了一种简单且行为良好的 **层次传播规则** 用于直接在图上操作的神经网络模型，并展示了如何从谱图卷积（Hammond等人，2011）的一阶近似中得到该规则。其次，我们展示了这种基于图的神经网络模型可以快速、可扩展的用于 图节点的半监督分类 。在多个数据集上的实验表明，与最先进的半监督学习方法相比，我们的模型在分类准确率和效率（以时钟时间衡量）方面都具有优势。\n\n\n\n## 2 快速图近似卷积\n\n在这一部分，我们为本文其余部分所使用的基于图的神经网络模型$f(X，A)$提供理论驱动（基础）。 我们考虑多层图卷积网络（GCN）具有以下层传播规则：\n\n![image-20240828110622809](/img/gcn/image-20240828110622809.png)\n\n在这里，$\\widetilde{A} = A + I_N $是无向图 G 包含了自连接的邻接矩阵，$I_N$ 是单位矩阵; $\\tilde D_{i,i} = ∑_j~A_{i,j}$，$W(l)$ 是一个特定层的可训练权重矩阵。$σ(\\cdot)$ 表示激活函数，如 $\\operatorname{ReLU}(\\cdot) = \\max(0,\\cdot)$。$H^{(l)} \\in \\mathbb{R}^{N\\times D}$ 是第$l$ 层的激活值矩阵；$H(0)=X$。在下面，我们将展示这种传播规则的形式可以通过对图的局部谱滤波的一阶近似来解释（Hammond等人，2011年；Defferrard等人，2016年）。\n\n\n\n### 2.1 谱图卷积\n\n我们考虑在图上进行谱卷积，定义为信号$x∈RN$（每个节点都是标量）与滤波器$g_θ=diag(θ)$的乘法，其中$θ∈R^N$ 在傅立叶(Fourier)域中，即： \n\n![image-20240828114415901](/img/gcn/image-20240828114415901.png)\n\n其中 $U$ 是归一化图拉普拉斯矩阵 $L=I_N−D^{−1/2}AD^{−1/2}=UΛU^T$，其中 Λ 是其特征值的对角线矩阵，且$ U^Tx$是 x 的图傅里叶变换。我们可以将 $g_θ$ 理解为关于 L 的特征值的函数，即 $g_θ(Λ)$。求解方程 (3) 非常昂贵，因为与特征向量矩阵 U 相乘需要 $O(N^2)$ 的计算量。此外，对于大型图来说，首先计算 L 的特征值分解可能非常昂贵。为了克服这个问题，Hammond等人(2011)建议通过截断Chebyshev多项式$T_k(x)$的级数来很好地近似$g_θ(Λ)$: \n\n![image-20240828114442499](/img/gcn/image-20240828114442499.png)\n\n其中，$~{\\boldsymbol \\Lambda} = 2/\\lambda_{\\max} \\times {\\boldsymbol \\Lambda}-\\boldsymbol I_N$。其中，$\\lambda_{\\max}$ 是 L 的最大特征值。$\\theta'$ 是 Chebyshev 样本系数向量。Chebyshev 多项式递归定义为：$T_k(x) = 2xT_{k-1}(x) - T_{k-2}(x)$，其中 $T_0(x) = 1$,  $ T_1(x) = x$。有关此近似式的详细讨论，请参阅 Hammond 等人(2011)。\n\n回到信号x与滤波器$g_{θ'}$的卷积定义，我们现在有： \n\n![image-20240828114629602](/img/gcn/image-20240828114629602.png)\n\n其中，$\\tilde L=2/λmax L−I_N$； 这可以通过注意到$(UΛU^T)^k=UΛ^kU^T$来轻松验证。 注意到这个表达式现在已经被K局部化了，因为它是一个关于拉普拉斯算子的K阶多项式，也就是说它只依赖于距离中心节点最多K步远的节点（K阶邻域）。 求解方程(5)的复杂度为$O(|E|)$，即图中边的数量线性增长。 Deferrard等人（2016）使用这种K局部卷积来定义图形上的卷积神经网络。\n\n### 2.2 层级线性模型\n\n因此，可以构建一个基于图卷积的神经网络模型，该模型由多个具有形式如等式(5)  的卷积层堆叠而成，每个层后跟一个点非线性。现在假设我们将 层之间的 卷积操作限制为$ K = 1$（参见等式 5），即一个关于 L 线性的函数，因此在图拉普拉斯谱上也是线性的函数。\n\n通过堆叠多个这样的层，我们仍然可以恢复一个丰富的卷积滤波器函数类，但我们不局限于由Chebyshev多项式等给出的显式参数化。 我们直观地期望这种模型能够缓解非常宽的节点度分布图（如社交网络、引文网络、知识图和许多其他现实世界图形数据集）上的局部邻域结构过拟合问题。 此外，在给定计算预算的情况下，这种分层线性建模使我们能够构建更深的模型，而众所周知，在许多领域中这可以提高建模能力(何等人，2016年)。 \n\n在 GCN 的线性公式中，我们进一步近似$λmax≈2$，因为我们可以预期神经网络参数将在训练过程中适应这种尺度变化。在这些近似下，方程（5）简化为： \n\n![image-20240828114755457](/img/gcn/image-20240828114755457.png)\n\n其中有两个自由参数$θ'_0$ 和$θ'_1$。 这个滤波器的参数可以应用在整个图上。 然后，连续应用这种形式的滤波器实际上有效地卷积了节点的k阶邻域，其中k 是神经网络模型中连续滤波操作或卷积层的数量。 \n\n实际上，为了应对过拟合问题并最小化每层的操作数量（如矩阵乘法），限制参数的数量可能更有益。 这给我们留下了以下表达式： \n\n![image-20240828114836943](/img/gcn/image-20240828114836943.png)\n\n其中 $θ = θ'_0=-θ'_1$。注意，$I_N + D^{−1/2}AD^{−1/2}$ 现在具有特征值范围 [0, 2]。因此，反复应用此算子可能导致在深度神经网络模型中使用时出现数值不稳定性和爆炸/消失梯度的问题。为了解决这个问题，我们引入了以下重新缩放技巧：$I_N + D^{−1/2}AD^{−1/2} →  \\tilde D^{−1/2} \\tilde A \\tilde D^{−1/2}$，其中 $\\tilde A = A + I_N $ 和 $\\tilde D_{ii} = \\sum_j \\tilde A_{ij}$。 \n\n我们可以推广这个定义，将其应用于一个信号$X \\in R^{N\\times C}$包含 C 个输入通道（即每个节点都有一个 C 维特征向量）和 F 个滤波器或特征图：\n$$\nZ = \\tilde D^{−1/2} \\tilde A \\tilde D^{−1/2} X Θ\n$$\n其中 $Θ \\in R^{C×F}$ 是一个滤波器参数矩阵，$Z∈R^{N×F}$ 是卷积信号矩阵。由于可以高效地实现 $\\tilde AX$ 的乘法运算，因此该滤波操作具有复杂度 $O(|E|FC)$。\n\n## 3. 半监督节点分类\n\n在引入了一个简单而灵活的模型 $f(X,A)$，用于高效地在图上传播信息后，我们可以回到半监督节点分类的问题。如引言中所述，我们可以通过使我们的模型 $f(X,A)$ 同时基于数据X和基本图形结构的邻接矩阵A来放松通常在基于图形的半监督学习中所做的某些假设。我们预计在这种设置下，在邻接矩阵包含数据X中不存在的信息的情况下，例如引用网络中的文档之间的引用链接或知识图谱中的关系时，该设置会特别强大。总体模型，多层GCN为半监督学习，用流程图1示意。\n\n### 3.1 示例\n\n在下面，我们考虑一个两层图卷积网络（GCN）用于具有对称邻接矩阵 A（二进制或加权）的图形半监督节点分类。首先我们在预处理步骤中计算估计的邻接矩阵：$\\hat{A}=\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}$。我们的前向模型采用简单的形式： \n\n![image-20240828142945194](/img/gcn/image-20240828142945194.png)\n\n式中，$W^{(0)} \\in R^{C\\times H}$ 是一个输入到隐藏层的权重矩阵，具有 H 个特征图。$W^{(1)} \\in R^{C\\times F}$ 是一个隐藏到输出的权重矩阵。softmax 激活函数定义为 $softmax(x_i ) = 1/Z \\times exp(x_i)$ ，其中 $Z = ∑_i exp(x_i)$ 。它被应用于每一行。对于半监督多类分类，我们计算所有标记示例的交叉熵误差： \n\n其中$Y_L$ 是有标签的节点索引集合。 \n\n神经网络权重 $W(0)$ 和 $W(1)$ 使用梯度下降进行训练。在本工作中，我们在每个训练迭代中使用整个数据集执行批量梯度下降，只要数据集适合内存，这是一个可行的选择。通过稀疏表示A，内存需求为$O(|E|)$，即与边数线性相关。通过dropout（Srivastava等人，2014）引入训练过程中的随机性。我们将在未来的工作中考虑具有 mini-batch 随机梯度下降的内存效率扩展。\n\n![image-20240828143058162](/img/gcn/image-20240828143058162.png)\n\n图 1：左：输入层通道数为C和输出层特征图为F 的多层图卷积网络 (GCN) 的示意图。图结构（用黑色线条表示）在各层共享，标签由 Y 表示。右：使用 5% 标签训练的两层 GCN 在 Cora 数据集（Sen 等人，2008 年）上的隐藏层激活的 t-SNE 可视化（Maaten 和 Hinton，2008）。颜色表示文档类别。 \n\n### 3.2 实现\n\n在实现时，我们使用 Abadi 等人 (2015) 的 TensorFlow 来实现一个基于 GPU 的高效的稀疏-稠密矩阵乘法来计算公式(9)的效率。公式(9) 的计算复杂度为 $O(|E|CHF)$ ，即图中边的数量呈线性增长。\n\n## 4. 相关工作\n\n我们的模型既受到基于图的半监督学习领域的启发，也受到最近关于在图上操作的神经网络的工作的启发。在接下来的内容中，我们将对这两个领域中的相关工作进行简要概述。\n\n### 4.1 基于图的半监督学习\n\n近年来，已经提出了许多使用图表示进行半监督学习的方法，其中大部分可以分为两大类：使用某种形式的显式图拉普拉斯正则化的方法和基于图嵌入的方法。图拉普拉斯正则化的著名例子包括标签传播（Zhu等人，2003年）、流形正则化（Belkin等人，2006年）和深度半监督嵌入（Weston等人，2012年）。 \n\n最近，注意力转向了使用启发自 skip-gram 模型（Mikolov 等人2013）的方法来学习图嵌入的模型。DeepWalk (Perozzi 等人2014)通过预测从图中随机游走采样到的节点的局部邻域来学习嵌入。LINE (Tang 等人，2015 年) 和 node2vec (Grover & Leskovec, 2016) 使用更复杂的随机游走或广度优先搜索方案扩展了 DeepWalk。然而，对于所有这些方法，都需要一个多阶段管道，包括生成随机游走和半监督训练，在每个阶段都必须单独优化。Planetoid (Yang 等人2016 )通过在嵌入学习过程中注入标签信息来缓解这种情况。\n\n### 4.2 图上的神经网络\n\n之前在Gori等人(2005); Scarselli等人(2009)中已经介绍了基于图的神经网络，作为一种循环神经网络的形式。他们的框架要求应用收缩映射作为传播函数，直到节点表示达到稳定不动点。随后Li等人,2016通过将现代循环神经网络训练方法引入到原始图形神经网络框架中来缓解了这一限制。Duvenaud等人,2015 在图上引入了一个类似于卷积的传播规则以及用于图分类的方法。他们的方法需要学习与节点度相关的权重矩阵，这并不适用于具有宽泛的节点度分布的大图。相反，我们的模型为每层使用一个权重矩阵，并通过适当归一化邻接矩阵来处理变化的节点度（见第3.1节）。 \n\nAtwood 和 Towles（2016 年）最近提出了一种使用基于图的神经网络对节点进行分类的近似方法。他们报告了 $O(N^2)$ 复杂度，限制了可能的应用范围。在不同的但相关的模型中，Niepert 等人（2016 年）将本地图形转换为序列，然后馈入常规 1D 卷积神经网络，这需要在预处理步骤中定义一个节点顺序。 \n\n我们的方法基于谱域图卷积神经网络，最初由 Bruna等人(2014)，后来由Defferrard等人(2016)通过快速局部卷积扩展。与这些工作不同的是，在这里我们考虑了在网络中进行归纳节点分类的任务。我们证明，在这种情况下，可以对 Bruna 等人的原始框架和Defferrard等人引入一些简化（见第2.2节），这提高了大规模网络中的可伸缩性和分类性能。\n\n## 5 实验\n\n我们在多个实验中测试了我们的模型：基于引用网络的半监督文档分类、从知识图谱中提取的二分图中的半监督实体分类、对各种图传播模型的评估以及在随机图上的运行时分析。\n\n### 5.1 数据集\n\n我们密切遵循 杨等(2016) 中的实验设置。数据集统计信息总结在表1中。在 引文网络数据集——CiteSeer、Cora 和 PubMed(Sen 等，2008)中——节点是文档，边是引文链接。标签比例表示用于训练的带标签节点数与每个数据集中所有节点总数之比。NELL(Carlson 等，2010；Yang 等，2016)是从知识图谱中提取出的二分图数据集，其中包含 55,864 个关系节点和 9,891 个实体节点。\n\nTable 1: Dataset statistics, as reported in Yang et al.(2016).\n\n| Dataset  | Type             | Nodes  | Edges   | Classes | Features | Label rate |\n| -------- | ---------------- | ------ | ------- | ------- | -------- | ---------- |\n| Citeseer | Citation network | 3,327  | 4,732   | 6       | 3,703    | 0.036      |\n| Cora     | Citation network | 2,708  | 5,429   | 7       | 1,433    | 0.052      |\n| Pubmed   | Citation network | 19,717 | 44,338  | 3       | 500      | 0.003      |\n| NELL     | Knowledge graph  | 65,755 | 266,144 | 210     | 5,414    | 0.001      |\n\n**引文网络**  我们考虑三个引文网络数据集：Citeseer、Cora 和 Pubmed（Sen 等，2008）。这些数据集包含每个文档的稀疏词袋特征向量以及文档之间的引用链接列表。我们把引文链接视为无向边，并构建一个二进制对称邻接矩阵A。每篇论文都有一个类别标签。在训练中，我们仅使用每个类别的20个标签，但所有特征向量都包含在内。 \n\n**NELL**  是一个从知识图中提取的数据集，该知识图由 (Carlson et al., 2010) 中介绍。知识图是由实体节点及其有向、带标签的边（关系）组成的集合。我们遵循了 Yang et al. (2016) 所描述的预处理方案。对于每个实体对 $(e_1, r, e_2)$，我们为它们分配单独的关系节点 $r_1 和r_2$，即 $(e_1, r_1)$ 和 $(e_2, r_2)$。实体节点由稀疏特征向量来表示。通过为每个关系节点分配唯一的 one-hot 表示，我们将 NELL 的特征数扩展到每个节点都有一个 61,278 维的稀疏特征向量。这里的半监督学习任务考虑的是训练集中每个类仅有一个标记示例的极端情况。我们根据图中的节点 i 和 j 之间是否存在一条或多条边来构建二进制且对称的邻接矩阵 $A_{ij}=1$。 \n\n**随机图**  我们模拟各种大小的随机图数据集进行实验，其中我们测量每个时期的训练时间。对于一个有N个节点的数据集，我们创建一个随机图，均匀地随机分配2N条边。我们将单位矩阵$I_N$作为输入特征矩阵X，从而隐式地采用无特征的方法，模型只知道每个节点的身份，由唯一的one-hot向量指定。我们为每个节点添加虚拟标签$Y_i = 1$。\n\n### 5.2 实验设置\n\n除非另有说明，我们在第 3.1 节中描述的两层图卷积网络进行训练，并在包含 1,000 个标记示例的测试集上评估预测准确性。我们在附录 B 中提供了使用深度模型（最多有 10 层）的额外实验。我们选择与 Yang 等人(2016)相同的拆分数据集，其中包含一个包含 500 个标记示例的验证集，用于超参数优化（所有层的丢弃率、第一层图卷积网络的 L2 正则化因子和隐藏单元数）。我们不使用验证集标签进行训练。 \n\n对于引用网络数据集，我们在 Cora 上优化超参数，并在 Citeseer 和 Pubmed 上使用相同的参数。我们使用 Adam (Kingma & Ba, 2015) 对所有模型进行训练，学习率为 0.01 ，最大训练轮数为 200 轮，并且使用包含 10 个元素的滑动窗口实现早停法，即如果验证损失连续 10 次没有下降，则停止训练。我们使用 Glorot & Bengio(2010) 中描述的初始化方法来初始化权重，并相应地对输入特征向量进行行归一化。对于随机图数据集，我们隐藏层大小设置为 32 个单元，省略了正则化（即不使用 dropout 或 L2 正则化）。\n\n### 5.3 基线\n\n我们与杨等人（2016）中使用的相同基线方法进行比较，即标签传播（LP）（Zhu等人，2003），半监督嵌入（SemiEmb）（Weston等人，2012），流形正则化（ManiReg）（Belkin等人，2006）和基于跳字词向量的图嵌入（DeepWalk）（Perozzi等人，2014）。 我们省略了TSVM（Joachims，1999），因为它无法扩展到我们的一个数据集中的大量类。 \n\n我们进一步与卢格托尔 (Lu & Getoor, 2003) 提出的迭代分类算法进行比较，该算法结合了两个逻辑回归分类器：一个用于仅使用本地节点特征的局部分类，另一个用于使用本地特征和聚合算子的关联分类，如 Sen 等人所述。(2008)。我们首先使用所有带标签的训练集节点来训练本地分类器，并将其用于为关联分类器训练生成未标记节点的类标签。我们在所有未标记节点（由本地分类器进行 bootstrapping）上对随机排列的节点运行迭代分类（关联分类器），共进行了 10 次迭代。对于每个数据集，我们根据验证集性能选择正则化参数 L2 和聚合算子（计数vs.比例，参见Sen等人。, 2008）。 \n\n最后，我们使用Planetoid（Yang等人，2016）进行比较，在此我们总是选择其最佳性能模型变体（推断与归纳之间）作为基线。\n\n## 6 结果\n\n### 6.1 半监督节点分类\n\n结果总结在表2中。报告的数量表示百分比分类精度。对于ICA，我们报告了随机节点顺序下100次运行的平均准确率。所有其他基线方法的结果来自Planetoid论文（Yang等人，2016）。Planetoid* 表示他们在论文中介绍的不同变体中的相应数据集的最佳模型。\n\nTable 2: Summary of results in terms of classiﬁcation accuracy(in percent).\n\n| Method          | Citeseer  | Cora      | Pubmed    | NELL       |\n| --------------- | --------- | --------- | --------- | ---------- |\n| ManiReg[3]      | 60.1      | 59.5      | 70.7      | 21.8       |\n| SemiEmb[28]     | 59.6      | 59.0      | 71.1      | 26.7       |\n| LP[32]          | 45.3      | 68.0      | 63.0      | 26.5       |\n| DeepWalk[22]    | 43.2      | 67.2      | 65.3      | 58.1       |\n| ICA[18]         | 69.1      | 75.1      | 73.9      | 23.1       |\n| Planetoid\\*[29] | 64.7(26s) | 75.7(13s) | 77.2(25s) | 61.9(185s) |\n| GCN(this paper) | 70.3(7s)  | 81.5(4s)  | 79.0(38s) | 66.0(48s)  |\n|GCN(rand.splits) | 67.9 ± 0.5| 80.1 ± 0.5| 78.9 ± 0.7| 58.4 ± 1.7 |\n\n我们进一步报告了我们的方法（包括验证误差评估）收敛所需的时间（括号内为秒数），以及行星仪。 对于后者，我们使用了作者提供的实现，并在与我们的GCN模型相同的硬件上进行了训练（带有GPU）。 我们在 Yang等人(2016年) 所使用的数据集拆分上训练和测试了我们的模型，并报告了 100 次随机权重初始化运行的平均准确率。 我们使用以下超参数组合对CiteSeer、Cora和Pubmed： 0.5 (丢弃率)，5 × 10 −4 （ L2正则化 ） 和 16 (隐藏单元数)； 对于 NELL ： 0.1 (丢弃率)，1 × 10 −5 （ L2 正则化）和 64 (隐藏单元数)。\n\n此外，我们在 Yang等人, (2016)中报告了与相同大小的随机数据集拆分相匹配的模型性能，这些数据集被标记为GCN（随机拆分）。在这里，我们报告测试集拆分的预测准确度的平均值和标准误差。\n\n### 6.2 模型评估\n\n我们在引用网络数据集上比较了我们提出的每层传播模型的不同变体。 我们遵循了前一节中描述的实验设置。 结果总结在表3中。 我们的原始GCN模型的传播模型用归一化技巧（粗体）表示。 在所有其他情况下，神经网络层的传播模型都替换为传播模型下指定的模型。 报告的数字表示对于具有随机权重矩阵初始化的100次重复运行的平均分类精度。 对于每个层中的多个变量$\\Theta_{i}$，我们对第一层的所有权重矩阵施加L2正则化。\n\nTable 3: Comparison of propagation models.\n\n| Description                  | Propagation model                                       | Citeseer | Cora | Pubmed |\n| ---------------------------- | ------------------------------------------------------- | -------- | ---- | ------ |\n| Chebyshev ﬁlter(Eq. 5)  K= 3 | $\\sum^K_{k=0}T_k(\\widetilde{L})XΘ_k$                    | 69.8     | 79.5 | 74.4   |\n| Chebyshev ﬁlter(Eq. 5) K= 2  | $\\sum^K_{k=0}T_k(\\widetilde{L})XΘ_k$                    | 69.6     | 81.2 | 73.8   |\n| 1st-order model(Eq. 6)       | $XΘ_0 + D^{−1/2 }AD^{−1/2}XΘ_1$                         | 68.3     | 80.0 | 77.5   |\n| Single parameter(Eq. 7)      | $(I_N + D^{−1/2}AD^{−1/2})XΘ$                           | 69.3     | 79.2 | 77.4   |\n| Renormalization trick(Eq. 8) | $\\widetilde D^{−1/2}\\widetilde A \\widetilde D^{−1/2}XΘ$ | 70.3     | 81.5 | 79.0   |\n| 1st-order term only          | $D^{−1/2}AD^{−1/2}XΘ $                                  | 68.7     | 80.5 | 77.8   |\n| Multi-layer perceptron       | $XΘ$                                                    | 46.5     | 55.1 | 71.4   |\n\n\n\n### 6.3 每个 epoch 的训练时间\n\n在这里，我们报告了模拟随机图上的每个训练周期（前向传播、交叉熵计算、反向传播）平均用时的结果，以秒为单位。请参见第5节中的详细描述在这些实验中使用的随机图形数据集。我们在GPU上以及使用TensorFlow (Abadi等人，2015年) 的CPU仅实现中比较结果。图2总结了结果。\n\n![image-20240828112130636](/img/gcn/image-20240828112130636.png)\n\nFigure 2: Wall-clock time per epoch for random graphs.(*) indicates out-of-memory error.\n\n## 7 讨论\n\n### 7.1 半监督模型\n\n在本文中，我们展示了半监督分类方法在实验中的优越性。基于图拉普拉斯算子的方法（Zhu等，2003；Belkin等，2006；Weston等，2012）很可能受到其假设边仅编码节点相似度的限制。另一方面，Skip-gram 基于的方法由于它们依赖于多步骤管道而难以优化。我们的模型克服了这两种局限性，在效率方面与相关方法相比仍然具有竞争力（以时钟时间衡量）。与仅聚合标签信息的方法（Lu 和 Getoor，2003）相比，传播来自邻居节点的功能信息可以提高分类性能。\n\n 我们进一步证明了提出的归一化传播模型（方程8）比简单的1阶模型（方程6）或使用Chebyshev多项式的高阶图卷积模型具有更好的效率（更少的参数和操作，如乘法或加法），以及在许多数据集上提供了更好的预测性能。\n\n### 7.2 局限性和未来工作\n\n在这里，我们描述了当前模型的一些局限性，并概述了未来如何克服这些局限性。 \n\n**内存需求** 在当前设置中，使用批量梯度下降法时，内存需求会线性增长。我们已经证明了对于无法装入 GPU 内存的大图来说，在 CPU 上训练仍然是一个可行的选择。小批量随机梯度下降可以缓解这个问题。然而，生成小批量的过程应该考虑 GCN 模型中的层数，因为具有 K 层的 GCN 的第 K 阶近邻必须存储在内存中才能进行精确计算。对于非常大且密集连接的图数据集，可能需要进一步的近似。\n\n**有向边和边特征**  我们的框架目前不支持自然地表示边特征，仅限于无向图（带权或不带权）。然而，在 NELL 上的结果表明，通过将原始有向图表示为一个带有额外节点的二分图，可以处理有向边和边特征（见第 5.1 节以获取更多详细信息）。\n\n**限制假设**  通过第 2 节中引入的近似，我们隐含地假设局部性（K 层 GNN 的依赖于 K 阶邻域）以及自我连接与邻居节点之间的边具有相等的重要性。然而，在某些数据集上，引入一个权重参数 λ 在定义 $\\tilde A$ 中可能更有益： \n$$\n\\tilde A = A + λI_N\n$$\n这个参数现在在典型的半监督设置中扮演着与监督和无监督损失之间的权衡参数相似的角色（参见等式 1）。然而，这里可以使用梯度下降来学习。\n\n### 8 结论\n\n我们引入了一种新颖的方法来处理图形结构数据上的半监督分类。我们的 GCN 模型使用一种基于图上一阶近似谱卷积的 层间传播规则。在多个网络数据集上的实验表明，提出的 GCN 模型能够以对半监督分类 有用的方式编码图结构和节点特征。在这种情况下，与最近提出的一些方法相比，我们的模型具有显著的优势，同时计算效率更高。\n\n","comments":true,"categories":[],"tags":[{"name":"GCN","slug":"GCN","permalink":"http://blog.ahulearn.com/tags/GCN/"},{"name":"ICLR 2017","slug":"ICLR-2017","permalink":"http://blog.ahulearn.com/tags/ICLR-2017/"}]},{"title":"Hierarchical Graph Pooling with Structure Learning","date":"2024-08-05T03:34:00.000Z","path":"2024/08/05/Hierarchical Graph Pooling with Structure Learning/","raw":"---\ntitle:  Hierarchical Graph Pooling with Structure Learning\ndate: 2024-8-5 11:34:00\ntoc: true\ntags:\n - 论文翻译\n - GCN\n - AI\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\\hgp-sl\n---\n\n## Hierarchical Graph Pooling with Structure Learning\n\n会议: AAAI 2020(疑似撤稿)\n\n论文地址：https://arxiv.org/abs/1911.05954\n\ngithub: https://github.com/cszhangzhen/HGP-SL\n\nDGL开源库：https://github.com/dmlc/dgl/tree/master/examples/pytorch/hgp_sl\n\n[TOC]\n\n### 摘要\n\n图神经网络 (GNN) 将深度神经网络扩展到图结构数据，在许多图相关任务中取得了最先进的性能。然而，现有的 GNN 模型主要关注设计图卷积操作。图池化 (或下采样) 操作在分层表示学习中发挥着重要作用，通常被忽视。在这篇论文中，我们提出了一种新的图池化操作符，称为具有结构学习的分层图池化 (HGP-SL)，它可以集成到各种图神经网络架构中。HGP-SL 将图池化和结构学习集成到一个统一的模块中，以生成图的分层表示。具体来说，图池化操作根据我们定义的节点信息分数自适应地选择一组节点来形成一个诱导子图，用于后续层。为了保留图的拓扑信息的完整性，我们进一步引入了一种结构学习机制，以学习每层池化图的精炼图结构。通过将 HGP-SL 操作符与图神经网络相结合，我们进行了图级别表示学习，重点关注图分类任务。在六个广泛使用的基准数据集上的实验结果表明了我们提出的模型的有效性。\n\n<!--more-->\n\n### 介绍\n具有卷积和池化层的深度神经网络在各种具有挑战性的任务中取得了巨大的成功，从计算机视觉 (He 等人，2016 年)、自然语言理解 (Bahdanau、Cho 和 Bengio，2015 年) 到视频处理 (Karpathy 等人，2014 年)。这些任务中的数据通常表示在欧几里得空间中（即，建模为二维或三维张量），因此通常包含卷积操作的局部和顺序信息 (Defferrard、Bresson 和 Vandergheynst，2016 年)。然而，在许多现实世界问题中，大量数据（例如社交网络、化学分子和生物网络）都位于非欧几里得领域，可以自然地表示为图。由于神经网络强大的能力，将卷积和池化操作推广到图结构数据非常吸引人。\n\n最近，人们已经进行了大量尝试将卷积操作推广到任意图，称为图神经网络 (GNN)。一般来说，这些算法可以分为两大类：频谱和空间方法。对于频谱方法，它们通常根据图傅里叶变换定义图卷积操作 (Bruna 等人，2013 年；Defferrard、Bresson 和 Vandergheynst，2016 年；Kipf 和 Welling，2017 年)。对于空间方法，图卷积操作是通过直接聚合来自其邻域的节点表示来设计的 (Hamilton、Ying 和 Leskovec，2017 年；Monti 等人，2017 年；Veliˇckovi´c 等人，2018 年；Morris 等人，2019 年)。上述大多数方法主要涉及跨图转换、传播和聚合节点特征，这可以符合消息传递方案 (Gilmer 等人，2017 年)。GNN 已应用于不同类型的图 (Veliˇckovi´c 等人，2018 年；Derr、Ma 和 Tang，2018 年)，并在许多图相关任务中取得了出色的性能，包括节点分类 (Kipf 和 Welling，2017 年)、链接预测 (Schlichtkrull 等人，2018 年；Zhang 等人，2018b 年) 和推荐 (Ying 等人，2018a 年) 等。\n\n然而，尽管图池化操作在图分类任务中起着关键作用 (Ying 等人，2018b 年)，但图中的池化操作尚未得到广泛研究。图分类的目标是通过利用其节点特征和图结构信息来预测整个图的标签，即需要图级别表示。GNN 最初是为学习有意义的节点级别表示而设计的，因此生成图级别表示的常用方法是通过全局汇总图中的所有节点表示。尽管可行，但通过这种方式生成的图级别表示本质上仍然是“平的”，因为在整个过程中忽略了整个图结构信息。此外，GNN 只能通过边在节点之间传递消息，但不能以分层的方式聚合节点信息。同时，图通常具有不同的子结构，节点扮演着不同的角色，因此它们应以不同的方式为图级别表示做出贡献。例如，在蛋白质-蛋白质相互作用图中，某些子结构可能代表一些特定的功能，这对预测整个图的特性具有重要意义。为了捕获图的局部和全局结构信息，需要分层池化过程。\n\n一些最新的工作专注于 GNN 中的分层池化过程 (Ying 等人，2018b 年；Gao 和 Ji，2019 年；Diehl，2019 年；Gao、Chen 和 Ji，2019 年)。这些模型通常通过将节点分组或采样到子图中来逐层粗化图，从而使整个图信息逐渐减少到分层诱导子图。然而，图池化操作仍有改进的余地。在节点分组方法中，分层池化方法 (Ying 等人，2018b 年；Diehl，2019 年) 具有很高的计算复杂性，需要额外的神经网络来减小节点数量。在节点采样方法中，生成的诱导子图 (Gao 和 Ji，2019 年；Lee、Lee 和 Kang，2019 年) 可能无法保留关键子结构，最终甚至丢失图拓扑信息的完整性。例如，在原始图中没有直接连接但共享许多共同邻居的两个节点可能在诱导子图中彼此无法到达，即使直观上它们在子图中应该是“接近”的。因此，扭曲的图结构会阻碍后续层中的消息传递。\n\n为了解决上述局限性，我们提出了一个新的图池化操作符 HGP-SL 来学习分层图级别表示。具体来说，HGP-SL 首先根据我们定义的节点信息分数自适应地选择一组节点，充分利用节点特征和图拓扑信息。此外，我们提出的图池化操作是一个非参数步骤，因此在这个过程中不需要优化任何额外的参数。然后，我们将稀疏注意力 (Martins 和 Astudillo，2016 年) 机制应用于池化图，旨在学习一个保留原始图关键子结构的精炼图结构。我们将池化操作符集成到图卷积神经网络中进行图分类，整个过程可以以端到端的方式进行优化。总结一下，本文的主要贡献如下：\n\n+ 我们引入了一个新的图池化操作符 HGP-SL，它可以集成到各种图神经网络架构中。与卷积神经网络中的池化操作类似，我们提出的图池化操作是非参数的，并且非常容易实现。\n+ 据我们所知，我们是第一个为池化图设计结构学习机制的人，其优点是学习一个精炼的图结构来保留图的关键子结构。\n+ 我们在六个公共数据集上进行了广泛的实验，以证明 HGP-SL 的有效性以及与一系列最先进方法的优越性。\n\n### 相关工作\n\n#### 图神经网络\n\nGNN 通常可以分为两大类：频谱和空间方法。频谱方法通常根据图谱理论定义参数化滤波器。Bruna 等人 (2013 年) 首先提出在傅里叶变换域中定义图卷积操作。由于其计算成本很高，难以扩展到大型图。后来，Defferrard、Bresson 和 Vandergheynst (2016 年) 通过使用切比雪夫展开近似 K-多项式滤波器来提高其效率。GCN (Kipf 和 Welling，2017 年) 通过截断切比雪夫多项式到局部谱滤波器的一阶近似来进一步简化 ChebNet。空间方法通过直接聚合节点的邻域信息来设计卷积操作。其中，GraphSAGE (Hamilton、Ying 和 Leskovec，2017 年) 提出了一个归纳算法，可以通过聚合其邻域内容信息来推广到未见过的节点。GAT (Veliˇckovi´c 等人，2018 年) 利用注意力机制以不同的权重聚合节点的邻域表示。JK-Net (Xu 等人，2018 年) 利用灵活的邻域范围来更好地表示节点。更多细节可以在几篇关于图神经网络的综合调查中找到 (Zhou 等人，2018 年；Zhang、Cui 和 Zhu，2018 年；Wu 等人，2019 年)。然而，上述 GNN 的两大分支主要是为学习有意义的节点表示而设计的，由于缺乏池化操作，无法生成分层图表示。\n\n#### 图池化\n\nGNN 中的池化操作可以缩小输入的大小并扩大感受野，从而提高泛化能力和性能。DiffPool (Ying 等人，2018b 年) 提出使用神经网络将节点软分配到一组簇，形成密集的簇分配矩阵，计算成本很高。gPool (Gao 和 Ji，2019 年) 和 SAGPool (Lee、Lee 和 Kang，2019 年) 设计了一个 top-K 节点选择过程，以形成一个诱导（简化）子图，用于下一个输入层。尽管效率很高，但它可能会丢失图结构信息的完整性，并导致孤立子图，这将阻碍后续层中的消息传递过程。EdgePool (Diehl，2019 年) 通过收缩图中的边来设计池化操作，但由于它总是池化大约一半的总节点，因此其灵活性较差。iPool (Gao、Xiong 和 Frossard，2019 年) 提出了一个无参数池化方案，它对图同构是不变的。EigenPool (Ma 等人，2019 年) 引入了一个基于图傅里叶变换的池化操作符，它通过谱聚类控制池化比率，并且也非常耗时。此外，还有一些方法执行全局池化。例如，Set2Set (Vinyals、Bengio 和 Kudlur2015 年) 通过使用 LSTM (Hochreiter 和 Schmidhuber，1997 年) 聚合信息来实现全局池化操作。DGCNN (Zhang 等人，2018a 年) 根据 feature map 值按降序排列的最后一通道来池化图。基于图拓扑的池化操作在 (Defferard、Bresson 和 Vandergheynst，2016 年) 和 (Rhee、Seo 和 Kim，2017 年) 中也有提出，其中 Graclus 方法 (Dhillon、Guan 和 Kulis，2007 年) 被用作池化模块。\n\n### 本文的模型\n\n#### 符号和问题公式\n\n给定一组图数据 $G={G_1, G_2, ··· , G_n}$，其中每个图中的节点和边数可能相差很大。对于任意图 $G_i = (V_i, E_i, X_i)$，我们有$n_i$ 和 $e_i$ 分别表示节点数和边数。令 $A_i ∈ R^{n_i×n_i} $为相邻矩阵，描述其边连接信息，$Xi∈R^{n_i×f}$代表节点特征矩阵，其中 $f $ 是节点属性的维度。标签矩阵 $Y∈R^{n×c} $ 指示每个图的关联标签，即如果 $G_i $属于类别 j，则$ Y_{ij}=1 $，否则 $Y_{ij }= 0$。由于图结构和节点数量在层之间由于图池化操作而发生变化，我们进一步将输入到第 k 层的第 i 个图表示为 $G^k_i$，具有 $n^k_i$ 个节点。相邻矩阵和隐藏表示矩阵分别表示为 $A^k_i ∈ R^{n^k_i ×n^k_i}$ 和$ H^k_i ∈ R^{n^k_i×d}$。使用上述符号，我们正式定义我们的问题如下：\n\t**输入**: 给定具有标签信息 $Y_L$ 的图数据集 $G_L$，图神经网络层的数量 K，池化比率 r，以及每层表示维度 d。\n\t**输出**: 我们的目标是使用图神经网络以端到端的方式预测 $G/G_L $的未知图标签。\n\n#### 图卷积神经网络\n\n图卷积神经网络 (或 GCN) (Kipf 和 Welling，2017 年) 已被证明在各种具有挑战性的任务中非常高效，并取得了有希望的 performance。因此，我们选择 GCN 作为我们模型的构建块，并在本节中简要回顾其机制。请注意，我们提出的 HGP-SL 操作符也可以集成到其他图神经网络架构中，例如 GraphSAGE (Hamilton、Ying 和 Leskovec，2017 年) 和 GAT (Veliˇckovi´c 等人，2018 年)。我们将在实验部分讨论这一点。\n在 GCN 的第 k 层中，它将图 $G$ 的相邻矩阵 $A$ 和隐藏表示矩阵 $H_k$ 作为输入，然后下一层的输出将生成如下：\n$$\nH_{k+1} = σ(\\tilde{D}^\\frac{−1}{2} \\tilde A \\tilde D^\\frac{−1}{2} H_kW^k) \\quad (1)\n$$\n其中 σ(·) 是非线性激活函数，H0 = X, ˜A = A + I 是具有自连接的相邻矩阵。˜D 是 ˜A 的对角度矩阵，Wk ∈ Rdk×dk+1 是一个可训练的权重矩阵。为了方便参数调整，我们设置输出维度 dk+1 = dk = d 对于所有层。\n\n#### 整体神经网络架构\n\n图 1 提供了我们提出的结合图神经网络的分层图池化与结构学习 (HGP-SL) 的概述，其中在图卷积操作之间添加了图池化操作。提出的 HGP-SL 操作符由两个主要组件组成：1) 图池化，它保留一组信息节点并形成一个更小的诱导子图；2) 结构学习，它学习一个精炼的图结构，用于池化子图。我们提出的结构学习的优点在于其能够保留基本图结构信息的能力，这将促进消息传递过程。正如这个说明性示例中所示，池化子图可能存在孤立节点，但直观上应该是连接的，因此它将阻碍后续层中特别是当从其邻域节点聚合信息时的信息传播。整个架构是卷积和池化操作的堆叠，因此可以以分层的方式进行图表示学习。然后，使用读取函数来汇总每个级别的节点表示，最终图级别表示是不同级别汇总的总和。最后，将图级别表示输入到具有 softmax 层的多层感知器 (MLP) 以执行图分类任务。在以下内容中，我们将介绍图池化和结构学习层的细节。\n\n![image-20240805140433189](/img/hgp-sl/image-20240805140433189.png)\n\n| 图 1：结合图神经网络的 HGP-SL 操作符架构概述。该图展示了 HGP-SL 操作符与图神经网络结合的架构。虚线框展示了 HGP-SL 的工作流程，包括图池化和结构学习。学习到的边在图中以虚线表示。这个过程（卷积和池化操作）会重复几次。然后，应用一个读取函数来汇总每个级别的节点表示，使其成为一个固定大小的表示，然后通过 MLP 层进行图分类。 |\n| :----------------------------------------------------------: |\n\n#### 图池化操作\n\n在本节中，我们介绍我们提出的图池化操作，以实现对图数据的下采样。受 (Gao 和 Ji，2019 年；Lee、Lee 和 Kang，2019 年；Gao、Xiong 和 Frossard，2019 年) 的启发，池化操作识别一组信息节点来形成一个新的但更小的图。在这里，我们设计了一个非参数池化操作，它可以充分利用节点特征和图结构信息。\n我们提出的图池化操作的关键是定义一个标准，该标准指导节点选择过程。为了执行节点采样，我们首先引入一个称为节点信息分数的标准来评估每个节点在其邻域中包含的信息。通常，如果一个节点的表示可以通过其邻域表示重建，则意味着该节点可能在池化图中被删除，而几乎没有信息丢失。在这里，我们正式定义节点信息分数为节点表示本身与其从邻域构建的表示之间的曼哈顿距离：\n$$\np = γ(G_i) = ||(I^k_i − (D^k_i)^{−1}A^k_i) H^k_i||_1, \\quad(2)\n$$\n其中 Ak i ∈ Rnk i ×nk i 和 Hk i ∈ Rnk i ×d 是相邻和节点表示矩阵。∥ · ∥1 执行逐行 ℓ1 范数。Dk i 表示 Ak i 的对角度矩阵，Ik i 是单位矩阵。因此，我们得到 p ∈ Rni 编码图中每个节点的信息分数。\n在获得节点信息分数后，我们现在可以选择应该由池化操作保留的节点。为了近似图信息，我们选择保留不能很好地由其邻域表示的节点，即，在构建池化图时，相对较大的节点信息分数的节点将被保留，因为它们可以提供更多信息。具体来说，我们首先根据其节点信息分数对图中的节点进行排序，然后选择 top-rank作为保留的节点，如下所示：\n$$\n\\begin{align}\nidx &= top-rank(p, ⌈r ∗ n^k_i⌉) \\\\\n\\hat H ^{k+1}_i &= H^k_i(idx, :) \\\\\nA^{k+1}_i &= A^k_i(idx, idx),\n\\end{align} \n\\quad(3)\n$$\n其中 r 是池化比率，top-rank(·) 表示返回 top nk+1 i = ⌈r ∗ nk i ⌉ 值的索引的函数。Hk i (idx, :) 和 Ak i (idx, idx) 执行行或 (和) 列提取，以形成诱导子图的节点表示矩阵和相邻矩阵。因此，我们有 ˜Hk+1 i ∈ Rnk+1 i ×d 和 Ak+1 i ∈ Rnk+1 i ×nk+1 i 表示下一层的节点特征和图结构信息。\n\n#### 结构学习机制\n\n在本节中，我们介绍了我们提出的结构学习机制如何在池化图中学习一个精炼的图结构。正如我们在图 1 中所说明的，池化操作可能导致高度相关的节点在诱导子图中断开连接，这会丢失图结构信息的完整性，并进一步阻碍后续层中的消息传递过程。同时，来自领域知识 (例如，社交网络) 或由人类建立的图结构 (例如，KNN 图) 通常对于图神经网络中的学习任务来说不是最优的，因为信息丢失或噪声。为了克服这个问题，(Li 等人，2018 年) 提出使用近似距离度量学习算法自适应地估计图拉普拉斯矩阵，这可能导致局部最优解。 (Jiang 等人，2019 年) 引入学习构建的图结构以进行节点标签估计，但它生成密集连接图，不适用于我们的分层图级别表示学习场景。\n在这里，我们开发了一个新的结构学习层，它通过稀疏注意力机制 (Martins 和 Astudillo，2016 年) 学习稀疏图结构。对于第 k 层第 k 层图 Gi 的池化子图 Gk i，我们将其结构信息 Ak i ∈ Rnk i ×nk i 和隐藏表示 Hk i ∈ Rnk i ×d 作为输入。我们的目标是学习一个精炼的图结构，该结构编码每对节点之间的潜在成对关系。形式上，我们使用一个参数化为权重向量 →a∈ R1×2d 的单层神经网络。然后，注意力机制计算节点 vp 和 vq 之间的相似度分数可以表示为：\n$$\nE^k_i(p, q) = σ(\\vec{a} [H^k_i (p, :)||H^k_i(q, :)]^⊤) + λ·A^k_i(p, q),\n\\quad(4)\n$$\n其中 σ(·) 是像 ReLU(·) 这样的激活函数，|| 表示连接操作。Hk i (p, :) ∈ R1×d 和 Hk i (q, :) ∈ R1×d 指的是矩阵 Hk i 的第 p 行和第 q 行，分别代表节点 vp 和 vq 的表示。具体来说，Ak i 编码诱导子图结构信息，其中 Ak i\n\n(p, q) = 0 如果节点 vp 和 vq 没有直接连接。我们将 Ak i 集成到我们的结构学习层中，以使注意力机制倾向于在直接连接的节点之间给出一个相对较大的相似度分数，同时尝试学习断开连接的节点之间的潜在成对关系。λ 是它们之间的权衡参数。\n为了使相似度分数易于跨不同节点进行比较，我们可以使用 softmax 函数跨节点对其进行归一化：\n$$\nS^k_i(p, q) = \\frac{exp(E^k_i(p, q))}{\\sum^{n^k_i}_{m=1} exp(E^k_i (p, m))} ,\n\\quad(5)\n$$\n\n然而，softmax 变换总是具有非零值，从而导致密集的全连接图，这可能会将大量噪声引入到学习的结构中。因此，我们建议使用 sparsemax 函数 (Martins 和 Astudillo，2016 年)，它保留了 softmax 函数的大多数重要特性，并且还具有生成稀疏分布的能力。sparsemax(·) 函数旨在返回输入到概率单纯形的欧几里得投影，可以表示如下：\n$$\n\\begin{align}\nS^k_i(p, q) &= sparsemax(E^k_i(p, q)) \\\\\nsparsemax(E^k_i(p, q)) &= [E^k_i(p, q) − τ(E^k_i(p, :))]_+,\n\\end{align}\n\\quad{(6)}\n$$\n\n其中 [x]+ = max{0, x}，τ(·) 是一个阈值函数，它根据算法 1 中所示的程序返回一个阈值。因此，sparsemax(·) 保留阈值以上的值，而其他值将被截断为零，从而产生稀疏图结构。与 softmax 函数类似，sparsemax(·) 也具有非负和总和为一的特性，也就是说，Sk i (p, q) ≥ 0 且 Pnk i q=1 Sk i (p, q) = 1。证明过程可在补充材料中找到。\n\n#### 提高结构学习效率\n\n对于大规模图，在学习结构 Sk i 时，计算每对节点之间的相似度将计算成本很高。如果我们进一步考虑图的局部化和平滑性特性，那么在节点的 h-hop 邻居内 (h = 2 或 3) 限制计算过程是合理的。因此，Sk i 的计算成本可以大大降低。\n\n#### 重新审视 GCN 和图池化\n\n在获得精炼的图结构 Sk i 后，我们在以下层中根据 ˜Hk i 和 Sk i (而不是 Ak i) 执行图卷积和池化操作。因此，方程 (1) 可以简化如下：\n$$\nH^k_i = σ(S^k_i \\tilde H^k_i W^k).\n\\quad(7)\n$$\n\n\n\n由于学习的 Sk i 满足 Pnk i q=1 Sk i (p, q) = 1，因此我们得到对角矩阵 Dk i = Diag(d1, d2, · · · , dnk i )，其中 dp = Pnk i q Sk i (p, q)，这退化为单位矩阵 Ik i。同样，方程 (2) 中的节点信息分数的计算也可以简化如下：\n$$\np = γ(G_i) =||(I^k_i − S^k_i)H^k_i||_1,\n\\quad(8)\n$$\n\n这使得我们的模型非常易于实现。\n\n#### 读取函数和输出层\n\n正如我们在图 1 中所证明的，神经网络架构重复了多次图卷积和池化操作，因此我们会在每个级别观察到不同大小的多个子图：H1 i ，H2 i ，· · · ，HK i。为了生成一个固定大小的图级别表示，我们设计了一个读取函数，该函数汇总子图中的所有节点表示。在这里，我们简单地使用每个子图中的平均池化和最大池化的连接，如下所示：\n$$\nr^k_i = R(H^k_i) = σ( \\frac{1}{n^k_i}\\sum^{h^k_i}_{p=1}H^k_i (p, :)|| \\overset{d}{max} H^k_i (:, q)),\n\\quad(9)\n$$\n\n其中 σ(·) 是一个非线性激活函数，rk i ∈ R2d。然后，我们将不同级别的读取输出相加以形成最终的图级别表示：\n$$\nz_i = r^1_i + r^2_i + ... + r^K_i,\n\\quad(10)\n$$\n\n它总结了不同级别的图表示。最后，我们将图级别表示输入到具有 softmax 分类器的 MLP 层，损失函数定义为预测值在标签上的交叉熵：\n$$\n\\begin{align}\n\\hat Y &= softmax(MLP(Z)) \\\\\nL &= − \\sum_{i∈L}\\sum^c_{j=1}Y_{ij}log \\hat Y_{ij},\n\\end{align}\n\\quad(11)\n$$\n\n其中 $ \\hat Y_{ij} $ 表示图 Gi 属于类别 j 的预测概率，$ Y_{ij} $ 是真实值。L 表示具有标签的图训练集。\n\n### 实验和分析\n\n#### 数据集\n\n我们采用六个常用的公共基准数据集进行实证研究。六个数据集的统计信息总结在表 1 中，更多描述如下：ENZYMES (Borgwardt 等人，2005 年) 是蛋白质三级结构的数据库，每个酶属于 6 个 EC 顶层类别之一。PROTEINS 和 D&D (Dobson 和 Doig，2003 年) 是两个蛋白质图数据集，其中节点表示氨基酸，如果两个节点之间的距离小于 6 埃，则通过边连接。标签指示蛋白质是否为非酶。NCI1 和 NCI109 (Shervashidze 等人，2011 年) 是针对非小细胞肺癌和卵巢癌细胞系的两个生物数据集，其中每个图是一个化学化合物，节点和边分别代表原子和化学键。Mutagenicity (Kazius、McGuire 和 Bursi，2005 年) 是药物化学化合物数据集，可分为两类：致突变物和非致突变物。\n\n#### 基线\n\n**图核方法**。 这组方法通过利用精心设计的核来执行图分类。我们选择三个经典算法：GRAPHLET (Shervashidze 等人，2009 年)、最短路径核 (SP) (Borgwardt 和 Kriegel，2005 年) 和 Weisfeiler-Lehman 核 (WL) (Shervashidze 等人，2011 年) 作为基线。\n\n**图神经网络**。 这组方法包括代表性图神经网络：GCN (Kipf 和 Welling，2017 年)、GraphSAGE (Hamilton、Ying 和 Leskovec，2017 年) 和 GAT (Veliˇckovi´c 等人，2018 年)，它们旨在学习有意义的节点级别表示。因此，我们使用我们提出的读取函数来汇总节点表示以进行图分类。\n\n**图池化模型**。 在这组中，我们进一步考虑了许多将 GNN 与池化操作结合在一起的模型，用于图级别表示学习。Set2Set (Vinyals、Bengio 和 Kudlur，2015 年) 和 DGCNN (Zhang 等人，2018a 年) 是两种新的全局图池化算法。其他五个分层图池化模型，包括 DiffPool (Ying 等人，2018b 年)、gPool (Gao 和 Ji，2019 年)、SAGPool (Lee、Lee 和 Kang，2019 年)、EdgePool (Diehl，2019 年) 和 EigenPool (Ma 等人，2019 年)，也作为基线进行比较。\n\n**HGP-SL 变体**。 为了进一步分析我们提出的 HGP-SL 操作符的有效性，我们在这里考虑四个变体：HGP-SLNSL (无结构学习) 丢弃结构学习层以验证我们提出的结构学习模块的有效性，HGP-SLHOP 删除结构学习层并在其 h-hop 内连接节点，HGP-SLDEN (DENse) 使用结构学习层学习一个密集图结构，使用方程 (5) 中定义的 softmax 函数，HGP-SL 使用方程 (6) 中定义的 sparsemax 函数学习一个稀疏图结构。HGP-SLDEN 和 HGP-SL 使用效率改进的结构学习策略。\n\n**实验和参数设置。**遵循许多先前的工作 (Ying 等人，2018b 年；Ma 等人，2019 年)，我们将每个数据集随机分为三部分：80% 作为训练集，10% 作为验证集，剩余 10% 作为测试集。我们重复此随机分割过程 10 次，并报告具有标准偏差的平均性能。对于基线算法，我们使用作者发布的源代码，并根据验证集将其超参数调整为最佳。为了确保公平比较，现有池化基线和我们的模型使用相同的神经网络架构。所有方法和数据集中节点表示的维度设置为 128。我们使用 PyTorch 实现 HGP-SL，并使用 Adam 优化器优化模型。学习率和权重衰减在 {0.1, 0.01, 0.001, 1e−4, 1e−5} 中搜索，池化比率 r ∈ [0.1, 0.9]，层 K ∈ [1, 5]。MLP 由三个全连接层组成，每层神经元的数量设置为 256、128、64，后跟 softmax 分类器。在训练过程中使用早期停止标准，即如果验证损失在 100 个连续的 epoch 中没有下降，则停止训练。源代码公开发布 4。\n\n#### 图分类的性能\n\n表 2 报告了分类性能。总结如下，我们可以从结果中得出以下观察结果：\n\n+ 首先，我们可以从结果中得出一个总的观察结果，即我们提出的 HGP-SL 在所有数据集上始终优于其他最先进的基线。 例如，我们的方法在 PROTEINS 数据集上比最佳基线提高了约 3.08%，比没有分层池化机制的 GCN 提高了 12.97%。这验证了添加图池化模块的必要性。\n+ 值得注意的是，传统的基于图核的方法表现出有竞争力的性能。 然而，精心设计的图核通常涉及大量的人类领域知识，难以推广到具有任意结构的图。此外，提取图特征和执行图分类的两阶段程序可能会导致次优性能。\n+ 与先前工作 (Ma 等人，2019 年) 的发现一致，我们还观察到 GNN 组无法达到令人满意的结果。 我们认为主要原因是因为它们在全局汇总节点表示时忽略了图结构信息，这进一步验证了添加图池化模块的必要性。\n+ 特别是，全局池化方法 Set2Set 和 DGCNN 被 HGP-SL 等大多数分层池化方法超越，但有少数例外。 这是因为它们学习的图表示仍然是“平面的”，并且忽略了图中的层次结构信息或功能单元，这些单元在预测整个图标签方面发挥着重要作用。\n+ 我们注意到，分层池化模型在大多数基线中实现了相对更好的性能，这进一步证明了分层池化机制的有效性。 其中，gPool 和 SAGPool 在 ENZYMES 数据集上的表现较差。这可能是由于每个类别的训练样本有限，导致神经网络过拟合。EdgePool 在这组竞争者中获得了最佳性能，它通过收缩图中的每一对节点来缩小图的大小。显然，我们的 HGP-SL 以不同的增益优于 EdgePool。\n+ 最后，HGP-SL 和 HGP-SLDEN 比 HGP-SLNSL 和 HGP-SLHOP 表现得更好，这证明了我们提出的结构学习层是有效的。 此外，HGP-SLHOP 的表现比 HGP-SL 差。这是因为其 h-hop 内的断开连接的节点仍然无法相互到达。HGP-SL 进一步优于 HGP-SLDEN，这表明学习的密集图结构可能会引入额外的噪声信息并降低性能。此外，在现实场景中，图通常具有稀疏的拓扑结构，因此我们提出的 HGP-SL 可以比 HGP-SLDEN 学习更合理的图结构。\n\n#### 消融研究和可视化\n\n**HGP-SL 卷积神经网络架构**。 如前几节所述，我们提出的 HGP-SL 可以集成到各种图神经网络架构中。我们考虑三种最广泛使用的图卷积架构作为我们模型的构建块，以研究不同卷积操作的影响：GCN (Kipf 和 Welling，2017 年)、GraphSAGE (Hamilton、Ying 和 Leskovec，2017 年) 和 GAT (Veliˇckovi´c 等人，2018 年)。我们在三个数据集上评估它们，这些数据集涵盖了小型和大型数据集。他们的结果如表 3 所示。在剩余的数据集中也可以找到类似的结果，但由于空间有限，我们省略了它们。如表 3 所示，图分类的性能取决于选择的数据集和 HGP-SL 中的 GNN 类型。此外，我们还结合了 gPool 和 SAGPool 提出的 top-K 选择程序，并将其与我们提出的结构学习相结合。我们将其命名为 gPool-SL 和 SAGPool-SL 架构。从结果中，我们观察到 gPool-SL 和 SAGPool-SL 通过集成结构学习机制优于 gPool 和 SAGPool，这验证了我们提出的结构学习的有效性。\n\n**超参数分析**。 我们进一步研究了几个关键超参数的敏感性，通过在不同的尺度上改变它们。具体来说，我们研究神经网络层数 K、图表示维度 d 和池化比率 r 如何影响图分类性能。如图 2 所示，当分别设置 K = 3、d = 128 和 r = 0.8 时，HGP-SL 几乎在所有数据集上都实现了最佳性能。池化比率 r 不能太小，否则在池化过程中会丢失大部分图结构信息。\n\n**可视化**。 我们使用 networkx 5 可视化 HGP-SL 及其变体的池化结果。具体来说，我们从 PROTEINS 数据集中随机抽取一个包含 154 个节点的图。我们构建了一个三层图神经网络，池化比率设置为 0.5，然后生成三个池化图，节点分别为 77、39 和 20。我们在图 3 中绘制了第三个池化图。它显示 HGP-SLNSL 和 HGP-SLDEN 无法保留有意义的图拓扑结构，而 HGP-SL 在池化后能够保留原始蛋白质图相对合理的拓扑结构。\n\n### 结论\n\n在本文中，我们研究了图分类任务的图级别表示学习。我们提出了一种新的图池化操作符 HGP-SL，它使 GNN 能够学习分层的图表示。它还可以方便地集成到各种 GNN 架构中。具体来说，图池化操作是一个非参数步骤，它利用节点特征和图结构信息对图进行下采样。然后，在池化操作上堆叠一个结构学习层，旨在学习一个精炼的图结构，该结构可以最好地保留基本的拓扑信息。我们将提出的 HGP-SL 操作符与图卷积神经网络相结合，以进行图分类任务。在六个广泛使用的基准数据集上进行的综合实验表明，它与一系列最先进的方法相比具有优越性。","comments":true,"categories":[],"tags":[{"name":"论文翻译","slug":"论文翻译","permalink":"http://blog.ahulearn.com/tags/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/"},{"name":"GCN","slug":"GCN","permalink":"http://blog.ahulearn.com/tags/GCN/"},{"name":"AI","slug":"AI","permalink":"http://blog.ahulearn.com/tags/AI/"}]},{"title":"Path Aggregation Network for Instance Segmentation","date":"2024-07-29T03:49:00.000Z","path":"2024/07/29/Path Aggregation Network for Instance Segmentation/","raw":"---\ntitle: Path Aggregation Network for Instance Segmentation\ndate: 2024-07-29 11:49:00\ntoc: true\ntags:\n - CS\n - CVPR 2018\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\\panet\n---\n\n用于实例分割的路径聚合网络\n ---\n\n\n会议: CVPR 2018\n\n论文地址：https://arxiv.org/abs/1803.01534\n\ngithub: https://github.com/ShuLiu1993/PANet\n\n[TOC]\n\n## 摘要\n\n信息在神经网络中的传播方式至关重要。本文提出了路径聚合网络 (PANet)，旨在提升基于候选框的实例分割框架中的信息流。具体来说，我们通过自底向上的路径增强，将低层中的精确定位信号引入整个特征层次，从而缩短了低层和顶层特征之间的信息路径。我们提出了自适应特征池化，将特征网格和所有特征级别连接起来，使每个特征级别中的有用信息可以直接传播到后续的候选框子网络中。我们创建了一个互补分支，用于捕获每个候选框的不同视角，从而进一步提高掩码预测的精度。这些改进易于实现，且计算开销微小。我们的 PANet 在 COCO 2017 挑战赛的实例分割任务中取得了第一名，并在没有使用大批次训练的情况下，在目标检测任务中取得了第二名。它也是 MVD 和 Cityscapes 上的最先进技术。代码地址: https://github.com/ShuLiu1993/PANet\n\n<!--more-->\n\n\n\n## 1. 引言\n\n实例分割是最重要和最具挑战性的任务之一。它旨在预测类别标签和像素级的实例掩码，以定位图像中出现的不同数量的实例。这项任务广泛应用于自动驾驶、机器人、视频监控等领域。\n\n在深度卷积神经网络的帮助下，已经提出了几种实例分割框架，例如 [21, 33, 3, 38]，其性能迅速提升 [12]。Mask R-CNN [21] 是一种简单而有效的实例分割系统。基于 Fast/Faster R-CNN [16, 51]，使用全卷积网络 (FCN) 进行掩码预测，并辅以框回归和分类。为了获得高性能，FPN [35] 被用于提取网络内部的层次特征，其中添加了一个自顶向下的路径和横向连接，以传播语义信息强的特征。\n\n最近发布的几个数据集 [37, 7, 45] 为算法改进提供了很大的空间。COCO [37] 包含 20 万张图像。每张图像中都有大量具有复杂空间布局的实例。Cityscapes [7] 和 MVD [45] 提供了包含大量交通参与者的街景，每张图像中都有模糊、遮挡严重和极其微小的实例。\n\n在图像分类中设计网络的一些原则也被证明对目标识别有效。例如，通过直接的残差连接 [23, 24] 和密集连接 [26] 缩短信息路径和简化信息传播，以及通过创建遵循“分割-变换-合并”策略的并行路径来增加信息路径的灵活性和多样性 [61, 6]，都是有益的。\n\n**本文发现**\n\n我们的研究表明，最先进的 Mask R-CNN 中的信息传播可以进一步改进。具体来说，低层特征对于大型实例识别很有帮助。但从低层结构到顶层特征的路径很长，增加了获取精确定位信息的难度。此外，每个候选框都是基于从单个特征级别池化的特征网格进行预测的，这个级别是启发式地分配的。由于在其他级别中丢弃的信息可能对最终预测有帮助，因此这个过程可以进行优化。最后，掩码预测是在单个视角上进行的，失去了收集更多多样化信息的机会。\n\n**本文贡献**\n\n受这些原则和观察结果的启发，我们提出了 PANet，如图 1 所示，用于实例分割。\n\n![image-20240729151551834](/img/panet/image-20240729151551834.png)\n\n`图1. 展示了网络框架插图。(a) FPN骨干网。(b)自下而上的路径聚合。(c)自适应特征池化。(d)检测框分支。(e)全连接融合。注意图中为了简洁起见，省略了(a)和(b)中特征映射的通道维度。`\n\n首先，为了缩短信息路径并使用低层中存在的精确定位信号增强特征金字塔，我们创建了自底向上的路径增强。实际上，低层特征已经在 [44, 42, 13, 46, 35, 5, 31, 14] 系统中使用。但将低层特征传播以增强整个特征层次以进行实例识别尚未被探索。\n\n其次，为了恢复每个候选框与所有特征级别之间中断的信息路径，我们开发了自适应特征池化。这是一个简单的组件，用于为每个候选框聚合来自所有特征级别的特征，避免任意分配的结果。通过此操作，与 [4, 62] 中的路径相比，创建了更直接的路径。\n\n最后，为了捕获每个候选框的不同视角，我们通过添加小型全连接 (fc) 层来增强掩码预测，这些层具有与 Mask R-CNN 原本使用的 FCN 互补的特性。通过融合来自这两个视角的预测，增加了信息多样性，并产生了质量更好的掩码。\n\n前两个组件由对象检测和实例分割共享，从而显著提高了这两个任务的表现。\n\n**实验结果**\n\n使用 PANet，我们在几个数据集上取得了最先进的性能。以 ResNet-50 [23] 作为初始网络，我们的 PANet 在单个尺度上测试的性能已经超过了 COCO 2016 挑战赛中对象检测 [27] 和实例分割 [33] 任务的冠军。请注意，这些先前结果是通过更大型的模型 [23, 58] 以及多尺度测试和水平翻转测试获得的。\n\n我们在没有使用大批次训练的情况下，在 COCO 2017 挑战赛的实例分割任务中取得了第一名，并在目标检测任务中取得了第二名。我们还将在 Cityscapes 和 MVD 上对系统进行基准测试，这同样会产生排名靠前的结果，表明我们的 PANet 是一个非常实用且性能优异的框架。\n\n## 2. 相关工作\n\n**实例分割**\n\n实例分割主要有两种方法。最流行的是基于候选框的方法。这种方法与目标检测有很强的联系。在 R-CNN [17] 中，来自 [60, 68] 的对象候选框被输入到网络中，以提取用于分类的特征。而 Fast/Faster R-CNN [16, 51] 和 SPPNet [22] 通过从全局特征图中池化特征来加速过程。早期的工作 [18, 19] 从 MCG [1] 中提取掩码候选框作为输入，以提取特征，而 CFM [9]、MNC [10] 和 Hayder 等人 [20] 将特征池化与网络合并，以提高速度。更新的设计是在网络中生成掩码作为候选框 [48, 49, 8] 或最终结果 [10, 34, 41]。Mask R-CNN [21] 是一个属于该类别的有效框架。我们的工作基于 Mask R-CNN，并从不同的方面对其进行了改进。\n\n另一类方法主要是基于分割的。它们学习了专门设计的变换 [3, 33, 38, 59] 或实例边界 [30]。然后从预测的变换中解码实例掩码。\n\n**多级特征**\n\n在图像识别中使用了来自不同层的特征。SharpMask [49]、Peng 等人 [47] 和 LRR [14] 通过融合特征图来进行分割，以获得更精细的细节。FCN [44]、U-Net [54] 和 Noh 等人 [46] 通过跳跃连接将来自较低层的信息融合在一起。TDM [56] 和 FPN [35] 通过横向连接增强自顶向下的路径，用于目标检测。与 TDM 不同，它将具有最高分辨率的融合特征图用于池化特征，SSD [42]、DSSD [13]、MS-CNN [5] 和 FPN [35] 将候选框分配到适当特征级别进行推理。我们将 FPN 作为基线，并对其进行了大幅改进。\n\nION [4]、Zagoruyko 等人 [62]、Hypernet [31] 和 Hypercolumn [19] 通过连接来自不同层的特征网格来进行更好的预测。但需要进行一系列操作，即归一化、连接和降维，以获得可行的新特征。相比之下，我们的设计要简单得多。\n\n**更大的上下文区域**\n\n[15, 64, 62] 中的方法使用类似于中间凹的结构为每个候选框池化特征，以利用具有不同分辨率的区域中的上下文信息。来自更大区域的特征提供了周围的环境信息。PSPNet [67] 和 ParseNet [43] 中使用了全局池化，极大地提高了语义分割的质量。Peng 等人 [47] 观察到类似的趋势，其中使用了全局卷积。我们的掩码预测分支也支持访问全局信息，但技术完全不同。\n\n## 3 模型框架\n\n我们的框架如图 1 所示。路径增强和聚合是为了提高性能。创建了一个自底向上的路径，以使低层信息更容易传播。我们设计了自适应特征池化，以允许每个候选框访问来自所有级别的信息进行预测。一个互补路径被添加到掩码预测分支中。这个新的结构导致了良好的性能。与 FPN 类似，这种改进与 CNN 结构无关，例如 [57, 32, 23]。\n\n### 3.1. 自底向上的路径增强\n\n**动机**\n\n论文[63] 中的深刻见解表明，高层神经元对整个目标有强烈的响应，而底层神经元更可能被局部纹理和图案激活，这表明了增强自顶向下路径以传播语义信息强的特征并增强所有特征以具有合理的分类能力的必要性。我们的框架通过基于高边缘或实例部分响应是对准确定位实例的强指标的事实，进一步增强了整个特征层次的空间定位能力。为此，我们构建了一条从低层到顶层的干净（指不经过变换直接连接）横向连接路径。因此，在这些层之间有一个“捷径”(图 1 中的虚线绿色线)，它由不到 10 层组成，横跨这些层。相比之下，FPN 中的 CNN 主干提供了一个从低层到最顶层的长路径(图 1 中的虚线红线)，它甚至经过 100 多层。\n\n**增强的自底向上结构**\n\n我们的框架首先完成自底向上的路径增强。我们遵循 FPN 来定义具有相同空间大小的特征图的层位于相同的网络阶段。每个特征级别对应一个阶段。我们还采用 ResNet [23] 作为基本结构，并使用 {P2, P3, P4, P5} 来表示 FPN 生成的特征级别。我们的增强路径从最低级别 P2 开始，并逐渐接近 P5，如图 1(b) 所示。\n\n从 P2 到 P5，空间大小逐渐以 2 为因子下采样。我们使用 {N2, N3, N4, N5} 来表示新产生的特征图，对应于 {P2, P3, P4, P5}。请注意，N2 就是 P2，没有经过任何处理。\n\n如图 2 所示，每个构建块从更高分辨率的特征图 $N_i$ 和更粗的特征图 $P_{i+1}$ 通过横向连接接收，并生成新的特征图 $N_{i+1}$。每个特征图 $N_i$ 首先通过一个步长为 2 的 3x3 卷积层来减少空间大小。然后，特征图 $P_{i+1}$ 的每个元素和下采样的图通过横向连接相加。然后，融合后的特征图经过另一个 3x3 卷积层来生成 $N_{i+1}$，以供后续子网络使用。这是一个迭代过程，并在接近 P5 时终止。\n\n![image-20240729155815876](/img/panet/image-20240729155815876.png)\n\n`图2. 自底向上路径扩展的构建块示意图。`\n\n在这些构建块中，我们始终使用特征图的通道 256。所有卷积层后面都跟着一个 ReLU [32]。然后，每个候选框的特征网格从新的特征图中池化，即 {N2, N3, N4, N5}。\n\n### 3.2. 自适应特征池化\n\n**动机**\n\n在 FPN [35] 中，根据候选框的大小将候选框分配到不同的特征级别。这使得小候选框被分配到低特征级别，而大候选框被分配到高特征级别。虽然简单有效，但它仍然可能产生非最优结果。例如，两个具有 10 像素差异的候选框可以被分配到不同的级别。实际上，这两个候选框相当相似。此外，特征的重要性可能与其所属的级别没有很强的相关性。高层特征是由具有大感受野生成的，并捕获更丰富的上下文信息。允许小候选框访问这些特征可以更好地利用有用的上下文信息进行预测。同样，低层特征包含许多精细的细节和高定位精度。让大候选框访问它们显然是有益的。基于这些想法，我们提出了为每个候选框从所有级别池化特征并进行融合，以供后续预测。我们将这个过程称为自适应特征池化。\n\n我们现在分析自适应特征池化中来自不同级别的特征池化的比例。我们使用最大操作来融合来自不同级别的特征，这允许网络选择逐元素的有用信息。我们根据候选框在 FPN 中被分配到的级别将候选框聚类为四类。对于每组候选框，我们计算从不同级别选择的特征的比例。在符号表示中，1-4 级别代表从低到高的级别。如图 3 所示，蓝色线代表最初在 FPN 中被分配到第 1 级别的小候选框。令人惊讶的是，近 70% 的特征来自其他更高的级别。我们还使用黄色线来表示最初在 FPN 中被分配到第 4 级别的大候选框。同样，50%+ 的特征是从其他较低的级别池化的。这个观察清楚地表明，多个级别的特征共同有助于准确的预测。这也是设计自底向上路径增强的强有力支持。\n\n![image-20240729160144008](/img/panet/image-20240729160144008.png)\n\n`图3. 自适应特征池化从不同特征层池化的特征比例。每条线代表一组应分配到FPN中相同特征级别的提案，即具有相似规模的提案。横轴表示汇集特征的来源。结果表明，不同规模的提案都利用了几个不同层次的特征。`\n\n**自适应特征池化结构**\n\n自适应特征池化实际上在实现上很简单，如图 1(c) 所示。首先，对于每个候选框，我们将它们映射到不同的特征级别，如图 1(b) 中的深灰色区域所示。遵循 Mask R-CNN [21]，ROIAlign 被用于从每个级别池化特征网格。然后，使用元素级最大值或求和的融合操作被用于融合来自不同级别的特征网格。\n\n在后续子网络中，池化的特征网格独立地通过一个参数层，该层后面跟着融合操作，以允许网络适应特征。例如，FPN 的框分支中有两个 fc 层。我们在第一层之后应用融合操作。由于 Mask R-CNN 中的掩码预测分支使用了四个连续的卷积层，我们将融合操作放置在第一个和第二个卷积层之间。关于自适应特征池化在框分支上的详细说明，请参见附录中的图 6。\n\n我们的设计侧重于融合网络内部特征层次的信息，而不是来自输入图像金字塔中不同特征图的 [52]。与 [4, 62, 31] 中的过程相比，它更简单，在这些过程中需要 L-2 归一化、连接和降维。\n\n### 3.3. 全连接融合\n\n**动机**\n\n全连接层(MLP) ，在实例分割 [10, 41, 34] 中的掩码预测和掩码候选框生成 [48, 49] 中被广泛使用。结果 [8, 33] 表明 FCN 也能够预测实例的像素级掩码。最近，Mask R-CNN [21] 在池化的特征网格上应用了一个小型 FCN 来预测相应的掩码，从而避免了类别之间的竞争。我们注意到 fc 层与 FCN 相比会产生不同的特性，其中后者根据局部感受野和不同空间位置的共享参数对每个像素进行预测。相反，fc 层是位置敏感的，因为不同空间位置的预测是通过不同的参数集实现的。因此，它们具有适应不同空间位置的能力。此外，每个空间位置的预测都是基于整个候选框的全局信息实现的。这有助于区分实例 [48] 并识别属于同一对象的独立部分。鉴于 fc 和卷积层之间不同的特性，我们将来自这两种类型层的预测进行融合，以获得更好的掩码预测。\n\n**掩码预测结构**\n\n我们的掩码预测组件轻量级且易于实现。掩码分支对每个候选框的池化特征网格进行操作。如图 4 所示，主路径是一个小型 FCN，由 4 个连续的卷积层和 1 个反转卷积层组成。每个卷积层由 256 个 3x3 滤波器组成，反转卷积层将特征上采样因子为 2。\n\n![image-20240729160326105](/img/panet/image-20240729160326105.png)\n\n`图4. 掩码预测分支与全连接融合。`\n\n它为每个类别独立地预测二值像素级掩码，以解耦分割和分类，类似于 Mask R-CNN。我们进一步创建了一条从 conv3 层到 fc 层的短路径。有两个 3x3 卷积层，其中第二个卷积层将通道数量减半，以减少计算开销。\n\n使用 fc 层预测类别无关的前景/背景掩码。它不仅效率高，而且允许 fc 层中的参数用更多样本来训练，从而获得更好的泛化能力。我们使用的掩码大小是 28x28，因此 fc 层产生一个 784x1x1 的向量。这个向量被重塑为与 FCN 预测的掩码相同的空间大小。为了获得最终的掩码预测，将 FCN 的每个类别的掩码和 fc 的前景/背景预测相加。使用一个 fc 层而不是多个 fc 层来进行最终预测，可以防止将隐藏的空间特征图坍缩成一个短的特征向量，从而丢失空间信息。\n\n## 4. 实验\n\n我们在具有挑战性的 COCO [37]、Cityscapes [7] 和 MVD [45] 数据集上将我们的方法与最先进的技术进行了比较。我们在所有这些数据集上都取得了排名靠前的结果。我们在 COCO 数据集上进行了全面的消融研究。我们还展示了我们在 COCO 2017 实例分割和目标检测挑战赛中的结果。\n\n### 4.1. 实现细节\n\n我们基于 Caffe [29] 重新实现了 Mask R-CNN 和 FPN。我们在实验中使用的所有预训练模型都是公开可用的。我们采用以图像为中心的训练 [16]。对于每张图像，我们采样 512 个感兴趣区域 (ROIs)，正负比例为 1:3。权重衰减为 0.0001，动量为 0.9。其他超参数略有不同，具体取决于数据集，我们在各自的实验中详细说明了它们。遵循 Mask R-CNN，候选框来自一个独立训练的 RPN [35, 51]，以便于消融和公平比较，即主干不与目标检测/实例分割共享。\n\n### 4.2. 在 COCO 上的实验\n\n**数据集和指标**\n\nCOCO [37] 数据集是实例分割和目标检测最具挑战性的数据集之一，因为数据复杂。它包含 11.5 万张训练图像和 5 千张验证图像(2017 年的新分割)。2 万张图像用于测试开发，2 万张图像用作测试挑战。测试挑战和测试开发的真实标签没有公开。有 80 个类别，带有像素级实例掩码注释。我们在 train-2017 子集上训练我们的模型，并在 val-2017 子集上报告消融研究的结果。我们还报告了测试开发集上的结果以进行比较。\n\n我们遵循标准的评估指标，即 $AP、AP_{50}、AP_{75}、AP_S、AP_M和 AP_L$ 。最后三个指标衡量不同尺度对象的表现。由于我们的框架对实例分割和目标检测都适用，我们还训练了独立的目标检测器。我们报告了独立训练的目标检测器的掩码 AP 和框 ap $AP^{bb}$，以及多任务方式训练的框分支的 box ap $AP^{bbM}$。\n\n**超参数**\n\n我们在一个图像批次中使用 16 张图像进行训练。如果未特别说明，则图像的短边和长边分别为 800 和 1000。对于实例分割，我们使用学习率 0.02 训练模型 120k 次迭代，并使用学习率 0.002 训练 40k 次迭代。对于目标检测，我们训练了一个没有掩码预测分支的目标检测器。目标检测器以学习率 0.02 训练 60k 次迭代，并以学习率 0.002 训练 20k 次迭代。\n\n这些参数是从 Mask R-CNN 和 FPN 中采用的，没有进行任何微调。\n\n**实例分割结果**\n\n我们报告了我们的 PANet 在测试开发集上的性能以进行比较，包括多尺度训练和不进行多尺度训练。如表 1 所示，我们的 PANet 使用在多尺度图像上训练并在单尺度图像上测试的 ResNet-50，已经超过了 Mask R-CNN 和 2016 年的冠军，其中后者使用了更大的模型集成和测试技巧 [23, 33, 10, 15, 39, 62]。在 800 的图像尺度上训练和测试，我们的方法在相同的初始模型下比单模型最先进的 Mask R-CNN 的性能提高了近 3 个百分点。\n\n![image-20240729161430557](/img/panet/image-20240729161430557.png)\n\n`表1：在COCO测试-验证子集中，基于PANet（COCO 2016实例分割挑战赛的获胜者）和Mask R-CNN（基准模型）的Mask AP的比较。`\n\n**目标检测结果**\n\n与 Mask R-CNN 采用的方式类似，我们还报告了从框分支推断的边界框结果。表 2 显示，我们的方法使用 ResNet-50，在单尺度图像上进行训练和测试，以大幅优势超过了所有其他单模型，即使使用了更大的 ResNeXt-101 [61] 作为初始模型。使用多尺度训练和单尺度测试，我们的 PANet 使用 ResNet-50 超过了 2016 年的冠军，后者使用了更大的模型集成和测试技巧。\n\n![image-20240729161536835](/img/panet/image-20240729161536835.png)\n\n`表2. COCO 2016目标检测挑战赛的获胜者PANet、RetinaNet和Mask R-CNN在COCO测试开发子集上的box AP比较，其中后三个为基线。`\n\n**组件消融研究**\n\n首先，我们分析了我们提出的每个组件的重要性。除了自底向上路径增强、自适应特征池化和全连接融合之外，我们还分析了多尺度训练、多 GPU 同步批归一化和更重的头部。对于多尺度训练，我们将长边设置为 1,400，而另一个则从 400 到 1,400。我们在一个批次中跨所有 GPU 的所有样本上计算均值和方差，在训练过程中不固定任何参数，并且当使用多 GPU 同步批归一化时，使所有新层后面跟着一个批归一化层。更重的头部使用 4 个连续的 3x3 卷积层，由框分类和框回归共享，而不是两个 fc 层。这与 [36] 中使用的头部类似，但在他们的情况下，框分类和框回归分支的卷积层不共享。\n\n我们在 val-2017 子集上从基线逐渐添加所有组件的消融研究，结果如表 3 所示。ResNet-50 [23] 是我们的初始模型。我们报告了掩码 AP、独立训练的目标检测器的框 ap APbb 和多任务方式训练的框分支的 box ap APbbM 的性能。\n\n1. 重新实现的基线。我们重新实现的 Mask R-CNN 的性能与原始论文中描述的性能相当，我们的目标检测器表现更好。\n2. 多尺度训练和多 GPU 同步批归一化。这两种技术有助于网络更好地收敛并提高泛化能力。\n3. 自底向上路径增强。无论是否有自适应特征池化，自底向上路径增强始终将掩码 AP 和框 ap APbb 分别提高 0.6 和 0.9 以上。对大尺度实例的改进最为显着。这证实了来自较低特征层次的信息的有用性。\n4. 自适应特征池化。无论是否有自底向上路径增强，自适应特征池化始终提高性能。所有尺度的性能通常都会提高，这与我们的观察结果一致，即其他层的特征在最终预测中也有用。\n5. 全连接融合。全连接融合旨在预测质量更好的掩码。它在掩码 AP 方面产生了 0.7 的改进。它对所有尺度的实例都通用。\n6. 更重的头部。更重的头部对多任务方式训练的边界框的 box ap APbbM 非常有效。而对于掩码 AP 和独立训练的目标检测器，改进很小。\n\n![image-20240729161823917](/img/panet/image-20240729161823917.png)\n\nTable3. 在val-2017上独立训练的目标检测器的mask AP、box AP $AP^{bb}$和多任务方式训练的box分支的box AP $AP^{bbM}$的性能指标。基于我们重新实现的基线(RBL)，我们逐渐增加了多尺度训练(MST)、多gpu同步批归一化(MBN)、自下而上路径增强(BPA)、自适应特征池化(AFP)、全连接融合(FF)和重头(HHD)的研究。MRB是原论文中报道的Mask R-CNN结果的简称。最后一行显示了与基线RBL相比的总体改善。\n\nPANet 中包含所有这些组件，掩码 AP 比 baselines 提高了 4.4。独立训练的目标检测器的 box AP $AP^{bb}$增加了 4.2。它们都是显着的。小尺寸和中尺寸实例的贡献最大。一半的改进来自多尺度训练和多 GPU 同步批归一化，这些是帮助训练更好模型的策略。\n\n**自适应特征池化消融研究**\n\n我们对自适应特征池化进行了消融研究，以找出在哪里放置融合操作以及最合适的融合操作。我们将它放置在 ROIAlign 和 fc1 之间，用“fu.fc1fc2”表示，或者放置在 fc1 和 fc2 之间，用“fc1fu.fc2”表示，如表 4 所示。类似的设置也应用于掩码预测分支。对于特征融合，我们测试了最大值和求和操作。\n\n![image-20240729162708703](/img/panet/image-20240729162708703.png)\n\n`表4. 基于独立训练目标检测器掩模AP和Box AP的val-2017自适应特征池化消融研究`\n\n如表 4 所示，自适应特征池化对融合操作不敏感。然而，允许一个参数层来适应来自不同级别的特征网格是非常重要的。我们在框架中使用最大值作为融合操作，并将其放在第一个参数层之后。\n\n**全连接融合消融研究**\n\n我们研究了以不同的方式实例化增强的 fc 分支的性能。我们考虑了两个方面，即开始新分支的层和融合来自新分支和 FCN 的预测的方法。我们分别从 conv2、conv3 和 conv4 创建新路径。“max”、“sum”和“product”操作用于融合。我们将我们重新实现的 Mask R-CNN，包括自底向上路径增强和自适应特征池化作为基线。相应的结果如表 5 所示。它们清楚地表明，从 conv3 开始并使用求和进行融合会产生最佳结果。\n\n![image-20240729162733861](/img/panet/image-20240729162733861.png)\n\n`表5所示。基于Mask AP的val-2017全连接融合消融研究。`\n\n**COCO 2017 挑战赛**\n\n使用 PANet，我们参加了 COCO 2017 实例分割和目标检测挑战赛。我们的框架在实例分割任务中取得了第一名，在目标检测任务中取得了第二名，而没有使用大批次训练。如图 1 和表 6 和表 7 所示，与去年的冠军相比，我们在实例分割方面取得了 9.1% 的绝对和 24% 的相对改进。而目标检测方面，则取得了 9.4% 的绝对和 23% 的相对改进。\n\n![image-20240729162909706](/img/panet/image-20240729162909706.png)\n\n`表6所示。测试开发中不同年份COCO实例分割挑战的Mask AP。`\n\n![image-20240729162934233](/img/panet/image-20240729162934233.png)\n\n`表7. COCO目标检测挑战赛不同年份测试开发的方框AP。`\n\n最先进的性能来自于 PANet 中的几个细节。首先，我们使用了可变形卷积，其中采用了 DCN [11]。常规的测试技巧 [23, 33, 10, 15, 39, 62]，例如多尺度测试、水平翻转测试、掩码投票和框投票，都被采用。对于多尺度测试，我们将长边设置为 1,400，而另一个则从 600 到 1,200，步长为 200。仅使用 4 个尺度。其次，我们使用了更大型的初始模型，这些模型是公开可用的。我们使用 3 个 ResNeXt-101 (64x4d) [61]、2 个 SE-ResNeXt-101 (32x4d) [25]、1 个 ResNet-269 [64] 和 1 个 SENet [25] 作为边界框和掩码生成的集成。使用不同的大型初始模型的性能相似。一个 ResNeXt-101 (64x4d) 被用作生成候选框的基本模型。我们使用不同的随机种子和平衡采样 [55] 来增强模型之间的多样性来训练这些模型。我们提交的检测结果是通过收紧实例掩码获得的。我们在图 5 中展示了几个视觉结果——我们的大多数预测都具有很高的质量。\n\n![image-20240729160459095](/img/panet/image-20240729160459095.png)\n\n`图5. 每行图像分别是本文的模型在COCO test-dev, cityscape test和MVD test上的可视化结果。`\n\n### 4.3. 在 Cityscapes 上的实验\n\n**数据集和指标**\n\nCityscapes [7] 包含由车载摄像头拍摄的街景。有 2,975 张训练图像、500 张验证图像和 1,525 张测试图像，具有精细注释。另外 20k 张图像具有粗略注释，不包括在训练中。我们在 val 和 secret 测试子集上报告我们的结果。8 个语义类别带有实例掩码注释。每张图像的大小为 1024x2048。我们根据 AP 和 AP50 评估结果。\n\n**超参数**\n\n我们使用与 Mask R-CNN [21] 相同的超参数集进行公平比较。具体来说，我们在训练时随机从 {800, 1024} 中选择短边进行训练，并在推理时使用短边为 1024 的图像。没有使用测试技巧或 DCN。我们以学习率 0.01 训练模型 18k 次迭代，并以学习率 0.001 训练 6k 次迭代。每个图像批次中有 8 张图像(每个 GPU 1 张图像)。\n\nResNet-50 是此数据集上的初始模型。\n\n**方法和结果**\n\n我们在测试子集上与最先进的技术进行了比较，结果如表 8 所示。在“fine-only”数据上训练，我们的方法比使用“fine-only”数据的 Mask R-CNN 的性能提高了 5.6 个百分点。它甚至可以与在 COCO 上预训练的 Mask R-CNN 相媲美。通过在 COCO 上进行预训练，我们比使用相同设置的 Mask R-CNN 的性能提高了 4.4 个百分点。我们在图 5 中展示了视觉结果。\n\n![image-20240729160910818](/img/panet/image-20240729160910818.png)\n\n`表8. 结果在cityscape val子集上，记为AP [val]，在cityscape测试子集上，记为AP。`\n\n我们对 val 子集上的改进进行的消融研究如表 9 所示。基于我们重新实现的基线，我们添加了多 GPU 同步批归一化，以帮助网络更好地收敛。它将精度提高了 1.5 个百分点。使用我们的完整 PANet，性能又提高了 1.9 个百分点。\n\n![image-20240729160645261](/img/panet/image-20240729160645261.png)\n\n`表9. 城市景观val子集消融研究结果。只有精细的注释用于训练。MBN是多gpu同步批处理规范化的缩写。`\n\n### 4.4. 在 MVD 上的实验\n\nMVD [45] 是一个相对较新且规模较大的实例分割数据集。它提供了 25,000 张街景图像，带有 37 个语义类别的精细实例级注释。它们是从几个国家使用不同的设备捕获的。内容和分辨率差异很大。我们在训练子集上使用 ResNet-50 作为初始模型训练我们的模型，并报告了在 val 和 secret 测试子集上根据 AP 和 AP50 的性能。\n\n我们在表 10 中展示了我们的结果。与 LSUN 2017 实例分割挑战赛中的冠军 UCenter [40] 相比，我们的 PANet 使用一个在单尺度图像上测试的 ResNet-50 已经与在 COCO 上进行预训练的集成结果相当。通过使用 UCenter 也采用的多种尺度测试和水平翻转测试，我们的方法表现得甚至更好。定性的结果在图 5 中展示。\n\n![image-20240729160743160](/img/panet/image-20240729160743160.png)\n\n`表10. MVD值子集和测试子集的结果。`\n\n## 5. 结论\n\n我们提出了用于实例分割的 PANet。我们设计了一些简单而有效的组件，以增强代表性管道中的信息传播。我们从所有特征级别池化特征，并缩短了低层和顶层特征之间的距离，以进行可靠的信息传递。互补路径被增强以丰富每个候选框的特征。产生了令人印象深刻的结果。我们的未来工作是将我们的方法扩展到视频和 RGBD 数据。\n\n## 附录\n\n### A. Cityscapes 和 MVD 的训练细节和生成锚点的策略\n\n在 Cityscapes [7] 上，我们采用了 Mask R-CNN [21] 中的训练超参数，并已在第 4.3 节中描述。RPN 锚点跨越 5 个尺度和 3 个宽高比，遵循 [21, 35]。而在 MVD [45] 上，我们采用了获胜者 [40] 中的训练超参数。我们以学习率 0.02 训练模型 60k 次迭代，并以学习率 0.002 训练 20k 次迭代。我们使用 16 张图像进行训练。我们设置输入图像的长边为 2400 像素，而另一个则从 600 到 2000 像素进行多尺度训练。我们采用了 {1600, 1800, 2000} 尺度进行多尺度测试。RPN 锚点跨越 7 个尺度，即 {82, 162, 322, 642, 1282, 2562, 5122}，和 5 个宽高比，即 {0.2, 0.5, 1, 2, 5}。RPN 使用与目标检测/实例分割网络训练相同的尺度进行训练。\n\n### B. 实现 多 GPU 同步批归一化的细节\n\n我们在 Caffe [29] 和 OpenMPI 上实现了多 GPU 批归一化。给定 n 个 GPU 和训练批次中的样本 B，我们首先将训练样本均匀地分割成 n 个子批次，每个子批次用 bi 表示，分配给一个 GPU。在每个 GPU 上，我们根据 bi 中的样本计算均值 µi。然后对所有 GPU 应用 AllReduce 操作来收集所有 µi，以获得整个批次 B 的均值 µB。µB 被广播到所有 GPU。然后我们独立地在每个 GPU 上计算临时统计数据，并应用 AllReduce 操作来生成整个批次 B 的方差 σ2 B。σ2 B 也被广播到所有 GPU。因此，每个 GPU 都具有在 B 上的所有训练样本上计算的统计数据。然后我们对每个训练样本执行归一化 $y_m = γ\\frac{x_m−µ_B}{\\sqrt{σ^2_B+ϵ}} + β$，如 [28] 中所示。在反向操作中，我们同样应用 AllReduce 操作来收集来自所有 GPU 的信息，以便进行梯度计算。","comments":true,"categories":[],"tags":[{"name":"CS","slug":"CS","permalink":"http://blog.ahulearn.com/tags/CS/"},{"name":"CVPR 2018","slug":"CVPR-2018","permalink":"http://blog.ahulearn.com/tags/CVPR-2018/"}]},{"title":"桩检测算法-自监督学习","date":"2024-07-17T10:30:00.000Z","path":"2024/07/17/桩检测算法/","raw":"---\ntitle:  桩检测算法-自监督学习\ndate: 2024-07-17 18:30:00\ntags:\n - work\n---\n\n\n\n# 桩检测算法\n\n## 总体流程\n\n1. **基于规则的桩检测**\n   - 采用基于规则的方法检测桩，检测时不区分桩类别。这一步保证绝对的准确率（100%），较高的召回率（>60%）。\n2. **生成桩检测数据集**\n   - 使用规则检测的结果作为标注生成桩检测数据集【pile_v0.1】。\n3. **模型训练**\n   - 使用YOLO算法在桩检测数据集上训练一个初步的桩检测模型【model_v0.1】。\n4. **自监督训练**\n   - 使用训练好的模型对基于规则无法检测的图纸进行检测，将置信度较高的结果加入到训练集继续训练。\n\n<!--more-->\n\n## 基于规则的桩检测\n\n- **过滤干扰线**\n  - 长度 < 1500\n  - 直径 < 1500\n  - 面积 < 1500×1500\n  - 只保留直线，多段线，圆，椭圆，圆弧，实体，填充\n\n- **桩检测**\n  - 将去除干扰线后的实体导出图像求连通域\n  - 在每个连通域内进行桩检测，提高效率\n  - 圆检测：圆实体，多段线实体（只包含曲线，且构成360度），圆弧实体（构成360度），椭圆实体（长轴=短轴）\n  - 矩形检测：基于最近邻算法，遍历直线和它最近邻的直线是否组成矩形\n  - 交叉线检测：基于扫描线算法检测线是否交叉，判断交点是否在上述圆或矩形中心附近\n  - 填充检测：检测填充是否在上述圆或矩形内\n  - 将检测结果导出图像，再求一次连通域，重复上述桩检测算法，保证准确率\n\n## 生成桩检测数据集\n\n- **生成桩边界框**\n  - 根据基于规则的检测结果生成桩边界框\n\n- **处理图像**\n  - 将原始图纸和过滤干扰线后的图纸都导出图片，增加数据规模和多样性\n  - 以640×640为滑动窗口，窗口重合度20%，将导出图像切分为小图\n  - 将边界框转为图像坐标下的结果，并转为小图坐标下的标注\n  - 筛除没有边界框的小图，剩余图像作为训练集\n\n## 模型训练\n\n- **使用YOLOv8n**\n  - 将数据集转为YOLOv8模型需要的格式，并修改数据集配置文件\n  - 加载预训练权重，使用batch=32，epoch=120进行训练，其他参数默认\n  - 训练出桩检测模型【model_v0.1】\n\n## 自监督训练\n\n- **测试集使用规则检测遗漏的桩**\n  - 将基于规则无法检测的桩作为测试集，使用桩检测模型【model_v0.1】对测试集的数据进行检测\n  - 将测试集中置信度较高的生成标签，合并原有数据集【pile_v0.1】中，生成新数据集【pile_v0.2】\n  - 在新数据集【pile_v0.2】上继续训练桩检测模型，训练结束后生成新的桩检测模型【model_v0.2】\n  - 使用新的模型重复上述步骤，循环5轮。","comments":true,"categories":[],"tags":[{"name":"work","slug":"work","permalink":"http://blog.ahulearn.com/tags/work/"}]},{"title":"YOLOV8代码阅读","date":"2024-05-22T12:00:00.000Z","path":"2024/05/22/YOLOV8代码阅读/","raw":"---\ntitle: YOLOV8代码阅读\ndate: 2024-05-22 20:00:00\ntags:\n - python\n - 深度学习\ntypora-root-url: ..\ntypora-copy-images-to: ../img/python\n---\n\n# YOLOV8代码阅读\n\n\n\n<!--more-->\n\n\n\n## YOLO 训练参数\n\n官网地址：[训练参数](https://docs.ultralytics.com/modes/train/#train-settings)\n\n| Argument      | Default | Description                                                  |\n| :------------ | :------ | :----------------------------------------------------------- |\n| model         | None    | Specifies the model file for training. Accepts a path to either a .pt pretrained model or a .yaml configuration file. Essential for defining the model structure or initializing weights. |\n| data          | None    | Path to the dataset configuration file (e.g., coco8.yaml). This file contains dataset-specific parameters, including paths to training and validation data, class names, and number of classes. |\n| epochs        | 100     | Total number of training epochs. Each epoch represents a full pass over the entire dataset. Adjusting this value can affect training duration and model performance. |\n| time          | None    | Maximum training time in hours. If set, this overrides the epochs argument, allowing training to automatically stop after the specified duration. Useful for time-constrained training scenarios. |\n| patience      | 100     | Number of epochs to wait without improvement in validation metrics before early stopping the training. Helps prevent overfitting by stopping training when performance plateaus. |\n| batch         | 16      | Batch size, with three modes: set as an integer (e.g., batch=16), auto mode for 60% GPU memory utilization (batch=-1), or auto mode with specified utilization fraction (batch=0.70). |\n| imgsz         | 640     | Target image size for training. All images are resized to this dimension before being fed into the model. Affects model accuracy and computational complexity. |\n| save          | True    | Enables saving of training checkpoints and final model weights. Useful for resuming training or model deployment. |\n| save_period   | -1      | Frequency of saving model checkpoints, specified in epochs. A value of -1 disables this feature. Useful for saving interim models during long training sessions. |\n| cache         | False   | Enables caching of dataset images in memory (True/ram), on disk (disk), or disables it (False). Improves training speed by reducing disk I/O at the cost of increased memory usage. |\n| device        | None    | Specifies the computational device(s) for training: a single GPU (device=0), multiple GPUs (device=0,1), CPU (device=cpu), or MPS for Apple silicon (device=mps). |\n| workers       | 8       | Number of worker threads for data loading (per RANK if Multi-GPU training). Influences the speed of data preprocessing and feeding into the model, especially useful in multi-GPU setups. |\n| project       | None    | Name of the project directory where training outputs are saved. Allows for organized storage of different experiments. |\n| name          | None    | Name of the training run. Used for creating a subdirectory within the project folder, where training logs and outputs are stored. |\n| exist_ok      | False   | If True, allows overwriting of an existing project/name directory. Useful for iterative experimentation without needing to manually clear previous outputs. |\n| pretrained    | True    | Determines whether to start training from a pretrained model. Can be a boolean value or a string path to a specific model from which to load weights. Enhances training efficiency and model performance. |\n| optimizer     | ‘auto’  | Choice of optimizer for training. Options include SGD, Adam, AdamW, NAdam, RAdam, RMSProp etc., or auto for automatic selection based on model configuration. Affects convergence speed and stability. |\n| seed          | 0       | Sets the random seed for training, ensuring reproducibility of results across runs with the same configurations. |\n| deterministic | True    | Forces deterministic algorithm use, ensuring reproducibility but may affect performance and speed due to the restriction on non-deterministic algorithms. |\n| single_cls    | False   | Treats all classes in multi-class datasets as a single class during training. Useful for binary classification tasks or when focusing on object presence rather than classification. |\n| rect          | False   | Enables rectangular training, optimizing batch composition for minimal padding. Can improve efficiency and speed but may affect model accuracy. |\n| cos_lr        | False   | Utilizes a cosine learning rate scheduler, adjusting the learning rate following a cosine curve over epochs. Helps in managing learning rate for better convergence. |\n| close_mosaic  | 10      | Disables mosaic data augmentation in the last N epochs to stabilize training before completion. Setting to 0 disables this feature. |\n| resume        | False   | Resumes training from the last saved checkpoint. Automatically loads model weights, optimizer state, and epoch count, continuing training seamlessly. |\n| amp           | True    | Enables Automatic Mixed Precision (AMP) training, reducing memory usage and possibly speeding up training with minimal impact on accuracy. |\n| fraction        | 1.0     | 指定用于训练的数据集的比例。允许在完整数据集的子集上进行训练，在资源有限或进行实验时非常有用。 |\n| profile         | False   | 启用ONNX和TensorRT在训练期间的速率分析，有助于优化模型部署。 |\n| freeze          | None    | 冻结模型的前N层或通过索引指定的层，减少可训练参数的数量。对于微调或迁移学习非常有用。 |\n| lr0             | 0.01    | 初始学习率（例如，SGD=1E-2，Adam=1E-3）。调整这个值对于优化过程至关重要，影响模型权重的更新速度。 |\n| lrf             | 0.01    | 最终学习率作为初始率的分数 =（lr0 * lrf），与调度器结合使用，随着时间的推移调整学习率。 |\n| momentum        | 0.937   | SGD或Adam优化器的动量因子，影响当前更新中过去梯度的融合。    |\n| weight_decay    | 0.0005  | L2正则化项，惩罚大权重以防止过拟合。                         |\n| warmup_epochs   | 3.0     | 学习率热身期的周期数，从低值逐渐增加到初始学习率，以在训练初期稳定训练。 |\n| warmup_momentum | 0.8     | 热身阶段的初始动量，逐渐调整到设定的动量。                   |\n| warmup_bias_lr  | 0.1     | 热身阶段偏置参数的学习率，帮助在初始周期稳定模型训练。       |\n| box             | 7.5     | 损失函数中框损失组件的权重，影响准确预测边界框坐标的重视程度。 |\n| cls             | 0.5     | 总损失函数中分类损失的权重，影响正确类别预测相对于其他组件的重要性。 |\n| dfl             | 1.5     | 分布焦点损失的权重，用于某些YOLO版本进行细粒度分类。         |\n| pose            | 12.0    | 在用于姿态估计的模型中姿态损失的权重，影响准确预测姿态关键点的重视程度。 |\n| kobj            | 2.0     | 姿态估计模型中关键点目标性损失的权重，平衡检测置信度与姿态准确性。 |\n| label_smoothing | 0.0     | 应用标签平滑，将硬标签软化为目标标签和均匀分布标签的混合，可以提高泛化能力。 |\n| nbs             | 64      | 用于损失标准化的名义批量大小。                               |\n| overlap_mask    | True    | 确定是否应该将对象掩码合并为单个掩码进行训练，或者为每个对象保持单独的掩码。在重叠的情况下，较小的掩码在合并期间覆盖在较大的掩码之上。 |\n| mask_ratio      | 4       | 分段掩码的下采样比率，影响训练期间使用的掩码的分辨率。       |\n| dropout         | 0.0     | 分类任务中的正则化丢弃率，通过在训练期间随机省略单元来防止过拟合。 |\n| val             | True    | 启用训练期间的验证，允许定期在独立数据集上评估模型性能。     |\n| plots           | False   | 生成并保存训练和验证度量的图表以及预测示例，提供模型性能和学习进展的可视化洞察。 |\n\n\n\n## YOLO 数据增强\n\n官网地址：[数据增强参数](https://docs.ultralytics.com/modes/train/#augmentation-settings-and-hyperparameters)\n\n| Argument   | Type    | Default | Range       | Description                                                                             |\n|:-----------|:--------|:--------|:------------|:--------------------------------------------------------------------------------------------|\n| hsv_h      | float   | 0.015   | 0.0 - 1.0   | 调整图像的色调，引入色彩变化。有助于模型在不同光照条件下泛化。               |\n| hsv_s      | float   | 0.7     | 0.0 - 1.0   | 通过分数改变图像的饱和度，影响色彩强度。对于模拟不同环境条件有用。                           |\n| hsv_v      | float   | 0.4     | 0.0 - 1.0   | 通过分数修改图像的明度（亮度），帮助模型在各种光照条件下表现良好。                            |\n| degrees    | float   | 0.0     | -180 - +180 | 在指定的角度范围内随机旋转图像，提高模型识别不同方向物体的能力。                             |\n| translate  | float   | 0.1     | 0.0 - 1.0   | 按照图像大小的分数水平和垂直平移图像，有助于学习检测部分可见的物体。                          |\n| scale      | float   | 0.5     | >=0.0       | 通过增益因子缩放图像，模拟不同距离下的物体。                                                 |\n| shear      | float   | 0.0     | -180 - +180 | 通过指定角度剪切图像，模仿从不同角度观察物体的效果。                                         |\n| perspective| float   | 0.0     | 0.0 - 0.001 | 对图像应用随机透视变换，增强模型理解三维空间中物体的能力。                                    |\n| flipud     | float   | 0.0     | 0.0 - 1.0   | 以指定概率上下翻转图像，增加数据多样性，不影响物体特征。                                     |\n| fliplr     | float   | 0.5     | 0.0 - 1.0   | 以指定概率左右翻转图像，对于学习对称物体和增加数据集多样性有用。                              |\n| bgr        | float   | 0.0     | 0.0 - 1.0   | 以指定概率将图像通道从RGB切换到BGR，对于增加对错误通道顺序的鲁棒性有用。                     |\n| mosaic     | float   | 1.0     | 0.0 - 1.0   | 将四个训练图像组合成一个，模拟不同的场景构成和物体互动。对于复杂场景理解非常有效。            |\n| mixup      | float   | 0.0     | 0.0 - 1.0   | 混合两个图像及其标签，创建复合图像。通过引入标签噪声和视觉变化，增强模型泛化能力。             |\n| copy_paste | float   | 0.0     | 0.0 - 1.0   | 从一个图像复制物体并粘贴到另一个图像上，对于增加物体实例和学习物体遮挡有用。                 |\n| auto_augment| str    | randaugment | - | 自动应用预定义的增强策略（randaugment, autoaugment, augmix），通过多样化视觉特征优化分类任务。 |\n| erasing    | float   | 0.4     | 0.0 - 0.9   | 在分类训练期间随机擦除图像的一部分，鼓励模型关注于不太明显的特征以进行识别。                  |\n| crop_fraction| float | 1.0     | 0.1 - 1.0   | 将分类图像裁剪为其大小的分数，强调中心特征，适应物体尺度，减少背景干扰。                    |","comments":true,"categories":[],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://blog.ahulearn.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"python","slug":"python","permalink":"http://blog.ahulearn.com/tags/python/"}]},{"title":"python-gRPC实战","date":"2024-05-20T12:00:00.000Z","path":"2024/05/20/gRPC实战/","raw":"---\ntitle: python-gRPC实战\ndate: 2024-05-20 20:00:00\ntags:\n - python\n - 深度学习\ntypora-root-url: ..\ntypora-copy-images-to: ../img/python\n---\n\n\n\n# python-gRPC实战\n\n\n\n## 前言\n\n**RPC**：远程过程调用（Remote Procedure Call）的缩写，即在不同设备进行远程方法调用，隐藏了底层网络技术。随着微服务的兴起而兴起。\n\n**gRPC**：谷歌开源的一套RPC框架，基于http2.0，采用protocol buffer的语法(检查proto)，通过proto语法可以定义好要调用的方法、和参数以及响应格式，可以很方便地完成远程方法调用，而且非常利于扩展和更新参数。\n\n![grpc框架](/img/python/grpc_struct.jpg)\n\n<!--more-->\n\n## 环境配置\n\n```shell\nconda create -n test python=3.8\nconda activate test\npip install grpcio -i https://pypi.tuna.tsinghua.edu.cn/simple\npip install grpcio-tools -i https://pypi.tuna.tsinghua.edu.cn/simple\n```\n\n\n\n## 编译配置\n\n```shell\n# 编译 proto 文件\npython -m grpc_tools.protoc --python_out=.  --grpc_python_out=.  -I. test.proto\n\npython -m grpc_tools.protoc: python 下的 protoc 编译器通过 python 模块(module) 实现, 所以说这一步非常省心\n--python_out=. : 编译生成处理 protobuf 相关的代码的路径, 这里生成到当前目录\n--grpc_python_out=. : 编译生成处理 grpc 相关的代码的路径, 这里生成到当前目录\n-I. test.proto : proto 文件的路径, 这里的 proto 文件在当前目录\n```\n\n","comments":true,"categories":[],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://blog.ahulearn.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"python","slug":"python","permalink":"http://blog.ahulearn.com/tags/python/"}]},{"title":"pytorch-优化器算法","date":"2024-05-14T06:24:00.000Z","path":"2024/05/14/pytorch-优化器/","raw":"---\ntitle: pytorch-优化器算法\ndate: 2024-05-14 14:24:00\ntags:\n - PyTorch\n - 深度学习\ntypora-root-url: ..\ntypora-copy-images-to: ../img/pytorch\n---\n\n# 优化器算法\n\n\n\n[TOC]\n\n## 0. 基础\n\n### 1. 导入\n\n```python\nimport torch.optim as optim\n```\n\n### 2. 常用的优化器\n\n+ SGD/Momentum SGD\n+ Adam/AdamW\n+ AdaGrad\n+ RMS prop\n\n<!--more-->\n\n\n\n### 3. 使用框架\n\n+ 生成优化器\n\n```python\nimport torch.optim as optim\n\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\noptimizer = optim.Adam([var1, var2], lr=0.0001)\n```\n\n+ 同一个模型定义不同的优化器\n\n```python\nimport torch\nimport torch.optim as optim\n\n# params可以用字典传参，给不同的参数赋值不同的学习率\noptim.SGD([{'params': model.base.parameters(), 'lr': 1e-2},\n            {'params': model.classifier.parameters()}\n        ], lr=1e-3, momentum=0.9)\n\n# 给不同的参数设置不同的权重衰减系数，bias权重衰减设为0\nbias_params = [p for name, p in model.named_parameters() if 'bias' in name]\nothers = [p for name, p in model.named_parameters() if 'bias' not in name]\noptim.SGD([{'params': others},\n           {'params': bias_params, 'weight_decay': 0}\n           ], weight_decay=1e-2, lr=1e-2)\n```\n\n\n\n+ 使用优化器\n\n```python\nfor input, target in dataset:\n    # 梯度清零\n    optimizer.zero_grad()\n    output = model(input)\n    # 计算损失\n    loss = loss_fn(output, target)\n    # 损失反向传播（计算每个参数的梯度）\n    loss.backward()\n    # 根据梯度更新权重参数\n    optimizer.step()\n```\n\n\n\n## 1. SGD/Momentum SGD\n\nSGD：随机梯度优化，最简单常用的优化器，卷积神经网络时代比较好用，transformer时代被AdamW取代。\n\n### 1.1 SGD原理\n\n**1. 计算梯度**:  $f_t$是模型函数，$θ_{t-1}$是上一步的参数，$\\nabla_θ$是向量梯度计算，$\\lambda$是权重衰减系数\n\n$$g_t=\\nabla_θ f_t (θ_{t-1})$$\n\n$$g_t=g_t + \\lambda θ_{t-1} $$\n\n**2. 梯度更新**：$\\lambda$是权重衰减系数，$\\gamma$是学习率\n\n\n$$\\theta_t = \\theta_{t-1} -\\gamma g_t $$\n\n### 1.2 Momentum SGD原理\n\n**1. 计算梯度**: 和SGD一样计算权重衰减后的梯度\n\n$$g_t=\\nabla_θ f_t (θ_{t-1})$$\n\n$$g_t=g_t + \\lambda θ_{t-1} $$\n\n**2. 计算动量**：$m_t$是当前动量，$m_{t-1}$上一步的动量，$\\beta$是动量系数\n\n$$m_0 = g_0$$\n\n$$m_t = \\beta m_{t-1} + (1-\\beta)g_t $$\n\n目前新的版本使用$1- \\tau$ 代替$1- \\beta$，$\\tau$作为动量抑制系数\n\n$$m_t = \\beta m_{t-1} + (1-\\tau)g_t $$\n\n**3. 梯度更新**：$\\gamma$是学习率\n\n$$g_t = b_t$$\n\n$$\\theta_t = \\theta_{t-1} -\\gamma g_t $$\n\n### 1.3 代码\n\n```python\nclass SGD(Optimizer):\n    def __init__(self, params, \n                 lr=1e-3, \n                 momentum=0, \n                 dampening=0,\n                 weight_decay=0, \n                 nesterov=False, *, \n                 maximize: bool = False, \n                 foreach: Optional[bool] = None,\n                 differentiable: bool = False, \n                 fused: Optional[bool] = None):\n```\n\n参数：\n\n* **params**：待优化的模型参数，通过**model.parameters()**获得\n* **lr**：学习率$\\gamma$\n* **momentum**：梯度动量系数$\\mu$\n* **dampening**：动量抑制$\\tau$\n* **eps**：分母的添加项，增加数值稳定性1e-8\n* **weight_decay**：权重衰减系数，正则化系数$\\lambda$\n\n## 2. Adam/AdamW\n\n### 2.1 Adam\n\n**1. 计算梯度**:  $f_t$是模型函数，$θ_{t-1}$是上一步的参数，$\\nabla_θ$是向量梯度计算，$\\lambda$是权重衰减系数\n\n$$g_t=\\nabla_θ f_t (θ_{t-1})$$\n\n$$g_t=g_t + \\lambda θ_{t-1}$$\n\n**2. 计算动量**：$m_t$是当前动量，$m_{t-1}$上一步的动量，$\\beta_1$是动量系数\n\n$$m_t = \\beta_1 m_{t-1} + (1-\\beta_1)g_t $$\n\n**3. 计算二阶动量**：$b_t$是当前动量，$b_{t-1}$上一步的动量，$\\mu$是动量系数\n\n$$v_t = \\beta_2 v_{t-1} + (1-\\beta_2)g^2_t $$\n\n**4. 快速启动**：由于初始时$m_0=0, v_0=0,\\beta \\approx1 $，m和v更新很慢，需要很多步才能到正常值，需要进行偏差修正\n\n$$\\hat{m_t}=m_t/(1-\\beta^t_1)$$\n\n$$\\hat{v_t}=v_t/(1-\\beta^t_2)$$\n\n**5. 梯度更新**：$\\gamma$是学习率\n$$\\theta_t = \\theta_{t-1} -\\gamma \\hat{m_t}/(\\sqrt {\\hat v_t} + \\epsilon)$$\n\n### 2.2 AdamW\n\nAdamW是对Adam的修正，修改了权重衰减的位置，权重衰减放到了最后的损失位置，而不是最开始的梯度位置。\n\n**1. 计算梯度**:  $f_t$是模型函数，$θ_{t-1}$是上一步的参数，$\\nabla_θ$是向量梯度计算，$\\lambda$是权重衰减系数\n\n$$g_t=\\nabla_θ f_t (θ_{t-1})$$\n\n**2. 计算动量**：$m_t$是当前动量，$m_{t-1}$上一步的动量，$\\beta_1$是动量系数\n\n$$m_t = \\beta_1 m_{t-1} + (1-\\beta_1)g_t $$\n\n**3. 计算二阶动量**：$b_t$是当前动量，$b_{t-1}$上一步的动量，$\\mu$是动量系数\n\n$$v_t = \\beta_2 v_{t-1} + (1-\\beta_2)g^2_t $$\n\n**4. 快速启动**：由于初始时$m_0=0, v_0=0,\\beta \\approx1 $，m和v更新很慢，需要很多步才能到正常值，需要进行偏差修正\n\n$$\\hat{m_t}=m_t/(1-\\beta^t_1)$$\n\n$$\\hat{v_t}=v_t/(1-\\beta^t_2)$$\n\n**5. 梯度更新**：$\\gamma$是学习率\n\n$$\\theta_t=\\theta_{t-1} - \\gamma\\lambda θ_{t-1}$$\n\n$$\\theta_t = \\theta_{t-1} -\\gamma \\hat{m_t}/(\\sqrt {\\hat v_t} + \\epsilon)$$\n\n\n\n## 3. AdaGrad/RMS prop\n\n相当于动量系数$\\beta_1$为0的Adam，根据参数之前的梯度作为当前参数的权重\n\n","comments":true,"categories":[],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://blog.ahulearn.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"PyTorch","slug":"PyTorch","permalink":"http://blog.ahulearn.com/tags/PyTorch/"}]},{"title":"pytorch 常用的学习率调整策略 [lr_scheduler]","date":"2024-05-11T02:07:00.000Z","path":"2024/05/11/pytorch-常用的学习率调整策略/","raw":"---\ntitle: pytorch 常用的学习率调整策略 [lr_scheduler]\ndate: 2024-05-11 10:07:00\ntags:\n - PyTorch\n - 深度学习\ntypora-root-url: ..\ntypora-copy-images-to: ../img/pytorch\n---\n\n\n\n# PyTorch 常用的学习率调整策略 [lr_scheduler]\n\n\n\n[TOC]\n\n参考地址：https://zhuanlan.zhihu.com/p/538447997\n\n官方文档：https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n\n\n\n## 0. 基础\n\n### 导入\n\n```python\nfrom torch.optim import lr_scheduler\n```\n\n### 常用的学习率策略\n\n+ StepLR\n+ LambdaLR\n  \n\n### 基础代码\n\n```python\nimport torch\nimport numpy as np\nfrom torch.optim import SGD\nfrom torch.optim import lr_scheduler\nfrom torch.nn.parameter import Parameter\n\n# 随机创建一组模型参数\nmodel = [Parameter(torch.randn(2, 2, requires_grad=True))]\n# 使用SGD优化器，学习率设为0.1\noptimizer = SGD(model, lr=0.1)\n```\n\n<!--more-->\n\n\n\n## 1. StepLR\n\n\n\n最简单且最常用的学习率调整方法，每过step_size轮，将此前的学习率乘以gamma。\n\n```python\nscheduler = lr_scheduler.StepLR(optimizer, step_size, gamma=0.1, last_epoch=-1, verbose='deprecated')\n```\n\n+ optimizer (Optimizer) - 优化器包装类\n+ step_size (int) - 学习率衰减的周期\n+ gamma (float) – 学习率衰减的乘法因子。默认值：0.1\n+ last_epoch (int) - 上一个epoch的索引。默认值：-1\n+ verbose (bool) - 如果为 True，则为每次更新打印一条消息到 stdout。默认值：False\n  + 已经废弃，2.2版本之后使用get_last_lr() 获取学习率\n\n\n\n### 示例\n\n```python\n# Assuming optimizer uses lr = 0.05 for all groups\n# lr = 0.05     if epoch < 30\n# lr = 0.005    if 30 <= epoch < 60\n# lr = 0.0005   if 60 <= epoch < 90\n# ...\noptimizer = SGD(model, lr=0.05)\nscheduler = StepLR(optimizer, step_size=30, gamma=0.1)\nfor epoch in range(100):\n    train(...)\n    validate(...)\n    scheduler.step()\n```\n\n\n\n## 2. MultiStepLR\n\nMultiStepLR同样也是一个非常常见的学习率调整策略，它会在每个milestone时，将此前学习率乘以gamma。\n\n```python\nscheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[30,80], gamma=0.99)\n```\n\n\n\n## 3. ExponentialLR\n\nExponentialLR是指数型下降的学习率调节器，每一轮会将学习率乘以gamma，所以这里千万注意gamma不要设置的太小，不然几轮之后学习率就会降到0。\n\n```python\nscheduler=lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n```\n\n\n\n## 4. LinearLR\n\nLinearLR是线性学习率，给定起始factor和最终的factor，LinearLR会在中间阶段做线性插值，比如学习率为0.1，起始factor为1，最终的factor为0.1，那么第0次迭代，学习率将为0.1，最终轮学习率为0.01。下面设置的总轮数total_iters为80,所以超过80时，学习率恒为0.01。\n\n```python\nscheduler=lr_scheduler.LinearLR(optimizer,start_factor=1,end_factor=0.1,total_iters=80)\n```\n\n\n\n## 5. CyclicLR\n\n```text\nscheduler=lr_scheduler.CyclicLR(optimizer,base_lr=0.1,max_lr=0.2,step_size_up=30,step_size_down=10\n```\n\nCyclicLR的参数要更多一些，它的曲线看起来就像是不断的上坡与下坡，base_lr为谷底的学习率，max_lr为顶峰的学习率，step_size_up是从谷底到顶峰需要的轮数，step_size_down时从顶峰到谷底的轮数。至于为啥这样设置，可以参见[论文](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1506.01186.pdf),简单来说最佳学习率会在base_lr和max_lr，CyclicLR不是一味衰减而是出现增大的过程是为了避免陷入鞍点。\n\n```python\nscheduler=lr_scheduler.CyclicLR(optimizer,base_lr=0.1,max_lr=0.2,step_size_up=30,step_size_down=10)\n```\n\n![img](/img/pytorch/v2-66190f7dde49c5af7de382351a0f083f_1440w.webp)\n\n## 6. OneCycleLR\n\nOneCycleLR顾名思义就像是CyclicLR的一周期版本，它也有多个参数，max_lr就是最大学习率，pct_start是学习率上升部分所占比例，一开始的学习率为max_lr/div_factor,最终的学习率为max_lr/final_div_factor，总的迭代次数为total_steps。\n\n```python\nscheduler=lr_scheduler.OneCycleLR(optimizer,max_lr=0.1,pct_start=0.5,total_steps=120,div_factor=10,final_div_factor=10)\n```\n\n\n\n## 7. CosineAnnealingLR\n\nCosineAnnealingLR是余弦退火学习率，T_max是周期的一半，最大学习率在optimizer中指定，最小学习率为eta_min。这里同样能够帮助逃离鞍点。值得注意的是最大学习率不宜太大，否则loss可能出现和学习率相似周期的上下剧烈波动。\n\n```python\nscheduler=lr_scheduler.CosineAnnealingLR(optimizer,T_max=20,eta_min=0.05)\n```\n\n\n\n## 8. CosineAnnealingWarmRestarts\n\n这里相对负责一些，公式如下，其中T_0是第一个周期，会从optimizer中的学习率下降至eta_min，之后的每个周期变成了前一周期乘以T_mult。\n\n$eta_t = \\eta_{min} + \\frac{1}{2}(\\eta_{max} - \\eta_{min})\\left(1 + \\cos\\left(\\frac{T_{cur}}{T_{i}}\\pi\\right)\\right)$\n\n```python\nscheduler=lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=20, T_mult=2, eta_min=0.01)\n```\n\n\n\n## 9. LambdaLR\n\nLambdaLR其实没有固定的学习率曲线，名字中的lambda指的是可以将学习率自定义为一个有关epoch的lambda函数，比如下面我们定义了一个指数函数，实现了ExponentialLR的功能。\n\n```python\nscheduler=lr_scheduler.LambdaLR(optimizer,lr_lambda=lambda epoch:0.9**epoch)\n```\n\n![img](/img/pytorch/v2-456e15503cdc3635c865d9866a138441_1440w.webp)\n\n## 10.SequentialLR\n\nSequentialLR可以将多个学习率调整策略按照顺序串联起来,在milestone时切换到下一个学习率调整策略。下面就是将一个指数衰减的学习率和线性衰减的学习率结合起来。\n\n```python\nscheduler=lr_scheduler.SequentialLR(optimizer,schedulers=[lr_scheduler.ExponentialLR(optimizer, gamma=0.9),lr_scheduler.LinearLR(optimizer,start_factor=1,end_factor=0.1,total_iters=80)],milestones=[50])\n```\n\n\n\n## 11.ChainedScheduler\n\nChainedScheduler和SequentialLR类似，也是按照顺序调用多个串联起来的学习率调整策略，不同的是ChainedScheduler里面的学习率变化是连续的。\n\n```python\nscheduler=lr_scheduler.ChainedScheduler([lr_scheduler.LinearLR(optimizer,start_factor=1,end_factor=0.5,total_iters=10),lr_scheduler.ExponentialLR(optimizer, gamma=0.95)])\n```\n\n\n\n## 12.ConstantLR\n\nConstantLRConstantLR非常简单，在total_iters轮内将optimizer里面指定的学习率乘以factor,total_iters轮外恢复原学习率。\n\n```python\nscheduler=lr_scheduler.ConstantLRConstantLR(optimizer,factor=0.5,total_iters=80)\n```\n\n\n\n## 13.ConstantLRConstantLR\n\nReduceLROnPlateau参数非常多，其功能是自适应调节学习率，它在step的时候会观察验证集上的loss或者准确率情况，loss当然是越低越好，准确率则是越高越好，所以使用loss作为step的参数时，mode为min，使用准确率作为参数时，mode为max。factor是每次学习率下降的比例，新的学习率等于老的学习率乘以factor。patience是能够容忍的次数，当patience次后，网络性能仍未提升，则会降低学习率。threshold是测量最佳值的阈值，一般只关注相对大的性能提升。min_lr是最小学习率，eps指最小的学习率变化，当新旧学习率差别小于eps时，维持学习率不变。 因为参数相对复杂，这里可以看一份完整的代码 [实操](https://link.zhihu.com/?target=https%3A//github.com/milesial/Pytorch-UNet/blob/master/train.py%23L69)。\n\n```python\nscheduler=lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',factor=0.5,patience=5,threshold=1e-4,threshold_mode='abs',cooldown=0,min_lr=0.001,eps=1e-8)\nscheduler.step(val_score)\n```","comments":true,"categories":[],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://blog.ahulearn.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"PyTorch","slug":"PyTorch","permalink":"http://blog.ahulearn.com/tags/PyTorch/"}]},{"title":"希腊字母、拉丁字母、Markdown、拼写与读音中英对照表","date":"2024-03-24T07:52:27.000Z","path":"2024/03/24/希腊字母、拉丁字母表/","raw":"---\ntitle:  希腊字母、拉丁字母、Markdown、拼写与读音中英对照表\ndate: 2024-03-24 15:52:27\ntags:\n - 随笔\n---\n\n\n\n\n\n| 大写 | 小写 | 中文名 | 英文| 英语音标注音 | 大写Markdown | 小写Markdown | 意义|\n| ------ | ---- | ------------------------ | ------- | --------------------------------- | ------------ | --------------------- | :----------------------------------------------------------- |\n| $\\Alpha$ |  $\\alpha$  | 阿尔法| Alpha   | /'ælfə/ | \\Alpha     | \\alpha | 角度、系数、角加速度、第一个、电离度、转化率                 |\n| $\\Beta$ | $\\beta$ | 贝塔/毕塔 | Beta    | /'bi:tə/ 或 /'beɪtə/              | \\Beta   | \\beta | 磁通系数、角度、系数 |\n| $\\Gamma$ | $\\gamma$ | 伽玛/甘玛  | Gamma   | /'gæmə/   | \\Gamma       | \\gamma   | 电导系数（小写）、角度、比热容比  |\n| $\\Delta$  | $\\delta$ | 德尔塔/岱欧塔 | Delta   | /'deltə/  | \\Delta       | \\delta | 变化量、焓变、熵变、屈光度、变动、方程判别式（大写）、允许误差（小写，统计学） |\n| $\\Epsilon$ | $\\epsilon$　$\\varepsilon$ | 伊普西隆/埃普斯棱   | Epsilon | /'epsɪlɒn/ | \\Epsilon | \\epsilon　\\varepsilon | 对数之基数、介电常数   |\n| $\\Zeta$ | $\\zeta$ | 泽塔/Z塔 | Zeta    | /'zi:tə/                          | \\Zeta | \\zeta  | 系数、方位角、阻抗、相对粘度、原子序数  |\n| $\\Eta$ | $\\eta$ | 伊塔/诶塔| Eta     | /'i:tə/  | \\Eta       | \\eta | 迟滞系数；机械效率（小写）  |\n| $\\Theta$ | $\\theta$ | 西塔\\非塔 | Theta   | /'θi:tə/  | \\Theta       | \\theta   | 温度、相位角       |\n| $\\Iota$ | $\\iota$ | 约塔\\埃欧塔  | Iota    | /aɪ'əʊtə/  | \\Iota   | \\iota | 微小、一点儿           |\n| $\\Kappa$ | $\\kappa$ | 卡帕\\堪帕   | Kappa   | /'kæpə/     | \\Kappa     | \\kappa    | 介质常数、绝热指数   |\n| $\\Lambda$ | $\\lambda$ | 兰姆达\\拉姆达    | Lambda  | /'læmdə/   | \\Lambda      | \\lambda   | 波长（小写）、体积、导热系数   |\n| $\\Mu$ | $\\mu$ | 米欧/谬/穆  | Mu      | /mju:/     | \\Mu   | \\mu    | 磁导系数、微（百万分之一）、动摩擦系（因）数、流体动力黏度、货币单位、放大因数（小写）、正态分布中的位置参数（小写） |\n| $\\Nu$ | $\\nu$ | 拗/奴/纽    | Nu      | /nju:/       | \\Nu        | \\nu     | 磁阻系数、流体运动粘度、光波频率、化学计量数        |\n| $\\Xi$ | $\\xi$ | 克西/可西/赛   | Xi | 希腊 /ksi/　英美 /ˈzaɪ/ 或 /ˈsaɪ/ | \\Xi  | \\xi      | 随机变量、（小）区间内的一个未知特定值           |\n| $\\Omicron$ | $\\omicron$ | 欧米克隆/欧 (阿~) 米可荣 | Omicron | /əuˈmaikrən/ 或 /ˈɑmɪˌkrɑn/   | \\Omicron   | \\omicron   | 高阶无穷小函数     |\n| $\\Pi$ | $\\pi$ | 派     | Pi      | /paɪ/     | \\Pi    | \\pi    | 圆周率=圆周÷直径=3.1416、π(n)表示不大于n的质数个数   |\n| $\\Rho$ | $\\rho$ | 柔/若    | Rho     | /rəʊ/   | \\Rho  | \\rho                  | 密度;电阻系数（小写）、柱坐标和极坐标中的极径      |\n| $\\Sigma$ | $\\sigma$ | 西格玛                   | Sigma   | /'sɪɡmə/                          | \\Sigma       | \\sigma                | 总和（大写），表面密度、跨导（小写）、正应力                 |\n| $\\Tau$ | $\\tau$ | 陶/套/驼                 | Tau     | /tɔ:/ 或 /taʊ/                    | \\Tau       | \\tau                  | 时间常数、切应力、2π（两倍圆周率）                           |\n| $\\Upsilon$ | $\\upsilon$ | 玉普西隆/宇 (阿~) 普西龙 | Upsilon | /ˈipsɪlon/ 或 /ˈʌpsɪlɒn/          | \\Upsilon     | \\upsilon              | 位移                                                         |\n| $\\Phi$ | $\\phi$$\\varphi$ | 斐/弗爱/弗忆             | Phi     | /faɪ/                             | \\Phi         | \\phi　\\varphi         | 磁通量、角、透镜焦度、热流量、电势、空集（大写）             |\n| $\\Chi$ | $\\chi$ | 凯/柯义                  | Chi     | /kaɪ/                             | \\Chi       | \\chi                  | 统计学中有卡方($\\Chi^2$)分布                                |\n| Ψ      | $\\psi$ | 赛/普赛/普西             | Psi     | /psaɪ/                            | \\Psi         | \\psi                  | 角速；介质电通量（静电力线）；角 ；波（$\\psi$）函数          |\n| Ω      | $\\omega$ | 奥米伽/欧米伽/欧枚嘎     | Omega   | /'əʊmɪɡə/ 或 /oʊ'meɡə/            | \\Omega       | \\omega                | 欧姆、电阻（大写）、角速度（小写）、交流电的电角度、化学中的质量分数、角 |","comments":true,"categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://blog.ahulearn.com/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"Generative Adversarial Networks","date":"2024-03-11T10:46:00.000Z","path":"2024/03/11/Generative Adversarial Nets/","raw":"---\ntitle: Generative Adversarial Networks\nlayout: post\ndate: 2024-03-11 18:46:00\ntoc: true\ntags:\n - 深度学习\n - 随笔\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\\gan\n---\n\n## Generative Adversarial Networks(GAN神经网络)\n\n[TOC]\n\n### 摘要\n\n本文提出了一个新的基于对抗的网络框架，主要包含两个模型。一个是生成模型G，用于获取整个数据分布；另一个是判别模型D，用于判别数据是来自真实数据还是生成数据。生成模型尽可能让判别模型犯错。判别模型试图找到一个函数，使得判别模型在真实的数据上得分较高，在生成模型的数据上得分较低。\n\n<!--more-->\n\n### 介绍\n\nGAN网络由两个模型组成：生成模型G和判别模型D。生成模型G的目标是生成尽可能接近真实数据的数据，判别模型D的目标是判别数据是来自真实数据还是生成数据。\n\n生成模型G通过一个随机过程生成数据，判别模型D试图判别数据是否来自真实数据。判别模型D有一个输出值，表示数据来自真实数据的概率。判别模型D有一个目标函数，使得判别模型在真实的数据上得分较高，在生成模型的数据上得分较低。\n\n生成模型G有一个目标函数，使得判别模型在生成模型的数据上得分较低，在真实的数据上得分较高。\n\n生成模型G和判别模型D交替更新，生成模型G的目标函数和判别模型D的目标函数相互对抗。\n\n### 方法\n\n\n![公式](/img/gan/image1.png)\n\nGAN网络可以应用在图像生成、语音生成等领域。\n\n### 参考资料\n\n[1] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bharath Ramsundar, Tomaso Poggio. Generative Adversarial Nets. 2014.","comments":true,"categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://blog.ahulearn.com/tags/%E9%9A%8F%E7%AC%94/"},{"name":"深度学习","slug":"深度学习","permalink":"http://blog.ahulearn.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"SpringBoot","date":"2023-08-23T05:00:00.000Z","path":"2023/08/23/SpringBoot/","raw":"---\ntitle: SpringBoot\ndate: 2023-08-23 13:00:00\ntags:\n - CS\n - SpringBoot\n - JAVA\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\\springboot\n---\n\n\n\n官方文档：https://spring.io/projects/spring-boot#learn\n\n其他笔记：\n\n**主要参考**：[ Spring Boot 2 学习笔记（1 / 2）_KISS-CSDN博客](https://blog.csdn.net/u011863024/article/details/113667634)\n\n[SpringBootWeb模块的默认规则研究_大恐龙的小弟的博客-CSDN博客](https://blog.csdn.net/qq_43240702/article/details/111032361)\n\n## 01、基础入门-Spring生态圈\n\n[Spring官网](https://spring.io/)\n\n### Spring能做什么\n\n\n\n![image-20210623135328829](../img/springboot/image-20210623135328829.png)\n\n#### Spring的生态\n\n覆盖了：\n\n- web开发\n- 数据访问\n- 安全控制\n- 分布式\n- 消息服务\n- 移动开发\n- 批处理\n- …\n\n\n\n<!--more-->\n\n\n\n#### Spring5重大升级\n\n- 响应式编程\n\n![在这里插入图片描述](../img/springboot/20210205004250581.png)\n\n+ 内部源码设计\n\n基于Java8的一些新特性，如：接口默认实现。重新设计源码架构。\n\n接口的默认实现：即适配器模式（adapter）\n\n+ 由于接口的抽象方法太多，而一般情况下我们只需要使用接口的某几个方法，此时继承了接口必须实现所有方法，即便不用，也要加上空方法。\n+ 此时我们使用适配器实现接口的所有方法，通过继承适配器来重新部分方法即可，避免大量无用的方法实现\n\n\n\n### 为什么用SpringBoot\n\n> Spring Boot makes it easy to create stand-alone, production-grade Spring based Applications that you can “just run”.link\n\n\n\n### SpringBoot优点\n+ Create stand-alone Spring applications\n\n  + 创建独立Spring应用\n\n+ Embed Tomcat, Jetty or Undertow directly (no need to deploy WAR files)\n\n  + 内嵌web服务器\n\n+ Provide opinionated ‘starter’ dependencies to simplify your build configuration\n\n  + 自动starter依赖，简化构建配置\n\n+ Automatically configure Spring and 3rd party libraries whenever possible\n\n  + 自动配置Spring以及第三方功能\n\n+ Provide production-ready features such as metrics, health checks, and externalized configuration\n  \n+ 提供生产级别的监控、健康检查及外部化配置\n  \n+ Absolutely no code generation and no requirement for XML configuration\n\n  + 无代码生成、无需编写XML\n\n  \n\n> SpringBoot是整合Spring技术栈的一站式框架\n>\n> SpringBoot是简化Spring技术栈的快速开发脚手架\n\n\n\n\n\n#### SpringBoot缺点\n\n- 人称版本帝，迭代快，需要时刻关注变化\n- 封装太深，内部原理复杂，不容易精通\n\n## 02、基础入门-SpringBoot的大时代背景\n\n### 微服务\n\n[James Lewis and Martin Fowler (2014)](https://martinfowler.com/articles/microservices.html) 提升微服务完整概念：https://martinfowler.com/microservices/\n\n> In short, the microservice architectural style is an approach to developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API. These services are built around business capabilities and independently deployable by fully automated deployment machinery. There is a bare minimum of centralized management of these services, which may be written in different programming languages and use different data storage technologies.——James Lewis and Martin Fowler (2014)\n\n\n\n+ 微服务是一种架构风格\n+ 一个应用拆分为一组小型服务\n+ 每个服务运行在自己的进程内，也就是可独立部署和升级\n+ 服务之间使用轻量级HTTP交互\n+ 服务围绕业务功能拆分\n+ 可以由全自动部署机制独立部署\n+ 去中心化，服务自治。服务可以使用不同的语言、不同的存储技术\n\n\n\n### 分布式\n\n![在这里插入图片描述](/img/springboot/2021020500434620.png)\n\n\n\n### 分布式的困难\n\n- 远程调用\n- 服务发现\n- 负载均衡\n- 服务容错\n- 配置管理\n- 服务监控\n- 链路追踪\n- 日志管理\n- 任务调度\n- …\n\n\n\n#### 分布式的解决\n\n- SpringBoot + SpringCloud\n\n![在这里插入图片描述](/img/springboot/20210205004523307.png)\n\n### 云原生\n\n原生应用如何上云。 Cloud Native\n\n#### 上云的困难\n\n- 服务自愈：出问题自动复制另一台服务自愈\n- 弹性伸缩：自动扩展下线服务\n- 服务隔离：一台出问题，不影响其他\n- 自动化部署：自动化部署\n- 灰度发布：新老版本共存并逐步取代所有老版\n- 流量治理：负载均衡\n- …\n\n\n\n## 03、基础入门-SpringBoot官方文档架构\n\n- [Spring Boot官网](https://spring.io/projects/spring-boot)\n- Spring Boot官方文档：https://docs.spring.io/spring-boot/docs/current/reference/html/\n- 官方PDF：https://docs.spring.io/spring-boot/docs/2.5.1/reference/pdf/spring-boot-reference.pdf\n\n### 官网文档架构\n\n![image-20210623150038557](/img/springboot/image-20210623150038557.png)\n\n权限信息\n\n概览：可以点进去下载pdf\n\n入门\n\n入门进阶\n\n高级特性\n\n监控\n\n部署\n\n命令行应用\n\n插件\n\n小技巧\n\n资源信息：\n\n所有可以配置的属性\n\n配置源信息\n\n自动配置\n\n\n\n## 04、基础入门-SpringBoot-HelloWorld\n\n### 系统要求\n\n- Java 8\n- Maven 3.3+\n- IntelliJ IDEA 2019.1.2\n\n### Maven配置文件\n\nMaven安装目录下**conf/settings.xml**新添内容：\n\n```xml\n<!--设置仓库源-->\n<mirrors>\n\t<mirror>\n\t\t<id>nexus-aliyun</id>\n\t\t<mirrorOf>central</mirrorOf>\n\t\t<name>Nexus aliyun</name>\n\t\t<url>http://maven.aliyun.com/nexus/content/groups/public</url>\n\t</mirror>\n\t<mirror>\n      <id>nexus-aliyun2</id>\n      <mirrorOf>*,!jeecy,!jeecg-snapshots</mirrorOf>\n      <name>aliyun maven2</name>\n      <url>http://maven.aliyun.com/nexus/content/repositories/central/</url>\n    </mirror>\n</mirrors>\n\n<!--设置jDK编译版本，可以不修改，在项目pom.xml中修改-->\n<profiles>\n\t<profile>\n\t\t<id>jdk-1.8</id>\n\n\t\t<activation>\n\t\t\t<activeByDefault>true</activeByDefault>\n\t\t\t<jdk>1.8</jdk>\n\t\t</activation>\n\n\t\t<properties>\n\t\t\t<maven.compiler.source>1.8</maven.compiler.source>\n\t\t\t<maven.compiler.target>1.8</maven.compiler.target>\n\t\t\t<maven.compiler.compilerVersion>1.8</maven.compiler.compilerVersion>\n\t\t</properties>\n\t</profile>\n</profiles>\n```\n\n\n\n#### 创建maven工程\n\n#### 创建pom.xml文件，引入父项目\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>com.example</groupId>\n    <artifactId>myproject</artifactId>\n    <version>0.0.1-SNAPSHOT</version>\n    \n    <!--引入父项目-->\n    <parent>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-parent</artifactId>\n        <version>2.5.1</version>\n    </parent>\n\n    <!-- Additional lines to be added here... -->\n\n</project>\n\n```\n\n\n\n#### 添加依赖\n\n```xml\n<dependencies>\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-web</artifactId>\n    </dependency>\n</dependencies>\n```\n\n创建主程序\n\nMaven默认编译src/main/java路径下的资源\n\n创建src/main/java/com/example/MyApplication.java，写入以下代码\n\n```java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.EnableAutoConfiguration;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\n@EnableAutoConfiguration\npublic class MyApplication {\n\n    @RequestMapping(\"/\")\n    String home() {\n        return \"Hello World!\";\n    }\n\n    public static void main(String[] args) {\n        SpringApplication.run(MyApplication.class, args);\n    }\n\n}\n```\n\n一般写法是只声明主类，不在主类中进行业务处理：\n\n```java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\n\n@SpringBootApplication\npublic class MainApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(MainApplication.class, args);\n    }\n\n}\n```\n\n编写Controller\n\n```java\npackage com.example.controller;\n\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.ResponseBody;\n\n//@RestController\n@Controller\n@RequestMapping(\"/hello\")\npublic class HelloController {\n    @GetMapping(\"/h1\")\n    //声明直接返回字符串\n    @ResponseBody\n    public String hello() {\n        return \"hello\";\n    }\n}\n```\n\n\n\n#### SpringBoot配置\n\n在maven工程的resource文件夹中创建application.properties文件。\n\nspringboot 所有配置均有默认值，不配置可直接启动\n\n```properties\n# 设置端口号\nserver.port=8888\n```\n\n[所有其他配置](https://docs.spring.io/spring-boot/docs/2.3.7.RELEASE/reference/html/appendix-application-properties.html#common-application-properties-server)\n\n\n\n#### 打包部署\n\n在pom.xml添加部署插件\n\n```xml\n<build>\n\t<plugins>\n\t\t<plugin>\n\t\t\t<groupId>org.springframework.boot</groupId>\n\t\t\t<artifactId>spring-boot-maven-plugin</artifactId>\n\t\t</plugin>\n\t</plugins>\n</build>\n```\n\n\n\n+ mvn clean：清空目录\n\n+ mvn package：打包程序\n\n+ 运行：java -jar boot-01-helloworld-1.0-SNAPSHOT.jar\n\n取消cmd的快速编辑模式，否则命令行方式启动SpringBoot时如果点击命令行，可能终止启动\n\n\n\n## 05、基础入门-SpringBoot-依赖管理特性\n\n- 父项目：做依赖管理\n\n```xml\n<!--依赖管理-->\n<parent>\n\t<groupId>org.springframework.boot</groupId>\n\t<artifactId>spring-boot-starter-parent</artifactId>\n\t<version>2.3.4.RELEASE</version>\n</parent>\n\n<!--上面项目的父项目如下：-->\n<parent>\n\t<groupId>org.springframework.boot</groupId>\n\t<artifactId>spring-boot-dependencies</artifactId>\n\t<version>2.3.4.RELEASE</version>\n</parent>\n\n<!--它几乎声明了所有开发中常用的依赖的版本号，自动版本仲裁机制-->\n```\n\n\n\nstarter的含义及支持的所有场景：https://docs.spring.io/spring-boot/docs/current/reference/html/using.html#using.build-systems.starters\n\n>Starters are a set of convenient dependency descriptors that you can include in your application. You get a one-stop shop for all the Spring and related technologies that you need without having to hunt through sample code and copy-paste loads of dependency descriptors. For example, if you want to get started using Spring and JPA for database access, include the `spring-boot-starter-data-jpa` dependency in your project.\n\n\n\n+ 开发导入starter场景启动器\n  1、见到很多 spring-boot-starter-* ： *就某种场景\n  2、只要引入starter，这个场景的所有常规需要的依赖我们都自动引入\n  3、更多SpringBoot所有支持的场景\n  4、见到的 *-spring-boot-starter： 第三方为我们提供的简化开发的场景启动器。\n\n  5、所有场景的启动器最底层的依赖\n\n```xml\n<!--所有场景启动器最底层的依赖-->\n<dependency>\n\t<groupId>org.springframework.boot</groupId>\n\t<artifactId>spring-boot-starter</artifactId>\n\t<version>2.3.4.RELEASE</version>\n\t<scope>compile</scope>\n</dependency>\n```\n\n\n\n- 无需关注版本号，自动版本仲裁\n  1. 引入依赖默认都可以不写版本\n  2. 引入非版本仲裁的jar，要写版本号。\n\n\n\n- 可以修改默认版本号\n  1. 查看spring-boot-dependencies里面规定当前依赖的版本 用的 key。\n  2. 在当前项目的pom.xml配置文件，添加如下面的代码。\n\n```xml\n<properties>\n    <!--查看底层父项目的标签-->\n\t<mysql.version>5.1.43</mysql.version>\n</properties>\n```\n\n\n\nIDEA快捷键：\n\n- `ctrl + shift + alt + U`：以图的方式显示项目中依赖之间的关系。\n- `alt + ins`：相当于Eclipse的 Ctrl + N，创建新类，新包等。\n\n\n\n## 06、基础入门-SpringBoot-自动配置特性\n\n- 自动配好Tomcat\n  - 引入Tomcat依赖。\n  - 配置Tomcat\n\n```xml\n<dependency>\n\t<groupId>org.springframework.boot</groupId>\n\t<artifactId>spring-boot-starter-tomcat</artifactId>\n\t<version>2.3.4.RELEASE</version>\n\t<scope>compile</scope>\n</dependency>\n```\n\n- 自动配好SpringMVC\n  - 引入SpringMVC全套组件\n  - 自动配好SpringMVC常用组件（功能）\n- 自动配好Web常见功能，如：字符编码问题\n  - SpringBoot帮我们配置好了所有web开发的常见场景\n\n```java\npublic static void main(String[] args) {\n    //1、返回我们IOC容器\n    ConfigurableApplicationContext run = SpringApplication.run(MainApplication.class, args);\n\n    //2、查看容器里面的组件\n    String[] names = run.getBeanDefinitionNames();\n    for (String name : names) {\n        System.out.println(name);\n    }\n}\n```\n\n- 默认的包结构\n  - 主程序所在包及其下面的所有子包里面的组件都会被默认扫描进来\n  - 无需以前的包扫描配置\n  - 想要改变扫描路径\n    - @SpringBootApplication(scanBasePackages=“com.lun”)\n    - @ComponentScan 指定扫描路径\n\n```java\n@SpringBootApplication\n//等同于以下三个注解\n@SpringBootConfiguration\n@EnableAutoConfiguration\n@ComponentScan(\"com.lun\")\n```\n\n\n\n- SpringBoot各种配置拥有默认值\n  - 默认配置最终都是映射到某个类上，如：`MultipartProperties`\n  - 配置文件的值最终会绑定每个类上，这个类会在容器中创建对象\n\n\n\n- 所有自动配置项是按需加载\n  - 非常多的starter，引入了哪些场景这个场景的自动配置才会开启\n  - SpringBoot所有的自动配置功能都在 spring-boot-autoconfigure 包里面\n\n\n\n## 07、底层注解-@Configuration配置类注解\n\n- 实验环境\n\n基本的bean\n\n+ User\n\n```java\npackage com.example.helloworld.bean;\n\npublic class User {\n    private String name;\n    private Integer age;\n    private Pet pet;\n\n    public Pet getPet() {\n        return pet;\n    }\n\n    public void setPet(Pet pet) {\n        this.pet = pet;\n    }\n\n    public User() {\n    }\n\n    public User(String name, Integer age) {\n        this.name = name;\n        this.age = age;\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public Integer getAge() {\n        return age;\n    }\n\n    public void setAge(Integer age) {\n        this.age = age;\n    }\n\n    @Override\n    public String toString() {\n        return \"User{\" +\n                \"name='\" + name + '\\'' +\n                \", age=\" + age +\n                \", pet=\" + pet +\n                '}';\n    }\n}\n```\n\n+ Pet\n\n```java\npackage com.example.helloworld.bean;\n\npublic class Pet {\n    private String name;\n\n    public Pet() {\n    }\n\n    public Pet(String name) {\n        this.name = name;\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    @Override\n    public String toString() {\n        return \"Pet{\" +\n                \"name='\" + name + '\\'' +\n                '}';\n    }\n}\n```\n\n\n\n- 基本使用\n  - Full模式与Lite模式\n  - 示例\n\n```java\npackage com.example.helloworld.config;\n\nimport com.example.helloworld.bean.Pet;\nimport com.example.helloworld.bean.User;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\n\n/**\n * @Configuration 声明这是一个配置类\n * 1、配置类里面使用@Bean标注在方法上给容器注册组件，默认也是单实例的\n * 2、配置类本身也是组件\n * 3、proxyBeanMethods：代理bean的方法\n *      Full(proxyBeanMethods = true)（保证每个@Bean方法被调用多少次返回的组件都是单实例的）（默认）\n *      Lite(proxyBeanMethods = false)（每个@Bean方法被调用多少次返回的组件都是新创建的）\n */\n@Configuration(proxyBeanMethods = false) //告诉SpringBoot这是一个配置类 == 配置文件\npublic class MyConfig {\n\n    /**\n     * Full:外部无论对配置类中的这个组件注册方法调用多少次获取的都是之前注册容器中的单实例对象\n     * @return\n     */\n    @Bean //给容器中添加组件。默认 方法名为组件id。返回类型就是组件类型。返回的值，就是组件在容器中的实例\n    public User user01(){\n        User user = new User(\"张三\", 18);\n        //user组件依赖Pet组件.\n        //但由于此时proxyBeanMethods = false，user中获取的并不是容器中的Pet, 而是创建了一个新的Pet\n        user.setPet(tomcatPet());\n        return user;\n    }\n\n    @Bean(name=\"tom01\") //指定组件id名为tom\n    public Pet tomcatPet(){\n        return new Pet(\"tomcat\");\n    }\n}\n```\n\n\n\n@Configuration测试代码如下:\n\n```java\n@SpringBootConfiguration\n@EnableAutoConfiguration\n@ComponentScan(\"com.atguigu.boot\")\npublic class MainApplication {\n\n    public static void main(String[] args) {\n    //1、返回我们IOC容器\n        ConfigurableApplicationContext run = SpringApplication.run(MainApplication.class, args);\n\n    //2、查看容器里面的组件\n        String[] names = run.getBeanDefinitionNames();\n        for (String name : names) {\n            System.out.println(name);\n        }\n\n    //3、从容器中获取组件\n        Pet tom01 = run.getBean(\"tom\", Pet.class);\n        Pet tom02 = run.getBean(\"tom\", Pet.class);\n        System.out.println(\"组件：\"+(tom01 == tom02));\n\n    //4、com.atguigu.boot.config.MyConfig$$EnhancerBySpringCGLIB$$51f1e1ca@1654a892\n        MyConfig bean = run.getBean(MyConfig.class);\n        System.out.println(bean);\n\n    //如果@Configuration(proxyBeanMethods = true)代理对象调用方法。SpringBoot总会检查这个组件是否在容器中有。\n        //保持组件单实例\n        User user = bean.user01();\n        User user1 = bean.user01();\n        System.out.println(user == user1);\n\n        User user01 = run.getBean(\"user01\", User.class);\n        Pet tom = run.getBean(\"tom\", Pet.class);\n\n        System.out.println(\"用户的宠物：\"+(user01.getPet() == tom));\n    }\n}\n```\n\n- 最佳实战\n  - 配置 类组件之间**无依赖关系**用Lite模式加速容器启动过程，减少判断\n  - 配置 类组件之间**有依赖关系**，方法会被调用得到之前单实例组件，用Full模式（默认）\n\n>lite 英 [laɪt] 美 [laɪt]\n>adj. 低热量的，清淡的(light的一种拼写方法);类似…的劣质品\n\n\n\nIDEA快捷键：\n\n- `Alt + Ins`:生成getter，setter、构造器等代码。\n- `Ctrl + Alt + B`:查看类的具体实现代码。\n\n\n\n\n\n## 08、底层注解-@Import导入组件\n\n+ 使用@import导入类，自动调用类的无参构造创建组件，可以放在任何被Springboot管理的组件中，不一定放入config配置类上\n\n@Bean、@Component、@Controller、@Service、@Repository，它们是Spring的基本注解，在Spring Boot中也可以导入容器。\n\n@ComponentScan 在**06、基础入门-SpringBoot-自动配置特性**有用例。\n\n@Import({User.class, DBHelper.class})给容器中**自动创建出这两个类型的组件**、默认组件的名字就是全类名\n\n```java\n//使用无参构造创建两个组件, 默认组件id为全类名\n@Import({User.class, DBHelper.class}) \n@Configuration(proxyBeanMethods = false)\npublic class MyConfig {\n}\n```\n\n测试类：\n\n```java\n\n//1、返回我们IOC容器\nConfigurableApplicationContext run = SpringApplication.run(MainApplication.class, args);\n\n//...\n\n//5、获取组件\nString[] beanNamesForType = run.getBeanNamesForType(User.class);\n\nfor (String s : beanNamesForType) {\n    System.out.println(s);\n}\n\nDBHelper bean1 = run.getBean(DBHelper.class);\nSystem.out.println(bean1);\n```\n\n\n\n## 9、底层注解-@Conditional条件装配\n\n**条件装配：满足Conditional指定的条件，则进行组件注入** 有很多派生注解\n\n![image-20210628123240922](/assets/springboot/image-20210628123240922.png)\n\nctrl+h：打开继承树\n\n用@ConditionalOnMissingBean举例说明\n\n+ 配置类\n\n```java\n /**\n  * 放在配置类上，如果某个组件存在，该配置才生效\n  */\n@Configuration(proxyBeanMethods = false)\n@ConditionalOnMissingBean(name = \"tom\")//容器中没有tom的Bean时，MyConfig类的Bean才能生效。\npublic class MyConfig {\n\n    @Bean\n    public User user01(){\n        User zhangsan = new User(\"zhangsan\", 18);\n        zhangsan.setPet(tomcatPet());\n        return zhangsan;\n    }\n\n    @Bean(\"tom22\")\n    public Pet tomcatPet(){\n        return new Pet(\"tomcat\");\n    }\n    /**\n     * 如果容器中存在tom组件则注册user02组件\n     */\n    @ConditionalOnBean(name = \"tom02\")//容器中有tom02的Bean时，才注册user02\n    @Bean\n    public User user02(){\n        User user = new User(\"张三\", 18);\n        user.setPet(tomcatPet());\n        return user;\n    }\n}\n```\n\n+ 主程序类\n\n```java\npublic static void main(String[] args) {\n    //1、返回我们IOC容器\n    ConfigurableApplicationContext run = SpringApplication.run(MainApplication.class, args);\n\n    //2、查看容器里面的组件\n    String[] names = run.getBeanDefinitionNames();\n    for (String name : names) {\n        System.out.println(name);\n    }\n\n    /**\n\t\t * @Import\n\t\t */\n\t\t//5、获取所有User类型的组件\n\t\tString[] beanNamesForType = run.getBeanNamesForType(User.class);\n\n\t\tfor (String s : beanNamesForType) {\n\t\t\tSystem.out.println(s);\n\t\t}\n\n\t\tDBHelper bean1 = run.getBean(DBHelper.class);\n\t\tSystem.out.println(bean1);\n\n\t\t/**\n\t\t *  @Conditional\n\t\t *  containsBean判断容器中是否存在指定组件\n\t\t */\n\t\tboolean tom03 = run.containsBean(\"tom\");\n\t\tSystem.out.println(\"容器中Tom03组件：\"+tom03);//false\n\n\t\tboolean tom22 = run.containsBean(\"tom01\");\n\t\tSystem.out.println(\"容器中tom22组件：\"+tom22);//true\n\n\t\tboolean user02 = run.containsBean(\"user02\");\n\t\tSystem.out.println(\"容器中user02组件：\"+user02);//false\n\n\t\tboolean user03 = run.containsBean(\"user01\");\n\t\tSystem.out.println(\"容器中user02组件：\"+user03);//true\n\n}\n```\n\n\n\n\n\n## 10、底层注解-@ImportResource 导入Spring配置文件\n\n比如，公司使用bean.xml文件生成配置bean，然而你为了省事，想继续复用bean.xml，可以使用@ImportResource注解。\n\nbean.xml：\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       http://www.springframework.org/schema/beans/spring-beans.xsd\">\n\n    <!-- Spring方式注册bean，springboot是使用config配置类-->\n    <bean id=\"haha\" class=\"com.example.helloworld.bean.User\">\n        <property name=\"name\" value=\"张三\"/>\n        <property name=\"age\" value=\"18\"/>\n        <property name=\"pet\" ref=\"hehe\"/>\n    </bean>\n\n    <bean id=\"hehe\" class=\"com.example.helloworld.bean.Pet\">\n        <property name=\"name\" value=\"tomcat\"/>\n    </bean>\n\n</beans>\n```\n\n\n\n使用方法：\n\n```java\n@ImportResource(\"classpath:beans.xml\")\npublic class MyConfig {\n...\n}\n```\n\n测试类：\n\n```java\npublic static void main(String[] args) {\n    //1、返回我们IOC容器\n    ConfigurableApplicationContext run = SpringApplication.run(MainApplication.class, args);\n\n\tboolean haha = run.containsBean(\"haha\");\n\tboolean hehe = run.containsBean(\"hehe\");\n\tSystem.out.println(\"haha：\"+haha);//true\n\tSystem.out.println(\"hehe：\"+hehe);//true\n}\n```\n\n\n\n## 11、底层注解-@ConfigurationProperties配置绑定\n\n如何使用Java读取到properties文件中的内容，并且把它封装到JavaBean中，以供随时使用\n\n传统方法，十分复杂：\n\n```java\npublic class getProperties {\n\tpublic static void main(String[] args) throws FileNotFoundException, IOException {\n\t\tProperties pps = new Properties();\n\t\tpps.load(new FileInputStream(\"a.properties\"));\n\t\tEnumeration enum1 = pps.propertyNames();//得到配置文件的名字\n\t\twhile(enum1.hasMoreElements()) {\n\t\t\tString strKey = (String) enum1.nextElement();\n\t\t\tString strValue = pps.getProperty(strKey);\n\t\t\tSystem.out.println(strKey + \"=\" + strValue);\n\t\t\t//封装到JavaBean。\n\t\t}\n\t}\n}\n```\n\n\n\n**Spring Boot一种配置配置绑定**：\n\n@ConfigurationProperties + @Component\n\n+ 基本的bean, Car\n\n```java\npackage com.example.helloworld.bean;\n\nimport lombok.AllArgsConstructor;\nimport lombok.Data;\nimport lombok.NoArgsConstructor;\nimport org.springframework.boot.context.properties.ConfigurationProperties;\nimport org.springframework.stereotype.Component;\n\n/**\n * 只有容器中的组件，才有springboot提供的强大功能\n * @Component 加入Spring容器中\n * @ConfigurationProperties 绑定配置文件\n */\n@Component\n@ConfigurationProperties(prefix = \"mycar\")\n@Data\n@AllArgsConstructor\n@NoArgsConstructor\npublic class Car {\n    private String brand;\n    private Integer price;\n\n    @Override\n    public String toString() {\n        return \"Car{\" +\n                \"brand='\" + brand + '\\'' +\n                \", price=\" + price +\n                '}';\n    }\n}\n```\n\n+ 配置文件application.properties\n\n```yml\nmycar.brand=BYD\nmycar.price=100000\n```\n\n+ Controller\n\n```java\npackage com.example.helloworld.controller;\n\nimport com.example.helloworld.bean.Car;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\npublic class HelloController {\n    \n    //自动装配\n    @Autowired\n    Car car;\n    @RequestMapping(\"/car\")\n    public Car car() {\n        return car;\n    }\n}\n```\n\n\n\n**Spring Boot另一种配置配置绑定**：\n\n@EnableConfigurationProperties + @ConfigurationProperties\n\n@EnableConfigurationProperties(Car.class)的作用\n\n1. 开启Car配置绑定功能\n2. 把Car这个组件自动注册到容器中\n\n```java\n@EnableConfigurationProperties(Car.class)\npublic class MyConfig {\n...\n}\n\n```\n\n```java\n@ConfigurationProperties(prefix = \"mycar\")\n@Data\n@AllArgsConstructor\n@NoArgsConstructor\npublic class Car {\n    private String brand;\n    private Integer price;\n\n    @Override\n    public String toString() {\n        return \"Car{\" +\n                \"brand='\" + brand + '\\'' +\n                \", price=\" + price +\n                '}';\n    }\n}\n```\n\n\n\n## 12、自动配置-自动包规则原理\n\nSpring Boot应用的启动类：\n\n```java\n/**\n * @SpringBootApplication相当与下面三个注解：\n * @SpringBootConfiguration\n * @EnableAutoConfiguration\n * @ComponentScan()\n */\n@SpringBootApplication\npublic class MainApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(MainApplication.class, args);\n    }\n\n}\n```\n\n\n\n分析下`@SpringBootApplication`\n\n```java\n@Target(ElementType.TYPE)\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\n@Inherited\n@SpringBootConfiguration\n@EnableAutoConfiguration\n@ComponentScan(\n    excludeFilters = {@Filter(\n    type = FilterType.CUSTOM,\n    classes = {TypeExcludeFilter.class}\n), @Filter(\n    type = FilterType.CUSTOM,\n    classes = {AutoConfigurationExcludeFilter.class}\n)}\n)\npublic @interface SpringBootApplication {\n    ...\n}\n\n```\n\n\n\n重点分析`@SpringBootConfiguration`，`@EnableAutoConfiguration`，`@ComponentScan`\n\n\n\n### @SpringBootConfiguration\n\n```java\n@Target(ElementType.TYPE)\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\n@Configuration\npublic @interface SpringBootConfiguration {\n    @AliasFor(\n        annotation = Configuration.class\n    )\n    boolean proxyBeanMethods() default true;\n}\n\n```\n\n除了元注解之外，就是一个`@Configuration`，表示主启动类也是一个配置类。\n\n### @ComponentScan\n\n指定扫描哪些路径，Spring注解。\n\n@ComponentScan 在 **07、基础入门-SpringBoot-自动配置特性** 有用例。\n\n### @EnableAutoConfiguration\n\n最重要的注解就是 @EnableAutoConfiguration\n\n```java\n@Target(ElementType.TYPE)\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\n@Inherited\n@AutoConfigurationPackage\n@Import(AutoConfigurationImportSelector.class)\npublic @interface EnableAutoConfiguration {\n    String ENABLED_OVERRIDE_PROPERTY = \"spring.boot.enableautoconfiguration\";\n\n    Class<?>[] exclude() default {};\n\n    String[] excludeName() default {};\n}\n```\n\n重点包含两个注解`@AutoConfigurationPackage`，`@Import(AutoConfigurationImportSelector.class)`。\n\n#### @AutoConfigurationPackage\n\n标签名直译为：自动配置包，指定了默认的包规则。\n\n```java\n@Target(ElementType.TYPE)\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\n@Inherited\n@Import(AutoConfigurationPackages.Registrar.class)//给容器中导入Registrar组件\npublic @interface AutoConfigurationPackage {\n    String[] basePackages() default {};\n\n    Class<?>[] basePackageClasses() default {};\n}\n\n```\n\n1. @Import给容器中导入一个组件Registrar，利用Registrar给容器批量导入一系列组件\n2. 将指定注解标注的包下的所有组件导入spring IOC容器中。\n\n\n\n#### @Import(AutoConfigurationImportSelector.class) 初始加载自动配置类\n\n1. 利用`getAutoConfigurationEntry(annotationMetadata);`给容器中批量导入一些组件\n2. 调用`List<String> configurations = getCandidateConfigurations(annotationMetadata, attributes)`获取到所有需要导入到容器中的配置类\n3. 利用工厂加载 `Map<String, List<String>> loadSpringFactories(@Nullable ClassLoader classLoader);`得到所有的组件\n4. 从`META-INF/spring.factories`位置来加载一个文件。\n   1. 默认扫描我们当前引入的所有包中的`META-INF/spring.factories`路径的文件\n   2. `spring-boot-autoconfigure-2.3.4.RELEASE.jar`包里面也有`META-INF/spring.factories`\n\n```xml\n# 文件里面写死了spring-boot一启动就要给容器中加载的所有配置类 共127个\n# spring-boot-autoconfigure-2.3.4.RELEASE.jar/META-INF/spring.factories\n# Auto Configure\norg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\\norg.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\\norg.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\\n...\n```\n\n127个默认组件\n\n![image-20210628142105606](../img/springboot/image-20210628142105606.png)\n\n虽然127个场景的所有自动配置启动的时候默认全部加载，但是`xxxxAutoConfiguration`按照条件装配规则（`@Conditional`），最终会按需配置。\n\n\n\n如`AopAutoConfiguration`类：\n\n```java\n@Configuration(\n    proxyBeanMethods = false\n)\n@ConditionalOnProperty(\n    prefix = \"spring.aop\",\n    name = \"auto\",\n    havingValue = \"true\",\n    matchIfMissing = true\n)\npublic class AopAutoConfiguration {\n    public AopAutoConfiguration() {\n    }\n\t...\n}\n\n```\n\n## 13、自动配置-自动配置流程\n\nSpringBoot自动配置相关，在 **spring-boot-autoconfigure-xxx.jar** 中\n\n以`DispatcherServletAutoConfiguration`的内部类`DispatcherServletConfiguration`为例子:\n\n+ 整段代码相当于alis，如果MultipartResolver.class类型的组件id不是标准名称multipartResolver，则设置别名为multipartResolver\n+ 放在用户设置的下载解析器名称不规范\n\n```java\n@Bean\n@ConditionalOnBean(MultipartResolver.class)  //容器中有这个类型组件\n@ConditionalOnMissingBean(name = DispatcherServlet.MULTIPART_RESOLVER_BEAN_NAME) //容器中没有名字 为multipartResolver 的组件\npublic MultipartResolver multipartResolver(MultipartResolver resolver) {\n\t//给@Bean标注的方法传入了对象参数，这个参数的值会从容器中找。\n\t//SpringMVC multipartResolver。防止有些用户配置的文件上传解析器不符合规范\n\t// Detect if the user has created a MultipartResolver but named it incorrectly\n\treturn resolver;//给容器中加入了文件上传解析器；\n}\n```\n\n\n\nSpringBoot默认会在底层配好所有的组件，但是**如果用户自己配置了以用户的优先**。\n\n\n\n**总结**：\n\n+ SpringBoot先加载所有的自动配置类 xxxxxAutoConfiguration\n+ 每个自动配置类按照条件生效，一旦生效默认都会绑定配置文件指定的值。（xxxxProperties类中读取，xxxProperties类和配置文件进行了绑定）\n+ 生效的配置类就会给容器中装配很多组件\n+ 只要容器中有这些组件，相当于这些功能就有了\n+ 定制化配置\n  + 用户直接自己@Bean替换底层的组件\n  + 用户去看这个组件是获取的配置文件什么值就去修改\n\n**xxxxxAutoConfiguration —> 组件 —> xxxxProperties类中拿值 ----> application.properties**\n\n\n\n## 14、最佳实践-SpringBoot应用如何编写\n\n+ 引入场景依赖\n  + 官方文档：https://docs.spring.io/spring-boot/docs/current/reference/html/using.html#using.build-systems.starters\n+ 查看自动配置了哪些（选做）\n  + 自己分析，引入场景对应的自动配置一般都生效了\n  + 配置文件中 debug=true 开启自动配置报告。\n    + Negative（不生效）\n    + Positive（生效）\n+ 是否需要修改\n  + 参照文档修改配置项\n    + 官方文档\n    + 自己分析。xxxxProperties绑定了配置文件的哪些。\n  + 自定义加入或者替换组件\n    + @Bean、@Component…\n  + 自定义器 XXXXXCustomizer；\n  + …\n\n## 15、最佳实践-Lombok简化开发\n\n\nLombok用标签方式代替构造器、getter/setter、toString()等鸡肋代码。\n\nspring boot已经管理Lombok。引入依赖：\n\n```xml\n <dependency>\n     <groupId>org.projectlombok</groupId>\n     <artifactId>lombok</artifactId>\n</dependency>\n```\n\nIDEA中File->Settings->Plugins，搜索安装Lombok插件。\n\n```java\n@NoArgsConstructor\n//@AllArgsConstructor\n@Data\n@ToString\n@EqualsAndHashCode\npublic class User {\n\n    private String name;\n    private Integer age;\n\n    private Pet pet;\n\n    public User(String name,Integer age){\n        this.name = name;\n        this.age = age;\n    }\n}\n```\n\n简化日志开发\n\n```java\n@Slf4j\n@RestController\npublic class HelloController {\n    @RequestMapping(\"/hello\")\n    public String handle01(@RequestParam(\"name\") String name){\n        log.info(\"请求进来了....\");\n        return \"Hello, Spring Boot 2!\"+\"你好：\"+name;\n    }\n}\n```\n\n\n\n\n\n## 17、配置文件-yaml的用法\n\n同以前的properties用法\n\nYAML 是 “YAML Ain’t Markup Language”（YAML 不是一种标记语言）的递归缩写。在开发的这种语言时，YAML 的意思其实是：“Yet Another Markup Language”（仍是一种标记语言）。\n\n**非常适合用来做以数据为中心的配置文件**。\n\n\n\n### 基本语法\n\n- key: value；kv之间的冒号后有空格\n- 大小写敏感\n- 使用空格缩进表示层级关系(同一层级左对齐即可)\n- 缩进不允许使用tab，只允许空格\n- 缩进的空格数不重要，只要相同层级的元素左对齐即可\n- '#'表示注释\n- 字符串无需加引号，如果要加单引号’’表示插入转义符、双引号\"\"表示字符串原样输出不转义\n\n\n\n### 数据类型\n\n- 字面量：单个的、不可再分的值。date、boolean、string、number、null\n\n```yaml\nk: v\n```\n\n- 对象：键值对的集合。map、hash、set、object\n\n```yaml\n#行内写法：  \nk: {k1:v1,k2:v2,k3:v3}\n\n#或\nk: \n  k1: v1\n  k2: v2\n  k3: v3\n```\n\n\n\n- 数组：一组按次序排列的值。array、list、queue\n\n```yaml\n#行内写法：  \nk: [v1,v2,v3]\n\n#或者\nk:\n - v1\n - v2\n - v3\n\n```\n\n\n\n### 示例\n\n```java\n//绑定配置文件前缀\n@ConfigurationProperties(prefix = \"person\")\n@Data\npublic class Person {\n    private String userName;\n    private Boolean boss;\n    private Date birth;\n    private Integer age;\n    private Pet pet;\n    private String[] interests;\n    private List<String> animal;\n    private Map<String, Object> score;\n    private Set<Double> salarys;\n    private Map<String, List<Pet>> allPets;\n}\n\n@Data\npublic class Pet {\n    private String name;\n    private Double weight;\n}\n```\n\n用yaml表示以上对象\n\n写在 `application.yml` 中，优先级是`application.properties`优先\n\n```yaml\nperson:\n  userName: zhangsan\n  boss: false\n  birth: 2019/12/12 20:12:33\n  age: 18\n  pet: \n    name: tomcat\n    weight: 23.4\n  interests: [篮球,游泳]\n  animal: \n    - jerry\n    - mario\n  score:\n    english: \n      first: 30\n      second: 40\n      third: 50\n    math: [131,140,148]\n    chinese: {first: 128,second: 136}\n  salarys: [3999,4999.98,5999.99]\n  allPets:\n    sick:\n      - {name: tom}\n      - {name: jerry,weight: 47}\n    health: [{name: mario,weight: 47}]\n```\n\n\n\n## 18、配置文件-自定义类绑定的配置提示\n\n    You can easily generate your own configuration metadata file from items annotated with @ConfigurationProperties by using the spring-boot-configuration-processor jar. The jar includes a Java annotation processor which is invoked as your project is compiled.——link\n需要在pom.xml中添加依赖\n\n```xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-configuration-processor</artifactId>\n    <optional>true</optional>\n</dependency>\n\n<!-- 2.4之前最好添加下面插件，作用是工程打包时，不将spring-boot-configuration-processor打进包内，让其只在编码的时候有用 -->\n<build>\n    <plugins>\n        <plugin>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-maven-plugin</artifactId>\n            <configuration>\n                <excludes>\n                    <exclude>\n                        <groupId>org.springframework.boot</groupId>\n                        <artifactId>spring-boot-configuration-processor</artifactId>\n                    </exclude>\n                </excludes>\n            </configuration>\n        </plugin>\n    </plugins>\n</build>\n```\n\n\n\n## 19、web场景-web开发简介\n\nSpring Boot provides auto-configuration for Spring MVC that **works well with most applications.(大多场景我们都无需自定义配置)**\n\nThe auto-configuration adds the following features on top of Spring’s defaults:\n\n\n\n- Inclusion of `ContentNegotiatingViewResolver` and `BeanNameViewResolver` beans.\n\n  - 内容协商视图解析器和BeanName视图解析器\n- Support for serving static resources, including support for WebJars (covered [later in this document](https://docs.spring.io/spring-boot/docs/current/reference/html/spring-boot-features.html#boot-features-spring-mvc-static-content))).\n  - 静态资源（包括webjars）\n\n- Automatic registration of `Converter`, `GenericConverter`, and `Formatter` beans.\n  - 自动注册 `Converter，GenericConverter，Formatter`\n- Support for `HttpMessageConverters` (covered [later in this document](https://docs.spring.io/spring-boot/docs/current/reference/html/spring-boot-features.html#boot-features-spring-mvc-message-converters)).\n  - 支持 `HttpMessageConverters` （后来我们配合内容协商理解原理）\n- Automatic registration of `MessageCodesResolver` (covered [later in this document](https://docs.spring.io/spring-boot/docs/current/reference/html/spring-boot-features.html#boot-features-spring-message-codes)).\n  - 自动注册 `MessageCodesResolver` （国际化用）\n- Static `index.html` support.\n  - 静态index.html 页支持\n- Custom `Favicon` support (covered [later in this document](https://docs.spring.io/spring-boot/docs/current/reference/html/spring-boot-features.html#boot-features-spring-mvc-favicon)).\n  - 自定义 `Favicon`\n- Automatic use of a `ConfigurableWebBindingInitializer` bean (covered [later in this document](https://docs.spring.io/spring-boot/docs/current/reference/html/spring-boot-features.html#boot-features-spring-mvc-web-binding-initializer)).\n  - 自动使用 `ConfigurableWebBindingInitializer` ，（DataBinder负责将请求数据绑定到JavaBean上）\n\n> If you want to keep those Spring Boot MVC customizations and make more MVC customizations (interceptors, formatters, view controllers, and other features), you can add your own @Configuration class of type WebMvcConfigurer but without @EnableWebMvc.\n> 不用@EnableWebMvc注解。使用 @Configuration + WebMvcConfigurer 自定义规则\n\n\n\n> If you want to provide custom instances of RequestMappingHandlerMapping, RequestMappingHandlerAdapter, or ExceptionHandlerExceptionResolver, and still keep the Spring Boot MVC customizations, you can declare a bean of type WebMvcRegistrations and use it to provide custom instances of those components.\n>\n> 声明 WebMvcRegistrations 改变默认底层组件\n\n\n\n> If you want to take complete control of Spring MVC, you can add your own @Configuration annotated with @EnableWebMvc, or alternatively add your own @Configuration-annotated DelegatingWebMvcConfiguration as described in the Javadoc of @EnableWebMvc.\n>\n> 使用 @EnableWebMvc+@Configuration+DelegatingWebMvcConfiguration 全面接管SpringMVC\n\n\n\n## 20、web场景-静态资源规则与定制化\n\n### 静态资源目录\n\n只要静态资源放在类路径下： called `/static` (or `/public` or `/resources` or `/META-INF/resources`\n\n访问 ： 当前项目根路径/ + 静态资源名\n\n原理： 静态映射/**。\n\n请求进来，先去找Controller看能不能处理。不能处理的所有请求又都交给静态资源处理器。静态资源也找不到则响应404页面。\n\n也可以改变默认的静态资源路径，`/static`，`/public`,`/resources`, `/META-INF/resources`失效\n\n```yml\nresources:\n  static-locations: [classpath:/haha/]\n```\n\n### 静态资源访问前缀\n\n```yml\nspring:\n  mvc:\n    static-path-pattern: /res/**\n```\n\n当前项目 + static-path-pattern + 静态资源名 = 静态资源文件夹下找\n\n### webjar\n\n可用jar方式添加css，js等资源文件，\n\nhttps://www.webjars.org/\n\n例如，添加jquery\n\n```xml\n<dependency>\n    <groupId>org.webjars</groupId>\n    <artifactId>jquery</artifactId>\n    <version>3.5.1</version>\n</dependency>\n```\n\n访问地址：http://localhost:8080/webjars/jquery/3.5.1/jquery.js 后面地址要按照依赖里面的包路径。\n\n\n\n## 21、web场景-welcome与favicon功能\n\n官方文档: https://docs.spring.io/spring-boot/docs/2.3.8.RELEASE/reference/htmlsingle/#boot-features-spring-mvc-welcome-page\n\n### 欢迎页支持\n\n- 静态资源路径下 index.html\n  - 可以配置静态资源路径\n  - 但是不可以配置静态资源的访问前缀。否则导致 index.html不能被默认访问\n\n```yml\nspring:\n#  mvc:\n#    static-path-pattern: /res/**   指定静态资源前缀，会导致welcome page功能失效\n  resources:\n    static-locations: [classpath:/haha/]\n```\n\n- controller能处理/index\n\n### 自定义Favicon\n\n指网页标签上的小图标。\n\nfavicon.ico 放在静态资源目录下即可。\n\n```yml\nspring:\n#  mvc:\n#    static-path-pattern: /res/**   指定静态资源前缀，会导致 Favicon 功能失效\n```\n\n\n\n## 22、web场景-【源码分析】-静态资源原理\n\n- SpringBoot启动默认加载 xxxAutoConfiguration 类（自动配置类）\n- SpringMVC功能的自动配置类`WebMvcAutoConfiguration`，生效\n\n\n\n```java\n@Configuration(proxyBeanMethods = false)\n@ConditionalOnWebApplication(type = Type.SERVLET)\n@ConditionalOnClass({ Servlet.class, DispatcherServlet.class, WebMvcConfigurer.class })\n@ConditionalOnMissingBean(WebMvcConfigurationSupport.class)\n@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE + 10)\n@AutoConfigureAfter({ DispatcherServletAutoConfiguration.class, TaskExecutionAutoConfiguration.class,\n\t\tValidationAutoConfiguration.class })\npublic class WebMvcAutoConfiguration {\n    ...\n}\n```\n\n给容器中配置的内容：\n\n- 配置文件的相关属性的绑定：WebMvcProperties==**spring.mvc**、ResourceProperties==**spring.resources**\n\n```java\n@Configuration(proxyBeanMethods = false)\n@Import(EnableWebMvcConfiguration.class)\n@EnableConfigurationProperties({ WebMvcProperties.class, ResourceProperties.class })\n@Order(0)\npublic static class WebMvcAutoConfigurationAdapter implements WebMvcConfigurer {\n    ...\n}\n```\n\n\n\n### WEB场景需要主要分析的包\n\n+ org.sspringframework.boot.autoconfigure: 路径org.springframework.boot:spring-boot-autoconfigure\n\n  自动配置原理\n\n+ org.springframework.web.servlet: 路径org.springframework:spring-webmvc\n\n  web应用原理\n\n\n\n\n\n### 配置类只有一个有参构造器\n\n```java\n有参构造器所有参数的值都会从容器中确定\npublic WebMvcAutoConfigurationAdapter(WebProperties webProperties, WebMvcProperties mvcProperties,\n\t\tListableBeanFactory beanFactory, ObjectProvider<HttpMessageConverters> messageConvertersProvider,\n\t\tObjectProvider<ResourceHandlerRegistrationCustomizer> resourceHandlerRegistrationCustomizerProvider,\n\t\tObjectProvider<DispatcherServletPath> dispatcherServletPath,\n\t\tObjectProvider<ServletRegistrationBean<?>> servletRegistrations) {\n\tthis.mvcProperties = mvcProperties;\n\tthis.beanFactory = beanFactory;\n\tthis.messageConvertersProvider = messageConvertersProvider;\n\tthis.resourceHandlerRegistrationCustomizer = resourceHandlerRegistrationCustomizerProvider.getIfAvailable();\n\tthis.dispatcherServletPath = dispatcherServletPath;\n\tthis.servletRegistrations = servletRegistrations;\n\tthis.mvcProperties.checkConfiguration();\n}\n```\n\n- ResourceProperties resourceProperties；获取和spring.resources绑定的所有的值的对象\n- WebMvcProperties mvcProperties 获取和spring.mvc绑定的所有的值的对象\n- ListableBeanFactory beanFactory Spring的beanFactory\n- HttpMessageConverters 找到所有的HttpMessageConverters\n- ResourceHandlerRegistrationCustomizer 找到 资源处理器的自定义器。\n- DispatcherServletPath\n- ServletRegistrationBean 给应用注册Servlet、Filter…\n\n\n\n### 资源处理的默认规则\n\n```java\n...\npublic class WebMvcAutoConfiguration {\n    ...\n\tpublic static class EnableWebMvcConfiguration extends DelegatingWebMvcConfiguration implements ResourceLoaderAware {\n        ...\n\t\t@Override\n\t\tprotected void addResourceHandlers(ResourceHandlerRegistry registry) {\n\t\t\tsuper.addResourceHandlers(registry);\n\t\t\tif (!this.resourceProperties.isAddMappings()) {\n\t\t\t\tlogger.debug(\"Default resource handling disabled\");\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tServletContext servletContext = getServletContext();\n\t\t\taddResourceHandler(registry, \"/webjars/**\", \"classpath:/META-INF/resources/webjars/\");\n\t\t\taddResourceHandler(registry, this.mvcProperties.getStaticPathPattern(), (registration) -> {\n\t\t\t\tregistration.addResourceLocations(this.resourceProperties.getStaticLocations());\n\t\t\t\tif (servletContext != null) {\n\t\t\t\t\tregistration.addResourceLocations(new ServletContextResource(servletContext, SERVLET_LOCATION));\n\t\t\t\t}\n\t\t\t});\n\t\t}\n        ...\n        \n    }\n    ...\n}\n```\n\n\n\n根据上述代码，我们可以同过配置禁止所有静态资源规则。\n\n```yml\nspring:\n  resources:\n    add-mappings: false   #禁用所有静态资源规则\n```\n\n静态资源规则：\n\n```yml\n@ConfigurationProperties(prefix = \"spring.resources\", ignoreUnknownFields = false)\npublic class ResourceProperties {\n\n    private static final String[] CLASSPATH_RESOURCE_LOCATIONS = { \"classpath:/META-INF/resources/\",\n            \"classpath:/resources/\", \"classpath:/static/\", \"classpath:/public/\" };\n\n    /**\n     * Locations of static resources. Defaults to classpath:[/META-INF/resources/,\n     * /resources/, /static/, /public/].\n     */\n    private String[] staticLocations = CLASSPATH_RESOURCE_LOCATIONS;\n    ...\n}\n```\n\n### 欢迎页的处理规则\n\n```java\n...\npublic class WebMvcAutoConfiguration {\n    ...\n\tpublic static class EnableWebMvcConfiguration extends DelegatingWebMvcConfiguration implements ResourceLoaderAware {\n        ...\n\t\t@Bean\n\t\tpublic WelcomePageHandlerMapping welcomePageHandlerMapping(ApplicationContext applicationContext,\n\t\t\t\tFormattingConversionService mvcConversionService, ResourceUrlProvider mvcResourceUrlProvider) {\n\t\t\tWelcomePageHandlerMapping welcomePageHandlerMapping = new WelcomePageHandlerMapping(\n\t\t\t\t\tnew TemplateAvailabilityProviders(applicationContext), applicationContext, getWelcomePage(),\n\t\t\t\t\tthis.mvcProperties.getStaticPathPattern());\n\t\t\twelcomePageHandlerMapping.setInterceptors(getInterceptors(mvcConversionService, mvcResourceUrlProvider));\n\t\t\twelcomePageHandlerMapping.setCorsConfigurations(getCorsConfigurations());\n\t\t\treturn welcomePageHandlerMapping;\n\t\t}\n```\n\n`WelcomePageHandlerMapping`的构造方法如下：\n\n```java\nWelcomePageHandlerMapping(TemplateAvailabilityProviders templateAvailabilityProviders,\n                          ApplicationContext applicationContext, Resource welcomePage, String staticPathPattern) {\n    if (welcomePage != null && \"/**\".equals(staticPathPattern)) {\n        //要用欢迎页功能，必须是/**\n        logger.info(\"Adding welcome page: \" + welcomePage);\n        setRootViewName(\"forward:index.html\");\n    }\n    else if (welcomeTemplateExists(templateAvailabilityProviders, applicationContext)) {\n        //调用Controller /index\n        logger.info(\"Adding welcome page template: index\");\n        setRootViewName(\"index\");\n    }\n}\n```\n\n这构造方法内的代码也解释了**web场景-welcome与favicon功能**中配置`static-path-pattern`了，welcome页面和小图标失效的问题。\n\n\n\n\n\n\n\n### 参数映射\n\n+ @PathVariable(\"路径变量\")\n+ @RequestHeader(\"请求头参数\")\n+ @RequestParam(\"?请求参数\")\n+ @CookieValue(\"cookie值\")\n+ @RequestBody(\"请求体，post请求中的表单\")\n+ @RequestAttribute(\"获取request域属性\")\n  + 即获取前一个请求request.setAttribute(\"\", \"\")放入的参数\n+ @MatrixVariable(value = \"矩阵变量\", pathVar = \"path\")\n  + 需要和路径变量合用\n  + /users/{tom;age=34;name=byd}\n  + 分号前是访问路径，分号后是矩阵变量，即controller中只需要GetMapping(\"/users/{path}\")\n  + 路径重写，解决cookie被禁用的问题\n  + SpringBoot默认关闭矩阵变量 \n\n\n\n### 定制SpringMVC\n\n在config类中添加一个 WebMvcConfigurer bean\n\n```java\n@Bean\npublic WebMvcConfigurer webMvcConfigurer() {\n    //接口\n    return new WebMvcConfigurer() {\n        @Override\n        public void extendMessageConverters(List<HttpMessageConverter<?>> converters) {\n            \n        }\n    }\n}\n```\n\n \n\n\n\n## 23、模板引擎\n\nspringboot默认打jar包，是一种压缩格式，而jsp不支持在jar包中编译，因此springboot默认不支持jsp，引入了第三方模板引擎\n\nThymeleaf：简单，自然语言的模板，但不高效。\n\n\n\n\n## 24、数据库\n\n查看版本：\n\n```xml\n父项目spring boot\n    <parent>\n\t\t<groupId>org.springframework.boot</groupId>\n\t\t<artifactId>spring-boot-starter-parent</artifactId>\n\t\t<version>2.5.0</version>\n\t\t<relativePath/> <!-- lookup parent from repository -->\n\t</parent>\nspring boot 版本仲裁依赖\n  <parent>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-dependencies</artifactId>\n    <version>2.5.0</version>\n  </parent>\n```\n\n\n\n```yml\nspring:\n  datasource:\n    url: jdbc:mysql://localhost:3306/my_test?serverTimezone=UTC&useSSL=false\n    username: root\n    password: shenhuo\n    driver-class-name: com.mysql.jdbc.Driver\n    # 如果导入数据源但是不配置属性项目会启动失败\n```\n\n\n\n\n\n##  25、整合第三方技术到spring boot 中\n\n第三方是否提供starter，提供可以直接使用，不提供则需要手动导入自定义使用\n\n\n\n导入依赖\n\n```xml\n        <dependency>\n\t\t\t<groupId>com.alibaba</groupId>\n\t\t\t<artifactId>druid</artifactId>\n\t\t\t<version>1.1.17</version>\n\t\t</dependency>\n```\n\n配置文件\n\n```xml\n<bean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\" destroy-method=\"close\">\n    <property name=\"url\" value=\"${jdbc.url}\" />\n    <property name=\"username\" value=\"${jdbc.username}\" />\n    <property name=\"password\" value=\"${jdbc.password}\" />\n    <property name=\"maxActive\" value=\"20\" />\n    <property name=\"initialSize\" value=\"1\" />\n    <property name=\"maxWait\" value=\"60000\" />\n    <property name=\"minIdle\" value=\"1\" />\n    <property name=\"timeBetweenEvictionRunsMillis\" value=\"60000\" />\n    <property name=\"minEvictableIdleTimeMillis\" value=\"300000\" />\n    <property name=\"testWhileIdle\" value=\"true\" />\n    <property name=\"testOnBorrow\" value=\"false\" />\n    <property name=\"testOnReturn\" value=\"false\" />\n    <property name=\"poolPreparedStatements\" value=\"true\" />\n    <property name=\"maxOpenPreparedStatements\" value=\"20\" />\n</bean>\n```\n\n","comments":true,"categories":[],"tags":[{"name":"CS","slug":"CS","permalink":"http://blog.ahulearn.com/tags/CS/"},{"name":"JAVA","slug":"JAVA","permalink":"http://blog.ahulearn.com/tags/JAVA/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://blog.ahulearn.com/tags/SpringBoot/"}]},{"title":"SpringMVC","date":"2023-06-23T05:00:00.000Z","path":"2023/06/23/SpringMVC/","raw":"---\ntitle: SpringMVC\ndate: 2023-06-23 13:00:00\ntags:\n - CS\n - SpringMVC\n - JAVA\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\\springmvc\n---\n\n\n\n官方文档：https://docs.spring.io/spring-framework/docs/current/reference/html/web.html#spring-web\n\n基于Spring实现的MVC轻量级Web框架\n\nSSM: mybatis+Spring+SpringMVC\n\nMVC三层架构\n\nJava基础：认真学习，老师带，入门快\n\n+ JavaSE\n\n+ JavaWeb\n\n框架：研究官方文档，锻炼官方文档，锻炼自学能力，锻炼笔记能力，锻炼项目能力\n\nSpringMVC + Vue + SpringBoot + SpringCloud + Linux\n\n\n\nSSM = JavaWeb项目\n\nSping: IOC和AOP\n\nSpringMVC：SpringMVC的执行流程！\n\nSpringMVC: SSM框架整合！\n\n\n\nMVC：模型（dao, service）, 视图（jsp），控制器（Servlet）\n\n<!--more-->\n\n## 1. 什么是SpringMVC\n\n**1、回顾MVC**\n\n### 1.1、什么是MVC\n\n- MVC是模型(Model)、视图(View)、控制器(Controller)的简写，是一种软件设计规范。\n- 是将业务逻辑、数据、显示分离的方法来组织代码。\n- MVC主要作用是**降低了视图与业务逻辑间的双向偶合**。\n- MVC不是一种设计模式，**MVC是一种架构模式**。当然不同的MVC存在差异。\n\n**Model（模型）：**数据模型，提供要展示的数据，因此包含数据和行为，可以认为是领域模型或JavaBean组件（包含数据和行为），不过现在一般都分离开来：Value Object（数据Dao） 和 服务层（行为Service）。也就是模型提供了模型数据查询和模型数据的状态更新等功能，包括数据和业务。\n\n**View（视图）：**负责进行模型的展示，一般就是我们见到的用户界面，客户想看到的东西。\n\n**Controller（控制器）：**接收用户请求，委托给模型进行处理（状态改变），处理完毕后把返回的模型数据返回给视图，由视图负责展示。也就是说控制器做了个调度员的工作。\n\n**最典型的MVC就是JSP + servlet + javabean的模式。**\n\n![图片](/img/springmvc/1.1_0.png)\n\n### 1.2、Model1时代\n\n- 在web早期的开发中，通常采用的都是Model1。\n- Model1中，主要分为两层，视图层和模型层。\n\n![图片](/img/springmvc/1.1_1.png)\n\n### 1.3、Model2时代\n\nModel2把一个项目分成三部分，包括**视图、控制、模型。**\n\n\n\n![图片](/img/springmvc/1.1_2.png)\n\n1. 用户发请求\n2. Servlet接收请求数据，并调用对应的业务逻辑方法\n3. 业务处理完毕，返回更新后的数据给servlet\n4. servlet转向到JSP，由JSP来渲染页面\n5. 响应给前端更新后的页面\n\n**职责分析：**\n\n**Controller：控制器**\n\n1. 取得表单数据\n2. 调用业务逻辑\n3. 转向指定的页面\n\n**Model：模型**\n\n1. 业务逻辑\n2. 保存数据的状态\n\n**View：视图**\n\n1. 显示页面\n\nModel2这样不仅提高的代码的复用率与项目的扩展性，且大大降低了项目的维护成本。Model 1模式的实现比较简单，适用于快速开发小规模项目，Model1中JSP页面身兼View和Controller两种角色，将控制逻辑和表现逻辑混杂在一起，从而导致代码的重用性非常低，增加了应用的扩展性和维护的难度。Model2消除了Model1的缺点。\n\n\n\n### 1.4、回顾Servlet\n\n1. 新建一个Maven工程当做父工程！pom依赖！\n\n```xml\n<dependencies>\n   <dependency>\n       <groupId>junit</groupId>\n       <artifactId>junit</artifactId>\n       <version>4.12</version>\n   </dependency>\n   <dependency>\n       <groupId>org.springframework</groupId>\n       <artifactId>spring-webmvc</artifactId>\n       <version>5.1.9.RELEASE</version>\n   </dependency>\n   <dependency>\n       <groupId>javax.servlet</groupId>\n       <artifactId>servlet-api</artifactId>\n       <version>2.5</version>\n   </dependency>\n   <dependency>\n       <groupId>javax.servlet.jsp</groupId>\n       <artifactId>jsp-api</artifactId>\n       <version>2.2</version>\n   </dependency>\n   <dependency>\n       <groupId>javax.servlet</groupId>\n       <artifactId>jstl</artifactId>\n       <version>1.2</version>\n   </dependency>\n</dependencies>\n```\n\n2. 建立一个Moudle：springmvc-01-servlet ， 添加Web app的支持！\n3. 导入servlet 和 jsp 的 jar 依赖\n\n```xml\n<dependency>\n   <groupId>javax.servlet</groupId>\n   <artifactId>servlet-api</artifactId>\n   <version>2.5</version>\n</dependency>\n<dependency>\n   <groupId>javax.servlet.jsp</groupId>\n   <artifactId>jsp-api</artifactId>\n   <version>2.2</version>\n</dependency>\n```\n\n4. 编写一个Servlet类，用来处理用户的请求\n\n```java\npackage com.ahulearn;\n\nimport javax.servlet.ServletException;\nimport javax.servlet.http.HttpServlet;\nimport javax.servlet.http.HttpServletRequest;\nimport javax.servlet.http.HttpServletResponse;\nimport java.io.IOException;\n\npublic class HelloServlet extends HttpServlet {\n    @Override\n    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {\n        //取得参数\n        String method = req.getParameter(\"method\");\n        if (method.equals(\"add\")){\n            req.getSession().setAttribute(\"msg\",\"执行了add方法\");\n        }\n        if (method.equals(\"delete\")){\n            req.getSession().setAttribute(\"msg\",\"执行了delete方法\");\n        }\n        //调用业务层\n        //视图请求转发或重定位向\n        req.getRequestDispatcher(\"/WEB-INF/jsp/hello.jsp\").forward(req,resp);\n    }\n\n    @Override\n    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {\n        doGet(req,resp);\n    }\n}\n```\n\n5. 编写Hello.jsp，在WEB-INF目录下新建一个jsp的文件夹，新建hello.jsp\n\n```xml\n<%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %>\n<html>\n<head>\n   <title>Shenhuo</title>\n</head>\n<body>\n${msg}\n</body>\n</html>\n```\n\n6. 在web.xml中注册Servlet\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\"\n         version=\"4.0\">\n    \n    <servlet>\n        <servlet-name>hello</servlet-name>\n        <servlet-class>com.ahulearn.HelloServlet</servlet-class>\n    </servlet>\n    <servlet-mapping>\n        <servlet-name>hello</servlet-name>\n        <url-pattern>/hello</url-pattern>\n    </servlet-mapping>\n</web-app>\n```\n\n7. 配置Tomcat，并启动测试\n   + localhost:8080/user?method=add\n   + localhost:8080/user?method=delete\n\n**MVC框架要做哪些事情**\n\n1. 将url映射到java类或java类的方法 .\n2. 封装用户提交的数据 .\n3. 处理请求--调用相关的业务处理--封装响应数据 .\n4. 将响应的数据进行渲染 . jsp / html 等表示层数据 .\n\n**说明：**\n\n​\t常见的服务器端MVC框架有：Struts、Spring MVC、ASP.NET MVC、Zend Framework、JSF；常见前端MVC框架：vue、angularjs、react、backbone；由MVC演化出了另外一些模式如：MVP、MVVM 等等....\n\n\n\n## 2. 什么是SpringMVC\n\n### 2.1、概述\n\n![图片](/img/springmvc/2.1_0.png)\n\nSpring MVC是Spring Framework的一部分，是基于Java实现MVC的轻量级Web框架。\n\n查看官方文档：https://docs.spring.io/spring/docs/5.2.0.RELEASE/spring-framework-reference/web.html#spring-web\n\n**我们为什么要学习SpringMVC呢?**\n\n Spring MVC的特点：\n\n1. 轻量级，简单易学\n2. 高效 , 基于请求响应的MVC框架\n3. 与Spring兼容性好，无缝结合\n4. 约定优于配置\n5. 功能强大：RESTful、数据验证、格式化、本地化、主题等\n6. 简洁灵活\n\nSpring的web框架围绕**DispatcherServlet** [ 调度Servlet ] 设计。\n\nDispatcherServlet的作用是将请求分发到不同的处理器。从Spring 2.5开始，使用Java 5或者以上版本的用户可以采用基于注解形式进行开发，十分简洁；\n\n正因为SpringMVC好 , 简单 , 便捷 , 易学 , 天生和Spring无缝集成(使用SpringIoC和Aop) , 使用约定优于配置 . 能够进行简单的junit测试 . 支持Restful风格 .异常处理 , 本地化 , 国际化 , 数据验证 , 类型转换 , 拦截器 等等......所以我们要学习 .\n\n**最重要的一点还是用的人多 , 使用的公司多 .** \n\n\n\n### 2.2、中心控制器\n\n​\tSpring的web框架围绕DispatcherServlet设计。DispatcherServlet的作用是将请求分发到不同的处理器。从Spring 2.5开始，使用Java 5或者以上版本的用户可以采用基于注解的controller声明方式。\n\n​\tSpring MVC框架像许多其他MVC框架一样, **以请求为驱动** , **围绕一个中心Servlet分派请求及提供其他功能**，**DispatcherServlet是一个实际的Servlet (它继承自HttpServlet 基类)**。\n\n![图片](/img/springmvc/2.2_0.png)\n\nSpringMVC的原理如下图所示：\n\n​\t当发起请求时被前置的控制器拦截到请求，根据请求参数生成代理请求，找到请求对应的实际控制器，控制器处理请求，创建数据模型，访问数据库，将模型响应给中心控制器，控制器使用模型与视图渲染视图结果，将结果返回给中心控制器，再将结果返回给请求者。\n\n![图片](/img/springmvc/2.2_1.png)\n\n### 2.3、SpringMVC执行原理\n\n![图片](/img/springmvc/2.3_0.png)\n\n\n\n图为SpringMVC的一个较完整的流程图；实线：表示SpringMVC框架提供的技术，不需要开发者实现；虚线：表示需要开发者实现。\n\n**简要分析执行流程**\n\n1. DispatcherServlet表示前置控制器，是整个SpringMVC的控制中心。用户发出请求，DispatcherServlet接收请求并拦截请求。\n\n   我们假设请求的url为 : http://localhost:8080/SpringMVC/hello\n\n   \n\n   **如上url拆分成三部分：**\n\n   http://localhost:8080服务器域名\n\n   SpringMVC部署在服务器上的web站点\n\n   hello表示控制器\n\n   通过分析，如上url表示为：请求位于服务器localhost:8080上的SpringMVC站点的hello控制器。\n\n2. HandlerMapping为处理器映射。DispatcherServlet调用HandlerMapping,HandlerMapping根据请求url查找Handler。\n\n3. HandlerExecution表示具体的Handler,其主要作用是根据url查找控制器，如上url被查找控制器为：hello。\n\n4. HandlerExecution将解析后的信息传递给DispatcherServlet,如解析控制器映射等。\n\n5. HandlerAdapter表示处理器适配器，其按照特定的规则去执行Handler。\n\n6. Handler让具体的Controller执行。\n\n7. Controller将具体的执行信息返回给HandlerAdapter,如ModelAndView。\n\n8. HandlerAdapter将视图逻辑名或模型传递给DispatcherServlet。\n\n9. DispatcherServlet调用视图解析器(ViewResolver)来解析HandlerAdapter传递的逻辑视图名。\n\n10. 视图解析器将解析的逻辑视图名传给DispatcherServlet。\n\n11. DispatcherServlet根据视图解析器解析的视图结果，调用具体的视图。\n\n12. 最终视图呈现给用户。\n\n在这里先听一遍原理，不理解没有关系，我们马上来写一个对应的代码实现大家就明白了，如果不明白，那就写10遍，没有笨人，只有懒人！\n\n\n\n## 2 . 第一个MVC程序\n\nIDEA shfit+shfit打开类搜索：\n\n在上一节中，我们讲解了 什么是SpringMVC以及它的执行原理！\n\n现在我们来看看如何快速使用SpringMVC编写我们的程序吧！\n\n### 2.1 配置版\n\n1、新建一个普通Moudle ， springmvc-02-hello ， 右键Add Framework support添加web的支持！\n\n2、确定导入了SpringMVC 的依赖！\n\n3、配置web.xml  ， 注册DispatcherServlet\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\"\n         version=\"4.0\">\n    <!--1.注册DispatcherServlet-->\n    <servlet>\n        <servlet-name>springmvc</servlet-name>\n        <servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class>\n        <!--关联一个springmvc的配置文件:【servlet-name】-servlet.xml-->\n        <init-param>\n            <param-name>contextConfigLocation</param-name>\n            <param-value>classpath:springmvc-servlet.xml</param-value>\n        </init-param>\n        <!--启动级别-1: 与服务器一起启动-->\n        <load-on-startup>1</load-on-startup>\n    </servlet>\n\n    <!--/ 匹配所有的请求；（不包括.jsp）-->\n    <!--/* 匹配所有的请求；（包括.jsp）-->\n    <servlet-mapping>\n        <servlet-name>springmvc</servlet-name>\n        <url-pattern>/</url-pattern>\n    </servlet-mapping>\n</web-app>\n```\n\n4. 编写SpringMVC 的 配置文件！名称：springmvc-servlet.xml  : [servletname]-servlet.xml\n\n说明，这里的名称要求是按照官方来的\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n      xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n      xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       http://www.springframework.org/schema/beans/spring-beans.xsd\">\n\n</beans>\n```\n\n5. 添加 处理映射器 可以不添加会使用默认的\n\n```xml\n<bean class=\"org.springframework.web.servlet.handler.BeanNameUrlHandlerMapping\"/>\n```\n\n6. 添加 处理器适配器 可以不添加会使用默认的\n\n```xml\n<bean class=\"org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter\"/>\n```\n\n\n\n7. 添加 视图解析器\n\n```xml\n<!--视图解析器:DispatcherServlet给他的ModelAndView,其他模板引擎 Thymeleaf Freemarker ...-->\n<bean id=\"InternalResourceViewResolver\" class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\">\n   <!--前缀-->\n   <property name=\"prefix\" value=\"/WEB-INF/jsp/\"/>\n   <!--后缀-->\n   <property name=\"suffix\" value=\".jsp\"/>\n</bean>\n```\n\n总的结构：\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       http://www.springframework.org/schema/beans/spring-beans.xsd\">\n\t\n    <!--处理映射器：根据bean名称映射，以后可以使用更强大的映射器-->\n    <bean class=\"org.springframework.web.servlet.handler.BeanNameUrlHandlerMapping\"/>\n    <bean class=\"org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter\"/>\n    \n    <!--视图解析器:DispatcherServlet给他的ModelAndView\n\t1. 获取ModeView的数据； 2. 解析ModelAndView的视图名字；\n\t3.拼接视图的名字，找到对应的视图；4. 将获取的数据渲染到获取的视图中\n\t-->\n    <bean id=\"InternalResourceViewResolver\" class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\">\n        <!--前缀-->\n        <property name=\"prefix\" value=\"/WEB-INF/jsp/\"/>\n        <!--后缀-->\n        <property name=\"suffix\" value=\".jsp\"/>\n    </bean>\n\n    <!--Handler：BeanNameUrlHandlerMapping需要用到，配置地址与类的映射，相当于原来的mapping-->\n    <bean id=\"/hello\" class=\"com.ahulearn.controller.HelloController\"/>\n</beans>\n```\n\n\n\n8、编写我们要操作业务Controller ，要么实现Controller接口，要么增加注解；需要返回一个ModelAndView，装数据，封视图；\n\n```java\npackage com.ahulearn.controller;\n\nimport org.springframework.web.servlet.ModelAndView;\nimport org.springframework.web.servlet.mvc.Controller;\n\nimport javax.servlet.http.HttpServletRequest;\nimport javax.servlet.http.HttpServletResponse;\n\n//注意：这里我们先导入Controller接口\npublic class HelloController implements Controller {\n\n    public ModelAndView handleRequest(HttpServletRequest request, HttpServletResponse response) throws Exception {\n        //ModelAndView 模型和视图\n        ModelAndView mv = new ModelAndView();\n\n        //封装对象，放在ModelAndView中 Model\n        mv.addObject(\"msg\", \"HelloSpringMVC!\");\n        \n        //封装要跳转的视图，放在ModelAndView中\n        // /WEB-INF/jsp/hello.jsp\n        mv.setViewName(\"hello\");\n        return mv;\n    }\n}\n```\n\n9、将自己的类交给SpringIOC容器，注册bean\n\n```xml\n<!--Handler：配置了地址与类的映射，相当于原来的mapping-->\n<bean id=\"/hello\" class=\"com.ahulearn.controller.HelloController\"/>\n```\n\n10、写要跳转的jsp页面，显示ModelandView存放的数据，以及我们的正常页面；\n\n```jsp\n<%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %>\n<html>\n<head>\n   <title>Shenhuo</title>\n</head>\n<body>\n${msg}\n</body>\n</html>\n```\n\n11、配置Tomcat 启动测试！\n\n\n\n### 问题：可能遇到的问题：访问出现404，排查步骤：\n\n1. 查看控制台输出，看一下是不是缺少了什么jar包。\n2. 如果jar包存在，显示无法输出，就在IDEA的项目发布中，添加lib依赖！\n3. 重启Tomcat 即可解决\n\n解决方法1：File->Project Structure->Project Settings->Artifacts->选择tomcat打包的的模块->右侧Output Layout->WEB-INF->新建lib文件夹，点击+号添加依赖\n\n![image-20210429144658180](/img/springmvc/image-20210429144658180.png)\n\n解决方法2：参考地址：[(2条消息) idea中的Maven项目没有lib的解决方案_佐月儿-CSDN博客_idea 没有lib](https://blog.csdn.net/CSDN_zuoyueer/article/details/103270227) \n\n​\t不用新建lib文件夹，直接右键右侧的项目，选择Put into Output Root\n\n使用maven-wabapp框架构建子项目不会有此问题\n\n### 2.2 注解版\n\n**1、新建一个Moudle，springmvc-03-hello-annotation 。添加web支持！**\n\n2、由于Maven可能存在资源过滤的问题，我们将配置完善\n\n```xml\n<build>\n   <resources>\n       <resource>\n           <directory>src/main/java</directory>\n           <includes>\n               <include>**/*.properties</include>\n               <include>**/*.xml</include>\n           </includes>\n           <filtering>false</filtering>\n       </resource>\n       <resource>\n           <directory>src/main/resources</directory>\n           <includes>\n               <include>**/*.properties</include>\n               <include>**/*.xml</include>\n           </includes>\n           <filtering>false</filtering>\n       </resource>\n   </resources>\n</build>\n```\n\n3、在pom.xml文件引入相关的依赖：主要有Spring框架核心库、Spring MVC、servlet , JSTL等。我们在父依赖中已经引入了！\n\n**4、配置web.xml**\n\n注意点：固定内容\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\"\n        xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n        xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\"\n        version=\"4.0\">\n\n   <!--注册DispatchServlet-->\n   <servlet>\n       <servlet-name>SpringMVC</servlet-name>\n       <servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class>\n       <!--通过初始化参数指定SpringMVC配置文件的位置，进行关联-->\n       <init-param>\n           <param-name>contextConfigLocation</param-name>\n           <param-value>classpath:springmvc-servlet.xml</param-value>\n       </init-param>\n       <!-- 启动顺序，数字越小，启动越早 -->\n       <load-on-startup>1</load-on-startup>\n   </servlet>\n\n   <!--所有请求都会被springmvc拦截 -->\n   <servlet-mapping>\n       <servlet-name>SpringMVC</servlet-name>\n       <url-pattern>/</url-pattern>\n   </servlet-mapping>\n\n</web-app>\n```\n\n**/ 和 /\\* 的区别：**< url-pattern > / </ url-pattern > 不会匹配到.jsp， 只针对我们编写的请求；即：.jsp 不会进入spring的 DispatcherServlet类 。< url-pattern > /* </ url-pattern > 会匹配 *.jsp，会出现返回 jsp视图 时再次进入spring的DispatcherServlet 类，导致找不到对应的controller所以报404错。\n\n1. - 注意web.xml版本问题，要最新版！\n   - 注册DispatcherServlet\n   - 关联SpringMVC的配置文件\n   - 启动级别为1\n   - 映射路径为 / 【不要用/*，会404】\n\n\n\n\n**5、添加Spring MVC配置文件**\n\n在resource目录下添加springmvc-servlet.xml配置文件，配置的形式与Spring容器配置基本类似，为了支持基于注解的IOC，设置了自动扫描包的功能，具体配置信息如下：\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xmlns:mvc=\"http://www.springframework.org/schema/mvc\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       http://www.springframework.org/schema/beans/spring-beans.xsd\n       http://www.springframework.org/schema/context\n       https://www.springframework.org/schema/context/spring-context.xsd\n       http://www.springframework.org/schema/mvc\n       https://www.springframework.org/schema/mvc/spring-mvc.xsd\">\n\n    <!-- 自动扫描包，让指定包下的自动装配注解生效,由IOC容器统一管理 -->\n    <context:component-scan base-package=\"com.ahulearn.controller\"/>\n    <!-- 让Spring MVC不处理静态资源 .css .js .html .mp4 -->\n    <mvc:default-servlet-handler />\n    \n    <!--\n    支持mvc注解驱动\n        在spring中一般采用@RequestMapping注解来完成映射关系\n        要想使@RequestMapping注解生效\n        必须向上下文中注册DefaultAnnotationHandlerMapping\n        和一个AnnotationMethodHandlerAdapter实例\n        这两个实例分别在类级别和方法级别处理。\n        而annotation-driven配置帮助我们自动完成上述两个实例的注入。\n     -->\n    <mvc:annotation-driven />\n\n    <!-- 视图解析器 : 模板引擎 ThymeLeaf Freemarker ... -->\n    <bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"\n          id=\"internalResourceViewResolver\">\n        <!-- 前缀 -->\n        <property name=\"prefix\" value=\"/WEB-INF/jsp/\" />\n        <!-- 后缀 -->\n        <property name=\"suffix\" value=\".jsp\" />\n    </bean>\n\n</beans>\n```\n\n1. 在视图解析器中我们把所有的视图都存放在/WEB-INF/目录下，这样可以保证视图安全，因为这个目录下的文件，客户端不能直接访问。\n\n2. - 让IOC的注解生效\n\n   - 静态资源过滤 ：HTML . JS . CSS . 图片 ， 视频 .....\n\n   - MVC的注解驱动\n\n   - 配置视图解析器\n\n     \n\n3. **6、创建Controller**\n\n4. 编写一个Java控制类：com.ahulearn.controller.HelloController , 注意编码规范\n\n```java\npackage com.ahulearn.controller;\n\nimport org.springframework.ui.Model;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.stereotype.Controller;\n\n@Controller\n@RequestMapping(\"/HelloController\")\npublic class HelloController {\n\n    //真实访问地址 : 项目名/HelloController/hello\n    @RequestMapping(\"/hello\")\n    public String sayHello(Model model){\n        //向模型中添加属性msg与值，可以在JSP页面中取出并渲染\n        model.addAttribute(\"msg\",\"hello,SpringMVC\");\n        //web-inf/jsp/hello.jsp\n        return \"hello\";\n    }\n}\n```\n\n1. - @Controller是为了让Spring IOC容器初始化时自动扫描到；\n   - @RequestMapping是为了映射请求路径，这里因为类与方法上都有映射所以访问时应该是/HelloController/hello；\n   - 方法中声明Model类型的参数是为了把Action中的数据带到视图中；\n   - 方法返回的结果是视图的名称hello，加上配置文件中的前后缀变成WEB-INF/jsp/**hello**.jsp。\n\n7、**创建视图层**\n\n在WEB-INF/ jsp目录中创建hello.jsp ， 视图可以直接取出并展示从Controller带回的信息；\n\n可以通过EL表示取出Model中存放的值，或者对象；\n\n```jsp\n<%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %>\n<html>\n<head>\n   <title>SpringMVC</title>\n</head>\n<body>\n${msg}\n</body>\n</html>\n```\n\n\n\n\n\n#### 小结\n\n\n实现步骤其实非常的简单：\n\n1. 新建一个web项目\n2. 导入相关jar包\n3. 编写web.xml , 注册DispatcherServlet\n4. 编写springmvc配置文件\n5. 接下来就是去创建对应的控制类 , controller\n6. 最后完善前端视图和controller之间的对应\n7. 测试运行调试.\n\n\n\n使用springMVC必须配置的三大件：\n\n**处理器映射器、处理器适配器、视图解析器**\n\n通常，我们只需要**手动配置视图解析器**，而**处理器映射器**和**处理器适配器**只需要开启**注解驱动**即可，而省去了大段的xml配置\n\n\n\n##  3. Controller配置\n\n### 控制器Controller\n\n- 控制器复杂提供访问应用程序的行为，通常通过接口定义或注解定义两种方法实现。\n\n- 控制器负责解析用户的请求并将其转换为一个模型。\n\n- 在Spring MVC中一个控制器类可以包含多个方法\n\n- 在Spring MVC中，对于Controller的配置方式有很多种\n\n  \n\n### 实现Controller接口\n\nController是一个接口，在org.springframework.web.servlet.mvc包下，接口中只有一个方法；\n\n```java\n//实现该接口的类获得控制器功能\npublic interface Controller {\n   //处理请求且返回一个模型与视图对象\n   ModelAndView handleRequest(HttpServletRequest var1, HttpServletResponse var2) throws Exception;\n}\n```\n\n只要实现了Controller接口的类，说明这就是一个控制器\n\n**测试**\n\n1. 新建一个Moudle，springmvc-04-controller 。\n\n2. 配置web.xml\n\n   ```xml\n   <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n   \n   <web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\"\n            xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n            xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\"\n            version=\"4.0\">\n   \n     <!--注册DispatchServlet-->\n     <servlet>\n       <servlet-name>springmvc</servlet-name>\n       <servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class>\n       <!--通过初始化参数指定SpringMVC配置文件的位置，进行关联-->\n       <init-param>\n         <param-name>contextConfigLocation</param-name>\n         <param-value>classpath:springmvc-servlet.xml</param-value>\n       </init-param>\n       <!-- 启动顺序，数字越小，启动越早 -->\n       <load-on-startup>1</load-on-startup>\n     </servlet>\n     <servlet-mapping>\n       <servlet-name>springmvc</servlet-name>\n       <url-pattern>/</url-pattern>\n     </servlet-mapping>\n   \n   </web-app>\n   ```\n\n   \n\n3. 配置beans文件：springmvc-servlet.xml\n\n   ```xml\n   <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n   <beans xmlns=\"http://www.springframework.org/schema/beans\"\n          xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n          xmlns:context=\"http://www.springframework.org/schema/context\"\n          xmlns:mvc=\"http://www.springframework.org/schema/mvc\"\n          xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n          http://www.springframework.org/schema/beans/spring-beans.xsd\n          http://www.springframework.org/schema/context\n          https://www.springframework.org/schema/context/spring-context.xsd\n          http://www.springframework.org/schema/mvc\n          https://www.springframework.org/schema/mvc/spring-mvc.xsd\">\n   \t\n       <!-- 接口方式下方内容不需要添加 -->\n       <!--自动装配扫描地址-->\n       <context:component-scan base-package=\"com.ahulearn.controller\"/>\n       <!-- 静态资源过滤 -->\n       <mvc:default-servlet-handler />\n       <!-- 开启mvc注解驱动 -->\n       <mvc:annotation-driven />\n       <!-- 接口方式上方内容不需要添加 -->\n   \n       <!-- 视图解析器 : 模板引擎 ThymeLeaf Freemarker ... -->\n       <bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"\n             id=\"internalResourceViewResolver\">\n           <!-- 前缀 -->\n           <property name=\"prefix\" value=\"/WEB-INF/jsp/\" />\n           <!-- 后缀 -->\n           <property name=\"suffix\" value=\".jsp\" />\n       </bean>\n       <bean name=\"/t1\" class=\"com.ahulearn.controller.ControllerTest\"/>\n   </beans>\n   ```\n\n   \n\n4. 编写一个Controller类，ControllerTest\n\n   ```java\n   package com.ahulearn.controller;\n   \n   import org.springframework.web.servlet.ModelAndView;\n   import org.springframework.web.servlet.mvc.Controller;\n   \n   import javax.servlet.http.HttpServletRequest;\n   import javax.servlet.http.HttpServletResponse;\n   \n   //定义控制器\n   //注意点：不要导错包，导入的是Controller接口，重写方法；\n   public class ControllerTest implements Controller {\n   \n       @Override\n       public ModelAndView handleRequest(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse) throws Exception {\n           //返回一个模型视图对象\n           ModelAndView mv = new ModelAndView();\n           mv.addObject(\"msg\",\"Test1Controller\");\n           mv.setViewName(\"test\");\n           return mv;\n       }\n   }\n   ```\n\n   \n\n5. 编写完毕后，去Spring配置文件中注册请求的bean；name对应请求路径，class对应处理请求的类\n\n```xml\n<bean name=\"/t1\" class=\"com.ahulearn.controller.ControllerTest\"/>\n```\n\n6. 编写前端test.jsp，注意在WEB-INF/jsp目录下编写，对应我们的视图解析器\n\n```jsp\n<%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %>\n<html>\n<head>\n   <title>shenhuo</title>\n</head>\n<body>\n${msg}\n</body>\n</html>\n```\n\n1. 配置Tomcat运行测试，我这里没有项目发布名配置的就是一个 / ，所以请求不用加项目名，OK！\n\n\n\n**说明：**\n\n- 实现接口Controller定义控制器是较老的办法\n- 缺点是：一个控制器中只有一个方法，如果要多个方法则需要定义多个Controller；定义的方式比较麻烦；\n\n\n\n### 使用注解@Controller\n\n四个相同的注解\n\n```java\n@Component 组件\n@Service \n@Controller\n@Reoisutiry\n```\n\n\n\n- @Controller注解类型用于声明Spring类的实例是一个控制器（在讲IOC时还提到了另外3个注解）；\n\n- Spring可以使用扫描机制来找到应用程序中所有基于注解的控制器类，为了保证Spring能找到你的控制器，需要在配置文件中声明组件扫描。\n\n  ```\n  <!-- 自动扫描指定的包，下面所有注解类交给IOC容器管理 -->\n  <context:component-scan base-package=\"com.kuang.controller\"/>\n  ```\n\n- 增加一个ControllerTest2类，使用注解实现；\n\n  ```java\n  package com.ahulearn.controller;\n  \n  import org.springframework.stereotype.Controller;\n  import org.springframework.ui.Model;\n  import org.springframework.web.bind.annotation.RequestMapping;\n  \n  //@Controller注解的类会注入到Spring中;\n  // 类中的方法如果返回值是String,并且具有可以跳转的页面,则会被视图解析器解析\n  @Controller\n  public class ControllerTest2{\n  \n      //映射访问路径\n      @RequestMapping(\"/t2\")\n      public String index(Model model){\n          //Spring MVC会自动实例化一个Model对象用于向视图中传值\n          model.addAttribute(\"msg\", \"ControllerTest2\");\n          //返回视图位置\n          return \"test\";\n      }\n  \n  }\n  ```\n\n- 运行tomcat测试\n\n\n\n**可以发现，我们的两个请求都可以指向一个视图，但是页面结果的结果是不一样的，从这里可以看出视图是被复用的，而控制器与视图之间是弱偶合关系。**\n\n**注解方式是平时使用的最多的方式！**\n\n\n\n## 4. RequestMapping\n\n**@RequestMapping**\n\n源码\n\n```java\n@Target({ElementType.METHOD, ElementType.TYPE})\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\n@Mapping\n\npublic @interface RequestMapping {\n\tString name() default \"\";\n\tString[] value() default {};\n\tString[] path() default {};\n\tRequestMethod[] method() default {};\n\tString[] params() default {};\n\tString[] headers() default {};\n\tString[] consumes() default {};\n\tString[] produces() default {};\n}\n```\n\n+ 在@Target中有两个属性，分别为 ElementType.METHOD 和 ElementType.TYPE ，也就是说 @RequestMapping 可以在方法和类的声明中使用。用于类上，表示类中的所有响应请求的方法都是以该地址作为父路径。\n+ @RequestMapping 中的 value 和 path 属性（这两个属性作用相同，可以互换，如果仅有这一个属性，则可以省略）\n\n+ 可以看到注解中的属性除了 name() 返回的字符串，其它的方法均返回数组，也就是可以定义多个属性值，例如 value() 和 path() 都可以同时定义多个字符串值来接收多个URL请求\n\n\n\n- 为了测试结论更加准确，我们可以加上一个项目名测试 myweb\n\n- 只注解在方法上面\n\n  ```java\n  package com.ahulearn.controller;\n  \n  import org.springframework.stereotype.Controller;\n  import org.springframework.web.bind.annotation.RequestMapping;\n  \n  @Controller\n  public class ControllerTest3 {\n      @RequestMapping(\"/h1\")\n      public String test(){\n          return \"test\";\n      }\n  }\n  ```\n\n  访问路径：http://localhost:8080 / 项目名 / h1\n\n- 同时注解类与方法\n\n  ```java\n  package com.ahulearn.controller;\n  \n  import org.springframework.stereotype.Controller;\n  import org.springframework.web.bind.annotation.RequestMapping;\n  \n  @Controller\n  @RequestMapping(\"/admin\")\n  public class TestController {\n      @RequestMapping(\"/h1\")\n      public String test(){\n          return \"test\";\n      }\n  }\n  ```\n\n  访问路径：http://localhost:8080 / 项目名/ admin /h1  , 需要先指定类的路径再指定方法的路径；\n\n\n\n### 4.1 RestFul 风格\n\n**概念**\n\nRestful就是一个资源定位及资源操作的风格。不是标准也不是协议，只是一种风格。基于这个风格设计的软件可以更简洁，更有层次，更易于实现缓存等机制。\n\n**功能**\n\n资源：互联网所有的事物都可以被抽象为资源\n\n资源操作：使用POST、DELETE、PUT、GET，使用不同方法对资源进行操作。\n\n分别对应 添加、 删除、修改、查询。\n\n**传统方式操作资源**  ：通过不同的参数来实现不同的效果！方法单一，post 和 get\n\n​\thttp://127.0.0.1/item/queryItem.action?id=1 查询,GET\n\n​\thttp://127.0.0.1/item/saveItem.action 新增,POST\n\n​\thttp://127.0.0.1/item/updateItem.action 更新,POST\n\n​\thttp://127.0.0.1/item/deleteItem.action?id=1 删除,GET或POST\n\n**使用RESTful操作资源** ：可以通过不同的请求方式来实现不同的效果！如下：请求地址一样，但是功能可以不同！\n\n​\thttp://127.0.0.1/item/1 查询,GET\n\n​\thttp://127.0.0.1/item 新增,POST\n\n​\thttp://127.0.0.1/item 更新,PUT\n\n​\thttp://127.0.0.1/item/1 删除,DELETE\n\n**学习测试**\n\n1. 在新建一个类 RestFulController\n\n   ```\n   @Controller\n   public class RestFulController {\n   }\n   ```\n\n2. 在Spring MVC中可以使用  @PathVariable 注解，让方法参数的值对应绑定到一个URI模板变量上。\n\n   ```java\n   package com.ahulearn.controller;\n   \n   import org.springframework.stereotype.Controller;\n   import org.springframework.ui.Model;\n   import org.springframework.web.bind.annotation.PathVariable;\n   import org.springframework.web.bind.annotation.RequestMapping;\n   \n   @Controller\n   public class RestFulController {\n   \n       //映射访问路径\n       @RequestMapping(value=\"/commit/{p1}/{p2}\")\n       public String index(@PathVariable int p1, @PathVariable int p2, Model model){\n   \n           int result = p1+p2;\n           //Spring MVC会自动实例化一个Model对象用于向视图中传值\n           model.addAttribute(\"msg\", \"结果：\"+result);\n           //返回视图位置\n           return \"test\";\n       }\n   }\n   ```\n\n\n\n1. 思考：使用路径变量的好处？\n\n2. - 使路径变得更加简洁；\n   - 获得参数更加方便，框架会自动进行类型转换。\n   - 通过路径变量的类型可以约束访问参数，如果类型不一样，则访问不到对应的请求方法，如这里访问是的路径是/commit/1/a，则路径与方法不匹配，而不会是参数转换失败。\n\n\n\n我们来修改下对应的参数类型，再次测试\n\n```java\npackage com.ahulearn.controller;\n\nimport org.springframework.web.bind.annotation.RequestMethod;\n\n@Controller\npublic class RestFulController {\n\n    //映射访问路径\n    @RequestMapping(value=\"/commit/{p1}/{p2}\", method = {RequestMethod.GET})\n    public String index(@PathVariable int p1, @PathVariable String p2, Model model){\n\n        int result = p1+p2;\n        //Spring MVC会自动实例化一个Model对象用于向视图中传值\n        model.addAttribute(\"msg\", \"结果：\"+result);\n        //返回视图位置\n        return \"test\";\n    }\n}\n```\n\n\n\n**使用method属性指定请求类型**\n\n用于约束请求的类型，可以收窄请求范围。指定请求谓词的类型如GET, POST, HEAD, OPTIONS, PUT, PATCH, DELETE, TRACE等\n\n我们来测试一下：\n\n- 增加一个方法\n\n  ```java\n  //映射访问路径,表单提交POST请求\n  @RequestMapping(value = \"/commit/{p1}/{p2}\",method = {RequestMethod.POST,RequestMethod.GET})\n  public String index2(@PathVariable int p1, @PathVariable int p2, Model model){\n      int result = p1+p2;\n      //Spring MVC会自动实例化一个Model对象用于向视图中传值\n      model.addAttribute(\"msg\", \"结果：\"+result);\n      return \"test\";\n  }\n  ```\n\n- 我们使用浏览器地址栏进行访问默认是Get请求，会报错405：\n\n\n\n另一种简洁的方式指定请求方法\n\n```java\n@GetMapping\n@PostMapping\n@DeleteMapping\n@PutMapping\n@PatchMapping\n```\n\n\n\n\n\n\n\n## 5. 乱码问题\n\n测试步骤：\n\n1、我们可以在首页编写一个提交的表单\n\n```xml\n<form action=\"/04/encoding/t1\" method=\"post\">\n    <input type=\"text\" name=\"name\">\n    <input type=\"submit\">\n</form>\n```\n\n2、后台编写对应的处理类\n\n```java\npackage com.ahulearn.controller;\n\nimport org.springframework.stereotype.Controller;\nimport org.springframework.ui.Model;\nimport org.springframework.web.bind.annotation.PostMapping;\n\n@Controller\npublic class EncodingController {\n    @PostMapping(\"/encoding/t1\")\n    public String test1(String name, Model model) {\n        model.addAttribute(\"msg\", name);\n        return \"test\";\n    }\n}\n```\n\n3、输入中文测试，发现乱码\n\n访问：http://localhost:8080/04/\n\n表单填入中文，返回乱码\n\n\n\n4、使用servlet的过滤\n\n```java\npackage com.ahulearn.controller;\n\nimport org.springframework.stereotype.Controller;\nimport org.springframework.ui.Model;\nimport org.springframework.web.bind.annotation.PostMapping;\n\nimport javax.servlet.http.HttpServletRequest;\nimport javax.servlet.http.HttpServletResponse;\nimport java.io.UnsupportedEncodingException;\n\n@Controller\npublic class EncodingController {\n    @PostMapping(\"/encoding/t1\")\n    public String test1(String name, Model model, HttpServletRequest req, HttpServletResponse resp) throws UnsupportedEncodingException {\n        //此处设置编码无效\n        req.setCharacterEncoding(\"utf-8\");\n        resp.setCharacterEncoding(\"utf-8\");\n        model.addAttribute(\"msg\", name);\n        return \"test\";\n    }\n}\n```\n\n+ 设置后还是乱码\n\n在提交页使用meta标签设置编码，可以让提交的数据正常\n\n```jsp\n<html>\n<head>\n    <meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8\">\n    <title>乱码问题</title>\n</head>\n<body>\n<h2>Hello World!</h2>\n<form action=\"/04/encoding/t1\" method=\"post\">\n    <input type=\"text\" name=\"name\">\n    <input type=\"submit\" value=\"提交\">\n</form>\n</body>\n</html>\n```\n\n**但是添加以下代码反而会再次变乱码**\n\n```jsp\n<%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %>\n```\n\n分析二者的差别，**未知**\n\n使用get方法则正常，后续分析post方法提交数据的编码方式\n\npost方法如果不使用jsp的设置，会使用html实体传送数据\n\n+ 比如：`神火` 会转为：`&#31070;&#28779;` 即utf-8编码的10进制**实体**表示\n+ 表示中全部在ASCII编码范围内，因此无论什么编码，都能保证内容正确\n\n添加上面jsp的方法后则使用URLEncode方式对数据进行编码\n\n+ 神火的16进制编码为：%u795E%u706B，而URLEncode的结果是：%E7%A5%9E%E7%81%AB\n+ 参考W3School发现url编码使用的是ISO-8859-1编码：https://www.w3school.com.cn/charsets/ref_html_8859.asp，虽然html5推荐使用Unicode UTF-8，但作为html4的默认字符，ISO-8859依然作为url编码使用。\n+ 另一方面接受的数据并不是和编码结果完全相同，接受的数据是将每个汉字结果转为3个字节，即每个%后的两个字母作为一个字节保存。\n\njava进行url编码：\n\n```java\npublic static String getURLEncoderString(String str) {\n    String result = \"\";\n    if (null == str) {\n        return \"\";\n    }\n    try {\n        result = java.net.URLEncoder.encode(str, \"UTF-8\");\n    } catch (UnsupportedEncodingException e) {\n        e.printStackTrace();\n    }\n    return result;\n}\n\npublic static String URLDecoderString(String str) {\n    String result = \"\";\n    if (null == str) {\n        return \"\";\n    }\n    try {\n        result = java.net.URLDecoder.decode(str, \"UTF-8\");\n    } catch (UnsupportedEncodingException e) {\n        e.printStackTrace();\n    }\n    return result;\n}\n```\n\n\n\n以前乱码问题使用过滤器解决 , 而SpringMVC给我们提供了一个过滤器 , 可以在web.xml中配置 .\n\n修改了xml文件需要重启服务器！\n\n```xml\n<filter>\n   <filter-name>encoding</filter-name>\n   <filter-class>org.springframework.web.filter.CharacterEncodingFilter</filter-class>\n   <init-param>\n       <param-name>encoding</param-name>\n       <param-value>utf-8</param-value>\n   </init-param>\n</filter>\n<filter-mapping>\n   <filter-name>encoding</filter-name>\n   <url-pattern>/*</url-pattern>\n</filter-mapping>\n```\n\n但是我们发现 , 有些极端情况下.这个过滤器对get的支持不好 .\n\n处理方法 :\n\n1、修改tomcat配置文件 ：设置编码！\n\n```xml\n<Connector URIEncoding=\"utf-8\" port=\"8080\" protocol=\"HTTP/1.1\"\n          connectionTimeout=\"20000\"\n          redirectPort=\"8443\" />\n```\n\n2、自定义过滤器\n\n```java\npackage com.ahulearn.filter;\n\nimport javax.servlet.*;\nimport javax.servlet.http.HttpServletRequest;\nimport javax.servlet.http.HttpServletRequestWrapper;\nimport javax.servlet.http.HttpServletResponse;\nimport java.io.IOException;\nimport java.io.UnsupportedEncodingException;\nimport java.util.Map;\n\n/**\n* 解决get和post请求 全部乱码的过滤器\n*/\npublic class GenericEncodingFilter implements Filter {\n\n   @Override\n   public void destroy() {\n  }\n\n   @Override\n   public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {\n       //处理response的字符编码\n       HttpServletResponse myResponse=(HttpServletResponse) response;\n       myResponse.setContentType(\"text/html;charset=UTF-8\");\n\n       // 转型为与协议相关对象\n       HttpServletRequest httpServletRequest = (HttpServletRequest) request;\n       // 对request包装增强\n       HttpServletRequest myrequest = new MyRequest(httpServletRequest);\n       chain.doFilter(myrequest, response);\n  }\n\n   @Override\n   public void init(FilterConfig filterConfig) throws ServletException {\n  }\n\n}\n\n//自定义request对象，HttpServletRequest的包装类\nclass MyRequest extends HttpServletRequestWrapper {\n\n   private HttpServletRequest request;\n   //是否编码的标记\n   private boolean hasEncode;\n   //定义一个可以传入HttpServletRequest对象的构造函数，以便对其进行装饰\n   public MyRequest(HttpServletRequest request) {\n       super(request);// super必须写\n       this.request = request;\n  }\n\n   // 对需要增强方法 进行覆盖\n   @Override\n   public Map getParameterMap() {\n       // 先获得请求方式\n       String method = request.getMethod();\n       if (method.equalsIgnoreCase(\"post\")) {\n           // post请求\n           try {\n               // 处理post乱码\n               request.setCharacterEncoding(\"utf-8\");\n               return request.getParameterMap();\n          } catch (UnsupportedEncodingException e) {\n               e.printStackTrace();\n          }\n      } else if (method.equalsIgnoreCase(\"get\")) {\n           // get请求\n           Map<String, String[]> parameterMap = request.getParameterMap();\n           if (!hasEncode) { // 确保get手动编码逻辑只运行一次\n               for (String parameterName : parameterMap.keySet()) {\n                   String[] values = parameterMap.get(parameterName);\n                   if (values != null) {\n                       for (int i = 0; i < values.length; i++) {\n                           try {\n                               // 处理get乱码\n                               values[i] = new String(values[i]\n                                      .getBytes(\"ISO-8859-1\"), \"utf-8\");\n                          } catch (UnsupportedEncodingException e) {\n                               e.printStackTrace();\n                          }\n                      }\n                  }\n              }\n               hasEncode = true;\n          }\n           return parameterMap;\n      }\n       return super.getParameterMap();\n  }\n\n   //取一个值\n   @Override\n   public String getParameter(String name) {\n       Map<String, String[]> parameterMap = getParameterMap();\n       String[] values = parameterMap.get(name);\n       if (values == null) {\n           return null;\n      }\n       return values[0]; // 取回参数的第一个值\n  }\n\n   //取所有值\n   @Override\n   public String[] getParameterValues(String name) {\n       Map<String, String[]> parameterMap = getParameterMap();\n       String[] values = parameterMap.get(name);\n       return values;\n  }\n}\n```\n\n\n\n这个也是我在网上找的一些大神写的，一般情况下，SpringMVC默认的乱码处理就已经能够很好的解决了！\n\n**然后在web.xml中配置这个过滤器即可！**\n\n乱码问题，需要平时多注意，在尽可能能设置编码的地方，都设置为统一编码 UTF-8！\n\n\n\n## 6. JSON数据交互\n\n\n\n> 什么是JSON？\n\n- JSON(JavaScript Object Notation, JS 对象标记) 是一种轻量级的数据交换格式，目前使用特别广泛。\n- 采用完全独立于编程语言的**文本格式**来存储和表示数据。\n- 简洁和清晰的层次结构使得 JSON 成为理想的数据交换语言。\n- 易于人阅读和编写，同时也易于机器解析和生成，并有效地提升网络传输效率。\n\n在 JavaScript 语言中，一切都是对象。因此，任何JavaScript 支持的类型都可以通过 JSON 来表示，例如字符串、数字、对象、数组等。看看他的要求和语法格式：\n\n- 对象表示为键值对，数据由逗号分隔\n- 花括号保存对象\n- 方括号保存数组\n\n**JSON 键值对**是用来保存 JavaScript 对象的一种方式，和 JavaScript 对象的写法也大同小异，键/值对组合中的键名写在前面并用双引号 \"\" 包裹，使用冒号 : 分隔，然后紧接着值：\n\n```js\n{\"name\": \"QinJiang\"}\n{\"age\": \"3\"}\n{\"sex\": \"男\"}\n```\n\n很多人搞不清楚 JSON 和 JavaScript 对象的关系，甚至连谁是谁都不清楚。其实，可以这么理解：\n\nJSON 是 JavaScript 对象的字符串表示法，它使用文本表示一个 JS 对象的信息，本质是一个字符串。\n\n\n\n**JSON 和 JavaScript 对象互转**\n\n要实现从JSON字符串转换为JavaScript 对象，使用 JSON.parse() 方法：\n\n```js\nlet obj = JSON.parse('{\"a\": \"Hello\", \"b\": \"World\"}');\n//结果是 {a: 'Hello', b: 'World'}\n```\n\n要实现从JavaScript 对象转换为JSON字符串，使用 JSON.stringify() 方法：\n\n```js\nlet json = JSON.stringify({a: 'Hello', b: 'World'});\n//结果是 '{\"a\": \"Hello\", \"b\": \"World\"}'\n```\n\n\n\n**代码测试**\n\n1、新建一个module ，springmvc-05-json ， 添加web的支持\n\n2、在web目录下新建一个 json-1.html ， 编写测试内容\n\n```html\n<html>\n<head>\n    <title>Title</title>\n    <meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8\">\n    <title>Json</title>\n    <script type=\"text/javascript\">\n        //编写一个JavaScript对象\n        let user = {\n            name:\"神火\",\n            age:\"8\",\n            sex:\"男\"\n        }\n        console.log(user)\n        //json对象转json字符串\n        let json = JSON.stringify(user);\n        console.log(json);\n        //json字符串转json对象\n        let jsObject = JSON.parse(json)\n        console.log(jsObject)\n\n    </script>\n</head>\n<body>\n    <h2>Json测试</h2>\n</body>\n</html>\n```\n\n3、在IDEA中使用浏览器打开，查看控制台输出！\n\n> Controller返回JSON数据\n\nJackson应该是目前比较好的json解析工具了\n\n当然工具不止这一个，比如还有阿里巴巴的 fastjson 等等。\n\n我们这里使用Jackson，使用它需要导入它的jar包；\n\n```xml\n<!-- https://mvnrepository.com/artifact/com.fasterxml.jackson.core/jackson-core -->\n<!--Json解析器：jackson-->\n<dependency>\n    <groupId>com.fasterxml.jackson.core</groupId>\n    <artifactId>jackson-databind</artifactId>\n    <version>2.10.0</version>\n</dependency>\n<!--偷懒专用：自动生成构造函数set get方法-->\n<dependency>\n    <groupId>org.projectlombok</groupId>\n    <artifactId>lombok</artifactId>\n    <version>1.18.16</version>\n</dependency>\n```\n\n配置SpringMVC需要的配置\n\n+ web.xml：所有项目通用\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\n<web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\"\n         version=\"4.0\">\n\n  <!--注册DispatchServlet-->\n  <servlet>\n    <servlet-name>springmvc</servlet-name>\n    <servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class>\n    <!--通过初始化参数指定SpringMVC配置文件的位置，进行关联-->\n    <init-param>\n      <param-name>contextConfigLocation</param-name>\n      <param-value>classpath:springmvc-servlet.xml</param-value>\n    </init-param>\n    <!-- 启动顺序，数字越小，启动越早 -->\n    <load-on-startup>1</load-on-startup>\n  </servlet>\n  <servlet-mapping>\n    <servlet-name>springmvc</servlet-name>\n    <url-pattern>/</url-pattern>\n  </servlet-mapping>\n\n  <!--注册过滤器-->\n  <filter>\n    <filter-name>encoding</filter-name>\n    <filter-class>org.springframework.web.filter.CharacterEncodingFilter</filter-class>\n    <init-param>\n      <param-name>encoding</param-name>\n      <param-value>utf-8</param-value>\n    </init-param>\n  </filter>\n  <filter-mapping>\n    <filter-name>encoding</filter-name>\n    <url-pattern>/*</url-pattern>\n  </filter-mapping>\n\n</web-app>\n```\n\n\n\n+ springmvc-servlet.xml：所有项目通用\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xmlns:mvc=\"http://www.springframework.org/schema/mvc\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       http://www.springframework.org/schema/beans/spring-beans.xsd\n       http://www.springframework.org/schema/context\n       https://www.springframework.org/schema/context/spring-context.xsd\n       http://www.springframework.org/schema/mvc\n       https://www.springframework.org/schema/mvc/spring-mvc.xsd\">\n\n    <!--自动装配扫描地址-->\n    <context:component-scan base-package=\"com.ahulearn.controller\"/>\n    <!-- 静态资源过滤 -->\n    <mvc:default-servlet-handler />\n    <!-- 开启mvc注解驱动 -->\n    <mvc:annotation-driven />\n\n    <!-- 视图解析器 : 模板引擎 ThymeLeaf Freemarker ... -->\n    <bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"\n          id=\"internalResourceViewResolver\">\n        <!-- 前缀 -->\n        <property name=\"prefix\" value=\"/WEB-INF/jsp/\" />\n        <!-- 后缀 -->\n        <property name=\"suffix\" value=\".jsp\" />\n    </bean>\n    \n</beans>\n```\n\n\n\n我们随便编写一个User的实体类，然后我们去编写我们的测试Controller；\n\n```java\npackage com.ahulearn.pojo;\n\nimport lombok.AllArgsConstructor;\nimport lombok.Data;\nimport lombok.NoArgsConstructor;\n\n@Data\n@AllArgsConstructor\n@NoArgsConstructor\npublic class User {\n    String name;\n    int age;\n    String sex;\n}\n```\n\n这里我们需要两个新东西，一个是`@ResponseBody`，一个是`ObjectMapper`对象，我们看下具体的用法\n\n简单测试：\n\n```java\npackage com.ahulearn.controller;\n\nimport com.ahulearn.pojo.User;\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.ResponseBody;\n\n@Controller\npublic class UserController {\n    //该注解让Controller中的方法不走视图解析器\n    // 直接返回字符串到客户端\n    @ResponseBody\n    @RequestMapping(\"json1\")\n    public String json1() {\n        User user = new User(\"神火\", 12, \"男\");\n        return user.toString();\n    }\n}\n```\n\n\n\n### 6.1 Jackson\n\n正式编写一个Controller；\n\n```java\npackage com.ahulearn.controller;\n\nimport com.ahulearn.pojo.User;\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.ResponseBody;\n\n@Controller\npublic class UserController {\n    //该注解让Controller中的方法不走视图解析器\n    // 直接返回字符串到客户端\n    @ResponseBody\n    @RequestMapping(\"json1\")\n    public String json1() throws JsonProcessingException {\n        //创建一个jackson的对象映射器，用来解析数据\n        ObjectMapper mapper = new ObjectMapper();\n        //创建一个对象\n        User user = new User(\"神火\", 12, \"男\");\n        //将对象解析成为json格式，该方法会抛出一个异常\n        String str = mapper.writeValueAsString(user);\n        //直接返回字符串\n        return str;\n    }\n}\n```\n\n配置Tomcat ， 启动测试一下！\n\nhttp://localhost:8080/05/json1\n\n\n\n乱码解决：出现了乱码问题，我们需要设置一下他的编码格式为utf-8，以及它返回的类型；\n\n通过@RequestMaping的produces属性来实现，修改下代码\n\n```java\n@Controller\npublic class UserController {\n    //该注解让Controller中的方法不走视图解析器\n    // 直接返回字符串到客户端\n    @ResponseBody\n    //produces:指定响应体返回类型和编码\n    @RequestMapping(value = \"/json1\", produces = \"application/json;charset=utf-8\")\n    public String json1() throws JsonProcessingException {\n        //创建一个jackson的对象映射器，用来解析数据\n        ObjectMapper mapper = new ObjectMapper();\n        //创建一个对象\n        User user = new User(\"神火\", 12, \"男\");\n        //将对象解析成为json格式，该方法会抛出一个异常\n        String str = mapper.writeValueAsString(user);\n        return str;\n    }\n}\n```\n\n再次测试， http://localhost:8080/05/json1 ， 乱码问题OK！\n\n【注意：使用json记得处理乱码问题】\n\n\n\n> 代码优化\n\n**乱码统一解决**\n\n上一种方法比较麻烦，如果项目中有许多请求则每一个都要添加，可以通过Spring配置统一指定，这样就不用每次都去处理了！\n\n我们可以在springmvc的配置文件上添加一段消息StringHttpMessageConverter转换配置！\n\n```xml\n<!-- 开启mvc注解驱动, 解决JSON乱码问题 -->\n<mvc:annotation-driven>\n    <mvc:message-converters register-defaults=\"true\">\n        <bean class=\"org.springframework.http.converter.StringHttpMessageConverter\">\n            <constructor-arg value=\"UTF-8\"/>\n        </bean>\n        <bean class=\"org.springframework.http.converter.json.MappingJackson2HttpMessageConverter\">\n            <property name=\"objectMapper\">\n                <bean class=\"org.springframework.http.converter.json.Jackson2ObjectMapperFactoryBean\">\n                    <property name=\"failOnEmptyBeans\" value=\"false\"/>\n                </bean>\n            </property>\n        </bean>\n    </mvc:message-converters>\n</mvc:annotation-driven>\n```\n\n\n\n**直接返回json字符串，设置成不经过视图解析器的统一解决**\n\n类上的**@Controller** 注解改为 **@RestController** ，这样，类中的所有的方法都只会返回字符串，不用再每一个方法都添加@ResponseBody ！我们在前后端分离开发中，一般都使用 @RestController ，十分便捷！\n\n```java\n@RestController\npublic class UserController {\n\n   //produces:指定响应体返回类型和编码\n   @RequestMapping(value = \"/json1\")\n   public String json1() throws JsonProcessingException {\n       //创建一个jackson的对象映射器，用来解析数据\n       ObjectMapper mapper = new ObjectMapper();\n       //创建一个对象\n       User user = new User(\"秦疆1号\", 3, \"男\");\n       //将我们的对象解析成为json格式\n       String str = mapper.writeValueAsString(user);\n       //由于@ResponseBody注解，这里会将str转成json格式返回；十分方便\n       return str;\n  }\n}\n```\n\n启动tomcat测试，结果都正常输出！\n\n\n\n+ 测试集合或数组的JSON格式\n\n增加一个新的方法\n\n```java\n@ResponseBody\n@RequestMapping(\"/json2\")\npublic String json2() throws JsonProcessingException {\n\n   //创建一个jackson的对象映射器，用来解析数据\n   ObjectMapper mapper = new ObjectMapper();\n   //创建一个对象\n   User user1 = new User(\"秦疆1号\", 3, \"男\");\n   User user2 = new User(\"秦疆2号\", 3, \"男\");\n   User user3 = new User(\"秦疆3号\", 3, \"男\");\n   User user4 = new User(\"秦疆4号\", 3, \"男\");\n   List<User> list = new ArrayList<User>();\n   list.add(user1);\n   list.add(user2);\n   list.add(user3);\n   list.add(user4);\n\n   //将我们的对象解析成为json格式\n   String str = mapper.writeValueAsString(list);\n   return str;\n}\n```\n\n运行结果 : 十分完美，没有任何问题！\n\n\n\n+ 输出时间对象\n\n增加一个新的方法\n\n```java\n@ResponseBody\n@RequestMapping(\"/json3\")\npublic String json3() throws JsonProcessingException {\n\n   ObjectMapper mapper = new ObjectMapper();\n\n   //创建时间一个对象，java.util.Date\n   Date date = new Date();\n   //将我们的对象解析成为json格式\n   String str = mapper.writeValueAsString(date);\n   return str;\n}\n```\n\n- 默认日期格式会变成一个数字，是1970年1月1日到当前日期的毫秒数！\n- Jackson 默认是会把时间解析为timestamps形式\n\n\n\n**解决方案：取消timestamps形式 ， 自定义时间格式**\n\n```java\n//使用jackson自定义时间格式，正常应该使用java基础包处理时间格式\n@ResponseBody\n@RequestMapping(\"/json4\")\npublic String json4() throws JsonProcessingException {\n\n    ObjectMapper mapper = new ObjectMapper();\n\n    //不使用时间戳的格式，因为下方设置了格式，因此不需要再用该方法\n    //mapper.configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false);\n    //自定义日期格式对象\n    SimpleDateFormat sdf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n    //指定日期格式\n    //mapper.setDateFormat(sdf);\n    \n    Date date = new Date();\n    String str = mapper.writeValueAsString(sdf.format(date));\n\n    return str;\n}\n```\n\n运行结果 : 成功的输出了时间！\n\n\n\n> 抽取为工具类\n\n**如果要经常使用的话，这样是比较麻烦的，我们可以将这些代码封装到一个工具类中；我们去编写下**\n\n```java\npackage com.ahulearn.utils;\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport com.fasterxml.jackson.databind.ObjectMapper;\n\nimport java.text.SimpleDateFormat;\n\npublic class JsonUtils {\n\t//根据参数重载方法\n    public static String getJson(Object object) {\n        return getJson(object, \"yyyy-MM-dd HH:mm:ss\");\n    }\n\n    public static String getJson(Object object, String dateFormat) {\n        ObjectMapper mapper = new ObjectMapper();\n        //自定义日期格式对象\n        SimpleDateFormat sdf = new SimpleDateFormat(dateFormat);\n        //指定日期格式\n        mapper.setDateFormat(sdf);\n        try {\n            return mapper.writeValueAsString(object);\n        } catch (JsonProcessingException e) {\n            e.printStackTrace();\n        }\n        return null;\n    }\n}\n```\n\n我们使用工具类，代码就更加简洁了！\n\n```java\n//使用自己的封装的方法输出数据\n@ResponseBody\n@RequestMapping(\"/json5\")\npublic String json5() throws JsonProcessingException {\n    Date date = new Date();\n    String json = JsonUtils.getJson(date);\n    return json;\n}\n```\n\n\n\n+ JSON字符串转java对象\n\n\n\n### 6.2 FastJson\n\nfastjson.jar是阿里开发的一款专门用于Java开发的包，可以方便的实现json对象与JavaBean对象的转换，实现JavaBean对象与json字符串的转换，实现json对象与json字符串的转换。实现json的转换方法很多，最后的实现结果都是一样的。\n\nfastjson 的 pom.xml依赖！\n\n```xml\n<!--Json解析器：fastjson-->\n<dependency>\n    <groupId>com.alibaba</groupId>\n    <artifactId>fastjson</artifactId>\n    <version>1.2.60</version>\n</dependency>\n```\n\nfastjson 三个主要的类：\n\n**JSONObject  代表 json 对象** \n\n- JSONObject实现了Map接口, 猜想 JSONObject底层操作是由Map实现的。\n- JSONObject对应json对象，通过各种形式的get()方法可以获取json对象中的数据，也可利用诸如size()，isEmpty()等方法获取\"键：值\"对的个数和判断是否为空。其本质是通过实现Map接口并调用接口中的方法完成的。\n\n**JSONArray  代表 json 对象数组**\n\n- 内部是有List接口中的方法来完成操作的。\n\n**JSON代表 JSONObject和JSONArray的转化**\n\n- JSON类源码分析与使用\n- 仔细观察这些方法，主要是实现json对象，json对象数组，javabean对象，json字符串之间的相互转化。\n\n\n\n**代码测试，我们新建一个FastJsonDemo 类**\n\n```java\npackage com.ahulearn.controller;\n\nimport com.alibaba.fastjson.JSON;\nimport com.alibaba.fastjson.JSONObject;\nimport com.ahulearn.pojo.User;\n\nimport java.util.ArrayList;\nimport java.util.List;\n\npublic class FastJsonController {\n\n    public static void main(String[] args) {\n        //创建一个对象\n        User user1 = new User(\"神火1号\", 3, \"男\");\n        User user2 = new User(\"神火2号\", 3, \"男\");\n        User user3 = new User(\"神火3号\", 3, \"男\");\n        User user4 = new User(\"神火4号\", 3, \"男\");\n        List<User> list = new ArrayList<User>();\n        list.add(user1);\n        list.add(user2);\n        list.add(user3);\n        list.add(user4);\n\n        System.out.println(\"*******Java对象 转 JSON字符串*******\");\n        String str1 = JSON.toJSONString(list);\n        System.out.println(\"JSON.toJSONString(list)==>\"+str1);\n        String str2 = JSON.toJSONString(user1);\n        System.out.println(\"JSON.toJSONString(user1)==>\"+str2);\n\n        System.out.println(\"\\n****** JSON字符串 转 Java对象*******\");\n        User jp_user1=JSON.parseObject(str2,User.class);\n        System.out.println(\"JSON.parseObject(str2,User.class)==>\"+jp_user1);\n\n        //java 对象是属性和值，json对象是map结构：键和值\n        System.out.println(\"\\n****** Java对象 转 JSON对象 ******\");\n        JSONObject jsonObject1 = (JSONObject) JSON.toJSON(user2);\n        System.out.println(\"(JSONObject) JSON.toJSON(user2)==>\"+jsonObject1.getString(\"name\"));\n\n        System.out.println(\"\\n****** JSON对象 转 Java对象 ******\");\n        User to_java_user = JSON.toJavaObject(jsonObject1, User.class);\n        System.out.println(\"JSON.toJavaObject(jsonObject1, User.class)==>\"+to_java_user);\n    }\n}\n```\n\n这种工具类，我们只需要掌握使用就好了，在使用的时候在根据具体的业务去找对应的实现。和以前的commons-io那种工具包一样，拿来用就好了！\n\n\n\n## 7. ssm整合\n\n简单项目流程：需求分析-》设计数据库-》业务-》前端界面\n\n> 环境要求\n\n环境：\n\n- IDEA\n- MySQL 5.7.19\n- Tomcat 9\n- Maven 3.6\n\n 要求：\n\n- 需要熟练掌握MySQL数据库，Spring，JavaWeb及MyBatis知识，简单的前端知识；\n\n\n\n> 数据库环境\n\n创建一个存放书籍数据的数据库表\n\n```sql\nCREATE DATABASE `ssmbuild`;\n\nUSE `ssmbuild`;\n\nDROP TABLE IF EXISTS `books`;\n\nCREATE TABLE `books` (\n`bookID` INT(10) NOT NULL AUTO_INCREMENT COMMENT '书id',\n`bookName` VARCHAR(100) NOT NULL COMMENT '书名',\n`bookCounts` INT(11) NOT NULL COMMENT '数量',\n`detail` VARCHAR(200) NOT NULL COMMENT '描述',\nKEY `bookID` (`bookID`)\n) ENGINE=INNODB DEFAULT CHARSET=utf8\n\nINSERT  INTO `books`(`bookID`,`bookName`,`bookCounts`,`detail`)VALUES\n(1,'Java',1,'从入门到放弃'),\n(2,'MySQL',10,'从删库到跑路'),\n(3,'Linux',5,'从进门到进牢');\n```\n\n\n\n### 项目基本环境搭建\n\n1、新建一Maven项目！ssmbuild ， 添加web的支持\n\n2、导入相关的pom.xml依赖！\n\n```xml\n<dependencies>\n    <!--Junit-->\n    <dependency>\n      <groupId>junit</groupId>\n      <artifactId>junit</artifactId>\n      <version>4.12</version>\n    </dependency>\n    <!--自动构造方法 get set方法-->\n    <dependency>\n      <groupId>org.projectlombok</groupId>\n      <artifactId>lombok</artifactId>\n      <version>1.18.16</version>\n    </dependency>\n    <!--数据库驱动-->\n    <dependency>\n      <groupId>mysql</groupId>\n      <artifactId>mysql-connector-java</artifactId>\n      <version>5.1.45</version>\n    </dependency>\n    <!-- 数据库连接池 -->\n    <dependency>\n      <groupId>com.mchange</groupId>\n      <artifactId>c3p0</artifactId>\n      <version>0.9.5.5</version>\n    </dependency>\n\n    <!--Servlet - JSP -->\n    <dependency>\n      <groupId>javax.servlet</groupId>\n      <artifactId>servlet-api</artifactId>\n      <version>2.5</version>\n    </dependency>\n    <dependency>\n      <groupId>javax.servlet.jsp</groupId>\n      <artifactId>jsp-api</artifactId>\n      <version>2.2</version>\n    </dependency>\n    <dependency>\n      <groupId>javax.servlet</groupId>\n      <artifactId>jstl</artifactId>\n      <version>1.2</version>\n    </dependency>\n\n    <!--Mybatis-->\n    <dependency>\n      <groupId>org.mybatis</groupId>\n      <artifactId>mybatis</artifactId>\n      <version>3.5.6</version>\n    </dependency>\n    <dependency>\n      <groupId>org.mybatis</groupId>\n      <artifactId>mybatis-spring</artifactId>\n      <version>2.0.5</version>\n    </dependency>\n\n    <!--Spring-->\n    <dependency>\n      <groupId>org.springframework</groupId>\n      <artifactId>spring-webmvc</artifactId>\n      <version>5.2.10.RELEASE</version>\n    </dependency>\n    <dependency>\n      <groupId>org.springframework</groupId>\n      <artifactId>spring-jdbc</artifactId>\n      <version>5.2.10.RELEASE</version>\n    </dependency>\n  </dependencies>\n```\n\n3、Maven资源过滤设置\n\n```xml\n<build>\n   <resources>\n       <resource>\n           <directory>src/main/java</directory>\n           <includes>\n               <include>**/*.properties</include>\n               <include>**/*.xml</include>\n           </includes>\n           <filtering>false</filtering>\n       </resource>\n       <resource>\n           <directory>src/main/resources</directory>\n           <includes>\n               <include>**/*.properties</include>\n               <include>**/*.xml</include>\n           </includes>\n           <filtering>false</filtering>\n       </resource>\n   </resources>\n</build>\n```\n\n4、建立基本结构和配置框架！\n\n- com.example.pojo\n\n- com.example.dao\n\n- com.example.service\n\n- com.example.controller\n\n- mybatis-config.xml\n\n  ```xml\n  <?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n  <!DOCTYPE configuration\n         PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\"\n         \"http://mybatis.org/dtd/mybatis-3-config.dtd\">\n  <configuration>\n  \n  </configuration>\n  ```\n\n- applicationContext.xml\n\n  ```xml\n  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n  <beans xmlns=\"http://www.springframework.org/schema/beans\"\n        xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n        xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n         http://www.springframework.org/schema/beans/spring-beans.xsd\">\n  \n  </beans>\n  ```\n\n\n\n### 整合Mybatis编写\n\n1、数据库配置文件 **database.properties**\n\n```java\njdbc.driver=com.mysql.jdbc.Driver\njdbc.url=jdbc:mysql://localhost:3306/ssmbuild?useSSL=true&useUnicode=true&characterEncoding=utf8&serverTimezone=UTC\njdbc.username=root\njdbc.password=123456\n```\n\n2、IDEA关联数据库\n\n3、编写MyBatis的核心配置文件\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<!DOCTYPE configuration\n       PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\"\n       \"http://mybatis.org/dtd/mybatis-3-config.dtd\">\n<configuration>\n    \n    <typeAliases>\n        <package name=\"com.ahulearn.pojo\"/>\n    </typeAliases>\n    <mappers>\n        <mapper resource=\"com/ahulearn/dao/BookMapper.xml\"/>\n    </mappers>\n    \n</configuration>\n```\n\n4、编写数据库对应的实体类 com.kuang.pojo.Books\n\n使用lombok插件！\n\n```java\npackage com.ahulearn.pojo;\n\nimport lombok.AllArgsConstructor;\nimport lombok.Data;\nimport lombok.NoArgsConstructor;\n\n@Data\n@AllArgsConstructor\n@NoArgsConstructor\npublic class Book {\n    private int bookID;\n    private String bookName;\n    private int bookCounts;\n    private String detail;\n}\n```\n\n5、编写Dao层的 Mapper接口！\n\n```java\npackage com.kuang.dao;\n\nimport com.kuang.pojo.Books;\nimport java.util.List;\n\npublic interface BookMapper {\n\n   //增加一个Book\n   int addBook(Books book);\n\n   //根据id删除一个Book\n   int deleteBookById(int id);\n\n   //更新Book\n   int updateBook(Books books);\n\n   //根据id查询,返回一个Book\n   Books queryBookById(int id);\n\n   //查询全部Book,返回list集合\n   List<Books> queryAllBook();\n\n}\n```\n\n6、编写接口对应的 Mapper.xml 文件。需要导入MyBatis的包；\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<!DOCTYPE mapper\n        PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"\n        \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\">\n\n<mapper namespace=\"com.ahulearn.dao.BookMapper\">\n\n    <!--增加一个Book-->\n    <insert id=\"addBook\" parameterType=\"Books\">\n      insert into ssmbuild.books(bookName,bookCounts,detail)\n      values (#{bookName}, #{bookCounts}, #{detail})\n   </insert>\n\n    <!--根据id删除一个Book-->\n    <delete id=\"deleteBookById\" parameterType=\"int\">\n      delete from ssmbuild.books where bookID=#{bookID}\n   </delete>\n\n    <!--更新Book-->\n    <update id=\"updateBook\" parameterType=\"Books\">\n      update ssmbuild.books\n      set bookName = #{bookName},bookCounts = #{bookCounts},detail = #{detail}\n      where bookID = #{bookID}\n   </update>\n\n    <!--根据id查询,返回一个Book-->\n    <select id=\"queryBookById\" resultType=\"Books\">\n      select * from ssmbuild.books\n      where bookID = #{bookID}\n   </select>\n\n    <!--查询全部Book-->\n    <select id=\"queryAllBook\" resultType=\"Books\">\n      SELECT * from ssmbuild.books\n   </select>\n\n</mapper>\n```\n\n7、编写Service层的接口和实现类\n\n接口：\n\n```java\npackage com.ahulearn.service;\n\nimport com.ahulearn.pojo.Books;\n\nimport java.util.List;\n\npublic interface BookService {\n    //增加一个Book\n    int addBook(Books book);\n    //根据id删除一个Book\n    int deleteBookById(int id);\n    //更新Book\n    int updateBook(Books books);\n    //根据id查询,返回一个Book\n    Books queryBookById(int id);\n    //查询全部Book,返回list集合\n    List<Books> queryAllBook();\n}\n```\n\n实现类：\n\n```java\npackage com.ahulearn.service;\n\nimport com.ahulearn.dao.BookMapper;\nimport com.ahulearn.pojo.Books;\n\nimport java.util.List;\n\npublic class BookServiceImpl implements BookService {\n    //调用dao层的操作，设置一个set接口，方便Spring管理\n    private BookMapper bookMapper;\n\n    //Spring会使用Mapper.xml中的配置实现BookMapper接口并实例化，然后自动装配\n    public void setBookMapper(BookMapper bookMapper) {\n        this.bookMapper = bookMapper;\n    }\n\n    public int addBook(Books book) {\n        return bookMapper.addBook(book);\n    }\n\n    public int deleteBookById(int id) {\n        return bookMapper.deleteBookById(id);\n    }\n\n    public int updateBook(Books books) {\n        return bookMapper.updateBook(books);\n    }\n\n    public Books queryBookById(int id) {\n        return bookMapper.queryBookById(id);\n    }\n\n    public List<Books> queryAllBook() {\n        return bookMapper.queryAllBook();\n    }\n}\n```\n\n**OK，到此，底层需求操作编写完毕！**\n\n\n\n### Spring层\n\n1、配置**Spring整合MyBatis**，我们这里数据源使用c3p0连接池；\n\n2、我们去编写Spring整合Mybatis的相关的配置文件；spring-dao.xml\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd\">\n    <!--1. 关联数据库配置-->\n    <context:component-scan base-package=\"com.ahulearn.service\" />\n    <!--2. 连接池配置\n        dbcp: 半自动化操作，不能自动连接\n        c3p0：自动化操作（自动化的加载配置文件，并且可以自动设置到对象中）\n        druid：企业使用\n        hikari：企业使用\n    -->\n    <bean id=\"dataSource\" class=\"com.mchange.v2.c3p0.ComboPooledDataSource\">\n        <!-- 配置连接池属性，由于下方配置了扫描Dao接口，此处${}可能取不出配置文件的配置 -->\n        <property name=\"driverClass\" value=\"${jdbc.driver}\"/>\n        <property name=\"jdbcUrl\" value=\"${jdbc.url}\"/>\n        <property name=\"user\" value=\"${jdbc.username}\"/>\n        <property name=\"password\" value=\"${jdbc.password}\"/>\n\n        <!-- c3p0连接池的私有属性 -->\n        <property name=\"maxPoolSize\" value=\"30\"/>\n        <property name=\"minPoolSize\" value=\"10\"/>\n        <!-- 关闭连接后不自动commit -->\n        <property name=\"autoCommitOnClose\" value=\"false\"/>\n        <!-- 获取连接超时时间 -->\n        <property name=\"checkoutTimeout\" value=\"10000\"/>\n        <!-- 当获取连接失败重试次数 -->\n        <property name=\"acquireRetryAttempts\" value=\"2\"/>\n    </bean>\n    \n    <!-- 3.配置SqlSessionFactory对象 -->\n    <bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\">\n        <!-- 注入数据库连接池 -->\n        <property name=\"dataSource\" ref=\"dataSource\"/>\n        <!-- 配置MyBaties全局配置文件:mybatis-config.xml -->\n        <property name=\"configLocation\" value=\"classpath:mybatis-config.xml\"/>\n    </bean>\n\n    <!-- 4.配置扫描Dao接口包，动态实现Dao接口注入到spring容器中 -->\n    <!--解释 ：https://www.cnblogs.com/jpfss/p/7799806.html-->\n    <bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\">\n        <!-- 注入sqlSessionFactory -->\n        <property name=\"sqlSessionFactoryBeanName\" value=\"sqlSessionFactory\"/>\n        <!-- 给出需要扫描Dao接口包 -->\n        <property name=\"basePackage\" value=\"com.kuang.dao\"/>\n    </bean>\n\n</beans>\n```\n\n\n\n3、**Spring整合service层**\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n   http://www.springframework.org/schema/beans/spring-beans.xsd\n   http://www.springframework.org/schema/context\n   http://www.springframework.org/schema/context/spring-context.xsd\">\n\n    <!-- 1. 扫描service相关的bean -->\n    <context:component-scan base-package=\"com.ahulearn.service\" />\n\n    <!--2. BookServiceImpl注入到IOC容器中-->\n    <bean id=\"BookServiceImpl\" class=\"com.ahulearn.service.BookServiceImpl\">\n        <!--spring-dao中的扫描，实例化了bookMapper对象-->\n        <property name=\"bookMapper\" ref=\"bookMapper\"/>\n    </bean>\n\n    <!--3. 配置声明式事务管理器-->\n    <bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\">\n        <!-- 注入数据库连接池 -->\n        <property name=\"dataSource\" ref=\"dataSource\" />\n    </bean>\n\n    <!--4. aop 事务织入-->\n\n</beans>\n```\n\nSpring层搞定！再次理解一下，Spring就是一个大杂烩，一个容器！对吧！\n\n\n\n### SpringMVC层\n\n1、**web.xml**\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\"\n         version=\"4.0\">\n  <display-name>Ahulearn</display-name>\n\n  <!--DispatcherServlet-->\n  <servlet>\n    <servlet-name>DispatcherServlet</servlet-name>\n    <servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class>\n    <init-param>\n      <param-name>contextConfigLocation</param-name>\n      <!--一定要注意:我们这里加载的是总的配置文件，之前被这里坑了！-->\n      <param-value>classpath:applicationContext.xml</param-value>\n    </init-param>\n    <load-on-startup>1</load-on-startup>\n  </servlet>\n  <servlet-mapping>\n    <servlet-name>DispatcherServlet</servlet-name>\n    <url-pattern>/</url-pattern>\n  </servlet-mapping>\n\n  <!--encodingFilter-->\n  <filter>\n    <filter-name>encodingFilter</filter-name>\n    <filter-class>\n      org.springframework.web.filter.CharacterEncodingFilter\n    </filter-class>\n    <init-param>\n      <param-name>encoding</param-name>\n      <param-value>utf-8</param-value>\n    </init-param>\n  </filter>\n  <filter-mapping>\n    <filter-name>encodingFilter</filter-name>\n    <url-pattern>/*</url-pattern>\n  </filter-mapping>\n\n  <!--Session过期时间，单位分钟-->\n  <session-config>\n    <session-timeout>15</session-timeout>\n  </session-config>\n\n</web-app>\n```\n\n2、**spring-mvc.xml**\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n      xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n      xmlns:context=\"http://www.springframework.org/schema/context\"\n      xmlns:mvc=\"http://www.springframework.org/schema/mvc\"\n      xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n   http://www.springframework.org/schema/beans/spring-beans.xsd\n   http://www.springframework.org/schema/context\n   http://www.springframework.org/schema/context/spring-context.xsd\n   http://www.springframework.org/schema/mvc\n   https://www.springframework.org/schema/mvc/spring-mvc.xsd\">\n\n   <!-- 配置SpringMVC -->\n   <!-- 1.开启SpringMVC注解驱动 -->\n   <mvc:annotation-driven />\n   <!-- 2.静态资源默认servlet配置-->\n   <mvc:default-servlet-handler/>\n\n   <!-- 3.配置jsp 显示ViewResolver视图解析器 -->\n   <bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\">\n       <property name=\"viewClass\" value=\"org.springframework.web.servlet.view.JstlView\" />\n       <property name=\"prefix\" value=\"/WEB-INF/jsp/\" />\n       <property name=\"suffix\" value=\".jsp\" />\n   </bean>\n\n   <!-- 4.扫描web相关的bean -->\n   <context:component-scan base-package=\"com.kuang.controller\" />\n\n</beans>\n```\n\n3、**Spring配置整合文件，applicationContext.xml**\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n      xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n      xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       http://www.springframework.org/schema/beans/spring-beans.xsd\">\n\n   <import resource=\"spring-dao.xml\"/>\n   <import resource=\"spring-service.xml\"/>\n   <import resource=\"spring-mvc.xml\"/>\n   \n</beans>\n```\n\n**配置文件，暂时结束！Controller 和 视图层编写**\n\n\n\n### 增删改查\n\n1、BookController 类编写 ， 方法一：查询全部书籍\n\n```java\n@Controller\n@RequestMapping(\"/book\")\npublic class BookController {\n\n   @Autowired\n   @Qualifier(\"BookServiceImpl\")\n   private BookService bookService;\n\n   @RequestMapping(\"/allBook\")\n   public String list(Model model) {\n       List<Books> list = bookService.queryAllBook();\n       model.addAttribute(\"list\", list);\n       return \"allBook\";\n  }\n}\n```\n\n2、编写首页 **index.jsp**\n\n```jsp\n<%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\" pageEncoding=\"UTF-8\" %>\n<!DOCTYPE HTML>\n<html>\n<head>\n   <title>首页</title>\n   <style type=\"text/css\">\n       a {\n           text-decoration: none;\n           color: black;\n           font-size: 18px;\n      }\n       h3 {\n           width: 180px;\n           height: 38px;\n           margin: 100px auto;\n           text-align: center;\n           line-height: 38px;\n           background: deepskyblue;\n           border-radius: 4px;\n      }\n   </style>\n</head>\n<body>\n\n<h3>\n   <a href=\"${pageContext.request.contextPath}/book/allBook\">点击进入列表页</a>\n</h3>\n</body>\n</html>\n```\n\n3、书籍列表页面 **allbook.jsp**\n\n```jsp\n<%@ taglib prefix=\"c\" uri=\"http://java.sun.com/jsp/jstl/core\" %>\n<%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %>\n<html>\n<head>\n   <title>书籍列表</title>\n   <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n   <!-- 引入 Bootstrap -->\n   <link href=\"https://cdn.bootcss.com/bootstrap/3.3.7/css/bootstrap.min.css\" rel=\"stylesheet\">\n</head>\n<body>\n\n<div class=\"container\">\n\n   <div class=\"row clearfix\">\n       <div class=\"col-md-12 column\">\n           <div class=\"page-header\">\n               <h1>\n                   <small>书籍列表 —— 显示所有书籍</small>\n               </h1>\n           </div>\n       </div>\n   </div>\n\n   <div class=\"row\">\n       <div class=\"col-md-4 column\">\n           <a class=\"btn btn-primary\" href=\"${pageContext.request.contextPath}/book/toAddBook\">新增</a>\n       </div>\n   </div>\n\n   <div class=\"row clearfix\">\n       <div class=\"col-md-12 column\">\n           <table class=\"table table-hover table-striped\">\n               <thead>\n               <tr>\n                   <th>书籍编号</th>\n                   <th>书籍名字</th>\n                   <th>书籍数量</th>\n                   <th>书籍详情</th>\n                   <th>操作</th>\n               </tr>\n               </thead>\n\n               <tbody>\n               <c:forEach var=\"book\" items=\"${requestScope.get('list')}\">\n                   <tr>\n                       <td>${book.getBookID()}</td>\n                       <td>${book.getBookName()}</td>\n                       <td>${book.getBookCounts()}</td>\n                       <td>${book.getDetail()}</td>\n                       <td>\n                           <a href=\"${pageContext.request.contextPath}/book/toUpdateBook?id=${book.getBookID()}\">更改</a> |\n                           <a href=\"${pageContext.request.contextPath}/book/del/${book.getBookID()}\">删除</a>\n                       </td>\n                   </tr>\n               </c:forEach>\n               </tbody>\n           </table>\n       </div>\n   </div>\n</div>\n```\n\n4、BookController 类编写 ， 方法二：添加书籍\n\n```java\n@RequestMapping(\"/toAddBook\")\npublic String toAddPaper() {\n   return \"addBook\";\n}\n\n@RequestMapping(\"/addBook\")\npublic String addPaper(Books books) {\n   System.out.println(books);\n   bookService.addBook(books);\n   return \"redirect:/book/allBook\";\n}\n```\n\n5、添加书籍页面：**addBook.jsp**\n\n```jsp\n<%@ taglib prefix=\"c\" uri=\"http://java.sun.com/jsp/jstl/core\" %>\n<%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %>\n\n<html>\n<head>\n   <title>新增书籍</title>\n   <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n   <!-- 引入 Bootstrap -->\n   <link href=\"https://cdn.bootcss.com/bootstrap/3.3.7/css/bootstrap.min.css\" rel=\"stylesheet\">\n</head>\n<body>\n<div class=\"container\">\n\n   <div class=\"row clearfix\">\n       <div class=\"col-md-12 column\">\n           <div class=\"page-header\">\n               <h1>\n                   <small>新增书籍</small>\n               </h1>\n           </div>\n       </div>\n   </div>\n   <form action=\"${pageContext.request.contextPath}/book/addBook\" method=\"post\">\n      书籍名称：<input type=\"text\" name=\"bookName\"><br><br><br>\n      书籍数量：<input type=\"text\" name=\"bookCounts\"><br><br><br>\n      书籍详情：<input type=\"text\" name=\"detail\"><br><br><br>\n       <input type=\"submit\" value=\"添加\">\n   </form>\n\n</div>\n```\n\n6、BookController 类编写 ， 方法三：修改书籍\n\n```java\n@RequestMapping(\"/toUpdateBook\")\npublic String toUpdateBook(Model model, int id) {\n   Books books = bookService.queryBookById(id);\n   System.out.println(books);\n   model.addAttribute(\"book\",books );\n   return \"updateBook\";\n}\n\n@RequestMapping(\"/updateBook\")\npublic String updateBook(Model model, Books book) {\n   System.out.println(book);\n   bookService.updateBook(book);\n   Books books = bookService.queryBookById(book.getBookID());\n   model.addAttribute(\"books\", books);\n   return \"redirect:/book/allBook\";\n}\n```\n\n7、修改书籍页面  **updateBook.jsp**\n\n```jsp\n<%@ taglib prefix=\"c\" uri=\"http://java.sun.com/jsp/jstl/core\" %>\n<%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %>\n<html>\n<head>\n   <title>修改信息</title>\n   <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n   <!-- 引入 Bootstrap -->\n   <link href=\"https://cdn.bootcss.com/bootstrap/3.3.7/css/bootstrap.min.css\" rel=\"stylesheet\">\n</head>\n<body>\n<div class=\"container\">\n\n   <div class=\"row clearfix\">\n       <div class=\"col-md-12 column\">\n           <div class=\"page-header\">\n               <h1>\n                   <small>修改信息</small>\n               </h1>\n           </div>\n       </div>\n   </div>\n\n   <form action=\"${pageContext.request.contextPath}/book/updateBook\" method=\"post\">\n       <input type=\"hidden\" name=\"bookID\" value=\"${book.getBookID()}\"/>\n      书籍名称：<input type=\"text\" name=\"bookName\" value=\"${book.getBookName()}\"/>\n      书籍数量：<input type=\"text\" name=\"bookCounts\" value=\"${book.getBookCounts()}\"/>\n      书籍详情：<input type=\"text\" name=\"detail\" value=\"${book.getDetail() }\"/>\n       <input type=\"submit\" value=\"提交\"/>\n   </form>\n\n</div>\n```\n\n8、BookController 类编写 ， 方法四：删除书籍\n\n```java\n@RequestMapping(\"/del/{bookId}\")\npublic String deleteBook(@PathVariable(\"bookId\") int id) {\n   bookService.deleteBookById(id);\n   return \"redirect:/book/allBook\";\n}\n```\n\n**配置Tomcat，进行运行！**\n\n到目前为止，这个SSM项目整合已经完全的OK了，可以直接运行进行测试！这个练习十分的重要，大家需要保证，不看任何东西，自己也可以完整的实现出来！\n\n\n\n事务管理：\n\n添加依赖\n\n```xml\n<!--aop织入包-->\n<dependency>\n    <groupId>org.aspectj</groupId>\n    <artifactId>aspectjweaver</artifactId>\n    <version>1.9.4</version>\n</dependency>\n```\n\n编写配置spring-sevice.xml\n\n头文件：\n\n```xml\nxmlns:aop=\"http://www.springframework.org/schema/aop\"\nxmlns:tx=\"http://www.springframework.org/schema/tx\"\nxsi:schemaLocation=\"http://www.springframework.org/schema/aop\n   http://www.springframework.org/schema/aop/spring-aop.xsd\n   http://www.springframework.org/schema/tx\n   http://www.springframework.org/schema/tx/spring-tx.xsd\"\n```\n\n\n\n切入\n\n```xml\n<!--4. aop 事务织入-->\n<!--配置事务通知-->\n<tx:advice id=\"txAdvice\" transaction-manager=\"transactionManager\">\n    <tx:attributes>\n        <!--配置哪些方法使用什么样的事务,配置事务的传播特性-->\n        <tx:method name=\"*\" propagation=\"REQUIRED\"/>\n    </tx:attributes>\n</tx:advice>\n<!--配置aop织入事务-->\n<aop:config>\n    <aop:pointcut id=\"txPointcut\" expression=\"execution(* com.ahulearn.dao.*.*(..))\"/>\n    <aop:advisor advice-ref=\"txAdvice\" pointcut-ref=\"txPointcut\"/>\n</aop:config>\n```\n\n\n\n\n\n## 8.Ajax研究\n\n\n\n### 1、简介\n\n- **AJAX = Asynchronous JavaScript and XML（异步的 JavaScript 和 XML）。**\n- AJAX 是一种在无需重新加载整个网页的情况下，能够更新部分网页的技术。\n- **Ajax 不是一种新的编程语言，而是一种用于创建更好更快以及交互性更强的Web应用程序的技术。**\n- 在 2005 年，Google 通过其 Google Suggest 使 AJAX 变得流行起来。Google Suggest能够自动帮你完成搜索单词。\n- Google Suggest 使用 AJAX 创造出动态性极强的 web 界面：当您在谷歌的搜索框输入关键字时，JavaScript 会把这些字符发送到服务器，然后服务器会返回一个搜索建议的列表。\n- 就和国内百度的搜索框一样!\n\n- 传统的网页(即不用ajax技术的网页)，想要更新内容或者提交一个表单，都需要重新加载整个网页。\n- 使用ajax技术的网页，通过在后台服务器进行少量的数据交换，就可以实现异步局部更新。\n- 使用Ajax，用户可以创建接近本地桌面应用的直接、高可用、更丰富、更动态的Web用户界面。\n\n\n\n### 2、伪造Ajax\n\n我们可以使用前端的一个标签来伪造一个ajax的样子。iframe标签\n\n1、新建一个module ：sspringmvc-06-ajax ， 导入web支持！\n\n2、编写一个 ajax-frame.html 使用 iframe 测试，感受下效果\n\n```jsp\n<!DOCTYPE html>\n<html>\n<head lang=\"en\">\n   <meta charset=\"UTF-8\">\n   <title>kuangshen</title>\n</head>\n<body>\n\n<script type=\"text/javascript\">\n   window.onload = function(){\n       var myDate = new Date();\n       document.getElementById('currentTime').innerText = myDate.getTime();\n  };\n\n   function LoadPage(){\n       var targetUrl =  document.getElementById('url').value;\n       console.log(targetUrl);\n       document.getElementById(\"iframePosition\").src = targetUrl;\n  }\n\n</script>\n\n<div>\n   <p>请输入要加载的地址：<span id=\"currentTime\"></span></p>\n   <p>\n       <input id=\"url\" type=\"text\" value=\"https://www.baidu.com/\"/>\n       <input type=\"button\" value=\"提交\" onclick=\"LoadPage()\">\n   </p>\n</div>\n\n<div>\n   <h3>加载页面位置：</h3>\n   <iframe id=\"iframePosition\" style=\"width: 100%;height: 500px;\"></iframe>\n</div>\n\n</body>\n</html>\n```\n\n3、使用IDEA开浏览器测试一下！\n\n**利用AJAX可以做：**\n\n- 注册时，输入用户名自动检测用户是否已经存在。\n- 登陆时，提示用户名密码错误\n- 删除数据行时，将行ID发送到后台，后台在数据库中删除，数据库删除成功后，在页面DOM中将数据行也删除。\n- ....等等\n\n\n\n### 3、jQuery.ajax\n\n纯JS原生实现Ajax我们不去讲解这里，直接使用jquery提供的，方便学习和使用，避免重复造轮子，有兴趣的同学可以去了解下JS原生XMLHttpRequest ！\n\nAjax的核心是XMLHttpRequest对象(XHR)。XHR为向服务器发送请求和解析服务器响应提供了接口。能够以异步方式从服务器获取新数据。\n\njQuery 提供多个与 AJAX 有关的方法。\n\n通过 jQuery AJAX 方法，您能够使用 HTTP Get 和 HTTP Post 从远程服务器上请求文本、HTML、XML 或 JSON – 同时您能够把这些外部数据直接载入网页的被选元素中。\n\njQuery 不是生产者，而是大自然搬运工。\n\njQuery Ajax本质就是 XMLHttpRequest，对他进行了封装，方便调用！\n\n```js\njQuery.ajax(...)\n      部分参数：\n            url：请求地址\n            type：请求方式，GET、POST（1.9.0之后用method）\n        headers：请求头\n            data：要发送的数据\n    contentType：即将发送信息至服务器的内容编码类型(默认: \"application/x-www-form-urlencoded; charset=UTF-8\")\n          async：是否异步\n        timeout：设置请求超时时间（毫秒）\n      beforeSend：发送请求前执行的函数(全局)\n        complete：完成之后执行的回调函数(全局)\n        success：成功之后执行的回调函数(全局)\n          error：失败之后执行的回调函数(全局)\n        accepts：通过请求头发送给服务器，告诉服务器当前客户端可接受的数据类型\n        dataType：将服务器端返回的数据转换成指定类型\n          \"xml\": 将服务器端返回的内容转换成xml格式\n          \"text\": 将服务器端返回的内容转换成普通文本格式\n          \"html\": 将服务器端返回的内容转换成普通文本格式，在插入DOM中时，如果包含JavaScript标签，则会尝试去执行。\n        \"script\": 尝试将返回值当作JavaScript去执行，然后再将服务器端返回的内容转换成普通文本格式\n          \"json\": 将服务器端返回的内容转换成相应的JavaScript对象\n        \"jsonp\": JSONP 格式使用 JSONP 形式调用函数时，如 \"myurl?callback=?\" jQuery 将自动替换 ? 为正确的函数名，以执行回调函数\n```\n\n**我们来个简单的测试，使用最原始的HttpServletResponse处理 , .最简单 , 最通用**\n\n1、配置web.xml 和 springmvc的配置文件，复制上面案例的即可 【记得静态资源过滤和注解驱动配置上】\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n      xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n      xmlns:context=\"http://www.springframework.org/schema/context\"\n      xmlns:mvc=\"http://www.springframework.org/schema/mvc\"\n      xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       http://www.springframework.org/schema/beans/spring-beans.xsd\n       http://www.springframework.org/schema/context\n       https://www.springframework.org/schema/context/spring-context.xsd\n       http://www.springframework.org/schema/mvc\n       https://www.springframework.org/schema/mvc/spring-mvc.xsd\">\n\n   <!-- 自动扫描指定的包，下面所有注解类交给IOC容器管理 -->\n   <context:component-scan base-package=\"com.kuang.controller\"/>\n   <!--静态资源过滤，js-->\n   <mvc:default-servlet-handler />\n   <mvc:annotation-driven />\n\n   <!-- 视图解析器 -->\n   <bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"\n         id=\"internalResourceViewResolver\">\n       <!-- 前缀 -->\n       <property name=\"prefix\" value=\"/WEB-INF/jsp/\" />\n       <!-- 后缀 -->\n       <property name=\"suffix\" value=\".jsp\" />\n   </bean>\n\n</beans>\n```\n\n2、编写一个AjaxController\n\n```java\n@Controller\npublic class AjaxController {\n\n   @RequestMapping(\"/a1\")\n   public void ajax1(String name , HttpServletResponse response) throws IOException {\n       if (\"admin\".equals(name)){\n           response.getWriter().print(\"true\");\n      }else{\n           response.getWriter().print(\"false\");\n      }\n  }\n\n}\n```\n\n3、导入jquery ， 可以使用在线的CDN ， 也可以下载导入\n\n```html\n<script src=\"https://code.jquery.com/jquery-3.1.1.min.js\"></script>\n<script src=\"${pageContext.request.contextPath}/statics/js/jquery-3.1.1.min.js\"></script>\n```\n\n4、编写index.jsp测试\n\n```jsp\n<%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %>\n<html>\n <head>\n   <title>$Title$</title>\n  <%--<script src=\"https://code.jquery.com/jquery-3.1.1.min.js\"></script>--%>\n   <script src=\"${pageContext.request.contextPath}/statics/js/jquery-3.1.1.min.js\"></script>\n   <script>\n       function a1(){\n           $.post({\n               url:\"${pageContext.request.contextPath}/a1\",\n               data:{'name':$(\"#txtName\").val()},\n               success:function(data,status) {\n                   alert(data);\n                   alert(status);\n              }\n          });\n      }\n   </script>\n </head>\n <body>\n\n<%--onblur：失去焦点触发事件--%>\n用户名:<input type=\"text\" id=\"txtName\" onblur=\"a1()\"/>\n\n </body>\n</html>\n```\n\n5、启动tomcat测试！打开浏览器的控制台，当我们鼠标离开输入框的时候，可以看到发出了一个ajax的请求！是后台返回给我们的结果！测试成功！\n\n \n\n### 4、**Springmvc实现**\n\n实体类user\n\n```java\n@Data\n@AllArgsConstructor\n@NoArgsConstructor\npublic class User {\n\n   private String name;\n   private int age;\n   private String sex;\n\n}\n```\n\n我们来获取一个集合对象，展示到前端页面\n\n```java\n@RequestMapping(\"/a2\")\npublic List<User> ajax2(){\n   List<User> list = new ArrayList<User>();\n   list.add(new User(\"秦疆1号\",3,\"男\"));\n   list.add(new User(\"秦疆2号\",3,\"男\"));\n   list.add(new User(\"秦疆3号\",3,\"男\"));\n   return list; //由于@RestController注解，将list转成json格式返回\n}\n```\n\n前端页面\n\n```jsp\n<%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %>\n<html>\n<head>\n   <title>Title</title>\n</head>\n<body>\n<input type=\"button\" id=\"btn\" value=\"获取数据\"/>\n<table width=\"80%\" align=\"center\">\n   <tr>\n       <td>姓名</td>\n       <td>年龄</td>\n       <td>性别</td>\n   </tr>\n   <tbody id=\"content\">\n   </tbody>\n</table>\n\n<script src=\"${pageContext.request.contextPath}/statics/js/jquery-3.1.1.min.js\"></script>\n<script>\n\n   $(function () {\n       $(\"#btn\").click(function () {\n           $.post(\"${pageContext.request.contextPath}/a2\",function (data) {\n               console.log(data)\n               var html=\"\";\n               for (var i = 0; i <data.length ; i++) {\n                   html+= \"<tr>\" +\n                       \"<td>\" + data[i].name + \"</td>\" +\n                       \"<td>\" + data[i].age + \"</td>\" +\n                       \"<td>\" + data[i].sex + \"</td>\" +\n                       \"</tr>\"\n              }\n               $(\"#content\").html(html);\n          });\n      })\n  })\n</script>\n</body>\n</html>\n```\n\n**成功实现了数据回显！可以体会一下Ajax的好处！**\n\n\n\n### 5、注册提示效果\n\n我们再测试一个小Demo，思考一下我们平时注册时候，输入框后面的实时提示怎么做到的；如何优化\n\n我们写一个Controller\n\n```java\n@RequestMapping(\"/a3\")\npublic String ajax3(String name,String pwd){\n   String msg = \"\";\n   //模拟数据库中存在数据\n   if (name!=null){\n       if (\"admin\".equals(name)){\n           msg = \"OK\";\n      }else {\n           msg = \"用户名输入错误\";\n      }\n  }\n   if (pwd!=null){\n       if (\"123456\".equals(pwd)){\n           msg = \"OK\";\n      }else {\n           msg = \"密码输入有误\";\n      }\n  }\n   return msg; //由于@RestController注解，将msg转成json格式返回\n}\n```\n\n前端页面 login.jsp\n\n```jsp\n<%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %>\n<html>\n<head>\n   <title>ajax</title>\n   <script src=\"${pageContext.request.contextPath}/statics/js/jquery-3.1.1.min.js\"></script>\n   <script>\n\n       function a1(){\n           $.post({\n               url:\"${pageContext.request.contextPath}/a3\",\n               data:{'name':$(\"#name\").val()},\n               success:function (data) {\n                   if (data.toString()=='OK'){\n                       $(\"#userInfo\").css(\"color\",\"green\");\n                  }else {\n                       $(\"#userInfo\").css(\"color\",\"red\");\n                  }\n                   $(\"#userInfo\").html(data);\n              }\n          });\n      }\n       function a2(){\n           $.post({\n               url:\"${pageContext.request.contextPath}/a3\",\n               data:{'pwd':$(\"#pwd\").val()},\n               success:function (data) {\n                   if (data.toString()=='OK'){\n                       $(\"#pwdInfo\").css(\"color\",\"green\");\n                  }else {\n                       $(\"#pwdInfo\").css(\"color\",\"red\");\n                  }\n                   $(\"#pwdInfo\").html(data);\n              }\n          });\n      }\n\n   </script>\n</head>\n<body>\n<p>\n  用户名:<input type=\"text\" id=\"name\" onblur=\"a1()\"/>\n   <span id=\"userInfo\"></span>\n</p>\n<p>\n  密码:<input type=\"text\" id=\"pwd\" onblur=\"a2()\"/>\n   <span id=\"pwdInfo\"></span>\n</p>\n</body>\n</html>\n```\n\n【记得处理json乱码问题】\n\n测试一下效果，动态请求响应，局部刷新，就是如此！\n\n\n\n### 6、获取baidu接口Demo\n\n```html\n<!DOCTYPE HTML>\n<html>\n<head>\n   <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n   <title>JSONP百度搜索</title>\n   <style>\n       #q{\n           width: 500px;\n           height: 30px;\n           border:1px solid #ddd;\n           line-height: 30px;\n           display: block;\n           margin: 0 auto;\n           padding: 0 10px;\n           font-size: 14px;\n      }\n       #ul{\n           width: 520px;\n           list-style: none;\n           margin: 0 auto;\n           padding: 0;\n           border:1px solid #ddd;\n           margin-top: -1px;\n           display: none;\n      }\n       #ul li{\n           line-height: 30px;\n           padding: 0 10px;\n      }\n       #ul li:hover{\n           background-color: #f60;\n           color: #fff;\n      }\n   </style>\n   <script>\n\n       // 2.步骤二\n       // 定义demo函数 (分析接口、数据)\n       function demo(data){\n           var Ul = document.getElementById('ul');\n           var html = '';\n           // 如果搜索数据存在 把内容添加进去\n           if (data.s.length) {\n               // 隐藏掉的ul显示出来\n               Ul.style.display = 'block';\n               // 搜索到的数据循环追加到li里\n               for(var i = 0;i<data.s.length;i++){\n                   html += '<li>'+data.s[i]+'</li>';\n              }\n               // 循环的li写入ul\n               Ul.innerHTML = html;\n          }\n      }\n\n       // 1.步骤一\n       window.onload = function(){\n           // 获取输入框和ul\n           var Q = document.getElementById('q');\n           var Ul = document.getElementById('ul');\n\n           // 事件鼠标抬起时候\n           Q.onkeyup = function(){\n               // 如果输入框不等于空\n               if (this.value != '') {\n                   // ☆☆☆☆☆☆☆☆☆☆☆☆☆☆☆☆☆☆JSONPz重点☆☆☆☆☆☆☆☆☆☆☆☆☆☆☆☆☆☆☆☆\n                   // 创建标签\n                   var script = document.createElement('script');\n                   //给定要跨域的地址 赋值给src\n                   //这里是要请求的跨域的地址 我写的是百度搜索的跨域地址\n                   script.src = 'https://sp0.baidu.com/5a1Fazu8AA54nxGko9WTAnF6hhy/su?wd='+this.value+'&cb=demo';\n                   // 将组合好的带src的script标签追加到body里\n                   document.body.appendChild(script);\n              }\n          }\n      }\n   </script>\n</head>\n\n<body>\n<input type=\"text\" id=\"q\" />\n<ul id=\"ul\">\n\n</ul>\n</body>\n</html>\n```\n\n\n\n\n\n\n\n## 8.拦截器\n\n### 1. 概述\n\nSpringMVC的处理器拦截器类似于Servlet开发中的过滤器Filter,用于对处理器进行预处理和后处理。开发者可以自己定义一些拦截器来实现特定的功能。\n\n**过滤器与拦截器的区别：**拦截器是AOP思想的具体应用。\n\n**过滤器**\n\n- servlet规范中的一部分，任何java web工程都可以使用\n- 在url-pattern中配置了/*之后，可以对所有要访问的资源进行拦截\n\n**拦截器** \n\n- 拦截器是SpringMVC框架自己的，只有使用了SpringMVC框架的工程才能使用\n- 拦截器只会拦截访问的控制器方法， 如果访问的是jsp/html/css/image/js是不会进行拦截的\n\n\n\n### 2、自定义拦截器\n\n那如何实现拦截器呢？\n\n想要自定义拦截器，必须实现 HandlerInterceptor 接口。\n\n1、新建一个Moudule ， springmvc-07-Interceptor  ， 添加web支持\n\n2、配置web.xml 和 springmvc-servlet.xml 文件\n\n3、编写一个拦截器\n\n```java\npackage com.kuang.interceptor;\n\nimport org.springframework.web.servlet.HandlerInterceptor;\nimport org.springframework.web.servlet.ModelAndView;\n\nimport javax.servlet.http.HttpServletRequest;\nimport javax.servlet.http.HttpServletResponse;\n\npublic class MyInterceptor implements HandlerInterceptor {\n\n   //在请求处理的方法之前执行\n   //如果返回true执行下一个拦截器\n   //如果返回false就不执行下一个拦截器\n   public boolean preHandle(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o) throws Exception {\n       System.out.println(\"------------处理前------------\");\n       return true;\n  }\n\n   //在请求处理方法执行之后执行\n   public void postHandle(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o, ModelAndView modelAndView) throws Exception {\n       System.out.println(\"------------处理后------------\");\n  }\n\n   //在dispatcherServlet处理后执行,做清理工作.\n   public void afterCompletion(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o, Exception e) throws Exception {\n       System.out.println(\"------------清理------------\");\n  }\n}\n```\n\n4、在springmvc的配置文件中配置拦截器\n\n```xml\n<!--关于拦截器的配置-->\n<mvc:interceptors>\n   <mvc:interceptor>\n       <!--/** 包括路径及其子路径-->\n       <!--/admin/* 拦截的是/admin/add等等这种 , /admin/add/user不会被拦截-->\n       <!--/admin/** 拦截的是/admin/下的所有-->\n       <mvc:mapping path=\"/**\"/>\n       <!--bean配置的就是拦截器-->\n       <bean class=\"com.kuang.interceptor.MyInterceptor\"/>\n   </mvc:interceptor>\n</mvc:interceptors>\n```\n\n5、编写一个Controller，接收请求\n\n```java\npackage com.kuang.controller;\n\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.ResponseBody;\n\n//测试拦截器的控制器\n@Controller\npublic class InterceptorController {\n\n   @RequestMapping(\"/interceptor\")\n   @ResponseBody\n   public String testFunction() {\n       System.out.println(\"控制器中的方法执行了\");\n       return \"hello\";\n  }\n}\n```\n\n6、前端 index.jsp\n\n```jsp\n<a href=\"${pageContext.request.contextPath}/interceptor\">拦截器测试</a>\n```\n\n7、启动tomcat 测试一下！\n\n\n\n![图片](https://mmbiz.qpic.cn/mmbiz_png/uJDAUKrGC7KshicHhIPa51icXVueiaMfB0HtJH2NsHDlcibyEJuibgomZzDNpHiammcSRt2V87uPMYGC7h0gt5KS2Dcw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)\n\n### 3、验证用户是否登录 (认证用户)\n\n**实现思路**\n\n1、有一个登陆页面，需要写一个controller访问页面。\n\n2、登陆页面有一提交表单的动作。需要在controller中处理。判断用户名密码是否正确。如果正确，向session中写入用户信息。*返回登陆成功。*\n\n3、拦截用户请求，判断用户是否登陆。如果用户已经登陆。放行， 如果用户未登陆，跳转到登陆页面\n\n**测试：**\n\n1、编写一个登陆页面  login.jsp\n\n```jsp\n<%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %>\n<html>\n<head>\n   <title>Title</title>\n</head>\n\n<h1>登录页面</h1>\n<hr>\n\n<body>\n<form action=\"${pageContext.request.contextPath}/user/login\">\n  用户名：<input type=\"text\" name=\"username\"> <br>\n  密码：<input type=\"password\" name=\"pwd\"> <br>\n   <input type=\"submit\" value=\"提交\">\n</form>\n</body>\n</html>\n```\n\n2、编写一个Controller处理请求\n\n```java\npackage com.kuang.controller;\n\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.RequestMapping;\n\nimport javax.servlet.http.HttpSession;\n\n@Controller\n@RequestMapping(\"/user\")\npublic class UserController {\n\n   //跳转到登陆页面\n   @RequestMapping(\"/jumplogin\")\n   public String jumpLogin() throws Exception {\n       return \"login\";\n  }\n\n   //跳转到成功页面\n   @RequestMapping(\"/jumpSuccess\")\n   public String jumpSuccess() throws Exception {\n       return \"success\";\n  }\n\n   //登陆提交\n   @RequestMapping(\"/login\")\n   public String login(HttpSession session, String username, String pwd) throws Exception {\n       // 向session记录用户身份信息\n       System.out.println(\"接收前端===\"+username);\n       session.setAttribute(\"user\", username);\n       return \"success\";\n  }\n\n   //退出登陆\n   @RequestMapping(\"logout\")\n   public String logout(HttpSession session) throws Exception {\n       // session 过期\n       session.invalidate();\n       return \"login\";\n  }\n}\n```\n\n3、编写一个登陆成功的页面 success.jsp\n\n```jsp\n<%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %>\n<html>\n<head>\n   <title>Title</title>\n</head>\n<body>\n\n<h1>登录成功页面</h1>\n<hr>\n\n${user}\n<a href=\"${pageContext.request.contextPath}/user/logout\">注销</a>\n</body>\n</html>\n```\n\n4、在 index 页面上测试跳转！启动Tomcat 测试，未登录也可以进入主页！\n\n```jsp\n<%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %>\n<html>\n <head>\n   <title>$Title$</title>\n </head>\n <body>\n <h1>首页</h1>\n <hr>\n<%--登录--%>\n <a href=\"${pageContext.request.contextPath}/user/jumplogin\">登录</a>\n <a href=\"${pageContext.request.contextPath}/user/jumpSuccess\">成功页面</a>\n </body>\n</html>\n```\n\n5、编写用户登录拦截器\n\n```java\npackage com.kuang.interceptor;\n\nimport org.springframework.web.servlet.HandlerInterceptor;\nimport org.springframework.web.servlet.ModelAndView;\n\nimport javax.servlet.ServletException;\nimport javax.servlet.http.HttpServletRequest;\nimport javax.servlet.http.HttpServletResponse;\nimport javax.servlet.http.HttpSession;\nimport java.io.IOException;\n\npublic class LoginInterceptor implements HandlerInterceptor {\n\n   public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws ServletException, IOException {\n       // 如果是登陆页面则放行\n       System.out.println(\"uri: \" + request.getRequestURI());\n       if (request.getRequestURI().contains(\"login\")) {\n           return true;\n      }\n\n       HttpSession session = request.getSession();\n\n       // 如果用户已登陆也放行\n       if(session.getAttribute(\"user\") != null) {\n           return true;\n      }\n\n       // 用户没有登陆跳转到登陆页面\n       request.getRequestDispatcher(\"/WEB-INF/jsp/login.jsp\").forward(request, response);\n       return false;\n  }\n\n   public void postHandle(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o, ModelAndView modelAndView) throws Exception {\n\n  }\n   \n   public void afterCompletion(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o, Exception e) throws Exception {\n\n  }\n}\n```\n\n6、在Springmvc的配置文件中注册拦截器\n\n```xml\n<!--关于拦截器的配置-->\n<mvc:interceptors>\n   <mvc:interceptor>\n       <mvc:mapping path=\"/**\"/>\n       <bean id=\"loginInterceptor\" class=\"com.kuang.interceptor.LoginInterceptor\"/>\n   </mvc:interceptor>\n</mvc:interceptors>\n```\n\n7、再次重启Tomcat测试！\n\n**OK，测试登录拦截功能无误.**\n\n\n\n\n\n\n\n### 4、文件上传和下载\n\n> 准备工作\n\n文件上传是项目开发中最常见的功能之一 ,springMVC 可以很好的支持文件上传，但是SpringMVC上下文中默认没有装配MultipartResolver，因此默认情况下其不能处理文件上传工作。如果想使用Spring的文件上传功能，则需要在上下文中配置MultipartResolver。\n\n前端表单要求：为了能上传文件，必须将表单的method设置为POST，并将enctype设置为multipart/form-data。只有在这样的情况下，浏览器才会把用户选择的文件以二进制数据发送给服务器；\n\n**对表单中的 enctype 属性做个详细的说明：**\n\n- application/x-www=form-urlencoded：默认方式，只处理表单域中的 value 属性值，采用这种编码方式的表单会将表单域中的值处理成 URL 编码方式。\n- multipart/form-data：这种编码方式会以二进制流的方式来处理表单数据，这种编码方式会把文件域指定文件的内容也封装到请求参数中，不会对字符编码。\n- text/plain：除了把空格转换为 \"+\" 号外，其他字符都不做编码处理，这种方式适用直接通过表单发送邮件。\n\n```xml\n<form action=\"\" enctype=\"multipart/form-data\" method=\"post\">\n   <input type=\"file\" name=\"file\"/>\n   <input type=\"submit\">\n</form>\n```\n\n一旦设置了enctype为multipart/form-data，浏览器即会采用二进制流的方式来处理表单数据，而对于文件上传的处理则涉及在服务器端解析原始的HTTP响应。在2003年，Apache Software Foundation发布了开源的Commons FileUpload组件，其很快成为Servlet/JSP程序员上传文件的最佳选择。\n\n- Servlet3.0规范已经提供方法来处理文件上传，但这种上传需要在Servlet中完成。\n- 而Spring MVC则提供了更简单的封装。\n- Spring MVC为文件上传提供了直接的支持，这种支持是用即插即用的MultipartResolver实现的。\n- Spring MVC使用Apache Commons FileUpload技术实现了一个MultipartResolver实现类：\n- CommonsMultipartResolver。因此，SpringMVC的文件上传还需要依赖Apache Commons FileUpload的组件。\n\n\n\n> 文件上传\n\n1、导入文件上传的jar包，commons-fileupload ， Maven会自动帮我们导入他的依赖包 commons-io包；\n\n```xml\n<!--文件上传-->\n<dependency>\n   <groupId>commons-fileupload</groupId>\n   <artifactId>commons-fileupload</artifactId>\n   <version>1.3.3</version>\n</dependency>\n<!--servlet-api导入高版本的-->\n<dependency>\n   <groupId>javax.servlet</groupId>\n   <artifactId>javax.servlet-api</artifactId>\n   <version>4.0.1</version>\n</dependency>\n```\n\n2、配置bean：multipartResolver\n\n【**注意！！！这个bena的id必须为：multipartResolver ， 否则上传文件会报400的错误！在这里栽过坑,教训！**】\n\n```xml\n<!--文件上传配置-->\n<bean id=\"multipartResolver\"  class=\"org.springframework.web.multipart.commons.CommonsMultipartResolver\">\n   <!-- 请求的编码格式，必须和jSP的pageEncoding属性一致，以便正确读取表单的内容，默认为ISO-8859-1 -->\n   <property name=\"defaultEncoding\" value=\"utf-8\"/>\n   <!-- 上传文件大小上限，单位为字节（10485760=10M） -->\n   <property name=\"maxUploadSize\" value=\"10485760\"/>\n   <property name=\"maxInMemorySize\" value=\"40960\"/>\n</bean>\n```\n\nCommonsMultipartFile 的 常用方法：\n\n- **String getOriginalFilename()：获取上传文件的原名**\n- **InputStream getInputStream()：获取文件流**\n- **void transferTo(File dest)：将上传文件保存到一个目录文件中**\n\n 我们去实际测试一下\n\n3、编写前端页面\n\n```html\n<form action=\"/upload\" enctype=\"multipart/form-data\" method=\"post\">\n <input type=\"file\" name=\"file\"/>\n <input type=\"submit\" value=\"upload\">\n</form>\n```\n\n4、**Controller**\n\n```java\npackage com.kuang.controller;\n\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RequestParam;\nimport org.springframework.web.multipart.commons.CommonsMultipartFile;\n\nimport javax.servlet.http.HttpServletRequest;\nimport java.io.*;\n\n@Controller\npublic class FileController {\n   //@RequestParam(\"file\") 将name=file控件得到的文件封装成CommonsMultipartFile 对象\n   //批量上传CommonsMultipartFile则为数组即可\n   @RequestMapping(\"/upload\")\n   public String fileUpload(@RequestParam(\"file\") CommonsMultipartFile file , HttpServletRequest request) throws IOException {\n\n       //获取文件名 : file.getOriginalFilename();\n       String uploadFileName = file.getOriginalFilename();\n\n       //如果文件名为空，直接回到首页！\n       if (\"\".equals(uploadFileName)){\n           return \"redirect:/index.jsp\";\n      }\n       System.out.println(\"上传文件名 : \"+uploadFileName);\n\n       //上传路径保存设置\n       String path = request.getServletContext().getRealPath(\"/upload\");\n       //如果路径不存在，创建一个\n       File realPath = new File(path);\n       if (!realPath.exists()){\n           realPath.mkdir();\n      }\n       System.out.println(\"上传文件保存地址：\"+realPath);\n\n       InputStream is = file.getInputStream(); //文件输入流\n       OutputStream os = new FileOutputStream(new File(realPath,uploadFileName)); //文件输出流\n\n       //读取写出\n       int len=0;\n       byte[] buffer = new byte[1024];\n       while ((len=is.read(buffer))!=-1){\n           os.write(buffer,0,len);\n           os.flush();\n      }\n       os.close();\n       is.close();\n       return \"redirect:/index.jsp\";\n  }\n}\n```\n\n5、测试上传文件，OK！\n\n\n\n**采用file.Transto 来保存上传的文件**\n\n1、编写Controller\n\n```java\n/*\n* 采用file.Transto 来保存上传的文件\n*/\n@RequestMapping(\"/upload2\")\npublic String  fileUpload2(@RequestParam(\"file\") CommonsMultipartFile file, HttpServletRequest request) throws IOException {\n\n   //上传路径保存设置\n   String path = request.getServletContext().getRealPath(\"/upload\");\n   File realPath = new File(path);\n   if (!realPath.exists()){\n       realPath.mkdir();\n  }\n   //上传文件地址\n   System.out.println(\"上传文件保存地址：\"+realPath);\n\n   //通过CommonsMultipartFile的方法直接写文件（注意这个时候）\n   file.transferTo(new File(realPath +\"/\"+ file.getOriginalFilename()));\n\n   return \"redirect:/index.jsp\";\n}\n```\n\n2、前端表单提交地址修改\n\n3、访问提交测试，OK！\n\n\n\n> 文件下载\n\n**文件下载步骤：**\n\n1、设置 response 响应头\n\n2、读取文件 -- InputStream\n\n3、写出文件 -- OutputStream\n\n4、执行操作\n\n5、关闭流 （先开后关）\n\n**代码实现：**\n\n```java\n@RequestMapping(value=\"/download\")\npublic String downloads(HttpServletResponse response ,HttpServletRequest request) throws Exception{\n   //要下载的图片地址\n   String  path = request.getServletContext().getRealPath(\"/upload\");\n   String  fileName = \"基础语法.jpg\";\n\n   //1、设置response 响应头\n   response.reset(); //设置页面不缓存,清空buffer\n   response.setCharacterEncoding(\"UTF-8\"); //字符编码\n   response.setContentType(\"multipart/form-data\"); //二进制传输数据\n   //设置响应头\n   response.setHeader(\"Content-Disposition\",\n           \"attachment;fileName=\"+URLEncoder.encode(fileName, \"UTF-8\"));\n\n   File file = new File(path,fileName);\n   //2、 读取文件--输入流\n   InputStream input=new FileInputStream(file);\n   //3、 写出文件--输出流\n   OutputStream out = response.getOutputStream();\n\n   byte[] buff =new byte[1024];\n   int index=0;\n   //4、执行 写出操作\n   while((index= input.read(buff))!= -1){\n       out.write(buff, 0, index);\n       out.flush();\n  }\n   out.close();\n   input.close();\n   return null;\n}\n```\n\n前端\n\n```\n<a href=\"/download\">点击下载</a>\n```\n\n测试，文件下载OK，大家可以和我们之前学习的JavaWeb原生的方式对比一下，就可以知道这个便捷多了!","comments":true,"categories":[],"tags":[{"name":"CS","slug":"CS","permalink":"http://blog.ahulearn.com/tags/CS/"},{"name":"JAVA","slug":"JAVA","permalink":"http://blog.ahulearn.com/tags/JAVA/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://blog.ahulearn.com/tags/SpringMVC/"}]},{"title":"Mybatis","date":"2023-06-07T10:00:00.000Z","path":"2023/06/07/Mybatis/","raw":"---\ntitle: Mybatis\ndate: 2023-06-07 18:00:00\ntags:\n - CS\n - Mybatis\n - JAVA\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\\java\\mybatis\n---\n\n**环境：**\n\n+ JDK1.8\n\n+ Mysql 5.7\n\n+ maven 3.6.1\n\n+ IDEA\n\n**回顾：**\n\n+ JDBC\n\n+ Mysql\n\n+ Java基础\n\n+ Maven\n\n+ Junit：单元测试\n\n\n\n## 1. 简介\n\n### 1.1 什么是Mybatis\n\nMyBatis 是一款优秀的持久层框架，它支持自定义 SQL、存储过程以及高级映射。MyBatis 免除了几乎所有的 JDBC 代码以及设置参数和获取结果集的工作。MyBatis 可以通过简单的 **XML** 或注解来配置和映射原始类型、接口和 Java POJO（Plain Old Java Objects，普通老式 Java 对象）为数据库中的记录。\n\n框架：配置文件最好直接看官网\n\nMyBatis官方文档：https://mybatis.org/mybatis-3/zh/index.html\n\nGitHub主页：https://github.com/mybatis/mybatis-3\n\nMaven地址：https://mvnrepository.com/artifact/org.mybatis/mybatis\n\n```xml\n<!-- https://mvnrepository.com/artifact/org.mybatis/mybatis -->\n<dependency>\n    <groupId>org.mybatis</groupId>\n    <artifactId>mybatis</artifactId>\n    <version>3.5.6</version>\n</dependency>\n```\n\n\n\n<!--more-->\n\n\n\n### 1.2 持久化\n\n数据持久化\n\n+ 持久化就是将程序的数据在持久状态和顺势状态转化的过程\n+ 内存：断电即失\n+ 数据库(JDBC)，文件IO持久化\n\n为什么需要持久化\n\n+ 有一些对象，不能让他丢掉\n+ 内存价格昂贵\n\n\n\n### 1.3 持久层\n\nDao层(data access object)：数据访问层、Service层、Controller层...\n\n+ 完成持久化工作的代码块\n+ 界限十分明显\n\n\n\n### 1.4 为什么需要Mybatis\n\n+ 帮助程序员将数据存入数据库\n\n+ 传统的JDBC代码太复杂。方便、简化框架、自动化\n\n+ 不用Mybatis也可以，但是Mybatis更容易上手。**技术没有高低之分**\n\n+ 优点：\n\n  + 简单易学：本身就很小且简单。没有任何第三方依赖，最简单安装只要两个jar文件+配置几个sql映射文件易于学习，易于使用，通过文档和源代码，可以比较完全的掌握它的设计思路和实现。\n  + 灵活：mybatis不会对应用程序或者数据库的现有设计强加任何影响。 sql写在xml里，便于统一管理和优化。通过sql语句可以满足操作数据库的所有需求。\n  + 解除sql与程序代码的耦合：通过提供DAO层，将业务逻辑和数据访问逻辑分离，使系统的设计更清晰，更易维护，更易单元测试。sql和代码的分离，提高了可维护性。\n  + 提供映射标签，支持对象与数据库的orm字段关系映射\n  + 提供对象关系映射标签，支持对象关系组建维护\n  + 提供xml标签，支持编写动态sql\n\n  **最重要的一点：使用的人多**\n\n\n\n## 2. 第一个Mybatis程序\n\n思路：搭建环境-》导入Mybatis包-》编写代码-》测试\n\n\n\n### 2.1 搭建环境\n\n创建数据库环境\n\n```mysql\ncreate database mybatis;\nuse mybatis;\n\ncreate table user (\n\tid int(20) not null,\n    name varchar(30) default null,\n    pwd varchar(30) default null\n)engine=innodb default charset=utf8;\n\ninsert into user(id, name, pwd) values\n(1, 'slz', '123456'),\n(2, '神火', '123456'),\n(3, '狂神', '123456');\n\ndelete from  user where id=1;\n```\n\n新建一个普通的maven项目\n\n1. 新建一个普通maven项目（父工程）\n2. 创建一个子模块\n\n添加依赖：\n\n```xml\n   <!-- https://mvnrepository.com/artifact/org.mybatis/mybatis -->\n    <dependency>\n      <groupId>org.mybatis</groupId>\n      <artifactId>mybatis</artifactId>\n      <version>3.5.6</version>\n    </dependency>\n    <!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java -->\n    <dependency>\n      <groupId>mysql</groupId>\n      <artifactId>mysql-connector-java</artifactId>\n      <version>8.0.16</version>\n    </dependency>\n```\n\n\n\n### 2.2 创建模块\n\n+ 在main/java/resources/下创建Mybatis配置文件\n\n```\n完整的JdbcUrl: \njdbc:mysql://localhost:3306/mybatis?useSSL=true&amp;useUnicode=true&amp;characterEncoding=UTF-8&amp;serverTimezone=UTC\n```\n\n\n\n[mybatis-config.xml]\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<!DOCTYPE configuration\n        PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\"\n        \"http://mybatis.org/dtd/mybatis-3-config.dtd\">\n\n<!--核心配置文件-->\n<configuration>\n    <environments default=\"development\">\n        <environment id=\"development\">\n            <transactionManager type=\"JDBC\"/>\n            <dataSource type=\"POOLED\">\n                <property name=\"driver\" value=\"com.mysql.cj.jdbc.Driver\"/>\n                <property name=\"url\" value=\"jdbc:mysql://localhost:3306/mybatis?serverTimezone=UTC\"/>\n                <property name=\"username\" value=\"root\"/>\n                <property name=\"password\" value=\"shenhuo\"/>\n            </dataSource>\n        </environment>\n    </environments>\n    <!--每一个Mpapper.xml都需要在Mybatis核心配置文件中注册！-->\n    <mappers>\n        <mapper resource=\"com/ahulearn/dao/UserMapper.xml\"/>\n    </mappers>\n</configuration>\n```\n\n+ 编写Mybatisg工具类\n\n```java\npublic class Mybatis {\n    //全局静态变量\n    private static SqlSessionFactory sqlSessionFactory;\n    static {\n        //从配置文件中获取SqlSessionFactory\n        String resource = \"mybatis-config.xml\";\n        try {\n            InputStream inputStream = Resources.getResourceAsStream(resource);\n            sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);\n        }catch(IOException e){\n            e.printStackTrace();\n        }\n    }\n    //使用SqlSessionFactory创建SqlSession实例\n    //SqlSesion包含了面向数据库执行SQL命令所需的所有方法\n    public static SqlSession getSqlSession(){\n        SqlSession sqlSession = sqlSessionFactory.openSession();\n        return sqlSsession;\n    }\n}\n```\n\n\n\n### 2.3 编写代码\n\n+ 实体类\n\n  ```java\n  package com.ahulearn.pojo;\n  \n  //实体类\n  public class User {\n      private int id;\n      private String name;\n      private String pwd;\n      public User() {\n      }\n  \n      public User(int id, String name, String pwd) {\n          this.id = id;\n          this.name = name;\n          this.pwd = pwd;\n      }\n  \n      public int getId() {\n          return id;\n      }\n  \n      public String getName() {\n          return name;\n      }\n  \n      public String getPwd() {\n          return pwd;\n      }\n  \n      public void setId(int id) {\n          this.id = id;\n      }\n  \n      public void setName(String name) {\n          this.name = name;\n      }\n  \n      public void setPwd(String pwd) {\n          this.pwd = pwd;\n      }\n  }\n  ```\n\n  \n\n+ Dao接口\n\n  ```java\n  public interface UserDao {\n      List<User> getUsers();\n  }\n  ```\n\n  \n\n+ 接口实现类：由原来的UserDaoImpl转变为一个Mapper.xml配置文件\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n        <!DOCTYPE mapper\n                PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"\n                \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\">\n<!--namespace绑定一个对应的Dao/Mapper接口-->\n<mapper namespace=\"com.ahulearn.dao.UserDao\">\n    <!--select查询语句\n        id: 接口中的方法\n        返回结果: 完全限定名，resultType，resultMap\n    -->\n    <select id=\"getUserList\" resultType=\"com.ahulearn.pojo.User\">\n        select * from mybatis.user where id = #{id}\n    </select>\n</mapper>\n```\n\n\n\n### 2.4 测试\n\n在test目录下创建和待测试文件一样的目录结构进行测试，test/java/com.ahulearn/dao\n\n+ 测试代码\n\n```java\npackage com.ahulearn.dao;\n\nimport com.ahulearn.pojo.User;\nimport com.ahulearn.utils.Mybatis;\nimport org.apache.ibatis.session.SqlSession;\nimport org.junit.Test;\n\nimport java.util.List;\n\npublic class UserDaoTest {\n    @Test\n    public void test() {\n        //获取SqlSession对象\n        SqlSession sqlSession = Mybatis.getSqlSession();\n        //执行SQL: 方式一, 面向接口编程，获取UserDao接口对象\n        UserDao userDao = sqlSession.getMapper(UserDao.class);\n        //调用接口方法\n        List<User> userList = userDao.getUserList();\n        for (User user : userList) {\n            System.out.println(user.toString());\n        }\n        //关闭SqlSession\n        sqlSession.close();\n    }\n}\n\n```\n\n\n\njava.lang.ExceptionInInitializerError\n\n​\tat com.ahulearn.dao.UserDaoTest.test(UserDaoTest.java:14)\n\nMapper.xml文件没用添加到mybatis主配置文件中，或者没有当作资源文件发布。\n\n\n\njava.lang.NullPointerException\n\n全局变量问题：\n\n```java\nprivate static SqlSessionFactory sqlSessionFactory;\nstatic {\n    //  获取SqlSessionFactory\n    String resource = \"mybatis-config.xml\";\n    try {\n        InputStream inputStream = Resources.getResourceAsStream(resource);\n        //注意此处使用全局变量，不能再用类声明。SqlSessionFactory sqlSessionFactory = ...形式\n        sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);\n    }catch(IOException e){\n        e.printStackTrace();\n    }\n}\n```\n\n\n\n错误\n\n```error\norg.apache.ibatis.exceptions.PersistenceException: \n### Error querying database.  Cause: java.sql.SQLException: Error setting driver on UnpooledDataSource. Cause: java.lang.ClassNotFoundException: Cannot find class: com.mysql.cj.jdbc.Driver\n### The error may exist in com/ahulearn/dao/Mapper.xml\n### The error may involve com.ahulearn.dao.UserMapper.selectById\n### The error occurred while executing a query\n### Cause: java.sql.SQLException: Error setting driver on UnpooledDataSource. \n```\n\n没有添加MySQL依赖，工厂返回NULL\n\n\n\n## 3. CRUD\n\n**1. namespace**\n\nnamespace中的包名要和Dao/Mapper中的接口的包名相同，绑定接口\n\n**2. select**\n\n选择，查询语句：\n\n+ id：namespace对应的接口中的方法名\n+ resultType：Sql语句执行的返回值! 该返回值类型在定义时要和表结构一致，即类属性要和表头一一对应。\n+ parameterType: 参数类型\n\n只需要改接口，接口映射、测试类\n\n\n\n代码\n\n```xml\n<mapper namespace=\"com.ahulearn.mapper.UserMapper\">\n    <!--select查询语句\n        id: 对应接口中的方法名\n        返回结果: 完整路径类名, resultType，resultMap\n    -->\n    <select id=\"selectUser\" resultType=\"user\">\n        select * from mybatis.user;\n    </select>\n    <insert id=\"addUser\" parameterType=\"user\">\n        insert into mybatis.user(id, name, pwd) values (#{id}, #{name}, #{pwd});\n    </insert>\n    <delete id=\"deleteUser\" parameterType=\"int\">\n        delete from mybatis.user where id=#{id};\n    </delete>\n    <update id=\"updateUser\" parameterType=\"user\">\n        update mybatis.user set id=#{id},name=#{name},pwd=#{pwd} where id=#{id};\n    </update>\n</mapper>\n```\n\n\n\n","comments":true,"categories":[],"tags":[{"name":"CS","slug":"CS","permalink":"http://blog.ahulearn.com/tags/CS/"},{"name":"JAVA","slug":"JAVA","permalink":"http://blog.ahulearn.com/tags/JAVA/"},{"name":"Mybatis","slug":"Mybatis","permalink":"http://blog.ahulearn.com/tags/Mybatis/"}]},{"title":"Spring","date":"2023-05-27T10:00:00.000Z","path":"2023/05/27/Spring/","raw":"---\ntitle: Spring\ndate: 2023-05-27 18:00:00\ntags:\n - CS\n - Spring\n - JAVA\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\\spring\n---\n\n\n\n## 1. Spring\n\n官网：https://spring.io/projects/spring-framework/\n\n文档：https://docs.spring.io/spring-framework/docs/current/reference/html/index.html\n\n**三大核心**：\n\n​\t控制反转（ioc）-----> Inversion of Control\n\n​\t依赖注入（di）---- >Dependency Injection\n\n​\t面向切面编程（AOP）---->Aspect Oriented Programming\n\n\n\n<!--more-->\n\n\n\n+ 测试依赖\n\n```xml\n   <dependency>\n      <groupId>junit</groupId>\n      <artifactId>junit</artifactId>\n      <version>4.11</version>\n      <scope>test</scope>\n    </dependency>\n```\n\n+ 测试代码写在/src/test/java目录下，最好包结构也和待测试代码一致。\n+ 测试代码中main函数可加但是**不需要**加测试注解，如果要测试其他函数则mian函数**不能**加测试注解\n\n```java\nimport com.ahulearn.pojo.People;\nimport com.ahulearn.pojo.ResourceTest;\nimport org.junit.Test;\nimport org.springframework.context.ApplicationContext;\nimport org.springframework.context.support.ClassPathXmlApplicationContext;\n\npublic class MyTest {\n    public static void main(String[] args) {\n        ApplicationContext context = new ClassPathXmlApplicationContext(\"beans3.xml\");\n        People people = context.getBean(\"people\", People.class);\n        people.getCat().shout();\n        people.getDog().shout();\n    }\n    @Test\n    public void testResource() {\n        ApplicationContext context = new ClassPathXmlApplicationContext(\"beans3.xml\");\n        ResourceTest resource = context.getBean(\"resource\", ResourceTest.class);\n        resource.getCat().shout();\n        resource.getDog().shout();\n    }\n}\n```\n\n\n\n## 2. IOC思想\n\n文档：https://docs.spring.io/spring-framework/docs/current/reference/html/core.html\n\n1. UserDao接口：面向接口编程\n2. UserDaoImpl实现类\n3. UserService业务接口：业务层，就是用来调用Dao层\n4. UserService也算实现类\n5. 用户测试类\n\n+ 工厂模式\n\n\n\n### 2.1 为什么需要IOC\n\n下方案例，如果用户获取用户的需求发生改变，则需要做\n\n+ 添加一个新的UserDao实现类\n+ 修改UserServiceI实现类的方法，调用新的的UserDao类\n\n这只是一个需求需要更改的情况，且项目本身很小。对于大项目需要修改的内容十分繁杂。如果项目代码需要每一次根据用户需求的改变或增加而大量修改代码显然是不合理的。\n\n\n\n\n\n+ UserDao接口\n\n```java\npackage com.ahulearn.dao;\n\npublic interface UserDao {\n    void getUsers();\n}\n```\n\n+ UserDaoImpl实现类\n\n```java\npackage com.ahulearn.dao;\n\npublic class UserDaoImpl implements UserDao {\n    @Override\n    public void getUsers() {\n        System.out.println(\"获取用户数据\");\n    }\n}\n```\n\n+ UserService业务接口\n\n```java\npackage com.ahulearn.service;\n\npublic interface UserService {\n    void getUsers();\n}\n```\n\n+ UserServiceImpl实现类\n\n```java\npackage com.ahulearn.service;\n\nimport com.ahulearn.dao.UserDao;\nimport com.ahulearn.dao.UserDaoImpl;\n\npublic class UserServiceImpl implements UserService {\n    //业务层调用dao层\n    private UserDao userDao = new UserDaoImpl();\n\n    @Override\n    public void getUsers() {\n        userDao.getUsers();\n    }\n}\n```\n\n+ 用户测试类\n\n```java\npackage com.ahulearn;\n\nimport com.ahulearn.service.UserService;\nimport com.ahulearn.service.UserServiceImpl;\n\npublic class MyTest {\n    public static void main(String[] args) {\n        //用户实际调用业务层, 不需要接触Dao层\n        UserService userService = new UserServiceImpl();\n        userService.getUsers();\n    }\n}\n```\n\n\n\n解决方法：利用set方法，实现动态的创建值的注入\n\n方法很简单，但思想很深刻\n\n+ UserServiceImpl实现类\n\n```java\npackage com.ahulearn.service;\n\nimport com.ahulearn.dao.UserDao;\n\npublic class UserServiceImpl implements UserService {\n    //业务层调用dao层\n    private UserDao userDao;\n\n    public void setUserDao(UserDao userDao) {\n        this.userDao = userDao;\n    }\n\n    @Override\n    public void getUsers() {\n        userDao.getUsers();\n    }\n}\n```\n\n+ 用户测试类: 利用泛型的思想，根据用户需求将不同的实现类传给service层，不需要对service层进行修改，只需要在业务层增加相应的实现即可。\n+ 存在一个问题就是，用户层需要接触dao层的具体实现类\n\n```java\npackage com.ahulearn;\n\nimport com.ahulearn.dao.UserDaoImpl;\nimport com.ahulearn.dao.UserDaoMysqlImpl;\nimport com.ahulearn.service.UserService;\nimport com.ahulearn.service.UserServiceImpl;\n\n\npublic class MyTest {\n    public static void main(String[] args) {\n        //用户实际调用业务层, 不需要接触Dao层\n        UserService userService = new UserServiceImpl();\n        ((UserServiceImpl)userService).setUserDao(new UserDaoImpl());\n        userService.getUsers();\n    }\n}\n```\n\n+ 之前，对象是程序主动创建的，控制权在程序员的手上。\n+ 使用set注入后，程序不再具有主动性，而是变成被动的接受对象！\n\n这种思想，从本质上解决问题，程序员不需要再去管理对象的创建。系统的耦合性降低，可以更加专注业务的实现上。\n\n这是IOC的原型，并不是真正的IOC。\n\n\n\n**IOC的本质**\n\n**控制反转**（Inversion of Control，缩写为**IoC**），是面向对象编中的一种设计原则，可以用来减低计算机代码之间的耦合度。其中最常见的方式叫做**依赖注入**（Dependency Injection，简称**DI**），还有一种方式叫“依赖查找”（Dependency Lookup）。通过控制反转，对象在被创建的时候，由一个调控系统内所有对象的外界实体将其所依赖的对象的引用传递给它。也可以说，依赖被注入到对象中。\n\n\n\n## 3. HelloSpring\n\n控制反转中初始化对象属性是依赖对象中的set方法实现的。\n\n+ 对象\n\n```java\npackage com.ahulearn.pojo;\n\npublic class Hello {\n    private String str;\n\n    @Override\n    public String toString() {\n        return \"Hello{\" +\n                \"str='\" + str + '\\'' +\n                '}';\n    }\n\n    public String getStr() {\n        return str;\n    }\n\n    public void setStr(String str) {\n        this.str = str;\n    }\n}\n```\n\n\n\n+ beans.xml\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\">\n    <!--使用Spring来创建对象，在Spring这些称为Bean\n    类型 变量名 = new 类型();\n    Hello hello = new Hello();\n    id = 变量名\n    class = new 的对象\n    property 相当于给对象中的属性设置一个值\n    -->\n    <bean id=\"hello\" class=\"com.ahulearn.pojo.Hello\">\n        <property name=\"str\" value=\"Spring\"/>\n    </bean>\n</beans>\n```\n\n\n\n+ 测试类\n\n```java\npackage com.ahulearn.pojo;\n\nimport org.springframework.context.ApplicationContext;\nimport org.springframework.context.support.ClassPathXmlApplicationContext;\n\npublic class MyTest {\n    public static void main(String[] args) {\n        //获取Spring的上下文对象\n        ApplicationContext context = new ClassPathXmlApplicationContext(\"beans.xml\");\n        //我们的对象现在都在Spring中管理，我们要使用，直接去里面取出来就可以！\n        Hello hello = (Hello) context.getBean(\"hello\");\n        System.out.println(hello);\n    }\n}\n\n```\n\n\n\n+ 重写IOC思想案例测试类\n\n```java\npackage com.ahulearn.pojo;\n\nimport com.ahulearn.service.UserServiceImpl;\nimport org.springframework.context.ApplicationContext;\nimport org.springframework.context.support.ClassPathXmlApplicationContext;\n\npublic class TestIoc {\n    public static void main(String[] args) {\n        //获取ApplicationContext：拿到Spring的容器\n        ApplicationContext context = new ClassPathXmlApplicationContext(\"beans.xml\");\n        UserServiceImpl userServiceImpl = (UserServiceImpl) context.getBean(\"userServiceImpl\");\n        userServiceImpl.getUsers();\n    }\n}\n```\n\nbeans.xml\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\">\n\n    <!--使用spring重写模块1中的内容-->\n    <bean id=\"userDaoImpl\" class=\"com.ahulearn.dao.UserDaoImpl\"/>\n    <bean id=\"mysqlImpl\" class=\"com.ahulearn.dao.UserDaoMysqlImpl\"/>\n    <bean id=\"sqlImpl\" class=\"com.ahulearn.dao.UserDaoSqlImpl\"/>\n    <bean id=\"userServiceImpl\" class=\"com.ahulearn.service.UserServiceImpl\">\n        <!--\n        ref: 引用Spring容器中创建好的对象\n        value: 具体的值，基本数据类型\n        -->\n        <property name=\"userDao\" ref=\"userDaoImpl\"/>\n    </bean>\n</beans>\n```\n\n注意：运行出错可能是代码没有重新编译\n\n此时修改实现只需要修改xml配置文件，配置文件可以通过配置选修修改。或者手动修改配置文件。但不需要修改代码了。用户和服务都不需要修改。\n\n\n\n## 4. IOC创建对象\n\n+ 依赖包\n\n```xml\n    <dependency>\n      <groupId>org.springframework</groupId>\n      <artifactId>spring-context</artifactId>\n      <version>5.2.10.RELEASE</version>\n      <scope>test</scope>\n    </dependency>\n```\n\n\n\nSpring在创建容器后，容器中注册管理的所有对象都被初始化了。\n\n1. 默认使用无参构造对象！\n\n2. 要使用有参构造创建对象\n\n   + 下标赋值\n\n   ```xml\n       <!--通过参数索引，有参构造-->\n       <bean id=\"user1\" class=\"com.ahulearn.pojo.User\">\n           <constructor-arg index=\"0\" value=\"sl\"/>\n       </bean>\n   ```\n\n   + 参数类型\n\n   ```xml\n       <!--通过参数类型，有参构造-->\n       <bean id=\"user2\" class=\"com.ahulearn.pojo.User\">\n           <constructor-arg type=\"java.lang.String\" value=\"lz\"/>\n       </bean>\n   ```\n\n   + 引用方式\n\n   ```xml\n       <!--主流方法，通过形参名，有参构造-->\n       <bean id=\"user3\" class=\"com.ahulearn.pojo.User\">\n           <constructor-arg name=\"name\" value=\"令章\"/>\n       </bean>\n   ```\n\n## 5. Spring配置\n\n### 5.1 别名\n\n```xml\n    <bean id=\"user3\" class=\"com.ahulearn.pojo.User\">\n        <constructor-arg name=\"name\" value=\"令章\"/>\n    </bean>\n    <!--别名-->\n    <alias name=\"user3\" alias=\"user\"/>\n```\n\n### 5.2 bean\n\nid: bean的唯一标识符，相当于对象名\n\nclass: bean对象对应的全限定命名：包名+类型\n\nname: 别名，相当于用alias去定义别名, 且可以同时取多个别名\n\n```xml\n    <!--name创建别名，可以创建多个别名，别名间通过逗号，分号或空格分隔-->\n    <bean id=\"user4\" class=\"com.ahulearn.pojo.User\" name=\"userName,u\">\n        <constructor-arg name=\"name\" value=\"令章\"/>\n    </bean>\n```\n\n\n\n### 5.3 import\n\nimport一般用于团队开发使用，他可以将多个配置文件，导入合并为一个：applicationContext.xml\n\n假设，现在项目中有多个人开发，两个人负责不同的类开发，不同的类需要注册在不同的bean中，可以利用import将所有人的beans.xml合并为一个总的配置文件，使用的时候只需要使用总的配置文件即可。\n\n如果两个文件中，存在相同的id, 则后导入的会覆盖之前导入的bean.\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       https://www.springframework.org/schema/beans/spring-beans.xsd\">\n    <import resource=\"beans.xml\"/>\n    <import resource=\"beans2.xml\"/>\n</beans>\n```\n\n\n\n## 6. 依赖注入\n\n文档：https://docs.spring.io/spring-framework/docs/current/reference/html/core.html#beans-factory-collaborators\n\n### 6.1构造器注入\n\n上方第5节已经使用并介绍\n\n### 6.2 set注入【重点】\n\n+ 依赖注入\n  + 依赖：bean对象的创建依赖于容器！\n  + 注入：bean对象的所有属性，由容器来注入！\n\n【环境搭建】\n\n1. 复杂类型\n\n```java\npackage com.ahulearn.pojo;\n\npublic class Address {\n    private String address;\n\n    public void setAddress(String address) {\n        this.address = address;\n    }\n\n    @Override\n    public String toString() {\n        return \"Address{\" +\n                \"address='\" + address + '\\'' +\n                '}';\n    }\n}\n```\n\n```java\npublic class Student {\n    private String name;\n    private Address address;\n    private String[] books;\n    private List<String> hobbies;\n    private Map<String, String> card;\n    private Set<String> games;\n    private String wife; //空指针Null\n    private Properties info; //配置类\n}\n```\n\n\n\n2. 真实测试对象\n\n```java\npackage com.ahulearn.pojo;\n\nimport java.util.*;\n\npublic class Student {\n    private String name;\n    private Address address;\n    private String[] books;\n    private List<String> hobbies;\n    private Map<String, String> card;\n    private Set<String> games;\n    private String wife; //空指针Null\n    private Properties info; //配置类\n\n    public Student() {\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public Address getAddress() {\n        return address;\n    }\n\n    public void setAddress(Address address) {\n        this.address = address;\n    }\n\n    public String[] getBooks() {\n        return books;\n    }\n\n    public void setBooks(String[] books) {\n        this.books = books;\n    }\n\n    public List<String> getHobbies() {\n        return hobbies;\n    }\n\n    public void setHobbies(List<String> hobbies) {\n        this.hobbies = hobbies;\n    }\n\n    public Map<String, String> getCard() {\n        return card;\n    }\n\n    public void setCard(Map<String, String> card) {\n        this.card = card;\n    }\n\n    public Set<String> getGames() {\n        return games;\n    }\n\n    public void setGames(Set<String> games) {\n        this.games = games;\n    }\n\n    public String getWife() {\n        return wife;\n    }\n\n    public void setWife(String wife) {\n        this.wife = wife;\n    }\n\n    public Properties getInfo() {\n        return info;\n    }\n\n    public void setInfo(Properties info) {\n        this.info = info;\n    }\n\n    @Override\n    public String toString() {\n        return \"Student{\" +\n                \"name='\" + name + '\\'' +\n                \", address=\" + address.toString() +\n                \", books=\" + Arrays.toString(books) +\n                \", hobbies=\" + hobbies +\n                \", card=\" + card +\n                \", games=\" + games +\n                \", wife='\" + wife + '\\'' +\n                \", info=\" + info +\n                '}';\n    }\n}\n```\n\n\n\n3. beans.xml\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       https://www.springframework.org/schema/beans/spring-beans.xsd\">\n\n    <bean id=\"address\" class=\"com.ahulearn.pojo.Address\">\n        <property name=\"address\" value=\"复旦大学\"/>\n    </bean>\n    <!--set方法注入-->\n    <bean id=\"student\" class=\"com.ahulearn.pojo.Student\">\n        <!--普通注入，直接赋值-->\n        <property name=\"name\" value=\"slz\"/>\n        <!--Bean id引用注入-->\n        <property name=\"address\" ref=\"address\"/>\n        <!--数组注入， ref-->\n        <property name=\"books\">\n            <array>\n                <value>红楼梦</value>\n                <value>西游记</value>\n                <value>三国演绎</value>\n                <value>水浒传</value>\n            </array>\n        </property>\n        <!--List注入， ref-->\n        <property name=\"hobbies\">\n            <list>\n                <value>听歌</value>\n                <value>看电影</value>\n                <value>敲代码</value>\n            </list>\n        </property>\n        <!--Map注入-->\n        <property name=\"card\">\n            <map>\n                <entry key=\"身份证\" value=\"341623343886816642\"/>\n                <entry key=\"银行卡\" value=\"1233423412314321342\"/>\n            </map>\n        </property>\n        <!--Set注入-->\n        <property name=\"games\">\n            <set>\n                <value>LOL</value>\n                <value>COC</value>\n                <value>FGO</value>\n            </set>\n        </property>\n        <!--Null和空字符串-->\n        <property name=\"wife\">\n            <null/>\n        </property>\n        <!--Property key=>value形式-->\n        <property name=\"info\">\n            <props>\n                <prop key=\"driver\">com.mysql.jdbc.Driver</prop>\n                <prop key=\"url\">jdbc:mysql://localhost:3306/mydb</prop>\n                <prop key=\"username\">root</prop>\n                <prop key=\"password\">1234</prop>\n            </props>\n        </property>\n\n    </bean>\n\n</beans>\n```\n\n4. 测试类\n\n```java\nimport com.ahulearn.pojo.Student;\nimport org.springframework.context.ApplicationContext;\nimport org.springframework.context.support.ClassPathXmlApplicationContext;\n\npublic class MyTest {\n    public static void main(String[] args) {\n        ApplicationContext context = new ClassPathXmlApplicationContext(\"beans.xml\");\n        Student student = (Student)context.getBean(\"student\");\n        //System.out.println(student.getName());\n        System.out.println(student);\n    }\n}\n```\n\n\n\n### 6.3 拓展方式注入\n\np命名空间注入，对应set方式注入\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:p=\"http://www.springframework.org/schema/p\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       https://www.springframework.org/schema/beans/spring-beans.xsd\">\n    <!--p命名空间注入，等同于通过set方法注入，必须要有无参构造方法，不然对象都构造不出，就不能设置属性-->\n    <bean id=\"user1\" class=\"com.ahulearn.pojo.User\" p:name=\"slz\" p:age=\"18\"/>\n</beans>\n```\n\n\n\nc命名空间注入，对应构造器注入\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:p=\"http://www.springframework.org/schema/p\"\n       xmlns:c=\"http://www.springframework.org/schema/c\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       https://www.springframework.org/schema/beans/spring-beans.xsd\">\n    <!--p命名空间注入，等同于通过set方法注入，必须要有无参构造方法，不然对象都构造不出，就不能设置属性-->\n    <bean id=\"user1\" class=\"com.ahulearn.pojo.User\" p:name=\"slz\" p:age=\"18\"/>\n    <!--c命名空间注入，等同于通过构造方法注入,要求必须定义有参构造：construct-args-->\n    <bean id=\"user2\" class=\"com.ahulearn.pojo.User\" c:name=\"slz\" c:age=\"18\"/>\n</beans>\n```\n\n注意点：p命名和c命名不能直接使用，需要导入相应的xml约束\n\n```xml\nxmlns:p=\"http://www.springframework.org/schema/p\"\nxmlns:c=\"http://www.springframework.org/schema/c\"\n```\n\n\n\n### 6.4 Bean Scopes 作用域\n\n文档：https://docs.spring.io/spring-framework/docs/current/reference/html/core.html#beans-factory-scopes\n\n6种作用域，后两种类似\n\n\n\n| Scope                                                        |                         Description                          |\n| :----------------------------------------------------------- | :----------------------------------------------------------: |\n| [singleton](https://docs.spring.io/spring-framework/docs/current/reference/html/core.html#beans-factory-scopes-singleton) | (Default) Scopes a single bean definition to a single object instance for each Spring IoC container. |\n| [prototype](https://docs.spring.io/spring-framework/docs/current/reference/html/core.html#beans-factory-scopes-prototype) | Scopes a single bean definition to any number of object instances. |\n| [request](https://docs.spring.io/spring-framework/docs/current/reference/html/core.html#beans-factory-scopes-request) | Scopes a single bean definition to the lifecycle of a single HTTP request. That is, each HTTP request has its own instance of a bean created off the back of a single bean definition. Only valid in the context of a web-aware Spring `ApplicationContext`. |\n| [session](https://docs.spring.io/spring-framework/docs/current/reference/html/core.html#beans-factory-scopes-session) | Scopes a single bean definition to the lifecycle of an HTTP `Session`. Only valid in the context of a web-aware Spring `ApplicationContext`. |\n| [application](https://docs.spring.io/spring-framework/docs/current/reference/html/core.html#beans-factory-scopes-application) | Scopes a single bean definition to the lifecycle of a `ServletContext`. Only valid in the context of a web-aware Spring `ApplicationContext`. |\n| [websocket](https://docs.spring.io/spring-framework/docs/current/reference/html/web.html#websocket-stomp-websocket-scope) | Scopes a single bean definition to the lifecycle of a `WebSocket`. Only valid in the context of a web-aware Spring `ApplicationContext`. |\n\n1. 单例模式singleton (Spring默认机制)\n\n   每次从容器中get, 同一个id取出的是同一个对象\n\n```xml\n<!--单例模式-->\n<bean id=\"user3\" class=\"com.ahulearn.pojo.User\" c:name=\"lz\" c:age=\"19\" scope=\"singleton\"/>\n```\n\n2. 原型模式prototype (多线程可能有用)\n\n   每次从容器中get, 同一个id都会产生一个新对象！\n\n```xml\n<!--原型模式-->\n<bean id=\"user4\" class=\"com.ahulearn.pojo.User\" c:name=\"lz\" c:age=\"19\" scope=\"prototype\"/>\n```\n\n3. 其余的request、session、application，这些只能在web开发中使用到！\n\n   request: 在一次请求中存活，session: 在一个会话中存活，application：全局有效\n\n\n\n\n\n## 7. Bean的自动装配\n\n+ 自动装配是Spring满足bean依赖的一种方式！\n+ Spring会在上下文中自动寻找，并自动给bean装配属性！\n\n在Spring中由三种装配方式\n\n1. 在xml中显示的配置\n2. 在java中显示的配置\n3. 隐式的自动装配bean【重点】\n\n### 7.1 测试\n\n环境搭建：一个人有两个宠物，看到一句话要立马反应出有几个对象\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       https://www.springframework.org/schema/beans/spring-beans.xsd\">\n\n    <bean id=\"dog\" class=\"com.ahulearn.pojo.Dog\"/>\n    <bean id=\"cat\" class=\"com.ahulearn.pojo.Cat\"/>\n    <bean id=\"people\" class=\"com.ahulearn.pojo.People\">\n        <property name=\"name\" value=\"kl\"/>\n        <property name=\"cat\" ref=\"cat\"/>\n        <property name=\"dog\" ref=\"dog\"/>\n    </bean>\n</beans>\n```\n\n\n\n### 7.2 byName自动装配\n\n要求bean ID要和set方法名一致，比如setCat方法装配则找id为cat的bean\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       https://www.springframework.org/schema/beans/spring-beans.xsd\">\n\n    <bean id=\"dog\" class=\"com.ahulearn.pojo.Dog\"/>\n    <bean id=\"cat\" class=\"com.ahulearn.pojo.Cat\"/>\n    <!--\n    byName：自动在容器上下文中和自己对象set方法后面的值对应的bean_id, 比如setCat则找id为cat的bean\n    -->\n    <bean id=\"people1\" class=\"com.ahulearn.pojo.People\" autowire=\"byName\">\n        <property name=\"name\" value=\"kl\"/>\n    </bean>\n</beans>\n```\n\n\n\n### 7.3 byType自动装配\n\n要求beans中的类型必须全局唯一，用于装配的bean甚至可以需要拥有bean-id\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       https://www.springframework.org/schema/beans/spring-beans.xsd\">\n\n    <bean class=\"com.ahulearn.pojo.Dog\"/>\n    <bean class=\"com.ahulearn.pojo.Cat\"/>\n\n    <!--\n    byName：自动在容器上下文中和自己对象set方法后面的值对应的bean_id, 比如setCat则找id为cat的bean\n    -->\n    <bean id=\"people\" class=\"com.ahulearn.pojo.People\" autowire=\"byType\">\n        <property name=\"name\" value=\"kl\"/>\n    </bean>\n</beans>\n```\n\n\n\n### 7.4 使用注解自动装配\n\nJDK1.5支持注解，Spring2.5开始支持注解\n\n文档：https://docs.spring.io/spring-framework/docs/current/reference/html/core.html#beans-annotation-config\n\n要使用注解须知：\n\n1. 导入约束： `xmlns:context=\"http://www.springframework.org/schema/context\"`\n2. 配置注解的支持: ` <context:annotation-config/>`\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xmlns:context=\"http://www.springframework.org/schema/context\"\n    xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n        https://www.springframework.org/schema/beans/spring-beans.xsd\n        http://www.springframework.org/schema/context\n        https://www.springframework.org/schema/context/spring-context.xsd\">\n\n    <context:annotation-config/>\n\n</beans>\n```\n\n\n\n+ 注解依赖：\n\n```xml\n    <dependency>\n      <groupId>org.springframework</groupId>\n      <artifactId>spring-beans</artifactId>\n      <version>5.2.10.RELEASE</version>\n      <scope>compile</scope>\n    </dependency>\n```\n\n+ 导入包：`import org.springframework.beans.factory.annotation.Autowired;`\n\n\n\n\n#### 7.4.1 **@Autowired**\n\n注解可以在属性上用，或者set方法上用，一般写在属性上。需要在IOC容器中注册相应的id.\n\n如果写在属性上，set方法都不用再写，因为注解是通过反射实现的，但get方法不能省略。\n\n注解优先按类型查找，没有类型匹配则报错；找到多个则按name匹配，如果没有name匹配的则报错。\n\n```java\npackage com.ahulearn.pojo;\n\nimport org.springframework.beans.factory.annotation.Autowired;\n\npublic class People {\n    private String name;\n    @Autowired\n    private Cat cat;\n    private Dog dog;\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public void setCat(Cat cat) {\n        this.cat = cat;\n    }\n\n    @Autowired\n    public void setDog(Dog dog) {\n        this.dog = dog;\n    }\n}\n\n```\n\n\n\n+ **@Autowired(required=false)** : 默认是true，如果设置成false则允许字段为空，即在beans可以不注册该对象。跳过装配。\n\n```java\npublic class People {\n    private String name;\n    //如果显示的定义了Autowired的required属性为false,说明这个对象可以为null,否则不能为空\n    @Autowired(required=false)\n    private Cat cat;\n    @Autowired\n    private Dog dog;\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public Cat getCat() {\n        return cat;\n    }\n\n    public Dog getDog() {\n        return dog;\n    }\n}\n```\n\n可以在xml不添加cat的bean，但必须添加dog的bean\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       https://www.springframework.org/schema/beans/spring-beans.xsd\n       http://www.springframework.org/schema/context\n       https://www.springframework.org/schema/context/spring-context.xsd\">\n    <!--开启注解支持-->\n    <context:annotation-config/>\n    <!--不需要注入任何东西-->\n    <bean id=\"dog\" class=\"com.ahulearn.pojo.Dog\"/>\n    <bean id=\"people\" class=\"com.ahulearn.pojo.People\"/>\n\n</beans>\n```\n\n@Nullable: 允许标记的字段为空\n\n```java\nimport org.springframework.lang.Nullable;\n\npublic class People {\n    private String name;\n    @Autowired\n    private Cat cat;\n    private Dog dog;\n\n    //允许name为空\n    public People(@Nullable String name) {\n        this.name = name;\n    }\n\n}\n\n```\n\n#### 7.4.2 @Qualifier\n\n+ 如果自动装配环境比较复杂，在beans注册对象中，通过类型可以匹配超过一个对象，但name都不匹配，可以配合@Qualifier(value=\"cat2\")注解指定要装配的id\n\n```java\npackage com.ahulearn.pojo;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.beans.factory.annotation.Qualifier;\n\npublic class People {\n    private String name;\n    //如果显示的定义了Autowired的required属性为false,说明这个对象可以为null,否则不能为空\n    @Autowired(required=false)\n    @Qualifier(value=\"cat2\")\n    private Cat cat;\n    @Autowired\n    private Dog dog;\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public Cat getCat() {\n        return cat;\n    }\n\n    public Dog getDog() {\n        return dog;\n    }\n}\n```\n\n\n\n#### 7.4.3 **@Resource**\n\njavax包下的注解，功能类似spring中的@Autowired注解，首先通过类型匹配，之后通过name匹配，可以手动指定name\n\n+ @Resource(name=\"cat2\")\n+ 依赖：javax下的包属于java拓展包，没有包含在java核心包中，需要自己添加依赖\n\n```xml\n    <dependency>\n      <groupId>javax.annotation</groupId>\n      <artifactId>javax.annotation-api</artifactId>\n      <version>1.3.2</version>\n    </dependency>\n```\n\n```java\npackage com.ahulearn.pojo;\nimport javax.annotation.Resource;\npublic class ResourceTest {\n    private String name;\n    @Resource(name=\"cat2\")\n    private Cat cat;\n    @Resource\n    private Dog dog;\n\n    public String getName() {\n        return name;\n    }\n    public Cat getCat() {\n        return cat;\n    }\n\n    public Dog getDog() {\n        return dog;\n    }\n}\n```\n\n\n\n## 8. 使用自动装配注解Component开发\n\n在Spring4之后，要使用注解开发，必须导入aop包\n\n```xml\n<!-- https://mvnrepository.com/artifact/org.springframework/spring-aop -->\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-aop</artifactId>\n    <version>5.3.5</version>\n</dependency>\n```\n\n\n\n### 8.1 bean\n\n+ 导入约束applicationContext.xml\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       https://www.springframework.org/schema/beans/spring-beans.xsd\n       http://www.springframework.org/schema/context\n       https://www.springframework.org/schema/context/spring-context.xsd\">\n    <!--指定要扫描的包，只有指定的包下的Component注解才会生效-->\n    <context:component-scan base-package=\"com.ahulearn.pojo\"/>\n    <!--注解驱动-->\n    <context:annotation-config/>\n    <import resource=\"beans.xml\"/>\n\n</beans>\n```\n\n\n\n```java\npackage com.ahulearn.pojo;\n\nimport org.springframework.stereotype.Component;\n\n//等价于<bean id=\"user\" class=\"com.ahulearn.pojo.User\"/>\n//Component组间，一般放在类上，让spring容器管理该类\n@Component\npublic class User {\n    public String name;\n}\n```\n\n\n\n### 8.2 属性如何注入\n\n\n\n```java\npackage com.ahulearn.pojo;\n\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.stereotype.Component;\n\n//等价于<bean id=\"user\" class=\"com.ahulearn.pojo.User\"/>\n//Component组间，一般放在类上，让spring容器管理该类\n@Component\npublic class User {\n    /**Value相当于\n     *<bean id=\"user\" class=\"com.ahulearn.pojo.User\">\n     *   <property name=\"name\" value=\"kk\"/>\n     *</bean>\n     * 用于简单的注入，复杂配置用xml\n     */\n    @Value(\"slz\")\n    public String name;\n}\n\n```\n\n+ 测试类\n\n```java\nimport com.ahulearn.pojo.User;\nimport com.ahulearn.service.UserService;\nimport org.springframework.context.ApplicationContext;\nimport org.springframework.context.support.ClassPathXmlApplicationContext;\n\npublic class MyTest {\n    public static void main(String[] args) {\n        ApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\");\n        //因为注解扫描装配没有配置bean,因此不存在bean id,通过getBean取对象时必须使用类名小写首字母的形式\n        User user = context.getBean(\"user\", User.class);\n        System.out.println(user.name);\n    }\n}\n```\n\n\n\n### 8.3 衍生注解\n\n\n\n@Component有几个衍生注解，作用相同，只是名称不同，用在不同的模块中。我们在web开发中，会按照mvc架构分层\n\n+ dao 【@Repository】\n\n```java\npackage com.ahulearn.dao;\nimport org.springframework.stereotype.Repository;\n\n/**\n *在dao层Component写作Repository\n * */\n@Repository\npublic class UserDao {\n    public String name;\n}\n```\n\n\n\n+ service【@Service】\n\n```java\npackage com.ahulearn.service;\nimport org.springframework.stereotype.Service;\n\n@Service\npublic class UserService {\n    public String name;\n}\n```\n\n\n\n+ controller【@Controller】\n\n```java\npackage com.ahulearn.controller;\nimport org.springframework.stereotype.Controller;\n\n@Controller\npublic class UserController {\n    public String name;\n}\n```\n\n这四个注解功能一样，都是代表将某个类注册到Spring中，装配Bean\n\n\n\n+ benas.xml\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       https://www.springframework.org/schema/beans/spring-beans.xsd\n       http://www.springframework.org/schema/context\n       https://www.springframework.org/schema/context/spring-context.xsd\">\n    <!--指定要扫描的包，只有指定的包下的Component注解才会生效-->\n    <context:component-scan base-package=\"com.ahulearn.pojo\"/>\n    <context:component-scan base-package=\"com.ahulearn.dao\"/>\n    <context:component-scan base-package=\"com.ahulearn.controller\"/>\n    <context:component-scan base-package=\"com.ahulearn.service\"/>\n    <!--注解驱动-->\n    <context:annotation-config/>\n\n</beans>\n```\n\n\n\n### 8.4 自动装配\n\n```\n@Autowired\n@Qualifier\n@Resource\n```\n\n\n\n### 8.5 作用域\n\n+ 导入依赖\n\n  ```java\n  import org.springframework.context.annotation.Scope;\n  ```\n\n+ @Scope\n  + 单例模式@Scope(\"singleton\") 等同于beans配置中的属性scope = \"singleton\"\n  + 多例模式@Scope(\"prototype\") 等同于beans配置中的属性scope = \"prototype\"\n\n```java\npackage com.ahulearn.pojo;\n\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.context.annotation.Scope;\nimport org.springframework.stereotype.Component;\n\n@Component\n/*设置作用域*/\n@Scope(\"prototype\")\npublic class User {\n    /**Value相当于\n     *<bean id=\"user\" class=\"com.ahulearn.pojo.User\">\n     *   <property name=\"name\" value=\"kk\"/>\n     *</bean>\n     * 用于简单的注入，复杂配置用xml\n     */\n    @Value(\"slz\")\n    public String name;\n}\n```\n\n\n\n### 8.6 小结\n\nxml与注解\n\n+ xml功能更强，适合任何场合！维护简单方便，配置都在同一个文件中\n+ 注解不是自己的类使用不了，维护相对复杂\n\nxml与注解最佳实践\n\n+ xml用来管理bean\n+ 注解只负责完成属性的注入\n+ 我们在使用的过程中，只需要注意一个问题：必须让注解生效，就需要开启注解支持\n\n```xml\n    <!--指定要扫描的包，只有指定的包下的Component注解才会生效-->\n    <context:component-scan base-package=\"com.ahulearn.pojo\"/>\n    <!--注解驱动-->\n    <context:annotation-config/>\n```\n\n\n\n## 9. 使用java的方式配置Spring\n\nJavaConfig原是Spring的子项目，在Spring4之后成为核心功能\n\n完全不使用Spring的xml配置，全权交给java来做\n\n文档：https://docs.spring.io/spring-framework/docs/current/reference/html/core.html#beans-java\n\n在一个类上加@Configuration类似于写一个配置文件：beans\n\n+ 配置类：AppConfig.java\n\n```java\npackage com.ahulearn.config;\n\nimport com.ahulearn.pojo.User;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.ComponentScan;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.context.annotation.Import;\n\n/**表示这是一个配置类，该注解本身也被@Component注解，即也被添加到Spring容器中\n * 和beans.xml作用相同\n * */\n@Configuration\n/**\n * 配置自动装配，如果自动装配，可以不用写下方的@Bean方法，取对象直接使用类名小写首字母\n * */\n@ComponentScan(\"com.ahulearn.pojo\")\n/** 导入其他配置类 */\n@Import(MyConfig.class)\npublic class AppConfig {\n    /**注册一个bean, 相当于写一个bean标签\n     * 方法名相当于bean标签的id属性\n     * 返回值，相当于bean标签的class属性*/\n    @Bean\n    public User myUser() {\n        return new User();\n    }\n}\n```\n\n等价于\n\n```xml\n<beans>\n    <bean id=\"myUser\" class=\"com.ahulearn.pojo.User\"/>\n</beans>\n```\n\n+ 实体类：User\n\n```java\npackage com.ahulearn.pojo;\n\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.stereotype.Component;\n\n/*让Spring容器接管该类，注册到容器中*/\n@Component\npublic class User {\n    /*注入初始值*/\n    @Value(\"slz\")\n    private String name;\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    @Override\n    public String toString() {\n        return \"User{\" +\n                \"name='\" + name + '\\'' +\n                '}';\n    }\n}\n```\n\n+ 测试类\n\n```java\nimport com.ahulearn.config.AppConfig;\nimport com.ahulearn.pojo.User;\nimport org.springframework.context.ApplicationContext;\nimport org.springframework.context.annotation.AnnotationConfigApplicationContext;\n\npublic class MyTest {\n    public static void main(String[] args) {\n        //从AppConfig中获取容器\n        ApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class);\n        //从容器中获取对象\n        User myUser = (User) context.getBean(\"myUser\");\n        System.out.println(myUser.getName());\n    }\n}\n```\n\n纯java的配置方式，在Springboot中随处可见\n\n\n\n## 10. AOP-代理模式\n\n为什么学习代码模式？【因为这就是SpringAOP的底层】\n\n代理模式分类：\n\n+ 静态代理\n+ 动态代理\n\n使用代理避免修改原有的业务代码（被代理角色），可以方便的添加公用的业务操作。\n\n### 10.1 静态代理\n\n角色分析：\n\n+ 抽象角色：一般会使用接口或抽象类\n\n```java\npackage com.ahulearn.demo01;\n\npublic interface Rent {\n    public void rent();\n}\n```\n\n\n\n+ 真实角色：被代理的角色\n\n```java\npackage com.ahulearn.demo01;\n\npublic class Host implements Rent{\n    //租房\n    public void rent(){\n        System.out.println(\"房东出租房子\");\n    }\n}\n```\n\n\n\n+ 代理角色：代理真实角色，代理真实角色后，一般还会做附属操作\n\n```java\npackage com.ahulearn.demo01;\n\npublic class Proxy {\n    //多用组合，少用继承\n    private Host host;\n\n    public Proxy() {\n    }\n\n    public Proxy(Host host) {\n        this.host = host;\n    }\n\n    public void setHost(Host host) {\n        this.host = host;\n    }\n    public void rent(){\n        host.rent();\n    }\n    public void seeHouse(){\n        System.out.println(\"看房\");\n    }\n    public void fare(){\n        System.out.println(\"收中介费\");\n    }\n    public void contract(){\n        System.out.println(\"签租赁合同\");\n    }\n}\n```\n\n\n\n+ 客户角色：访问代理对象的人\n\n```java\npackage com.ahulearn.demo01;\n\npublic class Client {\n    public static void main(String[] args) {\n        //房东\n        Host host = new Host();\n        //代理\n        Proxy proxy = new Proxy(host);\n        //看房\n        proxy.seeHouse();\n        //签合同\n        proxy.contract();\n        //租房\n        proxy.rent();\n        //收中介费\n        proxy.fare();\n    }\n}\n```\n\n代理模式的好处：\n\n+ 可以使真实角色的操作更加纯粹！不用去关注一些公共的业务\n+ 公共业务交给代理角色，实现业务分工\n+ 公共业务发生扩展的时候，方便集中管理！\n\n缺点：\n\n+ 一个真实角色就会产生一个代理角色；代码量会翻倍*开发效率变低*\n\n\n\n### 10.2 静态代理例子-加深理解\n\n代码对应 spring-08-proxy-demo02\n\n![静态代理](../img/spring/10.2_0.png)\n\n+ 抽象角色\n\n```java\npackage com.ahulearn.demo02;\n\npublic interface UserService {\n    public void add();\n    public void delete();\n    public void update();\n    public void query();\n}\n```\n\n\n\n+ 真实角色\n\n```java\npackage com.ahulearn.demo02;\n\npublic class UserServiceImpl implements UserService {\n    @Override\n    public void add() {\n        System.out.println(\"增加了一个用户\");\n    }\n\n    @Override\n    public void delete() {\n        System.out.println(\"删除了一个用户\");\n    }\n\n    @Override\n    public void update() {\n        System.out.println(\"修改了一个用户\");\n    }\n\n    @Override\n    public void query() {\n        System.out.println(\"查询用户\");\n    }\n}\n\n```\n\n\n\n+ 代理角色\n\n```java\npackage com.ahulearn.demo02;\n\npublic class UserServiceProxy implements UserService{\n    private UserServiceImpl userService;\n\n    public void setUserService(UserServiceImpl userService) {\n        this.userService = userService;\n    }\n\n    @Override\n    public void add() {\n        userService.add();\n        log(\"add\");\n    }\n\n    @Override\n    public void delete() {\n        userService.delete();\n        log(\"delete\");\n    }\n\n    @Override\n    public void update() {\n        userService.update();\n        log(\"update\");\n    }\n\n    @Override\n    public void query() {\n        userService.query();\n        log(\"query\");\n    }\n    //日志方法\n    public void log(String msg) {\n        System.out.println(\"log: 使用了\"+msg+\"方法\");\n    }\n}\n```\n\n\n\n+ 客户角色：访问代理对象的人\n\n```java\npackage com.ahulearn.demo02;\n\npublic class Client {\n    public static void main(String[] args) {\n        UserServiceImpl userService = new UserServiceImpl();\n        UserServiceProxy proxy = new UserServiceProxy();\n        proxy.setUserService(userService);\n\n        proxy.add();\n        proxy.delete();\n    }\n}\n```\n\n\n\n### 10.3 动态代理\n\n底层：反射\n\n+ 动态代理和静态代理角色一样\n+ 动态代理的类是动态生成的，不是直接写好的！\n+ 动态代理分为两大类：基于接口的动态代理，基于类的动态代理\n  + 基于接口--JDK的动态接口【本节使用的方法】\n  + 基于来：cglib\n  + 基于字节码：JAVAssist 目前用于JBoss 应用服务器项目\n\n需要了解两个类：\n\n+ Proxy: 代理\n\n提供了创建动态代理类和示例的静态方法\n\n```java\n//方法调用句柄\nInvocationHandler handler = new MyInvocationHandler();\n//动态代理类\nClass<?> proxyClass = Proxy.getProxyClass(Foo.getClass().getClassLoader(), Foo.getClass());\n//动态创建动态代理实例\nFoo f = (Foo) proxyClass.getConstructor(InvocationHandler.getClass()).\n    newInstance(handler);\n\n//或者更简单地：\nFoo proxy = (Foo) Proxy.newProxyInstance(Foo.getClass().getClassLoader(), \n                               new Class<?> [] {Foo.getClass()}, \n                               handler);\n```\n\n\n\n+ InvocationHandler: 调用处理程序接口\n\n  代理实例的 *调用处理程序* 的接口\n\n  只有一个invoke接口方法，该方法使用反射的方式调用另一个方法。\n\n  ```java\n  Object invoke(Object proxy, Method method, Object[] args)\n  ```\n\n  \n\n实验环境：\n\n+ 抽象角色：接口\n\n```java\npackage com.ahulearn.demo03;\n\npublic interface Rent {\n    public void rent();\n}\n```\n\n\n\n+ 真实角色：实体类\n\n```java\npackage com.ahulearn.demo03;\n\npublic class Host implements Rent {\n    public void rent(){\n        System.out.println(\"房东出租房子\");\n    }\n}\n```\n\n\n\n+ 代理角色\n\n```java\npackage com.ahulearn.demo03;\n\nimport java.lang.reflect.InvocationHandler;\nimport java.lang.reflect.Method;\nimport java.lang.reflect.Proxy;\n\npublic class ProxyInvocationHandler implements InvocationHandler {\n    //被代理的接口\n    private Object target;\n\n    public void setTarget(Object target) {\n        this.target = target;\n    }\n\n    //生成代理类\n    public Object getProxy() {\n        return Proxy.newProxyInstance(this.getClass().getClassLoader(), target.getClass().getInterfaces(), this);\n    }\n\n    //处理代理示例，并返回结果\n    @Override\n    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n        //前处理\n        seeHouse();\n        //动态代理的本质，就是使用反射机制实现！\n        Object result = method.invoke(target, args);\n        //后处理\n        fare();\n        return result;\n    }\n\n    public void seeHouse() { System.out.println(\"中介带看房子\"); }\n    public void fare() { System.out.println(\"收中介费\"); }\n}\n```\n\n\n\n+ 用户角色\n\n```java\npackage com.ahulearn.demo03;\n\npublic class Client {\n    public static void main(String[] args) {\n        //真实角色\n        Host host = new Host();\n        //代理角色生成程序\n        ProxyInvocationHandler pih = new ProxyInvocationHandler();\n        //通过调用处理程序来设置要代理的抽象类或接口\n        pih.setTarget(host);\n        //根据传入的类对应的接口生成抽象类\n        Rent proxy = (Rent) pih.getProxy(); //proxy是动态生成的\n        //租房\n        proxy.rent();\n    }\n}\n```\n\n\n\n动态代理的好处：\n\n+ 可以使真实角色的操作更加纯粹！不用去关注一些公共的业务\n+ 公共业务交给代理角色，实现业务分工\n+ 公共业务发生扩展的时候，方便集中管理！\n\n+ 一个动态代理类代理的是一个接口，一般就是对应一类业务\n+ 一个动态代理类可以代理多个类，只要是实现了同一个接口即可！\n\n\n\n\n\n## 11. AOP\n\n### 11.1 什么是AOP?\n\nAOP（Aspect Oriented Programming）意为：面向切面编程，通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。AOP是OOP的延续，是软件开发中的一个热点，也是Spring框架中的一个重要内容，是函数式编程的一种衍生范型。利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。\n\nAOP可以说是OOP（Object-Oriented Programing，面向对象编程）的补充和完善。OOP引入封装、继承和多态性等概念来建立一种对象层次结构，用以模拟公共行为的一个集合。当我们需 要为分散的对象引入公共行为的时候，OOP则显得无能为力。也就是说，**OOP允许你定义从上到下的关系，但并不适合定义从左到右的关系**。例如日志功能。日志代码往往水平地散布在所有对象层次中，而与它所散布到的对象的核心功能毫无关系。对于其他类型的代码，如安全性、异常处理和透明的持续性也是如此。这种散布在各处的无关的代码被称为横切（cross-cutting）代码，在OOP设计中，它导致了大量代码的重复，而不利于各个模块的重用。\n\n而AOP技术则恰恰相反，它利用一种称为“横切”的技术，剖解开封装的对象内部，并将那些影响了多个类的公共行为封装到一个可重用模块，并将其名为 “Aspect”，即方面。所谓“方面”，简单地说，就是将那些与业务无关，却为业务模块所共同调用的逻辑或责任封装起来，便于减少系统的重复代码，降低 模块间的耦合度，并有利于未来的可操作性和可维护性。AOP代表的是一个横向的关系，如果说“对象”是一个空心的圆柱体，其中封装的是对象的属性和行为； 那么面向方面编程的方法，就仿佛一把利刃，将这些空心圆柱体剖开，以获得其内部的消息。而剖开的切面，也就是所谓的“方面”了。然后它又以巧夺天功的妙手将这些剖开的切面复原，不留痕迹。\n\n![图片](../img/spring/11.2_0.jpg)\n\n### 11.2 AOP在Spring中的作用\n\n+ 提供声明式事务；允许用户自定义切面\n\n以下名词需要了解：\n\n| 名称                | 说明                                                         |\n| ------------------- | ------------------------------------------------------------ |\n| Joinpoint（连接点） | 指那些被拦截到的点，在 Spring 中，可以被动态代理拦截目标类的方法。 |\n| Pointcut（切入点）  | 指要对哪些 Joinpoint 进行拦截，即被拦截的连接点。            |\n| Advice（通知）      | 指拦截到 Joinpoint 之后要做的事情，即对切入点增强的内容。    |\n| Target（目标）      | 指代理的目标对象。                                           |\n| Weaving（植入）     | 指把增强代码应用到目标上，生成代理对象的过程。               |\n| Proxy（代理）       | 指生成的代理对象。                                           |\n| Aspect（切面）      | 切入点和通知的结合。                                         |\n\n![图片](../img/spring/11.2_1.jpg)\n\n\n\nSpringAOP中，通过Advice定义横切逻辑，Spring中支持5种类型的Advice:\n\n![图片](../img/spring/11.2_2.jpg)\n\n即 Aop 在 不改变原有代码的情况下 , 去增加新的功能 .\n\n\n\n### 11.3 使用Spring实现Aop\n\n**【重点】使用AOP织入包，需要导入一个依赖包！**\n\n```xml\n<!-- https://mvnrepository.com/artifact/org.aspectj/aspectjweaver -->\n<dependency>\n   <groupId>org.aspectj</groupId>\n   <artifactId>aspectjweaver</artifactId>\n   <version>1.9.4</version>\n</dependency>\n```\n\n\n\n#### 11.3.1 第一种方式：通过 Spring API 实现\n\n首先编写我们的业务接口和实现类\n\n```java\npackage com.ahulearn.service;\n\npublic interface UserService {\n    public void add();\n    public void delete();\n    public void update();\n    public void query();\n}\n```\n\n```java\npackage com.ahulearn.service;\n\npublic class UserServiceImpl implements UserService {\n    public void add() {\n        System.out.println(\"增加用户\");\n    }\n\n    public void delete() {\n        System.out.println(\"删除用户\");\n    }\n\n    public void update() {\n        System.out.println(\"更新用户\");\n    }\n\n    public void query() {\n        System.out.println(\"查询用户\");\n    }\n}\n```\n\n然后去写我们的增强类 , 我们编写两个 , 一个前置增强 一个后置增强\n\n```java\npackage com.ahulearn.log;\n\nimport org.springframework.aop.MethodBeforeAdvice;\nimport java.lang.reflect.Method;\n\npublic class Log implements MethodBeforeAdvice {\n    //method: 要执行的目标对象的方法\n    //objects: args 参数\n    //target: target 对象\n    public void before(Method method, Object[] objects, Object target) throws Throwable {\n        System.out.println(target.getClass().getName()+\"的\"+\n                method.getClass().getName()+\"被执行了\");\n    }\n}\n```\n\n\n\n```java\npackage com.ahulearn.log;\n\nimport org.springframework.aop.AfterReturningAdvice;\nimport java.lang.reflect.Method;\n\npublic class AfterLog implements AfterReturningAdvice {\n    //returnValue是返回值\n    public void afterReturning(Object returnValue, Method method, Object[] args, Object target) throws Throwable {\n        System.out.println(target.getClass().getName()+\"的\"+\n                method.getClass().getName()+\"执行,返回结果：\"+\n                returnValue);\n    }\n}\n```\n\n\n\n最后去spring的文件中注册 , 并实现aop切入实现 , 注意导入约束 .\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:aop=\"http://www.springframework.org/schema/aop\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       http://www.springframework.org/schema/beans/spring-beans.xsd\n\n       http://www.springframework.org/schema/aop\n       http://www.springframework.org/schema/aop/spring-aop.xsd\">\n\n    <!--注册bean-->\n    <bean id=\"userService\" class=\"com.ahulearn.service.UserServiceImpl\"/>\n    <bean id=\"log\" class=\"com.ahulearn.log.Log\"/>\n    <bean id=\"afterLog\" class=\"com.ahulearn.log.AfterLog\"/>\n    <!--需要导入AOP的约束，配置AOP-->\n    <aop:config>\n        <!--切入点:pointcut; expression:表达式：execution(返回值类型 包名.类名.方法名(参数))\n         * 通配符，前面指所有类型的方法，后面指所有方法，括号中两个点表示任意参数-->\n        <aop:pointcut id=\"pointcut\" expression=\"execution(* com.ahulearn.service.UserServiceImpl.*(..))\"/>\n        <!--设置切入方式: advice-ref执行方法 . pointcut-ref切入点-->\n        <aop:advisor advice-ref=\"log\" pointcut-ref=\"pointcut\"/>\n        <aop:advisor advice-ref=\"afterLog\" pointcut-ref=\"pointcut\"/>\n    </aop:config>\n\n</beans>\n```\n\n\n\n测试类\n\n```java\nimport com.ahulearn.service.UserService;\nimport org.springframework.context.ApplicationContext;\nimport org.springframework.context.support.ClassPathXmlApplicationContext;\n\npublic class MyTest {\n    public static void main(String[] args) {\n        ApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\");\n        //注意动态代理是代理的接口\n        UserService userService = context.getBean(\"userService\", UserService.class);\n        userService.add();\n    }\n}\n```\n\nAop的重要性 : 很重要 . 一定要理解其中的思路 , 主要是思想的理解 .\n\nSpring的Aop就是将公共的业务 (日志 , 安全等) 和领域业务结合起来 , 当执行领域业务时 , 将会把公共业务加进来 . 实现公共业务的重复利用 . 领域业务更纯粹 , 程序猿专注领域业务 , 其本质还是动态代理 . \n\n\n\n#### 11.3.2 第二种方式：自定义类来实现\n\n目标业务类不变依旧是userServiceImpl\n\n第一步 : 写我们自己的一个切入类\n\n```java\npackage com.ahulearn.diy;\n\npublic class DiyPointCut {\n    public void before() {\n        System.out.println(\"==========方法执行前================\");\n    }\n\n    public void after() {\n        System.out.println(\"==========方法执行后================\");\n    }\n}\n```\n\n去spring中配置\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:aop=\"http://www.springframework.org/schema/aop\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       http://www.springframework.org/schema/beans/spring-beans.xsd\n\n       http://www.springframework.org/schema/aop\n       http://www.springframework.org/schema/aop/spring-aop.xsd\">\n\n    <!--注册bean-->\n    <bean id=\"userService\" class=\"com.ahulearn.service.UserServiceImpl\"/>\n    <!--自定义切面类-->\n    <bean id=\"diyadvisor\" class=\"com.ahulearn.diy.DiyPointCut\"/>\n    <aop:config>\n        <!--自定义切面，ref: 要引用的类-->\n        <aop:aspect ref=\"diyadvisor\">\n            <!---切入点-->\n            <aop:pointcut id=\"point\" expression=\"execution(* com.ahulearn.service.UserServiceImpl.*(..))\"/>\n            <!--通知: 切面方法-->\n            <aop:before method=\"before\" pointcut-ref=\"point\"/>\n            <aop:after method=\"after\" pointcut-ref=\"point\"/>\n        </aop:aspect>\n    </aop:config>\n</beans>\n```\n\n测试：\n\n```java\nimport com.ahulearn.service.UserService;\nimport org.junit.Test;\nimport org.springframework.context.ApplicationContext;\nimport org.springframework.context.support.ClassPathXmlApplicationContext;\n\npublic class MyTest {\n    @Test\n    public void diyPointCut() {\n        ApplicationContext context = new ClassPathXmlApplicationContext(\"beans.xml\");\n        //注意动态代理是代理的接口\n        UserService userService = context.getBean(\"userService\", UserService.class);\n        userService.add();\n    }\n}\n```\n\n#### 11.3.3 第三种方式: 注解实现\n\n第一步：编写一个注解实现的增强类\n\n```java\npackage com.ahulearn.diy;\n\nimport org.aspectj.lang.ProceedingJoinPoint;\nimport org.aspectj.lang.annotation.After;\nimport org.aspectj.lang.annotation.Around;\nimport org.aspectj.lang.annotation.Before;\nimport org.aspectj.lang.annotation.Aspect;\n\n//标记这是一个注解\n@Aspect\npublic class AnnotationPointCut {\n    //前置切面\n    @Before(\"execution(* com.ahulearn.service.UserServiceImpl.*(..))\")\n    public void before() {\n        System.out.println(\"************方法执行前************\");\n    }\n    //前置切面\n    @After(\"execution(* com.ahulearn.service.UserServiceImpl.*(..))\")\n    public void after() {\n        System.out.println(\"************方法执行后************\");\n    }\n    @Around(\"execution(* com.ahulearn.service.UserServiceImpl.*(..))\")\n    public void around(ProceedingJoinPoint jp) throws Throwable {\n        System.out.println(\"环绕前\");\n        System.out.println(\"签名:\"+jp.getSignature());\n        //执行方法\n        Object proceed = jp.proceed();\n\n        System.out.println(\"环绕后\");\n    }\n}\n```\n\n第二步：在Spring配置文件中，注册bean，并增加支持注解的配置\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:aop=\"http://www.springframework.org/schema/aop\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       http://www.springframework.org/schema/beans/spring-beans.xsd\n\n       http://www.springframework.org/schema/aop\n       http://www.springframework.org/schema/aop/spring-aop.xsd\">\n\n    <!--注册bean-->\n    <bean id=\"userService\" class=\"com.ahulearn.service.UserServiceImpl\"/>\n    <!--方式三-->\n    <bean id=\"annotationPointCut\" class=\"com.ahulearn.diy.AnnotationPointCut\"/>\n    <!--开启注解支持,默认JDK方式实现，下方设为true使用cglib方式-->\n    <aop:aspectj-autoproxy proxy-target-class=\"false\" />\n</beans>\n```\n\naop:aspectj-autoproxy：说明\n\n通过aop命名空间的<aop:aspectj-autoproxy />声明自动为spring容器中那些配置@aspectJ切面的bean创建代理，织入切面。当然，spring 在内部依旧采用AnnotationAwareAspectJAutoProxyCreator进行自动代理的创建工作，但具体实现的细节已经被<aop:aspectj-autoproxy />隐藏起来了\n\n<aop:aspectj-autoproxy />有一个proxy-target-class属性，默认为false，表示使用jdk动态代理织入增强，当配为<aop:aspectj-autoproxy  poxy-target-class=\"true\"/>时，表示使用CGLib动态代理技术织入增强。不过即使proxy-target-class设置为false，如果目标类没有声明接口，则spring将自动使用CGLib动态代理。\n\n\n\n\n\n\n\n## 12. 整合Mybatis\n\n步骤：\n\n1. 导入相关jar包\n   + junit\n   + mybatis\n   + mysql数据库\n   + spring相关\n   + aop织入\n   + mybatis-spring 【新包】\n\n```xml\n<dependencies>\n    <!--mysql-connector-java,对应的dirver:com.mysql.jdbc.Driver-->\n    <dependency>\n      <groupId>mysql</groupId>\n      <artifactId>mysql-connector-java</artifactId>\n      <version>5.1.45</version>\n    </dependency>\n    <dependency>\n      <groupId>org.mybatis</groupId>\n      <artifactId>mybatis</artifactId>\n      <version>3.5.6</version>\n    </dependency>\n    <dependency>\n      <groupId>org.springframework</groupId>\n      <artifactId>spring-webmvc</artifactId>\n      <version>5.2.10.RELEASE</version>\n    </dependency>\n    <!-- spring操作数据库，需要spring-jdbc -->\n    <dependency>\n      <groupId>org.springframework</groupId>\n      <artifactId>spring-jdbc</artifactId>\n      <version>5.2.10.RELEASE</version>\n    </dependency>\n    <!-- aop织入包 -->\n    <dependency>\n      <groupId>org.aspectj</groupId>\n      <artifactId>aspectjweaver</artifactId>\n      <version>1.9.4</version>\n    </dependency>\n    <dependency>\n      <groupId>org.mybatis</groupId>\n      <artifactId>mybatis-spring</artifactId>\n      <version>2.0.5</version>\n    </dependency>\n  </dependencies>\n```\n\n2. 编写配置文件\n\n3. 测试\n\n### 12.1 回顾mybatis\n\n连接数据库：右侧边栏：Database打开数据库栏；+号点Data Source; 选择MySQL\n\n![image-20210419192943451](../img/spring/12.1_0.png)\n\n1. 编写实体类 User.java\n\n```java\npackage com.ahulearn.pojo;\n\npublic class User {\n    private int id;\n    private String name;\n    private String pwd;\n\n    @Override\n    public String toString() {\n        return \"User{\" +\n                \"id=\" + id +\n                \", name='\" + name + '\\'' +\n                \", pwd='\" + pwd + '\\'' +\n                '}';\n    }\n}\n```\n\n\n\n2. 编写核心配置文件: mybatis-config.xml\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<!DOCTYPE configuration\n        PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\"\n        \"http://mybatis.org/dtd/mybatis-3-config.dtd\">\n\n<!--核心配置文件-->\n<configuration>\n    <typeAliases>\n        <package name=\"com.ahulearn.pojo\"/>\n    </typeAliases>\n    <environments default=\"development\">\n        <environment id=\"development\">\n            <transactionManager type=\"JDBC\"/>\n            <dataSource type=\"POOLED\">\n                <property name=\"driver\" value=\"com.mysql.jdbc.Driver\"/>\n                <property name=\"url\" value=\"jdbc:mysql://localhost:3306/mybatis?useSSL=false&amp;serverTimezone=UTC\"/>\n                <property name=\"username\" value=\"root\"/>\n                <property name=\"password\" value=\"shenhuo\"/>\n            </dataSource>\n        </environment>\n    </environments>\n    <!--每一个Mpapper.xml都需要在Mybatis核心配置文件中注册！-->\n    <mappers>\n        <!--resource方式，指定路径-->\n        <!--<mapper resource=\"com/ahulearn/mapper/UserMapper.xml\"/>-->\n        <!--class方式，xml和class同名且放在同一个目录下-->\n        <mapper class=\"com.ahulearn.mapper.UserMapper\"/>\n    </mappers>\n</configuration>\n```\n\n\n\n3. 编写接口: UserMapper.java\n\n```java\npackage com.ahulearn.mapper;\n\nimport com.ahulearn.pojo.User;\nimport java.util.List;\n\npublic interface UserMapper {\n    public List<User> selectUser();\n}\n```\n\n\n\n4. 编写指令配置：UserMapper.xml\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<!DOCTYPE mapper\n        PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"\n        \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\">\n<!--namespace绑定一个对应的Dao/Mapper接口-->\n<mapper namespace=\"com.ahulearn.mapper.UserMapper\">\n    <!--select查询语句\n        id: 对应接口中的方法名\n        返回结果: 完整路径类名, resultType，resultMap\n    -->\n    <select id=\"selectUser\" resultType=\"user\">\n        select * from mybatis.user;\n    </select>\n</mapper>\n```\n\n\n\n5. 测试\n\n```java\nimport com.ahulearn.mapper.UserMapper;\nimport com.ahulearn.pojo.User;\nimport org.apache.ibatis.io.Resources;\nimport org.apache.ibatis.session.SqlSession;\nimport org.apache.ibatis.session.SqlSessionFactory;\nimport org.apache.ibatis.session.SqlSessionFactoryBuilder;\nimport org.junit.Test;\n\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.util.List;\n\npublic class MyTest {\n    @Test\n    public void test() throws IOException {\n        String resource = \"mybatis-config.xml\";\n        InputStream in = Resources.getResourceAsStream(resource);\n        SqlSessionFactory sessionFactory = new SqlSessionFactoryBuilder().build(in);\n        SqlSession sqlSession = sessionFactory.openSession(true);\n\n        UserMapper mapper = sqlSession.getMapper(UserMapper.class);\n        List<User> userList = mapper.selectUser();\n        for (User user : userList) {\n            System.out.println(user);\n        }\n    }\n}\n```\n\n\n\n### 12.2 Spring整合mybatis方式一\n\n+ 保留上方回顾mybatis中的 `com.ahulearn.pojo.User`、`com.ahulearn.mapper.UserMapper`、`com.ahulearn.mapper.UserMapper.xml`\n\n\n\n1. 配置数据源替换mybaits的数据源: `spring-mapper.xml`\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       http://www.springframework.org/schema/beans/spring-beans.xsd\">\n\n    <!--DataSource: 这里使用Spring的数据源替换Mybatis配置，可以使用其他任意数据源：c3p0 dbcp druid-->\n    <bean id=\"dataSource\" class=\"org.springframework.jdbc.datasource.DriverManagerDataSource\">\n        <property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"/>\n        <property name=\"url\" value=\"jdbc:mysql://localhost:3306/mybatis?useSSL=false&amp;serverTimezone=UTC\"/>\n        <property name=\"username\" value=\"root\"/>\n        <property name=\"password\" value=\"shenhuo\"/>\n     </bean>\n</beans>\n```\n\n原mybatis配置文件简化为下面的形式：`mybatis-config.xml`\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<!DOCTYPE configuration\n        PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\"\n        \"http://mybatis.org/dtd/mybatis-3-config.dtd\">\n\n<!--核心配置文件-->\n<configuration>\n    <typeAliases>\n        <package name=\"com.ahulearn.pojo\"/>\n    </typeAliases>\n    <!--使用spring环境不需要再配置dataSource和mapper-->\n</configuration>\n```\n\n\n\n2. sqlSessionFactory：beans.xml中\n\n```xml\n\t<!--sqlSessionFactory: 工厂-->\n    <bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\">\n        <property name=\"dataSource\" ref=\"dataSource\" />\n        <!---绑定mybatis配置文件-->\n        <property name=\"configLocation\" value=\"classpath:mybatis-config.xml\" />\n        <!---相当于mybatis-config.xml中的mapper-->\n        <property name=\"mapperLocations\" value=\"classpath:com/ahulearn/mapper/*.xml\"/>\n    </bean>\n```\n\n\n\n3. sqlSessionTemplate：beans.xml中\n\n```xml\n \t<!--SqlSession模板-->\n    <bean id=\"sqlSession\" class=\"org.mybatis.spring.SqlSessionTemplate\">\n        <!--没有set方法，只能用构造器注入-->\n        <constructor-arg index=\"0\" ref=\"sqlSessionFactory\"/>\n    </bean>\n```\n\n\n\n4. 接口实现类: UserMapperImpl\n\n```java\npackage com.ahulearn.mapper;\n\nimport com.ahulearn.pojo.User;\nimport org.mybatis.spring.SqlSessionTemplate;\n\nimport java.util.List;\n\npublic class UserMapperImpl implements UserMapper {\n    //在原来所有操作，都使用sqlSession来执行；现在换成使用SqlSessionTemplate\n    private SqlSessionTemplate sqlSession;\n    public void setSqlSession(SqlSessionTemplate sqlSession) {\n        this.sqlSession = sqlSession;\n    }\n    @Override\n    public List<User> selectUser() {\n        UserMapper mapper = sqlSession.getMapper(UserMapper.class);\n        return mapper.selectUser();\n    }\n}\n```\n\n\n\n5. 将实现类注入到Spring中\n\n```xml\n \t<!--注入接口实现类，执行的sql语句-->\n    <bean id=\"userMapper\" class=\"com.ahulearn.mapper.UserMapperImpl\">\n        <property name=\"sqlSession\" ref=\"sqlSession\"/>\n    </bean>\n```\n\n\n\n6. 测试使用\n\n```java\n    //使用mybatis-spring\n    @Test\n    public void testSpring() throws IOException {\n        ApplicationContext context = new ClassPathXmlApplicationContext(\"spring-mapper.xml\");\n\n        UserMapper userMapper = context.getBean(\"userMapper\", UserMapper.class);\n        List<User> userList = userMapper.selectUser();\n        for (User user : userList) {\n            System.out.println(user);\n        }\n\n    }\n```\n\n\n\n### 12.3 Spring整合mybatis方式二\n\n1. 修改UserMapperImpl\n\n```java\npackage com.ahulearn.mapper;\n\nimport com.ahulearn.pojo.User;\nimport org.apache.ibatis.session.SqlSession;\nimport org.mybatis.spring.support.SqlSessionDaoSupport;\n\nimport java.util.List;\n\npublic class UserMapperImpl2 extends SqlSessionDaoSupport implements UserMapper {\n    public List<User> selectUser() {\n        SqlSession sqlSession = getSqlSession();\n        UserMapper mapper = sqlSession.getMapper(UserMapper.class);\n        return mapper.selectUser();\n    }\n}\n```\n\n\n\n2. 修改beans.xml\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n       http://www.springframework.org/schema/beans/spring-beans.xsd\">\n\n    <!--DataSource: 使用Spring的数据源替换Mybatis配置，其他数据源：c3p0 dbcp druid-->\n    <bean id=\"dataSource\" class=\"org.springframework.jdbc.datasource.DriverManagerDataSource\">\n        <property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"/>\n        <property name=\"url\" value=\"jdbc:mysql://localhost:3306/mybatis?useSSL=false&amp;serverTimezone=UTC\"/>\n        <property name=\"username\" value=\"root\"/>\n        <property name=\"password\" value=\"shenhuo\"/>\n     </bean>\n\n    <!--sqlSessionFactory: 工厂-->\n    <bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\">\n        <property name=\"dataSource\" ref=\"dataSource\" />\n        <!---绑定mybatis配置文件-->\n        <property name=\"configLocation\" value=\"classpath:mybatis-config.xml\" />\n        <!---相当于mybatis-config.xml中的mapper-->\n        <property name=\"mapperLocations\" value=\"classpath:com/ahulearn/mapper/*.xml\"/>\n    </bean>\n    \n    <!--不再需要注入sqlSessionTemplate，直接获取sqlSession-->\n    <bean id=\"userMapper2\" class=\"com.ahulearn.mapper.UserMapperImpl2\">\n        <!--配置sqlSessionFactory-->\n        <property name=\"sqlSessionFactory\" ref=\"sqlSessionFactory\"/>\n    </bean>\n\n</beans>\n```\n\n\n\n3. 测试\n\n```java\n    @Test\n    public void testSpring2(){\n        ApplicationContext context = new ClassPathXmlApplicationContext(\"beans.xml\");\n        UserMapper mapper = (UserMapper) context.getBean(\"userMapper2\");\n        List<User> userList = mapper.selectUser();\n        for (User user : userList) {\n            System.out.println(user);\n        }\n    }\n```\n\n\n\n## 13. 声明式事务\n\n### 1. 回顾事务\n\n+ 把一组业务当成一个业务来做，要么都成功，要么失败\n+ 事务在项目开发中，十分重要，涉及到数据的一致性问题！\n+ 确保完整行和一致性\n\n**事务四个属性ACID**\n\n1. 原子性（atomicity）\n\n2. - 事务是原子性操作，由一系列动作组成，事务的原子性确保动作要么全部完成，要么完全不起作用\n\n3. 一致性（consistency）\n\n4. - 一旦所有事务动作完成，事务就要被提交。数据和资源处于一种满足业务规则的一致性状态中\n\n5. 隔离性（isolation）\n\n6. - 可能多个事务会同时处理相同的数据，因此每个事务都应该与其他事务隔离开来，防止数据损坏\n\n7. 持久性（durability）\n\n8. - 事务一旦完成，无论系统发生什么错误，结果都不会受到影响。通常情况下，事务的结果被写到持久化存储器中\n\n \n\n### 2. spring 中的事务管理\n\nSpring在不同的事务管理API之上定义了一个抽象层，使得开发人员不必了解底层的事务管理API就可以使用Spring的事务管理机制。Spring支持编程式事务管理和声明式的事务管理。\n\n**编程式事务管理**\n\n- 将事务管理代码嵌到业务方法中来控制事务的提交和回滚\n- 缺点：必须在每个事务操作业务逻辑中包含额外的事务管理代码\n\n**声明式事务管理**\n\n- 一般情况下比编程式事务好用。\n- 将事务管理代码从业务方法中分离出来，以声明的方式来实现事务管理。\n- 将事务管理作为横切关注点，通过aop方法模块化。Spring中通过Spring AOP框架支持声明式事务管理。\n\n**使用Spring管理事务，注意头文件的约束导入 : tx**\n\n```xml\nxmlns:tx=\"http://www.springframework.org/schema/tx\"\n\nxsi:schemaLocation=\"http://www.springframework.org/schema/tx\nhttp://www.springframework.org/schema/tx/spring-tx.xsd\">\n```\n\n导入aop\n\n```xml\nxmlns:aop=\"http://www.springframework.org/schema/aop\"\nxsi:schemaLocation=\"http://www.springframework.org/schema/tx\n   http://www.springframework.org/schema/tx/spring-tx.xsd\"\n```\n\n\n\n**事务管理器**\n\n- 无论使用Spring的哪种事务管理策略（编程式或者声明式）事务管理器都是必须的。\n- 就是 Spring的核心事务管理抽象，管理封装了一组独立于技术的方法。\n\n**JDBC事务**\n\n```XML\n<!--配置声明式事务-->\n<bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\">\n    <property name=\"dataSource\" ref=\"dataSource\" />\n</bean>\n```\n\n**配置好事务管理器后我们需要去配置事务的通知**\n\n```XML\n<!--配置事务通知-->\n<tx:advice id=\"txAdvice\" transaction-manager=\"transactionManager\">\n   <tx:attributes>\n       <!--配置哪些方法使用什么样的事务,配置事务的传播特性-->\n       <tx:method name=\"add\" propagation=\"REQUIRED\"/>\n       <tx:method name=\"delete\" propagation=\"REQUIRED\"/>\n       <tx:method name=\"update\" propagation=\"REQUIRED\"/>\n       <tx:method name=\"search*\" propagation=\"REQUIRED\"/>\n       <tx:method name=\"get\" read-only=\"true\"/>\n       <tx:method name=\"*\" propagation=\"REQUIRED\"/>\n   </tx:attributes>\n</tx:advice>\n```\n\n**spring事务传播特性：**\n\n事务传播行为就是多个事务方法相互调用时，事务如何在这些方法间传播。spring支持7种事务传播行为：\n\n- propagation_requierd：如果当前没有事务，就新建一个事务，如果已存在一个事务中，加入到这个事务中，这是最常见的选择。\n- propagation_supports：支持当前事务，如果没有当前事务，就以非事务方法执行。\n- propagation_mandatory：使用当前事务，如果没有当前事务，就抛出异常。\n- propagation_required_new：新建事务，如果当前存在事务，把当前事务挂起。\n- propagation_not_supported：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。\n- propagation_never：以非事务方式执行操作，如果当前事务存在则抛出异常。\n- propagation_nested：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与propagation_required类似的操作\n\nSpring 默认的事务传播行为是 PROPAGATION_REQUIRED，它适合于绝大多数的情况。\n\n假设 ServiveX#methodX() 都工作在事务环境下（即都被 Spring 事务增强了），假设程序中存在如下的调用链：Service1#method1()->Service2#method2()->Service3#method3()，那么这 3 个服务类的 3 个方法通过 Spring 的事务传播机制都工作在同一个事务中。\n\n就好比，我们刚才的几个方法存在调用，所以会被放在一组事务当中！\n\n\n\n**配置AOP**\n\n导入aop的头文件！\n\n```XML\n<!--配置aop织入事务-->\n<aop:config>\n    <aop:pointcut id=\"txPointcut\" expression=\"execution(* com.ahulearn.mapper.*.*(..))\"/>\n    <aop:advisor advice-ref=\"txAdvice\" pointcut-ref=\"txPointcut\"/>\n</aop:config>\n```\n\n**进行测试**\n\n删掉刚才插入的数据，再次测试！\n\n```java\n@Test\npublic void test2(){\n   ApplicationContext context = new ClassPathXmlApplicationContext(\"beans.xml\");\n   UserMapper mapper = (UserMapper) context.getBean(\"userDao\");\n   List<User> user = mapper.selectUser();\n   System.out.println(user);\n}\n```\n\n为什么需要配置事务？\n\n- 如果不配置，就需要我们手动提交控制事务；\n- 事务在项目开发过程非常重要，涉及到数据的一致性的问题，不容马虎！","comments":true,"categories":[],"tags":[{"name":"CS","slug":"CS","permalink":"http://blog.ahulearn.com/tags/CS/"},{"name":"JAVA","slug":"JAVA","permalink":"http://blog.ahulearn.com/tags/JAVA/"},{"name":"Spring","slug":"Spring","permalink":"http://blog.ahulearn.com/tags/Spring/"}]},{"title":"JAVA学习路线","date":"2022-06-27T10:00:00.000Z","path":"2022/06/27/JAVA学习路线/","raw":"---\ntitle: JAVA学习路线\ndate: 2022-06-27 18:00:00\ntags:\n - CS\n - JAVA\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\\javapath\n---\n\n\n# CodeSheep\n参考视频：https://www.bilibili.com/video/BV1GQ4y1N7HD\n\n相关思维导图：https://www.processon.com/view/link/5eb6a1b0e401fd16f4283225\n\n## 编程基础（掌握）\n### JAVA语法\n#### Java基础\n\n####  JVM\n- 类加载机制\n- 字节码执行机制\n- JVM内存模型\n- GC垃圾回收\n- JVM性能监控与故障定位\n- JVM调优\n\n#### 多线程\n- 并发编程的基础\n- 线程池\n- 锁\n- 并发容器\n- 原子类\n- JUC并发工具类\n\n<!--more-->\n\n\n### 数据结构和算法\n\n#### 数据结构\n- 字符串\n- 数组\n- 链表\n- 堆、栈、队列\n- 二叉树\n- 哈希\n- 图\n\n#### 算法\n- 排序\n- 查找\n- 贪心\n- 分治\n- 动态规划\n- 回溯\n\n### 计算机网络\n\n- ARP协议\n- IP、ICMP协议\n- TCP、UDP协议\n- DNS、HTTP/HTTPS协议\n- Session/Cookie\n\n### MySQL数据库\n\n- SQL语句的书写\n- SQL语句的优化\n- 事务、隔离级别\n- 索引\n- 锁\n\n### 操作系统\n\n- 进程、线程\n- 并发、锁\n- 内存管理和调度\n- I/O原理\n\n### 设计模式\n\n- 单例\n- 工厂\n- 代理\n- 策略\n- 模板方法\n- 观察者\n- 适配器\n- 责任链\n- 建造者\n\n\n\n## 研发工具\n### 集成开发环境\n- Eclipse\n- Intellij IDEA\n- VSCode\n\n### Linux系统（了解）\n- 常用命令\n- Shell脚本### 项目管理/构建工具（掌握）\n- Maven\n- Gradle### 代码管理工具（了解）\n- SVN\n- Git\n\n\n### 前端（了解）\n- 基础套餐（大致了解，2-3天）\n\t- 三大件\n\t\t- HTML\n\t\t- JavaScript\n\t\t- CSS\n\t- 基础库\n\t\t- jQuery\n\t\t- Ajax\n- 模板框架\n\t- JSP/JSTL（已过时）\n\t- Thymeleaf\n\t- FreeMarker\n- 组件化框架\n\t- Vue\n\t- React\n\t- Angular\n-----------------------------------------------\n\n## 运维知识（配置）\n- Web服务器\n\t- Nginx\n- 应用服务器\n\t- Tomcat\n\t- Jetty\n\t- Undertow\n- CDN加速\n- 持续集成/持续部署\n\t- Jenkins\n- 代码质量检查\n\t- sonar\n- 日志收集和分析\n\t- ELK\n\n\n-----------------------------------\n\n\n\n## 成神之路\n\n- 徒手撕源码\n- 光脚造轮子\n- 闭着眼睛深度调优\n- 吊打面试官\n\n-----------------------------------------------\n\n\n\n## 平稳降落\n\n调整心态、注意健康，飞的多高不重要，重要的是如何平望降落。\n\n\n\n\n\n# 韩顺平版\n\n参考视频：https://www.bilibili.com/video/BV14K4y177Qk\n\n东西很多，慢慢学，学完前5个阶段就可以找工作\n\n## 1、JAVA基础\n\n+ 数据类型\n+ 流程控制\n  + 顺序结构\n  + 分支结构\n  + 循环结构\n+ OOP\n  + 封装\n  + 继承\n  + 多态\n+ 数组\n+ JavaAPI：学会查看文档\n+ 异常和处理\n+ 集合\n+ 泛型\n+ IO\n+ 反射\n+ 网络通信\n\n## 2、Java高级\n\n+ **Java多线程/高并发**\n+ 并发基础\n    + 互斥同步\n    + 非阻塞同步\n    + 指令墨棑\n    + synchronized\n    + volatile\n  + 线程\n  + 锁\n    + 自旋锁\n    + 偏向锁\n    + 可重入锁\n  + 线程锁\n  + 并发容器\n  + JUC\n    + executor\n    + collections\n    + locks\n    + atomic(原子类)\n    + tools(CountDownLatch、Exchanger、ThreadLocal、CyclicBarrier)\n+ **数据结构和算法**\n+ 数据结构\n  \n  + 数组(稀疏数组)\n    + 队列\n    + 栈\n    + 链表\n    + 树\n    + 散列表\n    + 堆\n    + 图\n  \n+ 算法\n  \n  + **排序(8种)**\n+ 查找\n    + 分治\n+ **动态规划(背包问题)**\n    + **回溯(骑士周游问题)**\n+ **贪心算法**\n    + KMP\n+ Prim-普里姆最小生成树算法\n    + Kruskal-克鲁斯卡尔最小生成树算法\n+ Floyd-弗洛伊德最短路径算法\n    + Dijkstra-迪杰斯特拉最短路径算法\n+ 设计模式(23种)\n    + 单例模式\n    + 观察者模式\n    + 工厂模式\n    + 适配器模式\n    + 装饰器模式\n    + 代理模式\n    + 模板模式\n    + 职责链模式\n    + 其他(组合模式，桥接模式，原型模式，...)\n+ **JVM**\n    + JVM体系\n    + 类加载过程/机制\n    + 双亲委派机制/沙箱安全机制\n    + JMM(java内存模式)\n    + 字节码执行过程/机制\n    + GC(垃圾回收算法)\n    + JVM性能监控和故障定位\n    + JVM调优\n\n\n\n## 3、JavaWEB\n\n+ 前端基础\n  + HTML\n  + CSS\n  + JavaScript\n  + Ajax\n  + Jquery\n+ 前端框架（了解）\n  + VUE\n  + React\n  + Angular\n  + bootstrap\n  + Node.js\n+ Java web后端\n  + Tomcat\n  + Servlet\n  + JSP\n\n\n\n## 4、主流框架和项目管理\n\n+ Linux(操作系统的使用，必学)\n\n+ Nginx(做反向代理的WEB服务器)\n\n+ **SSM**\n\n  + Spring(轻量级的容器框架)\n  + SpringMVC(分层的web开发框架)\n  + MyBatis(持久层的框架)\n\n+ 项目管理\n\n  + Maven\n  + Git、Github\n  + *SVN*\n\n+ **数据库**\n  + MySQL\n  + Redis\n  + Oracle\n+ 其他框架\n  + WebService(即SOA)\n  + Activiti(工作流框架。引擎)\n  + Shiro(安全框架)\n  + Spring Security(安全框架)\n  + JPA(持久化)\n  + SpringData(持久层的通用解决解决方案)\n\n\n\n## 5、分布式 微服务 并行框架\n\n+ **Netty**\n\n  ​\t初始了解：https://www.jianshu.com/p/b9f3f6a16911\n\n+ Dubbo(RPC框架)\n\n+ FastDFS(分布式文件系统)\n\n+ Docker(应用容器引擎)\n\n+ **Spring家族**\n  + SpringBoot\n  + SpringCloud(组件很多)\n    + Nacos(阿里巴巴 服务发现、配置、管理)\n    + Seata(阿里巴巴 分布式事务中间件)\n    + Sentinel(阿里巴巴 流量控制 熔断 负载保护)\n    + GateWay(网关、限流、日志、监控、鉴权)\n    + OpenFeign(服务间调用)\n  \n+ 搜索引擎\n  + ElasticSearch\n  + Solr\n  \n+ **中间件**\n  + MyCat(数据库，分库分表)\n\n    了解参考：https://www.cnblogs.com/kingsonfu/p/10627802.html\n\n  + 消息中间件\n    + ActiveMQ\n    + RabbitMQ\n    + Kafka\n\n+ 日志分析与监控(ELK)\n  + ElasticSearch(搜索，存储数据)\n  + LogStash(分析日志)\n  + Kibana(可视化)\n  \n+ Zookeeper(一致性服务：配置维护、域名维护、分布式同步)\n\n\n\n## 6、DevOps(开发运维一体化，自动化项目部署管理，CI/CD)\n\n+ k8s(让部署容器化应用简单高效)\n+ Prometheus(普罗米修斯：系统监控和报警)\n+ Jenkins(监控持续的工作：部署、集成、交付)\n+ Harbor(容器的镜像仓库)\n+ GitLab\n+ 项目工程代码质量检测(sonarqube)\n\n\n\n## 7、大数据技术(了解)\n\n+ Hadoop\n+ Hive\n+ Impals\n+ spark\n+ flink\n\n\n\n## 8、项目：应用之前学的技术，做三个以上\n\n+ 电商：https://github.com/macrozheng/mall\n+ 金融：\n+ 教育\n+ 直播\n+ CRM, ERP\n\n\n\n## 9、大厂高频面试题\n\n+ 上面加黑部分：主要包括JAVA高级、主流框架、项目\n\n\n\n## 10、底层源码、内核研究\n\n\n\n## 11、编程基础扩展\n\n+ 计算机网络\n+ 操作系统\n+ 计算机组成原理\n+ 编译原理\n+ 离散数学\n+ 数值分析\n+ 汇编语言\n\n\n\n","comments":true,"categories":[],"tags":[{"name":"CS","slug":"CS","permalink":"http://blog.ahulearn.com/tags/CS/"},{"name":"JAVA","slug":"JAVA","permalink":"http://blog.ahulearn.com/tags/JAVA/"}]},{"title":"毫米波雷达","date":"2021-10-07T05:19:00.000Z","path":"2021/10/07/mmWave Radar/","raw":"---\ntitle: 毫米波雷达\ndate: 2021-10-07 13:19:00\ntags:\n - mmWave\n - other\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\\mmWave\n---\n\n毫米波雷达-AWR2243\n ---\n\n## 简介\n\n毫米波雷达，是工作在毫米波波段（Millimeter Wave ）探测的雷达。通常毫米波是指30～300GHz频域(波长为1～10mm)的。毫米波的波长介于微波和厘米波之间，因此毫米波雷达兼有微波雷达和光学雷达的一些优点。\n\n同厘米波雷达相比，毫米波雷达具有体积小、质量轻和空间分辨率高的特点。与红外、激光、电视等光学雷达相比，毫米波雷达穿透雾、烟、灰尘的能力强，具有全天候(大雨天除外)全天时的特点。另外，毫米波雷达的抗干扰、反隐身能力也优于其他微波雷达 。毫米波雷达能分辨识别很小的目标，而且能同时识别多个目标；具有成像能力，体积小、机动性和隐蔽性好，在战场上生存能力强 。\n\n目前在自动驾驶，智能监控领域广泛运用。毫米波雷达能直接获取目标的距离，速度，角度等基本信息。通过对数据的进一步处理，对目标的尺寸，轮廓可能也有一定的估计能力。\n\n<!--more-->\n\n\n\n## 1 调频连续波(FMCW)\n\n调频连续波(Frequency-Modulated Continuous Wave)，是一组幅值不变，但频率变化的连续波形，毫米波雷达使用的调频连续波是频率线性增加的正弦波，又叫线性调频连续波。\n\n如下图的蓝色波形所示，横坐标是时间，横坐标是幅度，波的频率从起始频率逐渐增加到截至频率。这个过程称为一个Chirp(脉冲，啁啾)。\n\n下方红色图，横坐标是时间，纵坐标是频率，更能直观的看出在每个Chirp中频率在线性增加，之后经过一个空闲时间迅速降到起始频率，开始下一个Chirp。\n\n![FMCW](/img/mmWave/clip_image001.png)\n\n\n\n### 1.1、为什么毫米波雷达使用FMCW\n\n由于线性调频波频率是随时间变化的，当毫米波发射出去，被远处的物体反射回来，可以很容易的根据回波的频率判断出波从发射到接收所经过的时间，从而根据电磁波的传播速度估算物体的距离。\n\n很容易想到，能够测距离自然就能测速度，测量两次距离除以两次测量的时间就是速度。\n\n进一步分析，可以发现角度也是可以通过距离计算出来的，通过多个雷达对同一目标的距离测量，可以根据细微的距离差，计算出目标的角度。\n\n以上只是简单说明毫米波雷达测量距离，速度，角度的基本原理，下面将详细介绍雷达工作的各个细节，以及如何来设计FMCW，来满足自己对距离，速度，角度的分辨率要求，最大测量范围要求。\n\n### 1.2、FMCW的基本参数\n\n![FMCW](/img/mmWave/TDM_MIMO_chirp_config.jpg)\n\n$chirp$：调频连续波信号。\n\n$startFreq$：起始频率(GHz)。\n\n$idleTime$：chirp与chirp之间的空闲时间(us)。\n\n$rampEndTime$：调频时间(斜坡周期)，信号从起始频率上升到截止频率的时间(us)。\n\n$T_c$ ：chirp总周期，等于 空闲时间+调频时间，即：$T_c = idleTime + rampEndTime$。\n\n$freqSlop(S)$：调频连续波的频率变化斜率(MHz/us)。\n\n$ADCSamples(N)$：数模转换采样数，后期数据处理需要使用的采样数据。\n\n$sampleRate(F_s)$：数模转换采样速率(ks/s)。\n\n$ADCSamplingTime(T_s)$：数模转换采样时间，等于 采样数/采样速率，即 $T_s = N/F_s, ADCSamplingTime = ADCSamples/sampleRate$。\n\n$B$：采样带宽，$B = S * T_s = S * N/F_s =  freqSlop * ADCSamples/sampleRate$\n\n$periodicity(T_s)$：帧时长，一个帧由多个chirp组成(ms)。\n\n\n\n上面各参数的名称为代码中常使用的命名方式，括号内的简写便于后面推导公式使用。\n\n\n\n### 1.2、距离\n\n雷达的基本构造如下图所示：1. 频率合成器；2. 发射雷达；3. 接收雷达；4.混频器。\n\n频率合成器用于生产线性调频波(FMCW)，之后通过发射雷达发射，雷达信号被目标反射后通过接收雷达接收信号，之后通过混频器生成发射信号和接收信号的差频信号(IF信号)。\n\n![image-20211007164131025](/img/mmWave/image-20211007164131025.png)\n\n差频信号(IF信号)的频率和距离正相关，如果距离为0，信号发射出去后立即反射接收，差频信号(IF信号)频率为0，距离越远，差频信号(IF信号)的频率越高。\n\n推导距离与IF信号的关系表达式：\n\n调频连续波斜率变化为 $S$，信号发射到接收的时间为 $\\Delta t$，IF信号的频率为：$f_{IF} = S * \\Delta t$，式中$\\Delta t$即电磁波传播的时间，所有 $\\Delta t = 2*d/c$ ，其中c是光速：$3.0 * 10^8$。\n\n$f_{IF} = S * 2 * d / c => d = \\frac{f_{IF} *c }{2 * S}$\n\n#### 1.2.1 最大距离\n\n最大距离取决于，IF信号的最大频率 $f_{IF\\_max}$，这取决于系统的硬件参数。一般毫米波雷达的的最大距离约200米左右。\n\n\n\n#### 1.2.2 距离分辨率\n\n距离分辨率，同样取决于$f_{IF}$的分辨率。前面分析我们很容易计算出来距离与IF信号的关系。但真实情况下往往前方不止一个目标，接收到的回波信号是多种频率波的叠加。分析叠加信号的频率，可以通过傅里叶变换，把接收的时域信号在频域展开。对于离散的采样数据，通常使用快速傅里叶变换(FFT)。\n\n傅里叶变换的频率分辨率与采样时间$T_c$成反比：$\\Delta f = 1/T_c$，带入距离公式：\n\n$$\\Delta f_{IF} = S * 2 * \\Delta d / c >= 1/T_c => \\Delta d >= \\frac{c}{2 * S *T_c}$$\n\n式中$S$是斜波斜率，$T_c$是采样时间，所有$S * T_C = B$，是采样带宽。\n\n综上，距离分辨率：\n\n$$\\Delta d = \\frac{c}{2 * B}$$\n\n可以知道，距离分辨率与带宽成反比，带宽越高，距离分辨率越小。\n\n\n\n### 1.3、速度\n\n根据多普勒效应，机械波满足如下公式，其中：$f'$是接收到的频率；$f$是发射源于该介质中的原始频率；$v$ 是波在该介质的传播速度；$v_0$是接收者的移动速度； $v_s$是发射源的移动速度；\n\n$f' = (\\frac{v +- v_0}{v-+v_s})f$\n\n但对于电磁波，多普勒效应更加复杂，且物体的运动速度一般相对光速几乎可忽略不计，因此不易通过频率频率获取目标速度。\n\n速度的估算，正如基本原理所介绍的那样，是通过测量距离的变化估算的。\n\n距离的变化，可以通过相位判断。对速度估算，需要发射一组N个等间隔的线性调频脉冲(chirp)，称为**帧(Frame)**，通过分析一帧内每个chirp的相位变化，估算速度。\n\n距离变化与相位变化的关系： 最简单的假设，一个初始相位为0的毫米波波射向距离为0的物体，回波的相位也是0，射向距离1/8波长的物体，回波的相位是 $2 * 1/8 * 2π$；同理一个波在某一时刻 $t0$ 射向距离为 d 的物体，下个时刻 $t0 + T_c$  射向 $d+Δd$ 的物体，遵循同样的规律，$Δω = 2* Δd/\\lambda * 2\\pi $，这里虽然是线性调频波，波长在变化，但是由于波长的变化量相对起始波长相差至少一个数量级，所有可以忽略不记，可以任务相位变化是和频率无关的。  \n\n又因为 $\\Delta d = v * T_c$，所以可得速度估算公式：\n\n$$Δω = \\frac{2 * v* T_c }{\\lambda} * 2\\pi = \\frac{4\\pi * v * T_c}{\\lambda} => v = \\frac{Δω * \\lambda}{4\\pi * T_c}$$\n\n\n\n#### 1.3.1 最大速度\n\n最大速度取决于最大相位角，为了不造成歧义，约定 $|Δ\\omega|<π$，大于0是远离，小于0是接近。\n\n所以有：$|Δ\\omega| = |\\frac{4\\pi * v * T_c}{\\lambda}| < \\pi => v< \\frac{λ}{4T_c}$\n\n即物体运动的最大速度不能超过$\\frac{λ}{4T_c}$，式中$\\lambda$ 是波长，$T_c$是是chirp总周期。(如果$T_c$容易搞混，可以考虑物体在 chirp的空闲时间或者不采样时也是运动的，所以是除chirp总周期，不是斜坡时间，也不是采样时间)\n\n\n\n#### 1.3.2 速度分辨率\n\n速度分辨率同样取决于相位角频率 $\\Delta \\omega$的分辨率，因为接收的信号是多个物体的速度叠加，因此不能通过简单相位法得到速度。同样是通过快速傅里叶变换，将回波信号在频域展开，获取频率。\n\n快速傅里叶变换的分辨率：对于离散的相位角频率满足 $\\Delta \\omega >= 2 * \\pi /M(radians/samples)$，或者$\\Delta \\omega >= 1/M  (cycles/sample)$ 这里M是采样点数，即每帧的chirp数。\n\n可以看出离散数据的分辨率，和连续数据的分辨率形式上是非常相似的($\\Delta f = 1/T_c$)。离散数据和采样点数相关，连续数据和采样时间相关。\n\n速度分辨率推导过程：\n\n$\\Delta \\omega = 2*\\pi / M => \\frac{4\\pi * v * T_c}{\\lambda} = 2*\\pi / M => v = \\frac{\\lambda}{4\\pi * T_c * M} = \\frac{\\lambda}{2 * T_f} $\n\n\n\n### 1.4、角度\n\n角度的测量需要多个接收雷达，根据不同接收雷达接收信号的的微小距离差来评估角度。如下图所示，假设物体足够远(一般来说相对雷达的间距是足够远的)。发射雷达TX发射信号，接收雷达RX接收回波信号。RX1与RX2接收的信号是近似平行的。因此两者的信号传播距离差可以表示为：\n\n$\\Delta d = dsin(\\theta)$，这里d表示两个RX的距离。\n\n![image-20211007212649899](/img/mmWave/image-20211007212649899.png)\n\n由上一节速度评估的分析可知，距离差和相位之间相关。\n\n这里距离与相位的关系为：\n\n$\\Delta \\phi = \\frac{2\\pi \\Delta d} {\\lambda}$\n\n可以看到测角与测速的相位变化：$\\Delta \\phi = \\frac{4\\pi \\Delta d} {\\lambda}$，存在二倍关系，是因为测角时电磁波去的时候距离相同，只有来的时候有距离差。（ps：下图滥用了符合，d表示物体与雷达的距离，而不是上图两个接收雷达的间距）\n\n![角度](/img/mmWave/clip_image001-1633613217736.png)\n\n带入可得：\n\n$\\Delta \\phi = \\frac{2\\pi \\Delta d} {\\lambda} = \\frac{2\\pi dsin(\\theta)} {\\lambda}$\n\n即：$\\theta = arcsin(\\frac{\\lambda*\\Delta \\phi}{2\\pi d})$\n\n#### 1.4.1最大角度\n\n与最大速度类似，最大角度取决于两个雷达之间的最大相位角，为了不造成歧义，约定 $|Δ\\phi|<π$。可得：\n\n$|\\Delta \\phi| = \\frac{2\\pi dsin(\\theta)} {\\lambda} < \\pi => |\\theta| < arcsin(\\frac{\\lambda}{2d})$\n\n一般毫米波雷达的间距 $d = \\lambda/2$，所以 $|\\theta| < \\pi/2$。\n\n雷达的最大可视角度为 正负 90度。\n\n#### 1.4.2 角度分辨率\n\n角度分辨率也和速度分辨率类似，由于可能存在多个物体导致回波叠加，因此同样需要使用快速傅里叶变换对回波信号进行处理。而这里也是离散信号，采样点是接收雷达RX的个数。在速度估算时，我们说过离散信号的分辨率取决与采样点的个数，所以这里相位分辨率为：\n\n$\\Delta \\phi > 2\\pi/N$，式中N是接收雷达的个数。\n\n所以：\n\n$\\Delta \\phi = \\frac{2\\pi dsin(\\theta)} {\\lambda} > 2\\pi/N => \\theta > arcsin(\\frac{\\lambda}{Nd}) => \\theta > arcsin(\\frac{2}{N}) $\n\n上式Nd，就是雷达阵列的宽度，可见当波长一定时，雷达的角分辨率与雷达阵列尺寸有关，分辨率越大，需要的雷达阵列的尺寸就越大。由于一般 $d = \\lambda/2$ ，所以角度和接收雷达的个数相关。\n\n\n\n## 2 德州仪器(TI) 产品使用\n\n### 2.1 MIMO雷达\n\n### 2.2 AWR 2243\n\n### 2.3 DCA 1000\n\n### 2.4  mmWave Studio\n\n\n\n## 3 雷达数据的处理\n\n### 3.1、格式处理\n\nTI公司的毫米波雷达通常使用DCA 1000 或 TSW 1400进行数据采集，这里主要分析DCA 1000采集的数据格式。\n\n#### 3.1.1 使用DCA 1000采集的xWR12xx或xWR14xx实数数据格式\n\n![12xx和14xx only real](/img/mmWave/clip_image001-1633616770256.png)\n\n#### 3.1.2 使用DCA 1000采集的xWR12xx或xWR14xx复数数据格式\n\n![12xx和14xx Complex](/img/mmWave/clip_image001-1633617062210.png)\n\nmatlab行优先\n\npython列优先\n\n返回：(numLoopsPerFrame * numTxAntennas, numRxAntennas, numRangeBins)\n\n```python\ndef organize2243(raw_frame, num_chirps, num_rx, num_samples):\n    \"\"\"Reorganizes raw ADC data into a full frame\n\n        Args:\n            raw_frame (ndarray): Data to format\n            num_chirps: Number of chirps included in the frame\n            num_rx: Number of receivers used in the frame\n            num_samples: Number of ADC samples included in each chirp\n\n        Returns:\n            ndarray: Reformatted frame of raw data of shape (num_chirps, num_rx, num_samples)\n\n        \"\"\"\n    ret = np.zeros(len(raw_frame) // 2, dtype=complex)\n\n    # Separate IQ data \n    # [n_chirp, n_Rx, n_simples/2, 2, 2]->[n_chirps, n_RX, n_simples]\n    # AWR1243 [n_chirp, n_simples, 2, n_Rx] -> [n_chirps, n_simples, n_RX]\n    ret[0::4] = raw_frame[0::8] + 1j * raw_frame[4::8]\n    ret[1::4] = raw_frame[1::8] + 1j * raw_frame[5::8]\n    ret[2::4] = raw_frame[2::8] + 1j * raw_frame[6::8]\n    ret[3::4] = raw_frame[3::8] + 1j * raw_frame[7::8]\n    # 交换维度 [n_chirps, n_simples, n_RX] -> [n_chirps, n_RX, n_simples]\n    ret = ret.reshape((num_chirps, num_samples, num_rx))\n    ret = np.swapaxes(ret, 1, 2)\n\n    return ret.reshape((num_chirps, num_rx, num_samples))\n```\n\n\n\n#### 3.1.3 使用DCA 1000采集的xWR16xx或IWR6843实数数据格式\n\n![xWR16xx和IWR6843 only real](/img/mmWave/image-20211007223153410.png)\n\n#### 3.1.3 使用DCA 1000采集的xWR16xx或IWR6843复数数据格式\n\n![xWR16xx和IWR6843 Complex](/img/mmWave/clip_image001-1633617123112.png)\n\n返回：(numLoopsPerFrame * numTxAntennas, numRxAntennas, numRangeBins)\n\n```python\ndef organize(raw_frame, num_chirps, num_rx, num_samples):\n    \"\"\"Reorganizes raw ADC data into a full frame\n\n        Args:\n            raw_frame (ndarray): Data to format\n            num_chirps: Number of chirps included in the frame\n            num_rx: Number of receivers used in the frame\n            num_samples: Number of ADC samples included in each chirp\n\n        Returns:\n            ndarray: Reformatted frame of raw data of shape (num_chirps, num_rx, num_samples)\n\n        \"\"\"\n    ret = np.zeros(len(raw_frame) // 2, dtype=complex)\n\n    # Separate IQ data \n    # [n_chirp, n_Rx, n_simples/2, 2, 2]->[n_chirps, n_RX, n_simples]\n    ret[0::2] = raw_frame[0::4] + 1j * raw_frame[2::4]\n    ret[1::2] = raw_frame[1::4] + 1j * raw_frame[3::4]\n\n    return ret.reshape((num_chirps, num_rx, num_samples))\n    \n```\n\n\n\n\n\n分离TX数据\n\n(numLoopsPerFrame * numTxAntennas, numRxAntennas, numRangeBins) -> (numLoopsPerFrame, numTxAntennas * numRxAntennas, numRangeBins)\n\n```python\ndef separate_tx(signal, num_tx, vx_axis=1, axis=0):\n    \"\"\"Separate interleaved radar data from separate TX along a certain axis to account for TDM radars.\n    从单独的TX沿某一轴将交错的雷达数据分离，以描述TDM雷达。\n    Args:\n        signal (ndarray): Received signal.\n        (numChirpsPerFrame, numRxAntennas, numRangeBins)\n        num_tx (int): Number of transmit antennas.\n        vx_axis (int): Axis in which to accumulate the separated data.\n        用于累积分离数据的轴。\n        axis (int): Axis in which the data is interleaved.\n        数据交错的轴。\n\n    Returns:\n        ndarray: Separated received data in the\n\n    \"\"\"\n    # Reorder the axes\n    # 维度交换，将待处理的维度交换到第0维\n    reordering = np.arange(len(signal.shape))\n    reordering[0] = axis\n    reordering[axis] = 0\n    signal = signal.transpose(reordering)\n\n    # 因为发TX雷达是分时的，numChirpsPerFrame = numLoopsPerFrame * numTxAntennas\n    # 这里是先取出同一个TX雷达数据(numLoopsPerFrame, numRxAntennas, numRangeBins)，\n    # 将取出的数据，沿原本的RX轴，即vx_axis = 1的轴拼接 (numLoopsPerFrame, numTxAntennas * numRxAntennas, numRangeBins)\n    # 相当于 (numLoopsPerFrame * numTxAntennas, numRxAntennas, numRangeBins) ->\n    # (numLoopsPerFrame, numTxAntennas * numRxAntennas, numRangeBins)\n    # 感觉这里可以直接reshape，效果应该一样，因为展成一维，数据位置并没有变动\n    out = np.concatenate([signal[i::num_tx, ...] for i in range(num_tx)], axis=vx_axis)\n\n    return out.transpose(reordering)\n```\n\n\n\n### 3.2、距离\n\n```python\n## 加窗\nfft1d_in = np.hamming(frame.shape[-1])\nrangeBins = np.fft.fft(fft1d_in, axis=2)\n\n```\n\n\n\n### 3.3、速度\n\n```python\nfft2d_in = np.transpose(rangeBins, axes=(2, 1, 0))\nfft2d_in = np.hamming(fft2d_in.shape[-1])\nfft2d_out = np.fft.fft(fft2d_in, axis=-1)\nfft2d_out = np.fft.fftshift(fft2d_out, axes=-1)\nrange_doppler = np.transpose(fft2d_out, axes=(2, 1, 0))\nrange_doppler = range_doppler[:, 0, :]\n```\n\n\n\n### 3.4、角度\n\n```python\ndopplerBins = aoa_input\npadding = ((0, 0), (0, numAngleBins-dopplerBins.shape[1]), (0, 0))\n# (numRangeBins, numAzimuthBins， numDopplerBins)\nrange_azimuth = np.pad(dopplerBins, padding, mode='constant')\n\"\"\"\n数组填充：\n填充的数组：dopplerBins\n填充的形状：padding\n填充模式：constant 常量填充，默认0\n\"\"\"\nprint(range_azimuth.shape)\n# print(range_azimuth)  # (Range, azimuth, Doppler)\nrange_azimuth = np.fft.fft(range_azimuth, axis=1)\n```\n\n\n\n\n\n## 4 信号处理相关算法\n\n### 4.1 杂波去除\n\n### 4.2 目标检测\n\n### 4.3 目标追踪\n\n\n\n\n\n参考连接：\n\n+  https://www.zhihu.com/question/455439504/answer/1901513398\n\n相机数据是结构化的高分辨率图像数据，毫米波雷达原始数据则是角分辨率很低且没有高程信息的稀疏点云，这二者原始数据很难融合成一套输入给到神经网络模型，因此目前绝大多数方案都是使用后融合（松耦合）方案。\n\n+ https://zhuanlan.zhihu.com/p/92887546","comments":true,"categories":[],"tags":[{"name":"mmWave","slug":"mmWave","permalink":"http://blog.ahulearn.com/tags/mmWave/"},{"name":"other","slug":"other","permalink":"http://blog.ahulearn.com/tags/other/"}]},{"title":"Python入门","date":"2021-08-05T10:00:00.000Z","path":"2021/08/05/Python入门/","raw":"---\ntitle: Python入门\ndate: 2021-08-5 18:00:00\ntags:\n - CS\n - python\n\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\\python\n\n---\n\n\n\n# 1、环境配置\n\npython作为脚本语言，只需要一个python解释器就可以直接编写代码和运行。\n但是为了方便我们通常会使用IDE(集成开发环境)或轻量级的文本编辑器进行开发。\n这里首先介绍使用最简单的python编辑器编写代码，以及使用VS Code、Jupyter开发。\n\n<!--more-->\n\n## 1.1 安装python解释器\n\n这里推荐安装Conda,Conda是极其方便且强大的包管理器，安装后自带python解释器，同时为以后开发带来极大的便利。如果只想安装python解释器可以从下方地址下载：\n官网Windows下载：https://www.python.org/downloads/windows/\n\n## 1.2、安装Conda\n\nconda分为anaconda和miniconda。anaconda是包含一些常用包的版本，miniconda则是精简版，需要什么装什么，这里介绍miniconda的安装。\n官网地址：https://docs.conda.io/en/latest/miniconda.html\n\n### 1.2.1、安装\n\n进入官网：https://docs.conda.io/en/latest/miniconda.html\n\n+ Windows installers一栏就是Windows安装包\n+ Linux installers一栏就是Linux安装包\n\n选择对应的操作系统和conda版本即可。\n一般安装MiniConda3，python版本无所谓，3.x以上都可以，后面可以根据需要自行更改。\n\n安装完成后，检测是否正常：conda info -e\n\n### 1.2.2、配置\n\n执行如下命令，配置Miniconda\n\n### 1.2.3、常用命令参数\n\n``` bash\n查看虚拟环境： conda info -e\n激活虚拟环境：conda activate <env_name>\n\tactivate 后是虚拟环境名\n退出虚拟环境： conda deactivate\n删除虚拟环境：conda remove -n <env_name> --all\n安装某个软件到当前虚拟环境：conda install 包名 -y\n卸载当前虚拟环境中的某个软件包：conda uninstall 包名 -y\n安装某个软件包到指定虚拟环境中：conda install -n 虚拟环境名 包名 -y\n卸载指定虚拟环境中的某个软件包：conda uninstall -n 虚拟环境名 包名 -y\n```\n\n# 2、牛刀小试\n\n打开cmd命令行，输入`python`\n\n![image-20210805160322930](/img/python/image-20210805160322930.png)\n\n\n\n如果你是Windows10,可能会跳转到Win10应用商店，因为Win10中有一个python下载程序。\n可以通过 `where python`查看python程序\n\n![image-20210805160005211](/img/python/image-20210805160005211.png)\n\n下方这个`C:\\sun_app\\Anaconda\\python.exe`才是我们安装的python解释器，\n如果想运行这个程序，cmd命令行中输入`C:\\sun_app\\Anaconda\\python.exe`即可，`.exe`后缀可以省略。\n\n![image-20210805160533737](/img/python/image-20210805160533737.png)\n\n此时进入python命令行中，可以输入简单的python语句执行：\n\n\n```python\nprint(\"Hello World\")\n```\n\n    Hello World\n\n\n\n```python\na = 1\nb = 2\nprint(a+b)\n```\n\n    3\n\n\n在命令行中，只能执行一些简单命令。如果代码很长，可以将代码写入一个 `.py`后缀的文件中。通过 `python xxx.py` 执行。\n\n![image-20210805165404778](/img/python/image-20210805165404778.png)\n\n\n\n![image-20210805163940858](/img/python/image-20210805163940858.png)","comments":true,"categories":[],"tags":[{"name":"CS","slug":"CS","permalink":"http://blog.ahulearn.com/tags/CS/"},{"name":"python","slug":"python","permalink":"http://blog.ahulearn.com/tags/python/"}]},{"title":"从零开始的深度学习","date":"2021-07-28T10:46:00.000Z","path":"2021/07/28/从零开始的深度学习/","raw":"---\ntitle: 从零开始的深度学习\ndate: 2021-07-28 18:46:00\ntags:\n - 深度学习\n - 随笔\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\\deeplearnning\n---\n\n## 从零开始的深度学习\n\n### 主要内容：\n\n- 安装NVIDIA GPU驱动\n- 安装CUDA Toolkit\n- 安装cuDNN\n- 安装Conda(附带python)\n- 安装PyTorch\n- 安装TensorFlow\n\n# 一、工具介绍\n\n- NVIDIA GPU驱动：nvidia-smi是nvidia 的系统管理接口，一般安装NVIDIA GPU驱动后即可使用。\n- CUDA  Toolkit：CUDA（Compute Unified Device Architecture），是NVIDIA推出的运算平台，AMD也有类似的平台 [ROCm](https://zhuanlan.zhihu.com/p/67940936)，但并不成熟。 CUDA™是一种由NVIDIA推出的通用并行计算架构，该架构使GPU能够解决复杂的计算问题。 它包含了CUDA指令集架构（ISA）以及GPU内部的并行计算引擎。\n- cuDNN：NVIDIA cuDNN是用于深度神经网络的GPU加速库。它强调性能、易用性和低内存开销。NVIDIA cuDNN可以集成到更高级别的机器学习框架中，如Tensorflow、pytorch等。简单的插入式设计可以让开发人员专注于设计和实现神经网络模型，而不是简单调整性能，同时还可以在GPU上实现高性能现代并行计算。\n\n\n\n- Conda：Conda 是一个开源的软件包管理系统和环境管理系统，用于安装多个版本的软件包及其依赖关系，并在它们之间轻松切换。\n  - 简单来说就是可以创建多个虚拟环境，各个虚拟环境互不干扰，在每个环境中可以装一个版本的python，以及各种版本的软件包。\n- PyTorch：PyTorch是一个开源的Python机器学习库，提供两个高级功能：1、具有强大的GPU加速的张量计算（如NumPy）。2、包含自动求导系统的深度神经网络。\n- TensorFlow：TensorFlow™是一个基于数据流编程（dataflow programming）的符号数学系统，被广泛应用于各类机器学习（machine learning）算法的编程实现，其前身是谷歌的神经网络算法库DistBelief。\n\n\n\n总结：NVIDIA GPU驱动、CUDA  Toolkit、cuDNN作用是使用NVIDIA进行GPU加速，如果只使用CPU或AMD显卡则不需要。Conda方便后面环境配置和软件管理。PyTorch和TensorFlow是两个不同的深度学习框架，PyTorch学术界使用较为广泛，方便简单，易于上手。TensorFlow工业界使用较为广泛，泛用性好，被更多框架和平台支持。\n\n<!--more-->\n\n\n\n# 二、环境配置\n\n## 2.1、GPU相关(可选)\n\n如果电脑GPU不是NVIDIA，则只能使用CPU，无法进行本小节的配置；是NVIDIA GPU，但只想使用CPU，也无需本小节的配置。建议初学者初期只使用CPU。\n\n### 2.1.1、Windows\n\n#### 1. 下载安装NVIDIA GPU驱动\n\n检查自己是否安装：打开cmd命令行，输入nvidia-smi，回车键运行，能运行成功说明已经正常安装。\n\n![image.png](/img/deeplearnning/1626923540260-01a20532-61d1-4ccf-ad49-7ab7a9a1bd3e.png)\n\n其中Driver Version是驱动版本号，CUDA Version可能是支持的CUDA最高版本，并不是当前运行的CUDA版本。\n​\n\n\n1. 查看显卡型号\n\n> 查看显卡：右键桌面 我的电脑(此电脑)->属性->设备管理器->显示适配器->查看显卡型号\n> 如果桌面没有 我的电脑：右键桌面空白处->个性化->主题->桌面图标设置->勾选计算机\n\n此处我的显卡是 NVIDIA Quadro K620\n![image.png](/img/deeplearnning/1626922174812-9c98f866-fd11-4dbb-af94-96d6c5ab8b4a.png)\n\n\n2. 根据显卡型号下载驱动\n\n下载地址：\n\n![image.png](/img/deeplearnning/1626922481409-847b8c4c-37cd-47e8-9402-c1057132bd60.png)\n\n根据型号选择对应驱动，点击搜索。跳转到下载页面下载即可。\n\n3. 安装NVIDIA GPU驱动\n\n点击安装程序，选择安装包解压路径\n\n![image.png](/img/deeplearnning/1626922952946-d05b52fc-be34-4f70-a453-4a1ea46f3022.png)\n\n\n\n选项自定义安装\n\n![image.png](/img/deeplearnning/1626923043333-624706c6-b04d-4c0a-a48c-114865466caa.png)\n\n选择要安装的组件，GPU加速只安装图形驱动程序即可；其他RTX桌面管理、HD音频驱动程序根据自己需要安装。\n\n![image.png](/img/deeplearnning/1626923702530-1d77b684-c711-4302-9c7e-77402ad6580f.png)\n\n重启，检查nvidia-smi命令是否可以运行\n​\n\n#### 2. 下载安装CUDA Toolkit\n\n根据NVIDIA驱动版本选择对应的CUDA下载，CUDA与NVIDIA版本对应关系如下：\n官网文档：[https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html](https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html)\n\n| **CUDA Toolkit**                                  | **Linux x86_64 Driver Version** | **Windows x86_64 Driver Version** |\n| ------------------------------------------------- | ------------------------------- | --------------------------------- |\n| CUDA 11.0.3 Update 1                              | >= 450.51.06                    | >= 451.82                         |\n| CUDA 11.0.2 GA                                    | >= 450.51.05                    | >= 451.48                         |\n| CUDA 11.0.1 RC                                    | >= 450.36.06                    | >= 451.22                         |\n| CUDA 10.2.89                                      | >= 440.33                       | >= 441.22                         |\n| CUDA 10.1 (10.1.105 general release, and updates) | >= 418.39                       | >= 418.96                         |\n| CUDA 10.0.130                                     | >= 410.48                       | >= 411.31                         |\n| CUDA 9.2 (9.2.148 Update 1)                       | >= 396.37                       | >= 398.26                         |\n| CUDA 9.2 (9.2.88)                                 | >= 396.26                       | >= 397.44                         |\n| CUDA 9.1 (9.1.85)                                 | >= 390.46                       | >= 391.29                         |\n| CUDA 9.0 (9.0.76)                                 | >= 384.81                       | >= 385.54                         |\n\n\n\n官网下载地址：[https://developer.nvidia.com/cuda-toolkit-archive](https://developer.nvidia.com/cuda-toolkit-archive)\n选择合适的版本，目前10.x版本使用较多。\n\n![image.png](/img/deeplearnning/1627188144095-d086aecb-e266-4350-bd01-fbd2b6c57089.png)\n\n\n\n之后选择操作系统(Windows)，指令集架构(x86_64)，系统版本(Win10)，安装类型(本地安装local)\n\n![image.png](/img/deeplearnning/1626925437436-616aaf36-063d-4663-ba2f-32f3361d52a6.png)\n\n\n\n选择完成后，点击下方的 **Base Installer** 下载安装；Base Installer下面的Patch补丁包可以不下载安装(可选)。\n\n![image.png](/img/deeplearnning/1627188233034-81c0314b-72a4-431d-bd03-b48fee0072fd.png)\n\n双击下载的安装包，选择解压路径，安装完成解压内容会自动删除；\n解压完成，开始安装，选择自定义安装：\n\n![image.png](/img/deeplearnning/1627189662948-b0e28f95-2933-47cb-8bc2-343a72114871.png)\n\n\n\n取消Driver components，即不安装驱动，前面已经安装。\n\n![image.png](/img/deeplearnning/1627189724918-d20dada7-4fc1-487d-9cad-b79b1c7700fc.png)\n\n选择安装路径并记住路径\n\n![image.png](/img/deeplearnning/1627189839445-f9165a2b-a301-42c8-b9ba-fa1a275b72f9.png)\n\n安装完成，运行 `nvcc -V ` ，能够正常执行，则说明安装成功。\n\n![image.png](/img/deeplearnning/1627190048859-d1c1e901-844d-4a81-b92a-64906ad04312.png)\n\n#### 3. 下载cuDNN\n\n官网下载地址：[https://developer.nvidia.com/rdp/cudnn-archive](https://developer.nvidia.com/rdp/cudnn-archive) (下载需要注册NVIDIA账号)\n根据CUDA版本选择cuDNN：\n\n![image.png](/img/deeplearnning/1627188965824-2ae40dad-970c-4446-8609-9561377db062.png)\n\n下载完成后解压只有一个cuda文件夹，文件夹下包含三个子文件夹：\n\n![image.png](/img/deeplearnning/1627190180934-dacd03b6-3071-497f-a748-e880732c79e2.png)\n\n将三个子文件夹中的文件，分别复制到CUDA Toolkit安装路径下对应的文件夹中\n\n- cuDNN中bin目录下的文件移动到 CUDA 的 bin 目录中\n- cuDNN目录中的 include 中的文件移动到 CUDA 的 include 目录中\n- cuDNN目录中的 lib 中的文件移动到 CUDA 的 lib 目录中\n\n![image.png](/img/deeplearnning/1627190473794-5b37df52-3f7b-486b-a16e-bbb87d03e29d.png)\n\n**复制完成，验证是否成功**\n通过NVIDIA提供的 deviceQuery.exe 和 bandwidthTest.exe 来查看GPU的状态，两者均在安装目录的 extras\\demo_suite文件夹中\n\n![image.png](/img/deeplearnning/1627190810521-8c4fb784-d1db-40bc-b424-b6496849f5b6.png)\n\n执行返回 `Result = PASS` 说明安装成功。\n\n### 2.1.2、Linux\n\n#### 1. 安装NVIDIA GPU驱动\n\n如果你使用Linux，我相信你应该有一定的基础，由于目前手上没有Linux设备，这里不再演示。\n安装过程，可参考知乎专栏：[https://zhuanlan.zhihu.com/p/59618999](https://zhuanlan.zhihu.com/p/59618999)\n\n#### 2. 安装CUDA  Toolkit\n\n官网下载地址：[https://developer.nvidia.com/cuda-toolkit-archive](https://developer.nvidia.com/cuda-toolkit-archive)\n根据系统和NVIDIA驱动版本，选择合适的CUDA。\n\n![image.png](/img/deeplearnning/1627191718067-cc5fb4ab-be49-4061-b6b2-77e86217accb.png)\n\n选择完成后，下方给出下载安装指令，执行 **Base Installer** 进行下载安装；Base Installer下面的Patch补丁包可以不下载安装(可选)。\n\n![image.png](/img/deeplearnning/1627191952417-ffcec4b7-acbf-4f1a-a3a4-e8e50ce18f86.png)\n\n这里的下载命令是：\n`​wget https://developer.download.nvidia.com/compute/cuda/10.2/Prod/local_installers/cuda_10.2.89_440.33.01_linux.run`\n安装命令是：\n`sudo sh cuda_10.2.89_440.33.01_linux.run`\n如果没有root权限，可以安装在用户目录，此时安装命令：\n`sh cuda_10.2.89_440.33.01_linux.run --silent --toolkit --toolkitpath=$HOME/cuda_10.2 --installpath=$HOME/cuda_10.2`\n​\n\n安装完成设置环境变量：\n\n```bash\n# 编辑用户目录下的.bashrc文件\ncd ~\nvim .bashrc\n\n# 添加如下内容\nexport PATH=$HOME/cuda_10.2/bin:$PATH\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HOME/cuda_10.2/lib64\n\n# 激活环境变量\nsource ~/.bashrc\n```\n\n测试是否安装成功：\n`nvcc -V`\n可以正常执行说明安装成功。\n\n\n#### 3. 下载cuDNN\n\n官网下载地址：[https://developer.nvidia.com/rdp/cudnn-archive](https://developer.nvidia.com/rdp/cudnn-archive) (下载需要注册NVIDIA账号)\n根据CUDA版本选择cuDNN\n\n![image.png](/img/deeplearnning/1627192799774-a12d4021-87b5-44aa-a317-c4ce1f8276b8.png)\n\n安装cuDNN\n\n```bash\n# 解压cuDNN\ntar -zxvf cudnn-10.2.tgz\n\n# 将cuDNN文件复制到CUDA Toolkit安装目录中\ncp cuda/include/cudnn.h ~/cuda_10.2/include/\ncp cuda/lib64/libcudnn* ~/cuda_10.2/lib64/\n\n# 赋予执行权限\nchmod a+r ~/cuda_10.2/include/cudnn.h\nchmod a+r ~/cuda_10.2/lib64/libcudnn*\n```\n\n\n\n\n\n## 2.2、安装Conda\n\nconda分为anaconda和miniconda。anaconda是包含一些常用包的版本，miniconda则是精简版，需要什么装什么，这里介绍miniconda的安装。\n官网地址：[https://docs.conda.io/en/latest/miniconda.html](https://docs.conda.io/en/latest/miniconda.html)\n\n### 2.2.1、安装\n\n进入官网：\n\n- Windows installers一栏就是Windows安装包\n- Linux installers一栏就是Linux安装包\n\n\n\n选择对应的操作系统和conda版本即可。\n一般安装MiniConda3，python版本无所谓，3.x以上都可以，后面可以根据需要自行更改。\n​\n\n安装完成后，检测是否正常：`conda info -e`\n\n### 2.2.2、配置\n\n执行如下命令，配置Miniconda\n\n```bash\n# 配置国内镜像清华源，下载加速\nconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/\nconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge \nconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/\nconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/\nconda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/main/\nconda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/\n\n# 其他\nconda config --set show_channel_urls yes\nconda config --set ssl_verify false\n```\n\n### 2.2.3、常用命令参数\n\n- 查看虚拟环境： `conda info -e`\n- 激活虚拟环境：`conda activate myTorch`\n  - activate 后是虚拟环境名\n- 退出虚拟环境： `conda deactivate`\n- 删除虚拟环境：`conda remove -n 虚拟环境名 --all`\n- 安装某个软件到当前虚拟环境：`conda install 包名 -y`\n- 卸载当前虚拟环境中的某个软件包：`conda uninstall 包名 -y`\n- 安装某个软件包到指定虚拟环境中：`conda install -n 虚拟环境名 包名 -y`\n- 卸载指定虚拟环境中的某个软件包：`conda uninstall -n 虚拟环境名 包名 -y`\n\n\n\n## 2.3、安装PyTorch\n\nPyTorch的安装分为GPU版和CPU版，使用官网命令安装和手动安装需要注意选择。\n​\n\n\n- 创建虚拟环境：`conda create -n myTorch python=3.6.9`\n  - -n 后接的myTorch是自定义的虚拟环境名，自己随便起名；python=3.6.9指定该虚拟环境下使用的python版本。\n- 激活环境：`conda activate myTorch`\n\n之后的安装都在此虚拟环境下进行！\n\n### 2.3.1 官网命令安装PyTorch\n\n官网地址：\n\n![image.png](/img/deeplearnning/1627458601473-137e2c3a-2acb-4f76-b6c8-984202664357.png)\n\n选择PyTorch版本(1.9.0)，操作系统版本(Windows)，包管理器(Conda)，语言(Language)，计算平台(CUDA 10.2)\n得到安装命令：`conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch`\n命令中 `-c` 后接的是官方默认源，如果比较慢，可以使用清华源(ps：好像也不快，经常下载失败)：\n\n```\nconda config --add channels  https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/\nconda install pytorch torchvision torchaudio cudatoolkit=10.2\n```\n\n同理包管理选择pip也可以：\n\n```\npip3 install torch==1.9.0+cu102 torchvision==0.10.0+cu102 torchaudio===0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n```\n\n这里可以看到使用pip安装，需要显式的指定pytorch和torchvison、torchaudio的版本。\n​\n\n### 2.3.2 手动安装PyTorch\n\n手动安装是为了解决自动下载安装总是由于网络问题失败的问题。\n安装前需要下载需要的包，地址：\n\n- 官网：[https://download.pytorch.org/whl/torch_stable.html](https://download.pytorch.org/whl/torch_stable.html)\n- 清华：[https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple/torch/](https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple/torch/)、[https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple/torchvision/](https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple/torch/)\n\n手动安装，最值得注意的是选择torch和torchvision的版本对应关系。\n\n> pytrch=1.4、torchvision=0.5\n> pytorch=1.6、torchvision=0.7\n> torch=1.9、torchvision=0.10\n> 其他版本可以自行百度\n\n\n\n以官网为例，访问上述地址，可以看到需要的whl包文件。\n\n![image.png](/img/deeplearnning/1627461859068-c9297fbf-b7ad-4646-8173-d6af03c9a312.png)\n\n![image.png](/img/deeplearnning/1627461797313-853bb9e2-8ed5-4dc7-9580-ce22a6f05ae1.png)\n\n软件包格式：`设备(cpu/gpu)-软件包名-包版本-python版本-操作系统_处理器`\n\n- 如果使用的是cpu那么就选cpu版本，如果适用gpu那么需要根据安装的cuda版本选择，比如安装了cuda10.2就选择cu102。\n- 如果使用的python版本是3.6.x就选择cp36-cp36m，其他版本对应选择即可。\n- 如果操作系统是Windows，就选择win；如果是linux就选择linux。\n- 处理器架构目前基本都是64位，amd64和x86_64相同都是64位。\n\n\n\n使用下载工具下载对应的torch和torchvision，下载完成使用pip命令安装。\n假如下载的文件分别为：torchvision-0.5.0+cpu-cp37-cp37m-win_amd64.whl、torch-1.4.0+cpu-cp37-cp37m-win_amd64.whl：\n\n```\npip install ./torchvision-0.5.0+cpu-cp37-cp37m-win_amd64.whl\npip install ./torch-1.4.0+cpu-cp37-cp37m-win_amd64.whl\n```\n\n\n\n## 2.4、安装TensorFlow\n\nTensorFlow的安装也分为GPU版和CPU版，CPU版本安装较简单；但如果安装GPU版，则需要满足与cuDNN和CUDA的关系。否则可能无法使用GPU加速。\n另外TensorFlow 1.x 和 2.x 变动较大，建议安装 2.x 版本，相对简单易用。\n​\n\n### 2.4.1 CPU版本安装\n\n使用pip直接输入以下命令：\n`pip install 'tensorflow==2.2.0' -i [http://pypi.doubanio.com/simple/](http://pypi.doubanio.com/simple/) --trusted-host pypi.doubanio.com`\n其中 2.2.0是版本号，-i 后指定安装源，--trusted-host 表示信任安装源，防止无法下载。\n​\n\n### 2.4.2 GPU版本安装\n\n命令与cpu版本类似，但需要保证TensorFlow版本与cuDNN和CUDA版本对应：\n`pip install 'tensorflow-gpu==2.2.0' -i [http://pypi.doubanio.com/simple/](http://pypi.doubanio.com/simple/) --trusted-host pypi.doubanio.com`\n只需要在tensorflow后加上-gpu即会下载gpu版本。\n​\n\n下方是官网给出的对应关系：\n\n- Linux GPU\n\n| 版本                  | Python 版本  | 编译器    | 构建工具     | cuDNN | CUDA |\n| --------------------- | ------------ | --------- | ------------ | ----- | ---- |\n| tensorflow-2.4.0      | 3.6-3.8      | GCC 7.3.1 | Bazel 3.1.0  | 8.0   | 11.0 |\n| tensorflow-2.3.0      | 3.5-3.8      | GCC 7.3.1 | Bazel 3.1.0  | 7.6   | 10.1 |\n| tensorflow-2.2.0      | 3.5-3.8      | GCC 7.3.1 | Bazel 2.0.0  | 7.6   | 10.1 |\n| tensorflow-2.1.0      | 2.7、3.5-3.7 | GCC 7.3.1 | Bazel 0.27.1 | 7.6   | 10.1 |\n| tensorflow-2.0.0      | 2.7、3.3-3.7 | GCC 7.3.1 | Bazel 0.26.1 | 7.4   | 10.0 |\n| tensorflow_gpu-1.15.0 | 2.7、3.3-3.7 | GCC 7.3.1 | Bazel 0.26.1 | 7.4   | 10.0 |\n| tensorflow_gpu-1.14.0 | 2.7、3.3-3.7 | GCC 4.8   | Bazel 0.24.1 | 7.4   | 10.0 |\n| tensorflow_gpu-1.13.1 | 2.7、3.3-3.7 | GCC 4.8   | Bazel 0.19.2 | 7.4   | 10.0 |\n| tensorflow_gpu-1.12.0 | 2.7、3.3-3.6 | GCC 4.8   | Bazel 0.15.0 | 7     | 9    |\n| tensorflow_gpu-1.11.0 | 2.7、3.3-3.6 | GCC 4.8   | Bazel 0.15.0 | 7     | 9    |\n| tensorflow_gpu-1.10.0 | 2.7、3.3-3.6 | GCC 4.8   | Bazel 0.15.0 | 7     | 9    |\n| tensorflow_gpu-1.9.0  | 2.7、3.3-3.6 | GCC 4.8   | Bazel 0.11.0 | 7     | 9    |\n| tensorflow_gpu-1.8.0  | 2.7、3.3-3.6 | GCC 4.8   | Bazel 0.10.0 | 7     | 9    |\n| tensorflow_gpu-1.7.0  | 2.7、3.3-3.6 | GCC 4.8   | Bazel 0.9.0  | 7     | 9    |\n| tensorflow_gpu-1.6.0  | 2.7、3.3-3.6 | GCC 4.8   | Bazel 0.9.0  | 7     | 9    |\n| tensorflow_gpu-1.5.0  | 2.7、3.3-3.6 | GCC 4.8   | Bazel 0.8.0  | 7     | 9    |\n| tensorflow_gpu-1.4.0  | 2.7、3.3-3.6 | GCC 4.8   | Bazel 0.5.4  | 6     | 8    |\n| tensorflow_gpu-1.3.0  | 2.7、3.3-3.6 | GCC 4.8   | Bazel 0.4.5  | 6     | 8    |\n| tensorflow_gpu-1.2.0  | 2.7、3.3-3.6 | GCC 4.8   | Bazel 0.4.5  | 5.1   | 8    |\n| tensorflow_gpu-1.1.0  | 2.7、3.3-3.6 | GCC 4.8   | Bazel 0.4.2  | 5.1   | 8    |\n| tensorflow_gpu-1.0.0  | 2.7、3.3-3.6 | GCC 4.8   | Bazel 0.4.2  | 5.1   | 8    |\n\n- Windows GPU\n\n| 版本                  | Python 版本 | 编译器             | 构建工具            | cuDNN | CUDA |\n| --------------------- | ----------- | ------------------ | ------------------- | ----- | ---- |\n| tensorflow_gpu-2.4.0  | 3.6-3.8     | MSVC 2019          | Bazel 3.1.0         | 8.0   | 11.0 |\n| tensorflow_gpu-2.3.0  | 3.5-3.8     | MSVC 2019          | Bazel 3.1.0         | 7.6   | 10.1 |\n| tensorflow_gpu-2.2.0  | 3.5-3.8     | MSVC 2019          | Bazel 2.0.0         | 7.6   | 10.1 |\n| tensorflow_gpu-2.1.0  | 3.5-3.7     | MSVC 2019          | Bazel 0.27.1-0.29.1 | 7.6   | 10.1 |\n| tensorflow_gpu-2.0.0  | 3.5-3.7     | MSVC 2017          | Bazel 0.26.1        | 7.4   | 10   |\n| tensorflow_gpu-1.15.0 | 3.5-3.7     | MSVC 2017          | Bazel 0.26.1        | 7.4   | 10   |\n| tensorflow_gpu-1.14.0 | 3.5-3.7     | MSVC 2017          | Bazel 0.24.1-0.25.2 | 7.4   | 10   |\n| tensorflow_gpu-1.13.0 | 3.5-3.7     | MSVC 2015 update 3 | Bazel 0.19.0-0.21.0 | 7.4   | 10   |\n| tensorflow_gpu-1.12.0 | 3.5-3.6     | MSVC 2015 update 3 | Bazel 0.15.0        | 7.2   | 9.0  |\n| tensorflow_gpu-1.11.0 | 3.5-3.6     | MSVC 2015 update 3 | Bazel 0.15.0        | 7     | 9    |\n| tensorflow_gpu-1.10.0 | 3.5-3.6     | MSVC 2015 update 3 | Cmake v3.6.3        | 7     | 9    |\n| tensorflow_gpu-1.9.0  | 3.5-3.6     | MSVC 2015 update 3 | Cmake v3.6.3        | 7     | 9    |\n| tensorflow_gpu-1.8.0  | 3.5-3.6     | MSVC 2015 update 3 | Cmake v3.6.3        | 7     | 9    |\n| tensorflow_gpu-1.7.0  | 3.5-3.6     | MSVC 2015 update 3 | Cmake v3.6.3        | 7     | 9    |\n| tensorflow_gpu-1.6.0  | 3.5-3.6     | MSVC 2015 update 3 | Cmake v3.6.3        | 7     | 9    |\n| tensorflow_gpu-1.5.0  | 3.5-3.6     | MSVC 2015 update 3 | Cmake v3.6.3        | 7     | 9    |\n| tensorflow_gpu-1.4.0  | 3.5-3.6     | MSVC 2015 update 3 | Cmake v3.6.3        | 6     | 8    |\n| tensorflow_gpu-1.3.0  | 3.5-3.6     | MSVC 2015 update 3 | Cmake v3.6.3        | 6     | 8    |\n| tensorflow_gpu-1.2.0  | 3.5-3.6     | MSVC 2015 update 3 | Cmake v3.6.3        | 5.1   | 8    |\n| tensorflow_gpu-1.1.0  | 3.5         | MSVC 2015 update 3 | Cmake v3.6.3        | 5.1   | 8    |\n| tensorflow_gpu-1.0.0  | 3.5         | MSVC 2015 update 3 | Cmake v3.6.3        | 5.1   | 8    |\n\n\n\n注：其实TensorFlow 2.x 以后不再区分CPU版和GPU版，上述两个命令只在 1.x 版本有区别。\n\n### 2.4.3 手动下载地址\n\n[https://pypi.org/project/tensorflow/#files](https://pypi.org/project/tensorflow/#files)\n手动下载后，pip安装即可，注意python版本、操作系统和处理器架构。\n\n```bash\npip install tensorflow-2.2.0-cp36-cp36m-win_amd64.whl\n```","comments":true,"categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://blog.ahulearn.com/tags/%E9%9A%8F%E7%AC%94/"},{"name":"深度学习","slug":"深度学习","permalink":"http://blog.ahulearn.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"Attention Is All You Need","date":"2021-05-21T02:35:00.000Z","path":"2021/05/21/Attention Is All You Need/","raw":"---\ntitle: Attention Is All You Need\ndate: 2021-05-21 10:35:00\ntoc: true\ntags:\n - NLP\n - transformer\n - NeurIPS 2017\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\\transformer\n---\n\n  Transformer 注意力就是您所需要的\n ---\n\n[TOC]\n\n会议： NeurIPS 2017\n\n论文地址：https://arxiv.org/abs/1706.03762\n\n## 摘要\n\n主流的序列转换模型多是基于复杂的循环或卷积神经网络，网络包括编码器和解码器。性能最好的模型还通过注意机制连接编码器和解码器。我们提出了一个新的简单且完全基于注意力机制的网络结构，Transformer，摒弃了循环和卷积。在两个机器翻译任务上的实验表明，这些模型具有更高的并行性，更少的训练时间。我们的模型在WMT 2014 Englishto-German 的翻译任务中达到28.4 BLEU，比现有的最佳结果（包括集成模型）提高了2 BLEU以上。在WMT 2014 English-to-French翻译任务中，我们的模型在8个GPU上训练3.5天后，达到了新的单模型BLEU 41.8的最新分数，这只相当于文献中最佳模型训练成本的一小部分。通过将Transformer成功地应用于大规模和有限训练数据下的英语选区分析，证明了Transformer具有良好的泛化能力。\n\n<!--more-->\n\n\n\n## 1 简介\n\n循环神经网络，特别是长-短期记忆(LSTM)[13]和门控循环(GRN))[7]神经网络，已经被确定为序列建模和转换问题（如语言建模和机器翻译）的最新方法[35，2，5]。自那以后，许多努力继续推动循环语言模型和编解码器架构的(性能)边界[38，24，15]。\n\n循环模型通常沿着输入序列和输出序列的符号位置进行因子计算。将序列中每位置数据与RNN计算时刻中的步骤对齐，它们生成一系列隐藏状态$h_t$，作为先前隐藏状态$h_{t−1}$和位置t输入的函数。这种固有的顺序性质阻碍了训练样本中的并行化，这(并行)在较长的序列长度下变得很关键，因为内存限制了跨样本的批处理。最近的工作通过因子分解技巧[21]和条件计算[32]在计算效率方面取得了显著的改进，同时也提高了后者的模型性能。然而，顺序计算的基本限制仍然存在。\n\n注意机制已经成为各种任务中序列建模和转换模型的一个重要组成部分，允许建模依赖性[2，19]，而不考虑其在输入或输出序列中的距离。然而，在除少数情况[27]外的所有情况下，这种注意机制都与循环网络结合使用。\n\n在这项工作中，我们提出了Transformer，一种避免循环结构的模型架构，而完全依赖于一种注意机制来绘制输入和输出之间的全局依赖关系。Transformer允许更明显的并行化，并可以在在8个P100 GPU上经过训练后，只12小时达到新的最先进的翻译效果。\n\n\n\n## 2 背景\n\n以减少顺序计算目的为基础形成了扩展神经GPU〔16〕、ByteNet〔18〕和ConvS2S〔9〕，所有这些都使用卷积神经网络作为基本构建块，并行的计算输入输出所有位置的隐藏表示。在这些模型中，将两个任意输入或输出位置的信号关联起来所需的操作数随着位置之间的距离而增长，ConvS2S是线性的，ByteNet是对数的。这使得学习远距离位置之间的依赖关系变得更加困难[12]。在Transformer中，这被减少到一个恒定的操作数，尽管由于平均注意加权位置(averaging attention-weighted positions)而降低了有效分辨率，我们用多头部注意抵消了这种影响，如第3.2节所述。\n\n自注意，有时被称为内部注意，是一种注意机制，将单个序列的不同位置联系起来，以计算序列的表示形式。自我注意在阅读理解、抽象总结、文本蕴涵和学习任务无关的句子表征等任务中得到了成功的应用[4,27,28,22]。\n\n端到端记忆网络是基于一种循环注意机制而不是序列对齐的循环，并且在简单的语言问答和语言建模任务中表现良好[34]。\n\n然而，据我们所知，Transformer是第一个完全依靠自注意来计算其输入和输出表示的转换模型，而不使用序列对齐RNN或卷积。在下面的章节中，我们将描述Transformer，自注意的动机，并讨论其相对于[17,18]和[9]等模型的优势。\n\n\n\n## 3 模型结构\n\n大多数竞争神经序列转换模型都有编码器-解码器结构[5，2，35]。这里，编码器将符号表示 $(x_1, …, x_n)$ 的输入序列映射到连续表示 $z=(z_1, …, z_n)$ 的序列。给定z，然后解码器生成符号的输出序列 $(y_1, …, y_m)$ ，一次生成一个元素。在每一步中，模型都是自递归的[10]，在下一步生成时，使用先前生成的符号作为额外的输入。\n\nTransformer遵循这个整体架构，使用堆叠的自注意和逐点，编码器和解码器使用全连接层连接，分别如图1的左半部分和右半部分所示。\n\n![1706](/img/transformer/1706.jpg)\n\n### 3.1 编码器和解码器堆叠\n\n**编码器**：编码器由N=6个相同的层组成。每层有两个子层。第一子层是多头自注意机制，第二子层是简单的、位置相关的全连接前馈网络。我们在两个子层的每一个子层周围使用残差连接[11]，然后使用层归一化[1]。也就是说，每个子层的输出是 $LayerNorm(x+Sublayer(x))$ ，其中 $Sublayer(x)$ 是子层本身实现的函数。为了便于使用残差连接，模型中的所有子层和嵌入层都生成维数为 $d_{model}=512$ 的输出。\n\n**解码器**：解码器也由N=6个相同层的堆叠组成。除了在每个编码器层中都存在的两个子层之外，解码器还插入第三个子层，该子层对编码器堆叠的输出执行多头部注意力。与编码器类似，我们在每个子层周围使用残差连接，然后进行层归一化。我们还修改了解码器堆叠中的自注意子层，以防止当前位置关注后续位置。这种掩码与输出嵌入偏移一个位置相结合，确保位置$i$的预测只能依赖于位置小于$i$的已知输出。\n\n\n\n### 3.2 注意力\n\n注意力函数可以描述为将查询和一组键值对映射到输出，其中查询、键、值和输出都是向量。输出作为值的加权和进行计算，其中分配给每个值的权重由查询与相应键的兼容性(相似性)函数计算。\n\n![image-20210521105517778](/img/transformer/image-20210521105517778.png)\n\n`图2：（左）缩放点乘注意力。（右）多头注意力由几个平行运行的注意力层组成。`\n\n#### 3.2.1  缩放点积注意力\n\n我们称我们的特别注意力为“标度点积注意力”（图2）。输入包括$d_k$维度的查询和键，以及$d_v$维度的值。我们用所有键计算与查询的点积，将每个点积除以$\\sqrt{d_k}$，然后应用$softmax$函数获得值的权重。\n\n\n\n在实践中，我们同时计算一组查询的注意函数，并将其打包到矩阵Q中。键和值也被打包到矩阵K和V中。我们将输出矩阵计算为：\n\n\n$$\nAttention(Q, K, V) = softmax \\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n$$\n\n\n最常用的两个注意函数是加性注意力(additive attention)[2]和点积（多重复制）注意力。点积注意力与我们的算法相同，[我们]除了比例因子$\\frac{1}{\\sqrt{d_k}}$。加性注意力(additive attention)利用一个具有单个隐层的前馈网络来计算相容函数。虽然两者在理论复杂度上相似，但由于可以使用高度优化的矩阵乘法码来实现，因此在实践中，点积关注速度更快，空间效率更高。\n\n而对于较小的$d_k$值，这两种机制表现相似，对于$d_k$值，加法注意优于点积注意[3]。我们怀疑对于较大的 $d_k$ 值，点积在数量级上增长很大，将softmax函数推到梯度非常小的区域^4。为了抵消这种影响，我们用$\\frac{1}{\\sqrt{d_k}}$缩放点积。\n\n#### 3.2.2 多头注意力\n\n取代使用 $d_{model}$ 维的键、值和查询执行单一注意函数，我们发现，使用不同的线性投影将查询、键和值线性投影h次，分别投影到 $d_k$、$d_k$ 和 $d_v$ 维是有益的。在查询、键和值的每个投影版本上，我们并行执行注意函数，产生 $d_v$ 维输出值。它们被连接起来并再次投影，从而得到最终值，如图2所示。\n\n多头部注意使得模型能够在不同位置，连带地关注来自不同表示子空间的信息。单注意头，平均值会抑制这一点。\n$$\n\\begin{aligned}\n\\operatorname{MultiHead}(Q, K, V) &=\\text { Concat }\\left(\\text { head }_{1}, \\ldots, \\text { head }_{\\mathrm{h}}\\right) W^{O} \\\\\n\n\\text { where head }_{\\mathrm{i}} &=\\text { Attention }\\left(Q W_{i}^{Q}, K W_{i}^{K}, V W_{i}^{V}\\right)\n\\end{aligned}\n$$\n其中投影为参数矩阵  $\nW_{i}^{Q} \\in \\mathbb{R}^{d_{\\text {model }} \\times d_{k}}, W_{i}^{K} \\in \\mathbb{R}^{d_{\\text {model }} \\times d_{k}}, W_{i}^{V} \\in \\mathbb{R}^{d_{\\text {model }} \\times d_{v}}, W^{O} \\in \\mathbb{R}^{ {hd_v} \\times d_{\\text{model}} }\n$  \n\n在这项工作中，我们采用 $h=8$ 平行注意层，或头。对于每一层，我们使用 $d_k=d_v=d_{model}/h=64$ 。由于每个头的维数减小，总的计算量与全维度单头注意力的计算量相似。\n\n#### 3.2.3 注意力在我们模型中的应用\n\nTransformer以三种不同的方式使用多头注意：\n\n+ 在“编码器-解码器注意”层中，查询来自前一个解码器层，而记忆键和值来自编码器的输出。这使得解码器中的每个位置都可以注意输入序列中的所有位置。这模仿了典型的编码器-解码器在序列到序列模型中的注意机制，如[38，2，9]。\n+ 编码器包含自注意层。在自注意层中，所有的键、值和查询都来自同一个地方，在本例中为编码器中前一层的输出。编码器中的每个位置都可以关注编码器前一层中的所有位置。\n+ 类似地，解码器中的自注意层允许解码器中的每个位置关注到解码器中所有位置，直到并且包括当前位置。我们需要防止解码器中的信息流向左流动，以保持自回归特性。我们通过屏蔽softmax输入中与非法连接相对应的所有值（设置为−∞），实现了这种缩放点积注意力。见图2。\n\n\n\n### 3.3 位置前馈网络\n\n除了注意力子层之外，我们的编码器和解码器中的每一层都包含一个完全连接的前馈网络，该网络单独且相同地应用于每个位置。这包括两个线性变换，中间有一个ReLU激活函数。\n$$\nFFN(x) = max(0, xW_1 + b_1)W_2 + b_2\n$$\n\n\n虽然线性变换在不同的位置上是相同的，但它们在层与层之间使用不同的参数。另一种描述前馈网络的方法是两个核大小为1的卷积。输入和输出的维数为 $d_{model}=512$ ，内层的维数为 $d_{ff}=2048$ 。\n\n\n\n### 3.4 嵌入和Softmax\n\n与其他序列转换模型类似，我们使用可学习的嵌入将输入标记和输出标记转换为维度 $d_{model}$ 的向量。我们还使用常用的可学习线性变换和softmax函数将解码器输出转换为预测的下一个词符(next-token)概率。在我们的模型中，我们在两个嵌入层和pre-softmax线性变换之间共享相同的权重矩阵，类似于[30]。在嵌入层，我们将这些权重乘以 $\\sqrt{d_{model}}$ 。\n\n\n\n### 3.5 位置编码\n\n由于我们的模型不包含循环和卷积，为了使模型能够利用序列的顺序，我们必须注入一些关于符号在序列中的相对或绝对位置的信息。为此，我们将“位置编码”添加到编码器和解码器堆栈底部的输入嵌入中。位置编码与嵌入具有相同的维度$d_{model}$，因此可以将两者相加。有许多位置编码的选择，学习的和固定的[9]。\n\n`表1：不同层类型的最大路径长度、每层复杂度和最小顺序操作数。n是序列长度，d是表示维数，k是卷积的核大小，r是限制自我注意的邻域大小。`\n\n![image-20210521111900969](/img/transformer/image-20210521111900969.png)\n\n在这项工作中，我们使用不同频率的正弦和余弦函数：\n$$\nPE_{(pos,2i)} = sin(pos / 10000^{2i/d_{\\text{model}}})\n$$\n\n$$\nPE_{(pos,2i+1)} = cos(pos / 10000^{2i/d_{\\text{model}}})\n$$\n\n\n\n其中pos是位置，i是尺寸。也就是说，位置编码的每个维度对应于一个正弦曲线。波长呈几何级数从2π到10000·2π。我们之所以选择这个函数，是因为我们假设它可以让模型很容易地通过相对位置来学习，因为对于任何固定的偏移量k，$PE_{pos+k}$ 可以表示为 $PE_{pos}$ 的线性函数。\n\n我们还尝试使用学习到的位置嵌入[9]，发现这两个版本产生了几乎相同的结果（见表3第（E）行）。我们选择正弦版本，因为它可能允许模型外推序列长度比训练中遇到的更长。\n\n\n\n## 4 为什么(使用)自注意力\n\n在这一节中，我们将自注意层与循环和卷积层的各个方面进行比较，循环和卷积层通常用于映射变长序列的符号表示 $(x_1, …, x_n)$ 到另一个等长序列 $(z_1, …, z_n)$ ，其中 $x_i, z_i \\in \\mathbb{R}^d，$  例如在一个典型的序列转换编码器或解码器的隐藏层。促使我们使用自注意的动机，我们考虑了三个条件。\n\n第一是每层的总计算复杂度。另一个是可以并行化的计算量，以所需的最小序列操作数来衡量。\n\n第三个是网络中远程依赖之间的路径长度。在许多序列转换任务中，学习长程依赖是一个关键的挑战。影响学习这种依赖关系能力的一个关键因素是前向和后向信号在网络中必须经过的路径长度。输入和输出序列中任何位置组合之间的路径越短，就越容易学习长期依赖关系[12]。因此，我们也比较了由不同层类型组成的网络中任意两个输入和输出位置之间的最大路径长度。\n\n如表1所示，自注意层连接所有位置都使用常数个顺序执行操作，而循环层需要 $O(n)$ 个顺序操作。在计算复杂性方面，当序列长度n小于表示维数d时，自注意层比循环层快，这通常是机器翻译中最先进模型使用的句子表示的情况，例如词条[38]和字节对[31]表示。为了提高包含很长序列的任务的计算性能，可以将自我注意限制为只考虑以相应输出位置为中心的输入序列中大小为 $r$ 的邻域。这会将最大路径长度增加到$O(n/r)$  。我们计划在今后的工作中进一步研究这种方法。\n\n核宽 $k<n$ 的单个卷积层并不连接所有的输入和输出位置对。这样做需要一个 $O(n/k)$ 卷积层的堆栈（对于连续的核contiguous kernels），或者$O(logk(n))$  的堆栈(对于空洞卷积dilated convolutions）[18]，增加网络中任意两个位置之间的最长路径的长度。卷积层通常比循环层的成本高出 $k$ 倍。然而，可分离卷积(Separable convolutions)[6]将复杂性大大降低到$O(k·n·d+n·d^2)$ 。然而，即使在 $k=n$ 的情况下，可分离卷积的复杂度也等于我们在模型中采用的自注意层和逐点前馈层的组合。\n\n作为副作用，自注意可以产生更多可解释的模型。我们从我们的模型中检查注意分布，并在附录中给出和讨论示例。不仅个体的注意力头清楚地学会执行不同的任务，更多的头似乎表现出与句子的句法和语义结构有关的行为。\n\n\n\n## 5 训练\n\n本节描述了模型的训练机制。\n\n### 5.1 训练数据和批处理\n\n我们在标准WMT 2014 English-German数据集上进行了训练，该数据集由大约450万个句子对组成。句子是用字节对编码的[3]，它有一个大约37000个标记的共享源-目标词汇表。对于English-French，我们使用了更大的WMT 2014 English-French数据集，该数据集由3600万个句子和拆分标记组成，包含32000个单词的词汇量[38]。句子对按大致的序列长度分批排列在一起。每个训练批包含一组句子对，其中包含大约25000个源标记和25000个目标标记。\n\n\n\n### 5.2 硬件和预设\n\n我们在一台有8个NVIDIA P100 GPU的机器上训练我们的模型。对于使用本文中描述的超参数的基础模型，每个训练步骤大约需要0.4秒。我们对基础模型进行了总共10万steps或12小时的训练。对于我们的大型模型（在表3的底行中描述），step时间是1.0秒。这些大模型被训练了30万步（3.5天）。\n\n\n\n### 5.3 优化器\n\n我们使用了Adam优化器[20]，其中 $β1=0.9, β2=0.98, \\sigma =10−9$ 。在整个训练过程中，我们根据以下公式改变了学习率：\n$$\n\\text { lrate } = d_{\\text {model }}^{-0.5} \\cdot \\min \\left(\\text { step\\_num }^{-0.5}, \\text { step\\_num } \\cdot \\text { warmup\\_steps }^{-1.5}\\right)\n$$\n这相当于在第一个预热步(warmup_steps)训练步骤中线性地增加学习率，然后按步骤数的平方反比成比例地降低学习率。我们使用warmup_steps=4000。\n\n\n\n### 5.4 正则化\n\n在训练期间，我们采用了三种正则化方法：\n\n**残差排除(Residual Dropout)**：我们在将每个子层的输出使用dropout(随机删除)[33]，在输出加到子层输入和归一化之前。此外，我们对编码器和解码器堆栈中的嵌入和位置编码的和也应用dropout。对于基本模型，我们使用$P_{drop}=0.1$ 的速率。\n\n`表2 Transformer在English-German和English-French newstest2014的测试中取得了比以前最先进的模型更好的BLEU分数，而训练成本仅占一小部分。`\n\n![image-20210521113103705](/img/transformer/image-20210521113103705.png)\n\n\n\n**标签平滑**：在训练过程中，我们使用了值 $e_{ls} = 0.1$  [36]的标签平滑。这伤害了困惑度，因为模型学会了更加不确定，但提高了准确性和BLEU分数。\n\n## 6 结果\n\n### 6.1 机器翻译\n\n在WMT 2014 English-German翻译任务中，transformer大模型（表2中的Transformer(big)）比之前报道的最佳模型（包括整体）的BLEU值高出2.0以上，建立了一个新的最先进的BLEU值28.4。这个模型的配置列于表3的底行。在8个P100 GPU上训练3.5天。即使是我们的基础模型超过了所有以前出版的模型和合奏，在训练代价只使用任何竞争模型的一小部分。\n\n在WMT 2014 English-French的翻译任务中，我们的大模型达到了41.0的BLEU分数，优于之前发布的所有单个模型，不到之前最先进模型训练成本的1/4。为 English-French训练的Transformer(big)模型使用的dropout率$P_{drop}=0.1$，而不是0.3。\n\n对于基本模型，我们使用一个单头模型，该模型通过平均最后5个checkpoints获得，这些checkpoints以10分钟的间隔写入。对于大型模型，我们平均了最后20个checkpoints。我们使用波束搜索，波束大小为4，长度惩罚 $α=0.6$ [38]。这些超参数是在开发集上进行实验后选择的。我们将推断过程中的最大输出长度设置为输入长度+50，但尽可能提前终止[38]。\n\n\n\n表2总结了我们的结果，并将我们的翻译质量和训练成本与文献中的其他模型架构进行了比较。我们通过乘以训练时间、使用的GPU数量和每个GPU的持续单精度浮点容量来估计用于训练模型的浮点运算的数量。\n\n### 6.2 模型变量\n\n为了评估Transformer不同组件的重要性，我们以不同的方式改变了我们的基本模型，在开发集newstest2013上测量 English-German翻译的性能变化。我们使用了前一节中描述的波束搜索，但是没有checkpoints平均。我们在表3中给出了这些结果。\n\n在表3（A）行中，我们改变了注意头的数量以及注意键和值维度，保持计算量不变，如第3.2.2节所述。虽然单头注意力比最佳设置差0.9 BLEU，但过多的头质量也会下降。\n\n\n\n`表3：Transformer结构的变化。未列出的值与基本模型的值相同。所有指标都在English-German翻译开发集newstest2013上。根据我们的字节对编码，列出的困惑是每个单词的，不应与每个单词的困惑进行比较。`\n\n![image-20210521113508486](/img/transformer/image-20210521113508486.png)\n\n\n\n`表4：Transformer可以很好地推广到英语选区分析（结果见WSJ第23节）`\n\n![image-20210521113658606](/img/transformer/image-20210521113658606.png)\n\n\n\n在表3行（B）中，我们观察到减小注意键大小 $d_k$ 会损害模型质量。这表明确定兼容性并不容易，而且比点乘更复杂的兼容性功能可能是有益的。我们在第（C）行和第（D）行中进一步观察到，正如预期的那样，更大的模型更好，而dropout对于避免过拟合非常有帮助。在第（E）行中，我们将正弦位置编码替换为学习的位置嵌入[9]，并观察到与基本模型几乎相同的结果。\n\n### 6.3 英语选区分析\n\n为了评估这个Transformer是否可以推广到其他任务，我们进行了英语选区分析实验。这项任务提出了具体的挑战：产出受到强大的结构约束，而且大大长于投入。此外，RNN序列到序列模型还不能在小数据区获得最先进的结果[37]。\n\n我们在Penn Treebank的华尔街日报（Wall Street Journal，WSJ）部分[25]上训练了一个4层的Transformer， $d_{model}=1024$　，大约有40K个训练句子。我们也在半监督的环境中训练它，使用了更大的高置信度和BerkleyParser语料库，来自大约1700万个句子[37]。我们使用了16K的词汇表用于仅限WSJ的设置，32K的词汇表用于半监督设置。\n\n我们只进行了少量的实验，在第22节的发展集上选择辍学、注意力和剩余（第5.4节）、学习率和波束大小，所有其他参数从English-German的基础翻译模型保持不变。在推理过程中，我们将最大输出长度增加到输入长度+300。我们使用了21和α=0.3的波束大小，用于WSJ和半监督设置。\n\n我们在表4中的结果表明，尽管缺乏特定于任务的调整，我们的模型表现得非常好，除了循环神经网络语法外，产生的结果比所有以前报道的模型都好[8]。\n\n与RNN序列到序列模型[37]相比，Transformer的性能优于Berkeley解析器[29]，即使只在WSJ训练集上训练40K个句子。\n\n## 7 结论\n\n在这项工作中，我们提出了第一个完全基于注意的序列转换模型Transformer，它用多头自注意取代了编解码结构中最常用的循环层。\n\n对于翻译任务，Transformer的训练速度比基于循环层或卷积层的架构快得多。在WMT 2014 English-German和WMT 2014 English-French的翻译任务中，我们实现了一个新的水平。在前一个任务中，我们的最佳模型甚至比所有先前报道的集成模型都要好。\n\n我们对基于注意力模型的未来感到兴奋，并计划将其应用于其他任务。我们计划将Transformer扩展到涉及文本以外的输入和输出模式的问题，并研究局部、受限的注意机制，以有效地处理图像、音频和视频等大量输入和输出。减少世代的连续性是我们的另一个研究目标。\n\n我们用来训练和评估模型的代码可以获取在https://github.com/tensorflow/tensor2tensor。\n\n\n\n## 注意力可视化\n\n![image-20210521114450660](/img/transformer/image-20210521114450660.png)\n\n`图3：注意机制的一个例子，在编码器中遵循长距离依赖，在第5层（共6层）自我注意。许多注意力集中的人注意到动词“making”的一个遥远的依赖关系，完成短语“使…更困难”。这里的注意仅限于“使”一词。不同的颜色代表不同的头。最好看彩色。`\n\n\n\n![image-20210521115133027](/img/transformer/image-20210521115133027.png)\n\n`图4：两个注意头，也在第5层的6，显然涉及回指决议。上图：5号头全神贯注。底部：将注意力从注意力头5和6的“its”字中分离出来。注意，这个词的注意力非常敏锐。`\n\n\n\n![image-20210521115353615](/img/transformer/image-20210521115353615.png)\n\n`图5：多头注意力集中的人表现出的行为似乎与句子的结构有关。我们在上面给出了两个这样的例子，来自6层第5层编码器自我注意的两个不同的头部。很明显，这些头学会了执行不同的任务。`","comments":true,"categories":[],"tags":[{"name":"NLP","slug":"NLP","permalink":"http://blog.ahulearn.com/tags/NLP/"},{"name":"transformer","slug":"transformer","permalink":"http://blog.ahulearn.com/tags/transformer/"},{"name":"NeurIPS 2017","slug":"NeurIPS-2017","permalink":"http://blog.ahulearn.com/tags/NeurIPS-2017/"}]},{"title":"Learning Event-Based Motion Deblurring","date":"2021-04-22T05:38:00.000Z","path":"2021/04/22/Learning Event-Based Motion Deblurring/","raw":"---\ntitle: Learning Event-Based Motion Deblurring\ndate: 2021-04-22 13:38:00\ntoc: true\ntags:\n - CS\n - CVPR2020\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\\event-based-motion\n---\n\n## 学习基于事件的运动去模糊\n\n会议：CVPR 2020\n\n地址：https://arxiv.org/abs/2004.05794\n\n## 摘要\n\n由于模糊过程中丢失了大量的运动信息，从运动模糊图像中恢复清晰的视频序列是一个高度[不适定问题](https://baike.baidu.com/item/不适定问题)。然而，对于基于事件的相机，快速运动可以在高时间率上作为事件被捕捉，从而提出了探索有效解决方案的新机遇。在本文中，我们从基于事件的运动去模糊的序列表述开始，然后说明如何使用新颖的端到端深度架构来实现其优化。所提出的架构是一个卷积循环神经网络，有原则的整合了全局和局部尺度的视觉和时间知识。为了进一步改进(图像的)重建，我们提出了一种可微的定向事件过滤模块，可以有效地从事件流中提取丰富的先验边界。我们在合成的GoPro数据集和新引入的使用DAVIS240C相机捕获的大型数据集上进行了大量的实验。我们提出的方法达到了最先进的重建质量，并更好地处理现实世界的运动模糊。\n\n<!--more-->\n\n\n\n## 1. 概述\n\n运动模糊通常是由于现代相机传感器需要曝光时间，在此期间，场景被记录在不同的时间戳，并累积成平均(模糊)信号。这个过程的反问题被称为“去模糊”，它揭示了运动模糊图像背后的场景动态，并生成一系列复原的清晰场景，在计算机视觉中仍然具有挑战性。虽然简单的运动模式(如相机抖动)已经被很好地建模，但是在现实世界中形成更复杂的运动模式却要困难得多。\n\n为了模拟一般的运动模糊，最近的深度学习方法提出通过观察大量的清晰图像及其模糊版本来恢复模糊图像。尽管他们在某些场景中取得了成功，但他们可能无法合理地重建严重的运动模糊场景(如图1)，这是常见的手持，车辆或无人机装备的相机。在这种情况下，由于时间顺序和视觉信息的显著丢失，对场景细节进行幻化几乎是不可能的。\n\n![image-20210422151736600](/img/event-based-motion/image-20210422151736600.png)\n\n`图1 我们方法的动机。严重的运动模糊图像（a）仅通过最先进的深度结构[50]很难通过观察其模棱两可的外观进行模糊处理[50](c)。尽管事件(b)提供了密集的时间线索，但由于事件(d)的嘈杂，物理重建方法[31]仍然呈现出未解决的模糊。我们深度运动去模糊技术可从不完美的图像和事件中恢复可能的细节(e)。`\n\n本工作在数据捕获阶段采用事件像机来缓解这一问题，而不是单纯依靠计算架构。事件相机是一种受生物学启发的传感器，擅长记录像素强度(称为事件)的变化，具有微秒精度和非常低的功耗。这类传感器的混合模型(如[5])允许用图像在时间上校准事件。因此，这些数据自然地编码了密集的时间信息，可以促进运动去模糊。如图1 (a)和(b)所示，尽管图像经历了明显的模糊，但伴随的事件在时间上是密集的，并显示出清晰的场景移动模式。\n\n尽管基于事件的运动去模糊的潜力很大，但一个关键问题是，事件是有损的和有噪声的信号，只有当像素强度变化到一定的阈值时才会触发，该阈值随着场景情况[35]的变化而变化。这种离散和不一致的采样使得纹理和对比度难以恢复。如图1 (d)所示，目前最先进的物理去模糊方法[31]仍然难以合理地重建图像。我们的解决方案是将深度学习的先验知识插入基于事件的去模糊过程中，从而超越数据的不完善性。\n\n具体来说，这项工作从基于事件的去模糊的序列表述开始。通过使用深度网络重新诠释其优化，我们提出了一种可端到端训练的新颖循环架构。对于每个时间步，从之前的重建和局部时间事件得到粗重建。然后，通过网络预测来提供精细的细节，并以全局和局部尺度上的外观和时间提示为指导。为了进一步提高重建质量，我们提出了一种可微分Directional Event Filtering(方向事件滤波: DEF)模块，它有效地聚合了事件所揭示的运动边界，并产生清晰的去模糊先验效果。为了评估所提出的方法，我们编制了一个使用DAVIS240C相机[5]捕获的大型户外数据集。在这个数据集和合成的GoPro数据集[25]上进行的大量实验表明，所提出的方法优于各种最新的方法，无论是基于图像的还是基于事件的，并且能够更好地处理真实世界的运动模糊。\n\n本文的贡献总结如下。1)我们提出了一种新的基于事件的运动去模糊循环深度架构，在两个大型基准上实现了最先进的结果。2)我们提出了定向事件过滤，从事件中生成清晰的边界，用于运动去模糊。3)我们使用真实的运动模糊编制了一个新的事件数据集，以促进未来的研究。\n\n## 2. 相关工作\n\n**盲去运动模糊** 目的是在不知道模糊内核的情况下解决模糊图像。早期的研究设计了各种模糊感知指标，如颜色通道统计[29,47]、块重复[22]和”离群“图像信号[8]来定义潜在图像的先验。一些研究提出从数据中学习运动核[39,28]、恢复函数[45,11]和图像先验[55,42]。由不同对象复合而成的更复杂的运动模式也被解决[16,37]。更丰富的先验知识(例如场景几何)被证明是有用的[30,32]。\n\n最近的一个趋势是使用深度神经网络来处理所有复杂的运动去模糊。提出了各种有效的网络设计，包括扩大接收野[52]、多尺度融合[25,27]、特征分离[26]和循环细化[44]。也有研究将模糊图像的运动动力学解码为清晰的视频序列[15]。尽管取得了这些进步，但现实世界中照明，纹理和运动的大量组合（在模糊图像中严重丢失）仍然难以合理恢复。\n\n**事件相机** 是一种特殊的传感器，它在微秒级检测场景的强度变化，功耗较小。它们在各种视觉任务中都有应用，如视觉跟踪[34,23]、立体视觉[54,1]和光流估计[20,48]。一个相关的分支是探索损坏的事件信号，以恢复高帧率图像序列[38,24,40] 。最近，Pan等人[31]用一个二重积分模型制定了基于事件的运动模糊。然而，事件摄像机的嘈杂的硬采样机制往往会引入强烈的累积噪声和场景细节/对比度的损失。\n\n这项工作分享了最近有关事件到视频翻译的研究[33,17,36]，这些研究通过从数据中学习可能的细节，超越了不完美的事件采样。[33]解决了未来的帧预测问题，[17，36]则根据局部运动线索以流方式将事件转换为合理的强度图像。 相反，这项工作探索了长期的局部外观/运动线索以及新颖的事件边界先验，以解决运动模糊问题。\n\n\n\n## 3. 学习基于事件的运动去模糊\n\n给定一个运动模糊图像 $\\overset{\\_}{I} $ ，我们的目标是恢复一个有T帧的清晰视频序列，$\\mathbb{I} = \\{I_i\\}^T_{i=1}$。我们假设在曝光期间，混合图像-事件传感器也捕获了一系列事件$E_{1\\sim T}$，其中波浪线表示时间间隔。每个事件 $\\mathcal{E}\\in \\mathbb{E}_{1\\sim T}$ 的形式为$\\mathcal{E}_{x,y,t}$，即在图像坐标(x, y)和时间点$t\\in[1,T]$的触发(激活)。注意这里**t**不需要是整数，也可以是小数，由于事件相机的高时间分辨率(即微秒级)。对 $\\mathcal{E}_{x,y,t}$ 记录一个极性 $p_{x,y,t}$ ，表示局部强度的变化。正式定义参考文献[19,5]，公式(1)：\n\n\n$$\np_{x, y, t}=\\left\\{\\begin{array}{l}\n+1, \\text { if } \\log \\left(\\frac{\\mathcal{I}_{t}(x, y)}{\\mathcal{I}_{t-\\Delta t}(x, y)}\\right)>\\tau \\\\\n-1, \\text { if } \\log \\left(\\frac{\\mathcal{I}_{t}(x, y)}{I_{t-\\Delta t}(x, y)}\\right)<-\\tau\n\\end{array}\\right.\n$$\n\n\n\n公式(1)表明，时刻t的瞬间图像，即$\\mathcal{I}_t$，在一个小时间周期$\\Delta t$内像素强度变化到阈值$\\pm\\tau$时触发事件。不失一般性，我们假设当$\\log \\left(\\frac{\\mathcal{I}_{t}(x, y)}{I_{t-\\Delta t}(x, y)}\\right)$在$[-τ, τ]$时，$p_{x,y,t}$取零。对于相邻的潜在图像$\\mathcal{I}_i$和$\\mathcal{I}_{i-1}$，可以得到如下关系，公式(2):\n\n\n$$\n\\mathcal{I}_{i}(x, y) \\approx \\mathcal{I}_{i-1}(x, y) \\cdot \\exp \\left(\\tau \\int_{t=i-1}^{i} p_{x, y, t} \\mathbb{1}\\left(\\mathcal{E}_{x, y, t}\\right) d t\\right)\n$$\n\n如果事件 $\\mathcal{E}_{x,y,t}$ 存在，则指示函数 $\\mathbb{1}(·)$ 等于1，否则为0。\n\n*注：这里用积分号表示累加，因为这里t可以是小数，即两帧潜在图像的间隔记录了多个时间戳的事件*\n\n\n\n需要注意的是，当 $\\Delta t,\\tau\\rightarrow 0$ 时上式(2)的近似误差越来越小，这意味着根据公式(1)是稠密事件。然而，由于受各种噪声的影响而不一致的$\\tau$，这种近似在实践中大部分是不够的，导致对比度和细节的丢失。为了解决这个问题，我们提出了一个联合框架，通过重新诠释一个序列去模糊过程，来学习从数据中重建清晰的图像。\n\n**深度序列去模糊** 事件辅助去模糊可以用**最大后验**表示，公式(3): \n$$\n\\mathbb{I}^* = arg\\ \\underset{\\mathbb{I}}{max}\\ P(\\mathbb{I}| \\overset{\\_}{\\mathcal{I}},\\mathbb{E}_{1\\sim T})\n$$\n读者注: 这里$\\mathbb{I}$表示模糊图像生成的图像序列，$\\overset{\\_}{\\mathcal{I}}$表示模糊图像，$\\mathbb{E}_{1\\sim T}$表示事件序列\n\n为了解决组合问题(3)，我们作以下简化。对于联合后验 $P(\\mathbb{I}| \\overset{\\_}{\\mathcal{I}},\\mathbb{E}_{1\\sim T})$，我们利用相邻潜在图像之间的时间关系(2)，并假设一个马尔可夫链模型，公式(4):\n\n\n$$\nP(\\mathbb{I}| \\overset{\\_}{\\mathcal{I}},\\mathbb{E}_{1\\sim T}) \\approx P(\\mathcal{I}_T| \\overset{\\_}{\\mathcal{I}},\\mathbb{E}_{1\\sim T})\\times\\prod_{i=1}^{T-1}P(\\mathcal{I}_i| \\mathcal{I}_{i+1},\\overset{\\_}{\\mathcal{I}},\\mathbb{E}_{1\\sim T})\n$$\n其中， $P(\\mathcal{I}_i|\\mathcal{I}_{i+1},\\overset{\\_}{\\mathcal{I}},\\mathbb{E}_{1\\sim T}) = P(\\mathcal{I}_i|\\mathcal{I}_{i+1},\\overset{\\_}{\\mathcal{I}},\\mathbb{E}_{i \\sim i+1})$ ，具有马尔可夫假设。请注意，这个简化的模型首先估计$\\mathcal{I}_T$(读者注：最后一张图)，然后按反向顺序执行序列重建。根据贝叶斯规则，一个最大化反向重构的步骤为，公式(5)：\n\n\n$$\n\\mathcal{I}^*_i = arg\\ \\underset{\\mathcal{I}_i}{max}\\ P(\\mathcal{I}_{i+1},\\overset{\\_}{\\mathcal{I}}, \\mathbb{E}_{i\\sim i+1}| \\mathcal{I}_i) P(\\mathcal{I}_i)\n$$\n在这里，前面的项 $P(\\mathcal{I}_i)$ 表示潜在图像的期望分布，类似在最近基于事件的图像重建中的 $\\mathcal{l}_1$ 梯度[3]或流形平滑[24]。为了对似然项建模，我们假设有一个从以前的重建得到的初步估计，通过(2):\n\n\n$$\n\\hat{\\mathcal{I}}_i = \\mathcal{I}_{i+1}\\odot exp(-\\tau S^i_{i+1})\n$$\n式中，对于 ${\\forall}x,y$ , 有  $\\mathcal{S}^i_{i+1}(x,y) = \\int_{t=i}^{i+1}p_{x,y,t} 1(\\mathcal{E}_{x,y,t})dt$ ，其中$\\odot$表示哈达玛(Hadamard)积。由于时间间隔很小，我们假设的常数$\\tau$，只引入了很小的漂移(注:可能指偏差，误差)，并提供良好的初始化。为了求解$\\mathcal{I}^*_i$，有几个工作假设以 $\\hat{\\mathcal{I}}_i^*$ 为中心的简单分布来定义(5)中的似然项，例如在[24]中使用了泊松分布。这样公式(5)可以作为一个深入研究的去噪问题。\n\n代替使用简单的图像先验，我们借用了最近基于学习的深度降噪先验研究[53,50]。特别地，我们插入一个深度网络 $\\mathcal{N}$ 作为可学习的降噪器，公式(7):\n\n\n$$\n\\mathcal{I}^*_i = \\mathcal{N}(\\hat{\\mathcal{I}}_i ,\\mathcal{I}_{i+1},\\overset{\\_}{\\mathcal{I}}, \\mathbb{E}_{i\\sim i+1 })\n$$\n因此，潜在图像$P(\\mathcal{I}_i)$ 的先验值不是明确定义的，而是从训练数据中隐式学习的。为了减少参数大小和防止过拟合，我们对公式(5)的每个去模糊步骤使用相同参数集控制的相同网络，形成一个循环架构。\n\n解问题(4)的剩余问题是如何得到初始潜在图像，即$\\mathcal{I}_T$。我们使用的事实是，模糊图像$\\overset{\\_}{\\mathcal{I}}$大致等于瞬时图像在曝光过程中的平均值。结合这个事实和公式(6)，我们有，公式(8)：\n\n\n$$\n\\overline{\\mathcal{I}} \\approx \\frac{1}{T} \\sum_{i=1}^{T} \\mathcal{I}_{i}=\\mathcal{I}_{T} \\odot \\frac{1}{T}\\left(1+\\sum_{t=2}^{T} \\prod_{i=1}^{t-1} \\mathcal{B}_{T-i+1}^{T-i}\\right)\n$$\n式中$\\mathcal{B}^{i}_{i+1} = exp(-\\tau\\mathcal{S}^i_{i+1})$，$\\mathcal{S}^i_{i+1}$在公式(6)中定义。它使用模糊图像$\\overline{\\mathcal{I}}$和事件对$\\mathcal{I}_T$进行初始估计，称为$\\hat{\\mathcal{I}}_T$。因此，我们也把$\\mathcal{I}_T$作为一个去噪问题来解决，以$\\hat{\\mathcal{I}}_T$为中心，并使用网络来近似它。然而，我们注意到，公式(8)中的累加运算符引入了更多的漂移，而不同于序列的去模糊步骤。因此，我们纠正$\\hat{\\mathcal{I}}_T$通过一个独立的、更强大的网络 $\\mathcal{I}^*_T = \\mathcal{N}_0(\\hat{\\mathcal{I}}_T ,\\overset{\\_}{\\mathcal{I}}, \\mathbb{E}_{1\\sim T})$ 。Alg.1 中总结了整个去模糊过程。注意，根据设计(7)，潜在图像以来自图像和事件的局部和长期线索为条件。\n\n\n\n`Alg.1 事件辅助的深度运动去模糊: 通过公式8计算原始模糊图像恢复出的最后一帧图像，用一个好的网络对该帧去模糊；之后根据公式2，已知一帧求前一帧，对求出的帧用待训练的网络去模糊`\n\n![image-20210422143259391](/img/event-based-motion/image-20210422143259391.png)\n\n\n\n## 4. 网络架构\n\n图2展示了本文提出的基于事件的运动去模糊架构，其中包括：(1)一个读取网络，它遍历事件并生成全局场景运动的单个表示；(2)一个初始化网络，它将外观和运动结合起来以生成初始潜在图像；(3)以及一个循环处理网络，依次对所有潜在图像去模糊。读取和初始化网络实例化算法Alg. 1中的 $\\mathcal{N}_0$ ，而处理网络实现算法Alg. 1中的 $\\mathcal{N}$ 。\n\n**读取网络** 读取所有事件数据并生成一个联合表示，代表全局的事件运动。为了实现这一点，在曝光期间的事件首先被存储为等长的时间间隔(在图2中有3个间隔)。在每个时间间隔中，事件通过stacked(堆叠)事件帧[17]来表示，进一步将时间间隔~~划分为8个大小相等的块~~，概括每个块中事件的极性，并沿着通道维度stacking(累计)结果。读网络是一个由卷积块和顶部的卷积LSTM[41]组成的循环编码器，用来长期累积特征。\n\n![image-20210422143446090](/img/event-based-motion/image-20210422143446090.png)\n\n`图2.本文基于事件的运动去模糊学习框架。为了更好的可视化，我们只假设从模糊图像中恢复4个清晰的帧。详细的层和参数配置参考补充材料。注意由于空间不够，运动补偿(MC)模块没有被画出。有关架构的详细描述，请参阅文本。`\n\n\n\n**初始化网络(InitializeNet)**  从模糊图像中解码出图像的外观，并将其与全局运动相结合，求解出潜在图像 $\\mathcal{I}^*_T$  。它将模糊图像 $\\overline{\\mathcal{I}}$ 和初始估计 $\\hat{\\mathcal{I}}_T$ (由公式(8)得到)作为输入，用卷积编码器对其进行处理，将得到的编码与读取网络中累积的全局运动特征拼接(Concat)起来，并将联合特征输入解码器得到结果。\n\n给定初始结果，然后处理网络依次对剩余的潜在图像去模糊。在第i步，它需要图像和基于事件的观测(作为输入)。图像部分包括：1)用前一帧的重建 ${\\mathcal{I}_{i+1}}$ 通过等式(6)获得的初始估计 $\\hat{\\mathcal{I}}_i$ ；2)对前一帧的结果${\\mathcal{I}_{i+1}}$ 使用运动补偿模块（图2中的MC）的变换，得到的局部+历史图像；3)由定向事件滤波模块（图2中的\"DEF''）给出的边界引导映射(boundary guidance map)。稍后将进一步解释这两个模块。输入图像通过卷积层处理，并拼接(concatenated)上通过潜在融合从读取网络中提取的每一步事件的特征。融合的特征被处理并反馈给另一个卷积LSTM，以沿时间方向传播时间知识。最后，解码器使用联合特征并生成去模糊图像。\n\n**运动补偿(Motion compensation)** 我们使用一个运动补偿模块来扭曲(Warp)前一帧的去模糊结果 ${\\mathcal{I}_{i+1}}$ ，来生成第i个时间步的初始化。尽管公式(6)通过事件整合来实现这一点（即获取第i帧的初始化），我们发现直接扭曲清晰结果 ${\\mathcal{I}_{i+1}}$ 作为**附加**指导来预测流场(flow ﬁeld)更有效。事件的运动补偿已经在论文[10]中讨论过了。为了提高效率，我们采用了FlowNetS架构[9]，以事件 $\\mathbb{E}_{i\\sim i+1 }$ 为输入，直接返回从 $i$ 到 $i+1$ 的前向流(forward ﬂows)。扭曲(Warping)是通过一个可微的空间变换层来实现的[18,14]。\n\n**定向事件过滤(Directional event filtering)** 由于天然的模糊模型(8)和事件的噪声，初始估计 $\\hat{\\mathcal{I}}_i$ 可能遭受未处理的模糊。我们借助锐利的边界先验来缓解这个问题，这是一种被广泛探索的图像先验[7,46]，它从事件$\\mathbb{E}_{i\\sim i+1 }$中提取用于盲去模糊。\n\n事件表明场景照明的局部变化，并揭示物理边界。然而，随着场景边界的移动，在特定的时间，它们仅与在其位置触发的最新事件在空间上对齐。作为一个简单的例子，图(3)显示了成像后的顶线和底线对应于两个不同时间点的事件。它给出了**通过在适当的时空位置对事件进行采样，可以预先生成场景边界的方法**。注意，由于场景深度的变化，场景的不同部分可能会有不同的运动，**位置自适应采样**(position-adaptive sampling )是必不可少的。\n\n此外，由于事件是稀疏的、有噪声的、非均匀分布的信号，鲁棒采样过程应该决定采样的地点(即中心)和采样的数量(即尺度)。我们通过可微采样和滤波从数据中学习这个任务。对于每个图像位置p，用小网络从事件中**预测**一个**时间中心** $c (p)$ 和一组 $2k + 1$ **滤波系数** $\\{α_i\\}^k_{i=−k}$ ，其中k是滤波核的支持(support)，满足 $∀i, α_i≥0, \\sum^k_{i=−k} α_k = 1$ 。过滤后的结果由下式获得，公式(9)：\n\n\n$$\n\\mathcal{G}(\\mathbf{p})=\\sum_{i=-k}^{k} \\alpha_{k} s(\\mathbf{p}+\\lambda k \\mathbf{d}(\\mathbf{p}, c(\\mathbf{p})), c(\\mathbf{p})+\\lambda k)\n$$\n`读者注：d(p, c(p))表示像素点p在时间c(p)时的速度`\n\n式中λ定义采样步长(我们用 k = 2, λ = 1)， s(·, ·)表示**时空域**的采样函数。对于事件 $\\mathbb{E}^{i+1}_i$ 的堆叠事件帧表示，可以应用连续采样[21]的三线性核(trilinear kernal)。注意，速度d应该遵循事件在时空点 $(p, c (p))$ 的局部运动方向，沿着事件的密集面过滤，而不是穿过它。\n\n![image-20210422143957672](/img/event-based-motion/image-20210422143957672.png)\n\n`图3. 自适应事件采样的动机。(a)一个玩具场景，顶部的线先向下移动，然后底部的线向上移动。事件的正极和负极的分别用红点和绿点表示。(b)成像过程后场景的投影图像。场景边界对应于最近触发的事件，这些事件可能会因不同的位置而变化，如箭头所示。(c)事件累积映射(map)。`\n\n\n\n为了得到局部速度，再利用了运动补偿模块预测的流向量。我们假设物体速度保持不变，在这里大致是正确的，因为只有一小部分(很短的)持续时间(只有曝光时间的 $\\frac{1}{T-1}$ )。运动补偿给出了所有位置 $p_0\\in \\mathbb{P}$ 在时间 $i$ 的速度 $d (p_0, i)$ 。在时间 $c(p)$，像素 $p_0$ 将通过流动移动到一个新的位置，公式(10): \n$$\nn(p_0)=p_0+(c(p)−i) d(p_0, i)\n$$\n注意，$n(p_0)$在局部常量假设下继承$p_0$的速度，即：$d(n(p_0)，c(p)) = d(p_0, i)$。\n\n\n\n但是，在时间平面$c(p)$的相交位置，即$\\{ n(p_0) | p_0 \\in \\mathbb{P} \\}$，并不能保证图像空间的完整采样。因此，我们用Nadaraya-Watson估计器重新采样给定目标p处的速度[4]，公式(11): \n\n\n$$\n\\mathbf{d}(\\mathbf{p}, c(\\mathbf{p}))=\\frac{\\sum_{\\mathbf{p}_{0} \\in \\mathbb{P}} \\kappa\\left(\\mathbf{n}\\left(\\mathbf{p}_{0}\\right)-\\mathbf{p}\\right) \\mathbf{d}\\left(\\mathbf{n}\\left(\\mathbf{p}_{0}\\right), c(\\mathbf{p})\\right)}{\\sum_{\\mathbf{p}_{0} \\in \\mathbb{P}} \\kappa\\left(\\mathbf{n}\\left(\\mathbf{p}_{0}\\right)-\\mathbf{p}\\right)}\n$$\n`读者注：n(p0)表示在第i帧的p0像素使用光流法估计出该点在第i+1帧时的位置，用周围的点预测一个点，清除噪声`\n\n式中核κ的定义是标准高斯函数。这在本质上与计算机图形学中用于表面渲染的收集(\"gather\")方法[49]有相似之处。\n\n公式(11)使用所有 $p_0$ 来估计每个位置p，是低效的。在实践中，我们只使用位于以p为中心的局部$L\\times L$窗口内的样本。窗口大小L应该考虑像素的最大空间位移，我们发现L = 20就足够了。所有提出的步骤都是可微的，可以插入到网络中进行端到端的训练。\n\n**损失函数** 我们使用下面的联合损失函数 \n\n\n$$\n\\mathcal{L}_{\\text {total }}=\\mathcal{L}_{\\text {content }}+\\lambda_{a} \\mathcal{L}_{a d v}+\\mathcal{L}_{\\text {flow }}+\\lambda_{t} \\mathcal{L}_{t v}\n$$\n式中，$\\mathcal{L}_{\\text {content}}$ 是亮度$\\mathcal{l}_1$损失 $\\frac{1}{T} \\sum_{i=1}^T ||\\mathcal{I}_i^*-\\mathcal{I}_i^g||$ ，式中 $\\mathcal{I}_i^g$ 是清晰图像的groundtruth(标签)。为了提高结果的清晰度，我们也纳入了对抗性损失 $\\mathcal{L}_{adv}$ 。我们使用相同的**PatchGAN**鉴别器[13]，并严格遵循它原来的损失定义。\n\n光流(flow)网络引入了另外两个损失项。第一个 $\\mathcal{L}_{flow}$ 是光度重建损失\n\n\n$$\n\\mathcal{L}_{\\text {flow }}=\\frac{1}{T-1} \\sum_{i=1}^{T-1}\\left\\|\\omega\\left(\\mathcal{I}_{i+1}^{*}, \\mathcal{F}_{i \\rightarrow i+1}\\right)-\\mathcal{I}_{i}^{g}\\right\\|\n$$\n式中 $\\omega(.,.)$ 是一个使用前向流 $\\mathcal{F}_{i\\rightarrow i+1}$ 的后向扭曲函数(backward warping function)， $\\mathcal{L}_{tv} = \\frac{1}{T-1} \\sum_{i=1}^{T-1}||\\triangledown \\mathcal{F}_{i\\rightarrow i+1}||$ 是流场平滑的总变化损失。 对于这些术语，我们遵循论文**[14]**相同的定义。设$λ_a$和$λ_t$的权值分别为0.01和0.05。\n\n## 5. 实验\n\n### 5.1 实验设置\n\n**数据准备** 我们使用两个数据集进行评估。首先，我们对在GoPro[25]数据集上进行评估，该数据集被广泛用于图像运动去模糊，最近[31]使用它来测试(benchmark)基于事件的去模糊。为了可靠地合成事件，我们使用了开放ESIM事件模拟器[35]。我们遵循训练和测试分离的建议。官方也提供了平均附近(数字从7到13)帧的模糊图像。\n\n由于缺乏在真实场景中评估基于事件的运动去模糊的大规模数据集，我们用DAVIS240C相机捕获了一个新的城市环境数据集，称为Blur-DVS。它混合了一个高速事件传感器和一个记录强度为 $180 \\times 240$ 的低帧率有源像素传感器(APS)。因此，APS在快速移动时可能会出现运动模糊。我们收集两个子集进行评估。慢速子集由15246幅相对静态场景的缓慢而稳定的相机运动捕获的图像组成，因此很少发生运动模糊。我们通过对附近7帧的平均来合成运动模糊，得到2178对模糊图像和清晰序列。通过这种方式，我们可以进行定量的基准测试。我们选择1782对用于训练，396对用于测试。快速子集由额外的8个序列组成，共740帧，在快速运动场景的快速相机运动下捕获，以研究如何将所提出的方法推广到真正的运动模糊。然而，没有关于这个子集的groundtruth数据可用。\n\n**方法对比** 我们用现有的结果和/或代码与最近的运动去模糊方法进行了广泛的比较。它们包括基于图像的方法:DCP [29]， MBR [42]， FLO [11]， DMS [25]， EVS [15]， SRN [43]， SVR[52]和MPN[50]，以及最先进的基于事件的运动去模糊方法BHA[31]。我们还比较了三种基于事件的视频重建方法，包括CIE [38]， MRL[24]和最先进的基于学习的方法ETV[36]。采用PSNR和SSIM指标进行定量评价。\n\n\n\n![image-20210429134035625](/img/event-based-motion/image-20210429134035625.png)\n\n\n\n![image-20210429134149352](/img/event-based-motion/image-20210429134149352.png)\n\n`图4. 在GoPro数据集上的可视化比较。从左到右分别展示了MPN[50]、BHA[31]和我们方法的模糊图像和groundtruth清晰图像的结果。放大看得更清楚。`\n\n\n\n![image-20210429134728267](/img/event-based-motion/image-20210429134728267.png)\n\n`一种混合基线，首先采用CIE对图像进行重构，然后采用SRN对图像进行去模糊处理。详情请参见[31]。`\n\n**实现细节** 对于这两个数据集，我们的训练采用的batch size为2个训练对的和优化器为Adam。该网络训练400个epoch，以学习速率 $10^{-4}$ 开始，并从第200个epoch开始线性衰减到零。网络的所有组件都是从零开始共同训练的。\n\n### 5.2 与最先进方法比较\n\n在GoPro数据集上，我们分别在表1和表2中报告了单幅图像去模糊(即只恢复中间帧)和视频重建(即恢复所有清晰帧)的结果。大部分其他方法(j结果)都直接取自论文。我们的方法在这两个任务中都达到了最高的位置，展示了事件辅助去模糊比纯粹依赖图像的优势，以及所提出的框架优于物理重建模型。我们在图4中展示了两个快速移动场景的视觉对比:虽然基于图像的方法MPN不能很好地解决这种模糊，但BHA对事件的噪声很敏感，特别是沿着物体边缘的噪声。我们的方法产生了更干净、更清晰的结果。\n\n需要注意的是，GoPro数据集主要表现为小到中等程度的运动模糊，因此模糊输入的质量较好，从事件中得到的改进是有限的。因此，最近强大的架构SRN和MPN得到了非常有前景的结果，尽管它们没有看到事件。出于这个原因，我们将我们的方法与最先进方法在提出的Blur-DVS数据集上进行比较，在这些数据集中，严重的运动模糊更为普遍。再次，我们报告单个图像去模糊(表3)和视频重建(表4)任务的结果。请注意，为了公平比较，基于学习的方法SRN、MPN和ETV在Blur-DVS的训练集上进行了微调。我们还比较了增强版的图像和事件:对于基于图像的SRN和MPN方法，我们将输入的模糊图像与所有48个事件帧(每个时间间隔和(7 1)时间间隔内的8个帧)连接起来。对于基于事件的方法ETV，我们也将模糊图像连同事件一起提供给其每个周期性重建步骤。我们分别将这些变量表示为SRN+、MPN+和ETV+。\n\n在表3和表4中，本文提出的方法取得了最好的结果。它的性能也优于所有增强的变体，证明了所提出的框架的有效性。从图5可以看出:1)在快速运动的情况下，仅基于图像的线索是不够的，限制了MPN的性能;2)由于事件的有损采样机制，物理模型BHA容易产生噪声，并呈现未处理的模糊;3)基于事件的重建方法CIE、MRL和ETV由于缺乏图像引导和/或物理模型简化，无法正确恢复场景对比度。我们的方法没有遇到上述问题，甚至比配备强大架构的增强图像+事件变体的结果更清晰。\n\n最后，我们分析了现实运动模糊的泛化行为。如图6所示，本文方法获得了最好的视觉质量。我们怀疑运动去模糊的显式建模和强去模糊先验的引入可能会减轻学习困难，并避免潜在的过拟合在更多的黑箱架构中。在实践中，我们发现这种改进与真实数据一致，这一点在补充材料中提供的快速子集的更多结果中得到了证明。\n\n![image-20210429134347374](/img/event-based-motion/image-20210429134347374.png)\n\n\n\n![image-20210429134535535](/img/event-based-motion/image-20210429134535535.png)\n\n`图5. 在模糊-分布式数据集的慢运动子集上，用不同方法生成的两个例子的代表性结果。更多的结果可以在我们的补充材料中找到。放大看得更清楚。`\n\n\n\n`模糊分布式 数据集 的视频重构性能。`\n\n![image-20210429134645033](/img/event-based-motion/image-20210429134645033.png)\n\n### 5.3 技术性能分析\n\n**分析不同的组件** 我们将重要的算法组件分离出来，看看其他对最终性能的贡献，并将结果总结在表5和图7中。由此可见，为了提高结果的PSNR和SSIM，每个分量都是必要的。只使用图像外观而不使用事件(App.)不能很好地消除图像模糊。另一方面，仅使用事件可以恢复大量的细节，但强度对比度不能很好地恢复(见图7(b))。同时使用两种输入信号(App. + event)效果更好，但由于噪声的影响，重构图像不是很平滑(如图7 (c)中的地面)。进一步结合运动补偿(+MC)有助于这些方面，因为它强加了时间平滑。最后，进一步引入定向事件过滤模块(+DEF)，学习到的边界指导可以产生更清晰的结果和更丰富的细节。\n\n`表5 模糊-分布式数据集的组件分析。App.和event分别表示以模糊图像外观和事件数据作为输入。MC和DEF分别为运动补偿模块和方向事件滤波模块。`\n\n![image-20210422145324727](/img/event-based-motion/image-20210422145324727.png)\n\n**DEF模块的校准** 在表6中，我们证明了提出的方向事件过滤模块的必要性。在这里,\"w/o guid\"。在整个流程中不包括边界指导。相反，“guid only”。在每个连续的清除步骤中丢弃事件特征，而只使用边界指导作为附加线索。我们进一步设计了一个变体“+param.”，它不包含DEF，但在处理网络的编码器中有额外的卷积层，超出了当前的参数大小(即参数变多了)。结果表明，学习到的边界引导极大地提高了估计(SSIM从0.786提高到0.827)，并且在没有其他线索的情况下也可以得到很好的结果。然而，简单地扩大网络规模，并没有观察到有意义的改善。\n\n![image-20210422145504218](/img/event-based-motion/image-20210422145504218.png)\n\n`图6 在Blur-DVS数据集的快速子集(真实世界运动模糊)上，通过不同方法生成代表性结果。更多的结果可以在我们的补充材料中找到。放大看得更清楚。`\n\n![image-20210422145626221](/img/event-based-motion/image-20210422145626221.png)\n\n`图7 可视化地分析不同组件在DVS-Blur数据集上的贡献。详情请参见文本。`\n\n\n\n`表6 分析了DVS-Blur数据集上的方向事件过滤模块。详情请参见text。`\n\n![image-20210422145728340](/img/event-based-motion/image-20210422145728340.png)\n\n在图8中，我们将学习边界引导的作用可视化。关注网络如何学习根据场景的运动选择不同的时间中心(图8 (c))。边界引导显著提高了场景的清晰度，并恢复了缺失的细节(图8 (e)和(f))。\n\n![image-20210422145909881](/img/event-based-motion/image-20210422145909881.png)\n\n`图8 可视化学习的边界指导。请注意图(c)中如何选择来自不同时间戳的运动边界(红色代表大值，蓝色代表小值)。`\n\n\n\n**微光摄影** 如图9所示，该方法的一个潜在应用是微光摄影。短曝光(13ms)图像缺乏光线。然而，长曝光(104ms)的相机可能会出现严重的运动模糊。利用事件线索，我们的方法产生自然的结果，没有这种模糊。\n\n![image-20210422150033834](/img/event-based-motion/image-20210422150033834.png)\n\n`图9 使用我们的方法进行微光摄影。在室内场景中，用DAVIS240C相机捕捉图像和事件。`\n\n## 6. 结论\n\n在这项工作中，我们提出在事件的帮助下从严重的运动模糊图像中提取视频。为此，提出了一种新的深度学习体系结构，在全局和局部粒度上有效融合外观和运动线索。在此基础上，利用新的定向事件滤波模块提取清晰的事件边界引导来改善重构细节。广泛的评估表明，与各种现有的基于图像和事件的方法相比，所提出的方法在合成和真实数据集上取得了更好的性能。","comments":true,"categories":[],"tags":[{"name":"CS","slug":"CS","permalink":"http://blog.ahulearn.com/tags/CS/"},{"name":"CVPR2020","slug":"CVPR2020","permalink":"http://blog.ahulearn.com/tags/CVPR2020/"}]},{"title":"2020机械跨考二战复旦大学计算机经验分享","date":"2020-09-01T05:00:00.000Z","path":"2020/09/01/机械跨考二战复旦大学计算机经验分享/","raw":"---\ntitle: 2020机械跨考二战复旦大学计算机经验分享\ndate: 2020-09-01 13:00:00\ntags:\n - 考研\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\n---\n\n经验这东西，必须具体问题具体对待，一人的经验不可能适合所有人。也不存在什么复习的捷径，个人认为好的经验并不能让你事半功倍，只是单纯指出一条让你相信自己这么干也能成功的道路。以下观点和经验都是一家之言，我不坚持自己的看法。本来打算多写点，但是现在突然感觉没什么可写的了，感触还没我去年的深。\n\n<!--more-->\n\n首先说明个人背景，如果和我相似可能这些经验有用，如果差别很大，那下面经验大概率没用的：\n\n\n* 本科机械，跨专业二战，第一年已经打下一定基础，但其实第二年开始复习的时候已经差不多都忘完了。\n\n* 有较好的数学基础，从小数学比较好，但是高中之后就考不了高分了，即便是题目很简单也考不高。自认为原因主要是粗心大意，草稿较乱，创新不足；分别导致简单题做错，计算复杂题做错，思路新颖题目做错。\n\n* 英语极差，单词量历史最高不超过5k, 今年考研复习之初应该已经降到低于2k了, 四级考3次才过，六级没过。唯一的基础大概就是初中英语老师教的16种时态语态，自此就觉得语法(应该是句法)这东西不用学，初中水平够用一辈子。\n\n* 对计算机很感兴趣，虽然没深入学习过任何一门语言，但是在平时做点自娱自乐的东西，接触或使用过至少四五种编程语言。\n\n* 喜欢通过视频学习，尤其是知识入门，对于新知识，我看书效率极低。\n\n\n这里先报一下初试成绩，以供参考：总分: 370, 英语二: 56, 政治: 69, 数学二 : 115, 408专业课: 130\n\n附一战成绩参考：总分: 345, 英语二: 70, 政治: 72, 数学二 : 118, 960专业课: 85\n\n**初试：**\n\n部分内容可参考去年我写的一战反思贴([http://www.cskaoyan.com/thread-652663-1-1.html](http://www.cskaoyan.com/thread-652663-1-1.html))，重复内容这里我会简略说。\n\n\n**数学：**\n\n今年主要跟的张宇，今年看的视频不多，但是对比去年我看的视频，我觉得高数张宇和汤家凤各有所长吧，宇哥特色风趣幽默，手里积累的题目较多，讲课会有不少新颖的题目和思路。汤神题型总结的很好，什么题用什么方法总结的很到位，这种总结如果自己做，是需要靠大量刷题才能积累出的经验。可根据自己的喜好选择，老师水平都在的，关键看自己适合哪个老师。线性代数还是非永乐大帝莫属吧，张宇的我今年看感觉也不错。\n\n看的视频：张宇的闭关修炼，张宇的线性代数强化。\n\n所用的资料：李范全书，书的章节顺序不知道为什么要和主流的资料不一致，但是质量还行，难度挺大，用来系统过一遍知识点还是值得推荐的。李永乐线性代数讲义，必做的一本资料。试卷：张宇八套卷，会有个别难题，但是跟过张宇的强化的话，里面的难题视频中都有涉及，做起来就还可以。超越共创5套卷，做了过去至今四五年的，质量还不错。历年真题: 其实并没有做，我只是把去年做过的有看了看。李林6套卷4套卷：比较推荐，便宜不说题目质量很好，林哥看来还是有两把刷子吧。\n\n复习推荐：全书类资料一本，或者张宇18讲这种，尽快过一遍，这类资料主要是学习知识点，同时通过做附带的题巩固知识点，也强化理解知识点在做题中的实际应用。我在这一块花费时间占数学复习的一大半，这非常不值得，去年其实我也犯了这个错误，但是没用改正。应该把做套卷作为复习的重点。通过做试卷才能熟悉考试的题型，真正的熟悉综合题目和发现自己不足之处，全书类的资料尽快一轮过然后扔一边即可，不会的时候再回头查查，试卷是关键，在做试卷的过程中查漏补缺可以迅速提高。\n\n\n政治：视频跟徐涛，做题用肖秀荣就行，别的不多说了。强调一下，政治复习的重点是选择题，选择的复习方法就是看视频，早晚皆可，最好9月之前就要开始，因为视频挺多，选择重在理解而非记忆，可以多倍速播放看。而大题尽量晚一点，早了没用，到11月底不迟，其实大部分人估计就是12月份才开始准备政治大题吧。肖秀荣4套卷出来才真正准备。另外推荐使用别人总结的框架或者说简洁版来背肖四。肖的语言背起来有点难，简洁版其实考场现场发挥补充一下，和肖的原话分数不会有区别。\n\n看的视频：徐涛基础，徐涛强化，徐涛刷题班(必看)，徐涛冲刺班，徐涛押题(即大题答题总结)\n\n用的资料：肖秀荣全家桶+徐涛核心考案\n\n另外推荐可用微信小程序刷题，不过基本都是付费的。\n\n\n**英语：**\n\n首先感谢群友MX拉我进他自建的墨墨打卡群，群里学习氛围真的好，我才坚持背了两三个月的单词。否则这次我铁定单科不过线。\n\n今年我英语分数比去年骤降，主要说明了两点问题：1. 同样菜的水平，既可以考50+也可以考70，分数和实力并不是正相关。因为我的英语水平相对去年即便没提高也绝不算降低，但是分数却降了很大，之后会说明原因。2. 二战大概率并不会提高分数，因为很多人根本不会去总结失败的原因，或者找到原因第二年也不会去改变。\n\n对于英语的观点我和去年还是一致，单词是关键，背单词是菜鸡提分最重要的一步，其他都是浮云。现在就要坚持每天背单词，记忆任务可以逐渐提高，最后要做到每天记忆或复习几百词的水平。其次考前冲刺很重要，作文和翻译基本靠考前冲刺，作文一定要尽早准备模板并背下。英语二作文基本可以肯定只考图表类了。图表可以准备两类，一类是数据随年份变化的，一类是只有一年数据的。至于为什么用模板？原因很简单，备考效率高，得分高(对大部分人来说)。虽然几乎所有英语作文辅导老师都反对模板，对模板嗤之以鼻，猛烈的抨击讲模板的老师。但是就我看了这么多视频发现，他们不过是没看出来自己讲的其实也是模板罢了，或者自觉自己讲的模板，但自以为自己的模板更灵活更新颖。不讲模板的老师怕是只有道长了，让背范文，强化几十篇，真题几十篇，押题再搞几十篇，说实在要真背了肯定高分，关键效率真的不高，而且适合的人群估计都是大佬。我个人觉得还是背模板吧。最后练字，作文和翻译字会对分数影响极大，一定要练字，这个非常非常重要。\n\n我分数下降那么多，主要是因为：背单词没有坚持考前，考前一个月差不多就没背过单词了，单词忘得真的太快太快了，请考前不要中断单词的复习。作文准备不充分，虽然我看了很多视频总结了自己的模板，但是最后我却没背下来，导致作文写的太烂。今年没练字，作文翻译都写的很难看。还有一点去年70分的成绩真的让我误以为我英语水平提高了，我想我已经不那么菜了，就有点松懈，没想到原来我还是那个菜的一批的我。\n\n资料视频用的和去年差不多，单词背诵软件推荐墨墨。\n\n\n**专业课：**\n\n今年专业课比去年提高了不少，主要以下原因：1. 专业课由960变为408，个人感觉虽然内容有增加，但难度下降。2. 去年专业课太低的阴影让我二战期间将大部分时间都交给了专业课，做题水平(非知识水平)有很大提高。3. 观看了大量408课程相关的视频，知识广度有很大提高。4. 408相关资料很多，真题样本足够，比较容易摸清考点。\n\n所看视频：\n\n计算机网络：韩顺平的计网必看，去年我各个群里是没少推荐，但真正看的好像不多，主要他视频不是针对考研的。实践操作较多，理论性的东西对考研又稍显不足。但视频里对计网的方方面面基本都讲到了，其中的实践可以把抽象的理论变得浅显易懂，看完对计网的理解会提高一个境界，远高于看教材或其他考研视频。该视频有两种用法，一是针对跨考生用来快速搭建计网框架，快速过一遍可以知道计网到底讲什么。二是通过和王道或tq单科书相互补充，认真观看视频，深入理解计算机网络。王道的计网视频好像也不错，可以一看，相互补充吧。\n\n数据结构：入门：郝斌，强推，实战演练式的教学，理论知识涉及不全面，但实战丰富，讲解通俗有趣，用此入门快准狠，学习数据结构的同时可以提高代码水平，跨考必看。强化：王道数据结构，严蔚敏数据结构，陈越数据结构，邓俊辉数据结构，选其一到二即可，我是都看了一点，但都没看完，总的来说，严的比较难，还很陈旧。邓的也比较难，和考研风格也不太符合，王道和陈越我看了一点点，不太了解，这些视频没必要系统看完，可根据自己不会的点选择观看。\n\n操作系统：操作系统王道的文件管理讲的很好，我没看完就看了这部分。浙江大学操作系统李善平，内存管理和进程管理都讲的十分好，强烈推荐。清华大学操作系统(向勇、陈渝)，除了文件管理讲的一般其他都不错，讲的很深，我看的第一个操作系统视频就是这个。\n\n组成原理：哈工大的计组很好，但是讲解较深，偏硬件一点，不过考研好像不那么硬。硬件了解多了其实对计组的理解有很大帮助的，我还是很推荐，我看了两遍收获颇大。另推荐周佳社的微机原理，微机原理更硬了一点，但是真的对计组的理解帮助很大，指令系统部分可以不看，其他部分都可以选择性看看。看完会发现计组也就是那回事，真的不难，就是内容多点，但这些内容并不是需要太多思考的东西，只需要了解或记忆即可，个人感觉数据结构才是难起来没上限的科目，其他三门都不是太大问题。\n\n\n资料：\n\n王道单科书全套2019(新版太贵封面还太难看，就没买)。王道八套卷2015,网上找的pdf打印做的，整体感觉还挺好的，考前也买了2020(发现没必要做，原因就不说了，有点尴尬)。tq八套卷2016，全套都做了感觉还不错。tq八套卷2020，群友分享的pdf，有点垃圾，不仅部分题目答案不对，而且选择题没解析。\n\n专业课总结：拓宽知识面，对408的复习很重要，今年的试题和往年相比，感觉风格变化挺大。有点偏向实践，理论考的不深，大题可以发现基本都没涉及到计算，和简答题差不多。所以广度可能比深度更重要点。还有一点，我一直代码水平极差，算法题无论难易我半小时内都搞不定，所以考前就下定决心，放弃算法题会我也不做，看都不看它一眼，就当满分135了。所以考场上压力就小，考的比较放松，结果做完了看时间还有五十来分钟，我才重新决定去看看算法题，最终也算做出了吧，思路不难就是实现成代码写了几十分钟，所以提前放弃一些题目可能会有更多收获，只要把会做的都做对。\n\n\n初试复习总结：复习要有计划，有计划效率会高很多，我在后期才有计划的复习，宏观计划我只精确到了周，到哪一周进度就完成到哪，而当周的复习，我会根据具体情况来看，任务虽然不一定都能完成，但确实比盲目复习效率高很多。少水点群，我以前都不怎么用qq的，考研考的整天水群，现在想想真浪费时间，没事群里胡侃没啥意思。另外基础好的水群可能更可怕，基础好自然好为人师，学习不就是为了装逼吹水么，在群里给这个讲讲题给那个讲讲题，讲题是好事，但是你会发现讲着讲着，其实别人早已经甩你一大截了，而你还自以为自己还很强呢，千万不要以为群里问题的水平菜就是群友都菜，大佬真的很多，给别人讲题讲多了容易飘。\n\n\n**复试：**\n\n今年的复试参考意义不大，毕竟特殊年份，以后不会再遇到网络复试这种情况。\n\n**机试：**\n\n机试往年的重中之重，几乎可以决定你复试的成与败，但今年却不直接算分，只是在面试环节会根据机试情况，进行了一定考察。\n\n底部附机试真题，及题解。\n\n**英语面**：\n\n英语面比例较小，只占复试的10%，折合成最后的总分只占5%。但是另一个角度想想还是蛮多的，折换为初试分竟有50分。\n\n好在英语面再差应该也有个及格分，所以折算为初复试总分，英语成绩的极差也就一两分。\n\n一定要好好准备自我介绍\n\n强调：自我介绍最好别提项目，除非你充分准备了项目相关的英语问答。\n\n\n**专业面**\n\n专业面我难度并不大，可能因为我是跨考，不过分数给的不高就是了。面试的时候竟然问了自动控制理论里的闭环控制算法(机械的专业选修课), 这个我是真的完全没印象，被嘲讽一波说应该是能脱口而出的东西，看来我本科学的东西都还是给了老师。之后就都问一些简单题了，可能这个给老师印象太差，认为我也回答不上难题。\n\n专业面的经验就是，如果有项目而且拿的出手，就好好准备项目，一定要搞懂自己的项目的各个细节。如果项目没什么意义，可以说，但是大概率导师不会问你项目的问题，基础知识和算法才是关键，而且这两样，回答稍有不好，就会很大影响老师的印象。准备必须要充分一点。\n\n同组的基础问题和算法很多会重复，如果能多认识同学，得到他们的面经，后面面试的可以极大的降低难度。\n\n低分选手专业面出现两种情况很可怕，问题自始至终很简单，甚至大部分时间在唠家常，或者问题很偏难度还较大，这两种情况极容易被刷。\n\n\n复试资料：[https://dir.lanzoum.com/iwi2kctr0xg](https://dir.lanzoum.com/iwi2kctr0xg)\n\n","comments":true,"categories":[],"tags":[{"name":"考研","slug":"考研","permalink":"http://blog.ahulearn.com/tags/%E8%80%83%E7%A0%94/"}]},{"title":"Designing Network Design Spaces","date":"2020-07-27T13:51:23.000Z","path":"2020/07/27/Designing Network Design Spaces/","raw":"---\ntitle: Designing Network Design Spaces\ndate: 2020-07-27 21:51:23\ntoc: true\ntags:\n - 论文翻译\n - 随笔\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\n---\n\n## 网络设计空间的设计\n\n### 摘要\n\n本文提出了一种新的网络设计范式。我们的目标是帮助提高对网络设计的理解，并发现在不同环境下普遍适用的设计原则。我们不再专注于设计单个的网络实例，而是设计了参数化网络总体的网络设计空间。整个过程类似于经典的人工网络设计，但提升到了设计空间层面。使用我们的方法，我们探索网络设计的结构方面，并得出一个低维的设计空间，由简单的，规则的网络组成，我们称之为RegNet。RegNet参数化的核心观点非常简单：良好网络的宽度和深度可以用量化的线性函数来解释。我们分析了RegNet的设计空间，得出了与当前网络设计实践不符的有趣发现。RegNet的设计空间提供了简单而快速的网络，可以很好地在各种不同的FLOP状态下工作。在类似的训练环境和FLOPs下，RegNet模型的性能优于流行的efficientnet模型，而在gpu上的速度高达5倍。\n\n<!--more-->\n\n### 介绍\n\n深卷积神经网络是视觉识别的引擎。在过去的几年里，更好的体系结构已经在广泛的视觉识别任务中取得了长足的进步。示例包括LeNet、AlexNet、VGG和ResNet。这一工作既提高了神经网络的有效性，也促进了我们对网络设计的理解。特别是，上述工作序列分别证明了卷积、网络和数据大小、深度和残差的重要性。这些工作的成果不仅是特定的网络实例，而且是可以推广和应用于许多设置的设计原则。\n\n尽管手动网络设计已取得了长足的进步，但手动寻找优化良好的网络可能会面临挑战，尤其是随着设计选择数量的增加。 解决此局限性的一种流行方法是神经体系结构搜索（NAS）。 给定可能的网络的固定搜索空间后，NAS会在搜索空间内自动找到一个好的模型。 最近，NAS备受关注，并显示出出色的效果。\n\n尽管NAS是有效的，但是这种范式有局限性。搜索的结果是将单个网络实例调整到特定设置（例如，硬件平台）。在某些情况下，这是不够的；但是，它不能帮助我们发现网络设计原则，加深我们的理解，使我们能够概括到新的设置。特别是，我们的目标是找到易于理解、建立和概括的简单模型。\n\n在这项工作中，我们提出了一个新的网络设计范例，它结合了人工设计和NAS的优点。我们不是专注于设计单个网络实例，而是设计参数化网络总体的设计空间。1与手动设计一样，我们的目标是可解释性，并发现描述网络的一般设计原则，这些原则简单、运行良好，并可跨设置进行概括。与NAS一样，我们的目标是利用半自动化过程来帮助实现这些目标。\n\n\n\n","comments":true,"categories":[],"tags":[{"name":"论文翻译","slug":"论文翻译","permalink":"http://blog.ahulearn.com/tags/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/"},{"name":"随笔","slug":"随笔","permalink":"http://blog.ahulearn.com/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"Large-Scale Image Retrieval with Attentive Deep Local Features","date":"2020-07-03T07:28:12.000Z","path":"2020/07/03/Large-Scale Image Retrieval with Attentive Deep Local Features/","raw":"---\ntitle: Large-Scale Image Retrieval with Attentive Deep Local Features\ndate: 2020-07-3 15:28:12\ntoc: true\ntags:\n - 论文翻译\n - 随笔\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\n---\n\n## 注意力深层局部特征的大规模图像检索\n\n### 摘要\n\n提出了一种适合于大规模图像检索的局部特征描述器，称为Deep-local-feature。新的特征是基于卷积神经网络，它只在地标图像数据集上使用图像级注释进行训练。为了识别在**语义上有用的图像检索局部特征**，我们还提出了一种用于关键点选择的**注意机制**，该机制**与描述符共享大部分网络层**。该框架可用于图像检索，作为其他**关键点检测器和描述符**的替代品，实现更精确的特征匹配和几何匹配验证。我们的系统产生可信的分数拒绝误报(FP)，尤其是它的健壮性针对数据库中没有正确匹配的查询。为了评估所提出的描述符，我们引入了一个新的大规模数据集，被称为谷歌地标(GLD)数据集，包括数据库和 查询搜索作为背景杂波，部分遮挡，多个地标、可变尺度的物体等DELF的成绩超过了全球和当地最先进的水平(SOTA)在大范围数据集中的描述符。可在以下网页找到项目代码：https://github.com/tensorflow/models/tree/master/research/delf。\n\n<!--more-->\n\n### 1. 介绍\n\n大规模图像检索是计算机视觉中的一项基本任务，它直接关系到目标检测、视觉位置识别、产品识别等各种实际应用。在过去的几十年里，图像检索系统取得了巨大的进步，从手工制作的特征和索引算法[22,33,27,16]到最近的基于卷积神经网络（CNNs）的全局描述符学习方法[2,29,11]。\n\n尽管基于CNN的全局描述符在中小型数据集中的图像检索方面取得了最新进展[27,28]，但在大规模数据集中观察到的各种具有挑战性的条件（如杂波<背景杂波>、遮挡和视点和照明的变化）可能会阻碍其性能。全局描述符缺乏在图像之间查找补丁级别匹配的能力。因此，在存在遮挡和背景杂波的情况下，基于部分匹配的图像检索非常困难。在最近的一个趋势中，基于CNN的局部特征被提出用于斑块级匹配[12,42,40]。然而，这些技术并没有特别针对图像检索进行优化，因为它们缺乏检测语义上有意义的特征的能力，并且在实际应用中显示出有限的准确性。\n\n大多数现有的图像检索算法都是在**查询图像**较少的中小型数据集中进行评估的，即[27,28]中只有55张和[16]中只有500张，并且数据集中的图像在地标位置和类型方面的多样性有限。因此，我们认为，通过大规模的数据集来提高检索结果的综合性和有效性，可以使我们从中得到更具挑战性的大规模图像检索方法论。\n\n本文的主要目标是开发一个基于CNN的特征描述子的大规模图像检索系统。为此，我们首先引入一个新的大规模数据集Google Landmarks(GLD)，它包含了来自近13K个独特地标的超过100万个地标图像。这个数据集覆盖了世界范围，因此比现有的数据集更加多样化和全面。查询集由额外的100K个具有各种特性的图像组成；特别是，我们在数据库中包含了不匹配(可能指数据库中不存在查询结果)的图像，这使得我们的数据集更具挑战性。这允许评估检索系统的健壮性通过查询不必要的地标描述。\n\n然后，我们提出了一种基于CNN的有注意力机制的局部特征，它只使用图像级的类标签进行弱监督训练，而不需要对象级和补丁级的标注。这种新的特征描述符被称为DELF（Deep Local feature），图1说明了特征提取和图像检索的总体过程。在我们的方法中，注意力模型与所提取的描述符紧密耦合；它采用相同的CNN架构，并且只需很少的额外计算就可以生成特征分数（符合对象检测的最新进展[30]）。这使得本地描述符和关键点的提取都可以通过一个前向通道网络。结果表明，与基于全局和局部描述子的方法相比，基于DELF的图像检索系统具有更高的检索效率。\n\n### 2. 相关工作\n\n有标准的数据集通常用于评价图像检索技术。**Oxford5K**[27]有5062个在牛津拍摄的建筑图像，其中55个查询图像。**Paris6k**[28]由6412幅巴黎地标图片组成，也有55幅查询图片。这两个数据集通常使用来自Flickr100k数据集[27]的**Flickr100k**图像进行扩充，后者分别构建**Oxford105k**和**Paris106k**数据集。另一方面，**Holidays dataset**数据集[16]提供了1491张图片，包括500张查询图片，这些图片来自个人假日照片。这三个数据集都非常小，尤其是查询图像的数量非常少，这使得在这些数据集中测试的性能很难**通用化**。虽然**Pitts250k**[35]比较大，但它专门用于具有重复图案的视觉区域，可能不适合一般的图像检索任务。\n\n实例检索是近十年来研究的热点问题。最近的调查见[43]。早期的系统依赖于手工制作的局部特征[22,5,8]，再加上使用**KD树**或**词汇树**的**近似最近邻搜索方法**[6,25]。时至今日，这种基于特征的技术与几何重排序相结合，在检索系统需要高精度操作时提供了强大的性能。\n\n最近，许多研究集中在局部特征的聚集方法上(应该指使用局部描述符聚合成全局描述符)，其中包括一些流行的技术，如**VLAD**[18]和**Fisher Vector**（FV）[19]。这种全局描述符的主要优点是能够以紧凑的索引提供高性能的图像检索。\n\n在过去的几年中，一些基于cnn的全局描述符被提出使用预先训练的[4,34]或学习网络[2,29,11]。为了保持相关图像和无关图像之间的排序，这些全局描述符最常用三元组损失进行训练。一些使用这些基于CNN的全局描述符的检索算法利用深度局部特征作为传统聚集技术（如VLAD或FV）中手工构建的特征的替代品[24,36]。其他的工作已经重新评估和提出了不同的特征聚合方法使用这些深的局部特征[3，21]。\n\nCNN也被用来检测、表示和比较局部图像特征。Verdie等人[37]学习了**可重复关键点检测**的回归函数。Yi等人[41]提出了一种基于CNN的通用技术来估计局部特征的典型方向，并成功地将其应用到多个不同的描述符上。**MatchNet**[12]和**Deep Compare**[42]提出联合学习块表达和相关的指标。最近，LIFT[40]提出了一个端到端的框架来检测关键点、估计方向和计算描述符。与我们的工作不同的是，这些技术不是为图像检索应用而设计的，因为它们没有学习**选择语义上有意义的特征**。\n\n许多视觉识别问题都采用了基于深层神经网络的视觉注意力，包括目标检测[45]、语义分割[14]、图像捕获[38]、视觉问题回答[39]等。然而，视觉注意力在图像检索应用中的学习视觉特征还没有被积极探索。\n\n### 3. 谷歌地标数据集\n\n我们的数据集是基于[44]中描述的算法构造的。与现有的用于图像检索的数据集[27,28,16]相比，新的数据集要大得多，包含多个地标，并且涉及大量挑战。它包含来自12894个地标的1 060 709个图像，以及111 036个其他查询图像。数据集中的图像被捕捉到世界上不同的位置，每个图像都与一个GPS坐标相关联。图2和图3分别示出了示例图像及其地理分布。虽然现有数据集中的大多数图像都是以地标为中心的，这使得全局特征描述子工作得很好，但是我们的数据集包含了更真实的图像，包括前景/背景杂波、遮挡、部分视野外的对象等。由于我们的查询图像是从个人照片库中收集的，其中一些可能不包含任何地标，因此不应该从数据库中检索任何图像。我们称这些查询图像为*distractors*分心器，它在评估算法对无关和噪声查询的鲁棒性方面起着至关重要的作用。\n\n我们使用视觉特征和GPS坐标来构建 地面真相 。数据库中的所有图像都使用这两种信息进行聚类，并为每个簇分配一个地标标识符。如果查询图像的位置与与检索到的图像相关联的簇中心之间的物理距离小于阈值，我们假设这两个图像属于同一个地标。请注意，地面真实性注释非常具有挑战性，特别是考虑到很难预先定义什么是地标，地标有时不明显，并且在一个图像中可能有多个实例。显然，由于GPS误差的影响，这种地面真相构建方法存在噪声。另外，一些地标（如埃菲尔铁塔、金门大桥）的照片可以从很远的地方拍摄到，因此照片位置可能与实际地标位置相对较远。然而，在手工检查数据子集时，我们发现很少出现阈值为25km的错误注释。即使有很少的小错误，它也不成问题，特别是在相对评估中，因为算法不太可能在地标之间混淆，如果它们的视觉外观足够歧视的话。\n\n### 4. 使用DELF图像检索\n\n我们的大规模检索系统可以分解为四个主要模块：\n\n（i）密集的局部特征提取；\n\n（ii）关键点选择；\n\n（iii）降维；\n\n（iv）索引和检索。\n\n这一部分详细介绍了DELF特征提取和学习算法以及我们的索引和检索过程。\n\n#### 4.1 密集局部特征提取\n\n我们采用一个完全卷积网络（FCN）从图像中提取密集特征，该网络是利用训练后的CNN的特征提取层构造的。我们使用一个取自ResNet50[13]模型的FCN，使用conv4x卷积块的输出。为了处理尺度的变化，我们显式地构造了一个图像金字塔，并对每个层次独立地应用FCN。将得到的特征映射视为局部描述子的密集网格。基于接收场对特征进行局部定位，可通过考虑FCN卷积层和池层的结构来计算特征。我们使用感受野中心的像素坐标作为特征定位。图像在原始尺度下的感受野大小为291×291。利用图像金字塔，我们得到了描述不同大小图像区域的特征。\n\n我们使用在ImageNet[31]上训练的原始ResNet50模型作为基线，并对其进行微调，以增强我们的局部描述符的辨别力。由于我们考虑了一个地标识别应用，我们使用地标图像的注释数据集[4]，并使用**标准交叉熵损失**对网络进行训练，以便进行图像分类，如图4（a）所示。输入图像最初被中心裁剪以生成方形图像，然后重新缩放到250 x 250。然后随机使用224 x 224部分进行训练。作为训练的结果，局部描述符隐式学习与地标检索问题更相关的表示。以这种方式，对象级和补丁级的标签都不需要即可获得改进的局部描述符。\n\n#### 4.2 基于注意力的关键点选择\n\n与直接使用密集提取的特征进行图像检索不同，我们设计了一种有效地选择特征子集的技术。由于密集提取的特征中有相当一部分与我们的识别任务无关，并且可能会增加杂波(背景杂波)，分散检索过程的注意力，因此关键点的选择对于检索系统的准确性和计算效率都非常重要。\n\n##### 4.2.1 弱监督学习\n\n我们建议训练一个地标分类器来显式地测量局部特征描述子的相关性分数。为了训练函数，特征一个加权和池化，其中权重由注意力网络预测。培训程序与第4.1描述的损失函数和数据集相似，如图4（b）所示，其中注意力网络以黄色突出显示。这将生成整个输入图像的嵌入，然后用于训练基于softmax的地标分类器。\n\n更确切地说，我们制定如下训练计划。用$f_n\\in R^d, n=1,...,N$，这d维特征与注意模型联合学习。我们的目标是学习每个特征的得分函数$\\alpha(f_n ;\\theta )$，其中$\\theta$表示函数$\\alpha(\\cdot)$的参数。网络的输出逻辑y由特征向量的加权和生成，该加权和由\n\n(1)$$y=W(\\sum_n\\alpha(f_n;\\theta)\\cdot f_n)$$\n\n式中$W\\in R^{M\\times d}$表示训练用于预测M类的CNN最终完全连接层的权重。\n\n对于训练，我们使用交叉熵损失，它由\n\n$$L=-y^* \\cdot log(\\frac{exp(y)}{1^T exp(y)})$$\n\n式中$y^*$ 是one-hot之后的ground-truth向量，1是一向量[N维1向量]。分数函数$\\alpha(\\cdot)$中的参数通过反向传播进行训练，其中梯度由\n\n$$\\frac{\\partial L}{\\partial\\theta}=\\frac{\\partial L}{\\partial y}\\sum_n \\frac{\\partial y}{\\partial\\alpha_n}\\frac{\\partial \\alpha_n}{\\partial\\theta}=\\frac{\\partial L}{\\partial y}\\sum_n Wf_n \\frac{\\partial \\alpha_n}{\\partial\\theta}$$\n\n式中反向传播的输出分数 $\\alpha_n==\\alpha(f_n;\\theta)$相对于$\\theta$与标准多层感知器相同。\n\n我们将$\\alpha(\\cdot )$限制为非负，以防止它学习负权重。score函数使用2层CNN设计，顶部使用softplus[9]激活（限制为非负）。为了简单起见，我们采用了尺寸为1 x 1的卷积滤波器，这在实践中效果良好。一旦注意力模型被训练出来，就可以用来评估模型所提取特征的相关性。\n\n##### 4.2.2 训练注意力\n\n在该框架中，描述子和注意模型都是通过图像级标签进行隐式学习的。不幸的是，这给学习过程带来了一些挑战。当特征表示和分数函数可以通过反向传播联合训练时，我们发现这种方法在实际应用中产生了弱模型。因此，我们采用两步训练策略。首先，我们通过微调学习描述符，如第4.1节所述。在给定固定的描述子的情况下，学习得分函数。\n\n另一个改进是在注意力训练过程中通过随机图像重缩放来实现的。这是直观的，因为注意力模型应该能够为不同尺度的特征生成有效的分数。在这种情况下，输入图像最初被中心裁剪以产生方形图像，然后重新缩放到900 x 900。然后随机抽取720 x 720个输出，最后用系数$\\gamma<=1$随机缩放。\n\n##### 4.2.3 特点\n\n我们系统的一个非传统的方面是，关键点选择是在描述符提取之后进行的，这与现有的技术（例如SIFT[22]和LIFT[40]）不同，后者首先检测到关键点，然后再进行描述。传统的关键点检测器只根据关键点的低电平特性，在不同成像条件下对关键点进行重复检测。然而，对于像图像检索这样的高级识别任务，选择能够区分不同对象实例的关键点也是至关重要的。该流程通过训练一个在特征映射中编码高级语义的模型，以及学习如何为分类任务选择有区别的特征来达到这两个目的。这与最近提出的学习关键点检测器的技术（即LIFT[40]）相反，后者根据SIFT匹配收集训练数据。虽然我们的模型不受约束地学习姿势和视点的不变性，但它隐含地学习这样做，类似于基于CNN的图像分类技术。\n\n#### 4.3 降维\n\n我们降低所选特征的维数以提高检索精度，这是常见的做法[15]。首先，对选取的特征进行L2标准化，通过PCA将其维数降到40，在紧凑性和区分性之间取得了很好的折衷。最后，这些特征再次经过L2标准化。\n\n#### 4.4 图片检索系统\n\n我们从查询图像和数据库图像中提取特征描述子，从中选择每个图像中具有**最高关注分数**的预定义数量的局部特征。我们的图像检索系统是基于**最近邻搜索**的，它是由**KD树**[7]和**乘积量化**（PQ）[17]相结合来实现的。我们使用PQ将每个描述子编码成50位编码，每个40D特征描述子被分成10个子向量，每个子向量用k均值聚类法识别25个聚类中心，实现50位编码。我们执行非对称距离计算，其中查询描述符不进行编码，以提高最近邻检索的准确性。为了加快最近邻搜索的速度，我们使用8K码本构造了一个描述符的倒排索引，为了减少编码错误，我们使用KD树对每个Voronoi(类似VLAD的聚类中心范围)单元进行划分，并对每个特征小于30K的子树使用局部优化的乘积量化器[20]。\n\n当给定一个查询时，我们对从查询图像中提取的每个局部描述符执行近似近邻搜索。然后，对于从索引中检索到的前K个最近的局部描述符，我们将每个数据库图片的所有匹配项集合起来。最后，我们使用**RANSAC**[10]进行几何验证，并使用inliner(样本点)的数量作为检索图像的分数。这个几何验证步骤拒绝了许多分心器查询，因为分心器的特征可能与地标图像的特征不一致。\n\n这个流程索引10亿个描述符需要的内存少于8GB，这足以处理我们的大型地标数据集。在我们的实验设置下，使用单个CPU，最近邻搜索的延迟小于2秒，我们在每个查询中软分配5个聚类中心，并在每个倒排索引树中搜索多达10K个叶节点。\n\n### 5 实验\n\n本节主要讨论与我们数据集中现有的全局和局部特征描述符相比，DELF的性能。此外，我们还展示了如何使用DELF在现有数据集中获得良好的精度。\n\n#### 5.1 实施细节\n\n**多尺度描述子提取**  我们使用相距$\\sqrt2$倍的尺度来构造图像金字塔。对于范围从0.25到2.0的一组比例尺，使用7种不同的比例尺。感受野的大小与尺度成反比；例如，对于2.0尺度，网络的感受野覆盖146 x 146像素。\n\n**训练**  我们使用landmarks数据集[4]来微调描述符和训练关键点选择。在数据集中，有“完整”版本，称为LF（在删除了Oxf5k / Par6k的重叠类之后，通过[11]），包含586个地标的140372个图像，以及通过基于SIFT的匹配过程[11]获得的“干净”版本(LC)，包含586个地标的35382个图像。我们使用LF训练我们的注意模型，并使用LC对图像检索的网络进行微调。\n\n**参数**  我们为一个查询中的每个特征确定最接近的K（=60）个近邻，并从每个图像中提取多达1000个局部特征，每个特征是40维的。\n\n#### 5.2 算法比较\n\nDELF与最近的几个全局和局部描述符进行了比较。虽然有各种与图像检索相关的研究成果，但我们相信以下方法要么与我们的算法相关，要么由于其良好的性能而对评估至关重要。\n\n**深度图像检索(DIR)**  这是一个最新的全局描述符，它在多个现有数据集中达到了最先进的性能。DIR特征描述符为2048维，所有情况下都使用多分辨率描述符。我们还使用查询扩展（QE）进行评估，这通常可以提高标准数据集的准确性。我们使用发布的源代码来实现ResNet101[13]版本。在检索方面，采用了暴力搜索的并行实现，避免了近似近邻搜索的错误造成的惩罚。\n\n**siaMAC**  这是一个最新的全局描述符，可以在现有数据集中获得高性能。我们使用发布的源代码与暴力搜索的并行实现。基于VGG16[32]的CNN提取512维全局描述子。我们还对DIR中的查询扩展（QE）进行了实验。\n\n**CONGAS**  CONGAS是一个40D的手工构建的局部特征，已被广泛应用于实例级图像匹配和检索[1,44]。该特征描述子是通过在检测到的关键点的尺度和方向上采集Gabor小波响应来提取的，并且与SIFT等基于梯度的局部描述子具有非常相似的性能和特性。采用拉普拉斯高斯关键点检测器\n\n**LIFT**  LIFT[40]是最近提出的一种特征匹配流程，它将关键点检测、方向估计和关键点描述结合起来学习。特征是128维的。我们使用公开的源代码。\n\n#### 5.3 评估\n\n图像检索系统通常是基于平均平均精度（mAP）来评估的，平均平均精度是通过按每个查询的相关性降序对图像进行排序并平均每个查询的AP来计算的。然而，对于带有干扰查询的数据集，这种评估方法并不具有代表性，因为确定每个图像是否与查询相关很重要。在我们的例子中，使用绝对检索分数来估计每个图像的相关性。对于性能评估，我们使用了一个改进版本的精度（PRE）和召回（REC），方法是同时考虑所有查询图像，由\n\n$$P_{RE}=\\frac{|R_q^{TP}|}{|R_q|} 和 R_{EC}=\\sum_q |R_q^{TP}|$$\n\n式中$R_q$表示给定阈值的查询q的一组检索图像，$R_q^{TP}(\\subseteq R_q)$是一组真正类。这与[26]中引入的micro-AP指标类似。请注意，在我们的例子中，在最终评分中只考虑每个地标的最高得分图像。我们更喜欢非标准化的回调值，它表示检索到的真阳性数。\n\n#### 5.4 定量结果\n\n图5显示了与其他方法相比，DELF（用DELF+FT+ATT表示）的精确召回曲线。由于特征提取速度非常慢，无法进行大规模实验，因此无法显示LIFT的结果。DELF明显优于所有其他技术。全局特征描述符，比如DIR，在我们富有挑战性的数据集中受到了影响。特别是，由于查询集中存在大量干扰因素，使用QE的DIR会显著降低准确性。CONGAS做得相当不错，但仍然比DELF差很多。\n\n为了分析精细调整和注意力对图像检索的好处，我们比较了我们的完整模型（DELF+FT+ATT）及其变体：DELF-noFT、DELF+FT和DELFnoFT+ATT。DELF-noFT是指提取的特征基于ImageNet上预训练的CNN，而不需要精细调整和注意力学习。DELF+FT表示有微调但没有注意建模的模型，DELFnoFT+ATT对应于未经微调但使用注意力的模型。如图5所示，微调和注意力建模都对性能改进做出了重大贡献。特别要注意的是，注意力的使用比微调更重要。这表明，所提出的注意层可以有效地学习为检索任务选择最有区别的特征，即使这些特征只是在ImageNet上预先训练过的。\n\n在内存需求方面，DELF、CONGAS和DIR几乎同样复杂。DELF和CONGAS采用相同的特征维数和每个图像的最大特征数；它们需要大约8GB的内存。DIR描述符需要每个图像8KB，加起来大约8GB来索引整个数据集。\n\n#### 5.5 定量结果\n\n我们给出定性的结果来说明DELF与两种基于全局和局部特征的竞争算法DIR和CONGAS的性能比较。同时，通过可视化分析了基于注意力的关键点检测算法。\n\n**DELF vs. DIR** 图6显示了检索结果，其中DELF的性能优于DIR。DELF得到图像中特定局部区域之间的匹配，这对于在不同成像条件下找到同一目标具有重要意义。DIR的常见故障案例发生在数据库包含类似的对象或场景时，例如方尖碑、山脉、港口，如图6所示。在许多情况下，DIR无法区分这些特定的对象或场景；尽管它发现语义上相似的图像，但它们通常与感兴趣的实例不对应。DIR和其他全局描述符的另一个缺点是它们不善于识别感兴趣的小对象。图7显示了DIR优于DELF的情况。虽然DELF能够在不同的图像上匹配局部模式，但当不同地标的地板砖或植被相似时，这会导致错误。\n\n**DELF vs. CONGAS**  与CONGAS相比，DELF的主要优势在于它的召回率；它比CONGAS检索到更多相关的地标，这表明DELF描述符更具辨别力。我们没有观察到CONGAS优于DELF的显著例子。图8显示了来自查询和数据库的成对图像，这些图像通过DELF成功匹配，但被CONGAS忽略，其中特征对应通过连接用于匹配特征的接收字段的中心来呈现。由于感受野可能相当大，一些特征似乎局限于无差别的区域，例如海洋或天空。然而，在这些情况下，这些特征会考虑到邻近区域中更具歧视性的区域。\n\n**关键点检测方法分析**  图9显示了关键点检测的三种变化，其中我们的注意模型的好处被清楚地定性地说明，而微调特征的L2范数与未经微调的L2范数略有不同。\n\n#### 5.6 现有数据集中的结果\n\n为了完整性，我们展示了DELF在现有数据集中的性能，比如Oxf5k、Par6k及其扩展Oxf105k和Par106k。对于这个实验，我们简单地使用所提出的方法来获得每幅图像的分数，并通过计算两个标准化分数的加权平均值来与DIR的分数进行后期融合，其中DELF的权重设置为0.25。结果显示在表1中，我们提出了现有方法的准确性在他们的原始论文和我们的复制使用公共源代码，这是非常接近。当与DIR结合使用时，DELF显著地提高了数据集中的准确性，尽管它本身并没有显示出最好的性能。这一事实表明，DELF能够对全局特征描述符中不可用的补充信息进行编码。\n\n### 6 结论\n\n本文提出了一种新的局部特征描述子DELF，它是专门为大规模图像检索应用而设计的。DELF是在弱监督下学习的，只使用图像级别的标签，并与我们的新的注意机制的语义特征选择相结合。在所提出的基于CNN的模型中，一次前向传递就足以获得关键点和描述符。为了正确评估大规模图像检索算法的性能，我们引入了Google Landmarks数据集，该数据集由超过1M个数据库图像、13K个唯一路标和100K个查询图像组成。在这样一个大规模的环境下的评估表明，DELF的性能远远超过现有的全局和局部描述符。在已有的数据集上，我们也给出了结果，并表明当与全局描述符相结合时，DELF具有良好的性能。","comments":true,"categories":[],"tags":[{"name":"论文翻译","slug":"论文翻译","permalink":"http://blog.ahulearn.com/tags/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/"},{"name":"随笔","slug":"随笔","permalink":"http://blog.ahulearn.com/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"Unifying Deep Local and Global Features for Image Search","date":"2020-07-02T10:36:45.000Z","path":"2020/07/02/Unifying Deep Local and Global Features for Image Search/","raw":"---\ntitle: Unifying Deep Local and Global Features for Image Search\ndate: 2020-7-2 18:36:45\ntoc: true\ntags:\n - 论文翻译\n - 随笔\n - cv\n - AI\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\\vision-locallization\n\n---\n\n\n\n## 统一局部和全局特征进行图像搜索的深层(网络)\n\n​    本文使用机翻，稍加润色，主要用于个人理解，不恰当之处请看客见谅。\n\n### 摘要\n\n图像检索是在图像数据库中搜索与查询图像相似的项的问题。为了解决这一问题，研究了两种主要的图像表示方法：全局图像特征和局部图像特征。在这项工作中，我们的主要贡献是将全局和局部特征统一到一个单一的深度模型中，从而实现精确的检索和高效的特征提取。我们将新模型称为DELG，代表了深层网络的本地和全局特性。我们利用最近特征学习工作的经验教训，提出了一个将全局特征的广义均值池和局部特征的注意选择相结合的模型。通过仔细平衡两部分之间的梯度流，整个网络可以端到端地学习——只需要图像级别的标签。我们还引入了一种基于自动编码器的局部特征降维技术，并将其集成到模型中，提高了训练效率和匹配性能。在重新修改的牛津和巴黎数据集上的实验表明，我们共同学习的基于ResNet-50的特征优于使用深层全局特征（大多数具有更重量级的主干）和那些进一步使用局部特征重新排序的结果。代码和模型将被发布。\n\n**关键词：deep features，image retrieval，unified model，深度特征，图像检索，统一模型**\n\n<!--more-->\n\n### 1. 介绍\n\n大规模图像检索是计算机视觉中一个长期存在的问题，甚至在深度学习革命之前，计算机视觉就已经取得了很好的结果。这个问题的核心是用来 描述 图像及其相似性 的表示。\n\n为了获得高的图像检索性能，需要两种图像表示方法：全局特征和局部特征。全局特征，也称为“全局描述符”或“嵌入”，总结图像的内容，通常导致紧凑的表示；同时有关视觉元素的空间排列的信息丢失。另一方面，局部特征包括关于特定图像区域的描述符和几何信息；它们对于匹配描述刚性对象的图像特别有用。一般来说，全局特征的召回率较高，而局部特征的准确率较高。全局特征可以在局部特征无法找到对应关系的非常不同的姿势中学习相似性；相反，基于局部特征的几何验证提供的分数通常能很好地反映图像相似性，比全局特征距离更可靠。一个常见的检索系统设置是首先按全局特征进行搜索，然后使用局部特征匹配对顶级数据库图像进行重新排序，以获得两个特征字的最佳结果。这种混合方法得到普及的一个突出应用是视觉定位。\n\n如今，大多数依赖于这两种特性的系统都需要使用不同的模型分别提取每种特性。这是不可取的，因为它可能导致高内存使用率和增加延迟，例如，如果两个模型都需要使用专用和有限的硬件（如gpu）运行。此外，在许多情况下，对两者执行类似类型的计算，导致冗余处理和不必要的复杂性。\n\n![视觉定位总图](/img/vision-locallization/1593687410536.png)\n\n图1. 我们提出的**DELG(Deep Local and Global features) **模型（左）联合提取了深层的局部和全局特征。全局特征可用于检索系统的第一阶段，以便有效地选择最相似的图像（底部）。然后，可以使用局部特征对上面的结果重新排序，从而提高检索结果的精度（右上角）。统一模型利用卷积神经网络诱导的层次图像表示来学习局部和全局表示，结合全局特征池和注意局部特征检测的最新进展。\n\n\n\n贡献:（1）我们的第一个贡献是使用卷积神经网络（CNN）表示局部和全局特征的统一模型，称为DELG（深层局部和全局特征），如图1所示。这允许通过提取图像的全局特征、检测到的关键点和单个模型中的局部描述符进行有效的推断。我们的模型是通过利用CNNs中出现的分层图像表示来实现的，我们将其与广义均值池和注意局部特征检测相结合。（2）其次，我们采用卷积式自动编码模块，可以成功地学习低维的局部描述子。这可以很容易地集成到统一的模型中，并且避免了通常使用的后处理学习步骤（如PCA）的需要。（3）最后，我们设计了一个程序，使得只使用图像级监控的端到端的训练模型。这需要在反向传播过程中仔细控制全局和本地网络头之间的梯度流，以避免破坏所需的表示。通过系统的实验，我们证明我们的联合模型在仅使用全局特征进行检索或使用局部特征对这些结果重新排序时，在重新访问的ROxford和RParis数据集上取得了最新的性能。\n\n### 2. 相关工作\n\n我们回顾了局部和全局特征的相关工作，主要集中在与图像检索相关的方法上。\n\n*局部特征*：手工（特征）的技术，如**SIFT**和**SURF**已经被广泛用于检索问题。早期的系统[32,28,39]的工作方式是根据一个包含局部描述符的大型数据库搜索查询局部描述符，然后用足够数量的对应关系对数据库图像进行几何验证。随后，根据通过局部描述符聚类获得的视觉单词，结合TF-IDF评分，采用**Bag-of-Words**[52]和相关方法[42,43,24]。与全局特征相比，局部特征用于检索的关键优势在于能够执行空间匹配，通常使用**RANSAC**。这已经被广泛使用，因为它取得了可靠和可解释的分数。最近，一些基于深度学习的局部特征被提出。与我们工作最相关的是DELF；我们提出的统一模型包含了DELF的注意力模块，但是除了支持全局特征提取之外，还有一个更简单的训练流程。\n\n*全局特征*：全局特征在提供紧凑表示的高图像检索性能方面表现突出。在深度学习在计算机视觉中流行之前，它们主要是通过聚集手工制作的局部描述符来开发的。如今，大多数高性能的全局特征都是基于深层卷积神经网络，这些神经网络通过基于**ranking-loss**或**classification loss**进行训练。我们的工作利用了最近在全局特性设计方面的经验教训，通过采用**GeM**池化和**ArcFace loss**。这使得全局特征检索性能比以往的方法有了很大的提高，而基于同一模型的局部特征的几何重排序进一步提高了全局特征检索性能。\n\n*联合本地和全局CNN特征*：以前的工作考虑卷积神经网络联合提取全局和局部图像特征。对于室内定位应用程序，Taira[53]等人使用预先训练的基于**VGG**的**NetVLAD**模型提取全局特征用于候选姿态检索，然后使用来自同一网络的特征映射进行密集的局部特征匹配。Simeoni[51]等人的**DSM**利用预先训练的全局特征模型，提出使用**MSER**检测深度激活映射中的关键点；激活通道被解释为视觉词义，可用于提出一对图像之间的暂定对应关系。我们的工作与[53,51]有很大的不同，因为它们只对经过预训练的全局特征模型进行后期处理以生成局部特征，而我们则联合训练局部和全局特征。Sarlin等人[48]提取预先训练好的局部SuperPoint[12]和全局NetVLAD[1]功能整合到单个模型中，以视觉定位应用为目标。相比之下，我们的模型是端到端的图像检索训练，并且不限于模拟单独的预先训练的局部和全局模型。据我们所知，我们是第一个研究 学习一个既能产生局部图像特征又能产生全局图像特征的非分离模型。\n\n*图像检索的降维方法*：**PCA**和**whitening**（白化）技术广泛应用于图像检索中局部和全局特征的降维。正如在[23]中所讨论的那样，白化权重同时作用于局部特征，这通常有利于检索应用。Mukundan等人[35]进一步引入一个收缩参数，该参数控制应用白花的程度。如果有匹配对或类别标签形式的监督，可以使用更复杂的方法。最近，Gordo等人[16] 提出用一个完全连通的层来代替PCA/白化，该层与全局描述符一起学习。\n\n在本文中，我们的目标是构建一个可以端到端学习的系统，只使用图像级标签，不需要使训练更复杂的后处理阶段。此外，由于我们从常见CNN主干网的特征图中提取局部特征，它们往往是高维的，不适用于大规模问题。所有上述方法要么需要一个单独的后处理步骤来降低特征的维数，要么需要在本地补丁的级别上进行监督，导致它们不适合我们的需要。因此，我们在我们的模型中引入了一个自动编码器，它可以与网络的其他部分共同有效地学习。它不需要额外的监督，因为它可以训练与重建损失。\n\n### 3. DELG\n\n#### 3.1 设计注意事项\n\n为了获得最佳性能，图像检索需要对用户可能感兴趣的对象类型进行语义理解，以便系统能够区分相关对象与杂波/背景。因此，局部和全局特征都应该只关注图像中最具鉴别能力的信息。然而，在这两种特征模式的期望行为方面存在着实质性的差异，这对共同学习它们构成了相当大的挑战。\n\n对于描绘同一感兴趣对象的图像，全局特征应该相似，否则应该不同。这需要对视点和光度变换保持不变的高级抽象表示。另一方面，局部特征需要对基于特定图像区域的表示进行编码；特别是，关键点检测器对于视点应该是等价的，并且关键点描述符需要对局部视觉信息进行编码。这对于在图像检索系统中广泛应用的查询图像和数据库图像之间进行几何一致性检查至关重要。\n\n此外，我们的目标是设计一个可以端到端学习的模型，具有局部和全局特性，而不需要额外的学习阶段。这简化了训练流程，允许更快的迭代和更广泛的适用性。相比之下，以往的特征学习工作通常需要几个学习阶段：专注的局部特征深度学习[38]需要3个学习阶段（微调、注意力、主成分分析）；全局特征深度通常需要两个阶段，例如区域建议和Siamese训练[17]，或Siamese训练和监督白化[45]，或者ranking loss 训练和主成分分析[46]。\n\n#### 3.2 模型\n\n我们设计DELG模型，如图1所示，以满足上述要求。我们建议利用CNNs[60]中的层次表示来表示要学习的不同类型的特征。虽然全局特征可以与表示高级线索的深层关联，但局部特征更适合于编码局部信息的中间层。\n\n给定一幅图像，我们应用卷积神经网络主干来获得两个特征映射：$S\\in R^(H_S \\times W_S \\times C_S)$ 和$D\\in R^(H_D \\times W_D \\times C_D)$，分别代表浅激活和深激活，式中H，W，C对应于每种情况下的高度、宽度和通道数量。对于通常的卷积网络，$H_D <= H_S$，$W_D <= W_S$，$C_D >=C_S$；较深的层具有空间上较小的映射，具有较大数量的通道。设$s_{h,w}\\in R^{C_S}$和 $d_{h,w} ∈R^{C_D}$ 表示这些映射中h，w位置的特征。对于一般的网络设计，这些特征是非负的，因为它们是在ReLU非线性之后获得的，我们的方法就是这样。\n\n为了聚合深度激活值为全局特征，我们采用了广义平均池化（GeM）[45]，它有效地加权了每个特征的贡献。\n\n\n\n\n\n\n\n\n\n\n\n","comments":true,"categories":[],"tags":[{"name":"论文翻译","slug":"论文翻译","permalink":"http://blog.ahulearn.com/tags/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/"},{"name":"随笔","slug":"随笔","permalink":"http://blog.ahulearn.com/tags/%E9%9A%8F%E7%AC%94/"},{"name":"AI","slug":"AI","permalink":"http://blog.ahulearn.com/tags/AI/"},{"name":"cv","slug":"cv","permalink":"http://blog.ahulearn.com/tags/cv/"}]},{"title":"移动数据流量请求头分析","date":"2020-03-28T11:14:13.000Z","path":"2020/03/28/数据流量请求头分析/","raw":"---\ntitle: 移动数据流量请求头分析\ndate: 2020-03-28 19:14:13\ntags:\n - 计网\n - 随笔\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\n---\n\n**1. http协议请求头**\n==================\n\n```http\n[method] [uri] [version]\\r\\n\nHost: www.example.com\\r\\n\nConnection: keep-alive\\r\\n\n...\n\\r\\n\n```\n\n**1.1 第一行的字段为请求的：方法，资源地址，协议版本**\n\nhttp协议常用的请求方法[method]为\n\n  + GET：用于向服务器请求数据；\n  + POST: 用于向服务器提交数据；\n  + CONNECT: 用于隧道代理;\n  + HEAD: 用于向服务器请求报头;\n\n资源地址[uri]：一般为URL中去掉域名后剩下的那部分，即浏览器地址栏网址中域名之后的内容。\nhttp协议版本[version]: 目前主流版本有HTTP/1.0和HTTP/1.1。\nhttp请求头中的的换行用的是\\r\\n, 而非Linux中的换行符\\n。以下为一个真实请求头的示例\n\n> GET /index.html HTTP/1.1\n>\n> Host: www.example.com \n>\n> Connection: keep-alive    \n\n<!--more-->\n\n**1.2 Host字段为请求的主机域名**\n\n早期没有虚拟主机的概念，一台服务器有一个主机名。因此规定在请求头的第一行，资源地址只需给出相对地址，不必给出主机名（域名）。但现在一台服务器可能提供多个主机服务，比如一条服务器同时运行了example.com和example.cn两个web站点。只给出相对地址，服务器在收到连接请求后，无法得知该请求是希望与自己哪个web服务建立连接。因此增加了Host字段[^1]。\n\n**1.3 Connection字段为连接选项**\n\n用于对连接进行说明：说明是保持连接还是关闭连接等。\n早期的http协议不支持此字段，因此为http提供代理的http代理服务器自然也不支持此字段。如今互联网上比较古老的代理服务器依然存在。为了兼容早期的http代理服务器，在客户端和代理之间又增加了Proxy-Connection字段。关于此字段此处简要介绍。\nhttp代理的实现原理是，代理服务器作为通信中介；客户端把代理当作他想访问的服务器，向代理发送连接轻求。之后代理收到连接请求，向客户端真正想访问的服务器转发此连接请求。\n使用http代理的客户端，会主动修改其http请求头，比如浏览器在设置http代理后，会将请求头做出如下修改：\n\n>GET  http://www.example.com/index.html HTTP/1.1\n>\n>Host: www.example.com \n>\n>Proxy-Connection: keep-alive \n\n修改内容主要是请求头第一行的URI, 由相对地址变为绝对地址。原因同Host字段的产生类似，为了让代理能够区分此连接是希望与哪个主机建立连接。但是这里存在一个疑问：既然有了host字段，为什么还要完整地址？我个人给出两个**可能**的理由：\n\n+ Host字段出现的更晚，起初是通过完整URI解决虚拟主机的问题，后来提出的Host字段更方便，但为了兼容早期的代理服务器，现在二者同时使用。\n\n+ Host字段是为了让**服务器**知道，收到的请求是连接自己的哪个主机。而完整URI是让**代理**知道客户端向服务器的哪个主机发起连接，二者作用不同。\n\n修改的第二部分是Connection字段，该字段修改为Proxy-Connection。\nProxy-Connection: 用于兼容不支持Connection字段的旧版代理服务器，因为代理服务器默认会将所有未知字段原样转发，而老旧的代理工具不支持Connection选项。当客户端发送`Connection: Keep-Alive`希望保持连接请求，但是代理无法识别此字段，转发一次数据依然会立即断开连接。虽然服务端收到请求且接受保持连接，但代理却关闭了连接，会导致连接中断。因此代理协议要求将Connection修改为Proxy-Connection，只有识别Proxy-Connection的代理服务器才能将Proxy-Connection转为Connection发给服务端，让服务端保持连接。\n\n**2. 隧道代理请求头**\n==================\n\n**2.1 CONNECT方法**\n\n隧道代理不同于http代理：http代理是代理服务器作为中介，获取到客户端的数据转发给服务器端，获取到服务端的数据转发给客户端。其通信过程是客户端与代理建立http连接，代理和服务端建立http连接。显然无法用于https通信：因为https是加密协议，代理即使使用https协议代替客户端与服务端通信获取到连接应答数据，也无法使用https加密发送给客户端，因为代理没有服务器的证书。此时退而求其次的方式是，代理到客户端这段转为http通信，可能会降低安全性。当然可以在应用层进行加密，依然能保证安全性。但这样并不是完美的https代理。为了解决此问题，http或者说https增加了CONNECT方法，该方法是请求代理向服务器建立一条隧道通信。该隧道是在TCP层建立，客户端与代理建立一条TCP连接，代理再与服务器建立一条TCP连接。之后客户端和服务端在这条TCP连接之上建立一条https连接。\n\n> CONNECT www.example.com:443 HTTP/1.1 \n>\n> Host: www.example.com \n\n建立连接的请求头方法为CONNECT， 地址只需要主机地址，不能再添加具体的资源路径，因为该请求只是用来建立一条连接，连接建立完成才真正请求数据用来通信。\n这里说明一下隧道和http直观上的区别：隧道所使用的TCP属于ISO七层网络模型的第4层，而http和https协议处于第7层，所以TCP作为https的底层协议，https并不会察觉代理的存在。举个例子：隧道相当于A向C输送石油，建立了一条A到B的公路，然后建立了一条B到C的公路，之后在这段公路上建立一条A经由B到C的油管。而http代理是建立了一条A到B的公路，然后建立了一条A到B的油管；之后建立了一条B到C的公路，再建立了一条B到C的油管。隧道方式AC是油管直连，http方式在B处要有个储油罐。\n\n\n**3. 移动通信数据代理**\n====================\n\n**3. 1 简述**\n\n移动通信提供了wap和net两种网络接入方式，net即直连，和电脑通过网线连接网络没有什么区别。而wap则是通过代理连接，类比电脑通过路由器联网，多台电脑可以共用一个路由器，多部手机也可共用一个代理，这样只需要一个ip地址即可让多个用户实现通信。对运营商而言wap是节省资源的一种方式。所以早期的手机默认都是wap方式，但是这样当一个代理提供接入的用户过多时，可能导致网速下降。这即是网上盛传修改接入点能提高网速的原因。~但我个人感觉其实影响不大，因为运营商的代理吞吐能力肯定够高，不会和直连有太大差距~。\n\n> 移动联通的wap接入点代理为10.0.0.127\n>\n> 电信的wap接入点代理为10.0.0.200\n>\n> 接入点代理地址相当于路由器ip：192.168.0.1\n\n**3.2 移动接入点cmwap分析**[^2]\n\n[^2]: https://www.cnblogs.com/xitang/archive/2011/11/07/2239454.html \n\ncmwap代理, 在http协议之上增加了扩展字段X-Online-Host；\n移动的网关代理和http协议相似，而又同于http代理或隧道代理。\nhttp协议在不使用代理时才使用相对url，与Host字段拼接为绝对地址。\n标准的http代理协议是在GET 后添加绝对URL，而非相对URL(http协议在不使用代理时才使用相对url，与Host字段拼接为绝对地址)；\n而移动的wap代理GET字段仍是相对URL，但是增加了X-Online-Host字段，通过与X-Online-Host字段拼接为绝对地址。\n但是如果GET字段获取到绝对地址，则不再和X-Online-Host字段拼接。\n\n这就产生了下面这个问题：\n假设我连接的URL为：http://wap.baidu.com/logo.gif?img=http://wap.uc.cn/uc.png\n使用移动网关代理X-Online-Host字段联网：\n\n> Conection to 10.0.0.172:80\n>\n> GET /logo.gif?img=http://wap.uc.cn/uc.png HTTP/1.1\n>\n> Host: wap.baidu.com\n>\n> X-Online-Host: wap.baidu.com\n\n早期的移动网络，这样的请求到达移动网关之后，可能会被误发至http://wap.baidu.com/uc.png。但是实际上我们想要请求的是http://wap.baidu.com/logo.gif （?之后表示提交内容）。\n因为，移动网关实际上就是一个HTTP的代理服务器，它对于X-Online-Host协议处理如下：\n截取请求头中的URL字段：\n\n+ 如果URL字段没有域名的话，则将该字段作为相对URI，同X-Online-Host字段进行补全，作为目的地址；\n+ 如果URL字段有域名的话，则将该字段作为绝对URI，将host替换为X-Online-Host的值。\n\n现在处理方法应该已经完善，不会再出现此问题。\n\n这里可以看到存在3个位置可以出现域名：\n\t请求头第一行方法字段；\n\tHost字段；\n\tX-Online-Host字段；\n符和移动网关代理协议的标准请求，应该是方法字段使用无域名的相对地址，Host和X-Online-Host字段使用相同的域名。但是事情往往没有想象的那么美好：如果我修改请求方法用绝对地址，同时Host和X-Online-Host字段使用两个不同的域名，将三个域名设为都不相同。网关收到此数据包会发生什么，直接丢掉异或是三个地址具有某种优先级，选择优先级高的作为目的地址转发？这个就看各自地区的运营商如果制定规则了。\n\n但更有趣的事情不在这里而是下面这个问题，流量费用是由网关统计的，当网关转发目的地址都难以确定时，费用又是如何计算呢？之所以发出这个疑问，是因为有些访问特定主机的流量运营商是不收费的，比如访问运营商官网，又或者现在互联网套餐兴起，各种定向免流数据。也就是说计费也需要知道用户请求的Host地址。那么计费又是根据哪个字段，所用的规则和转发规则是相同的么？我想此处是可以给个否定回答的。转发规则和计费规则是不同的!!!\n\n由此我们就可以顺理成章的提出一个坊间流传多年词汇：免流。相传2012年就有人运用此漏洞修改UC浏览器达到免流的目的。时隔多年，三大运营商或注意到或没注意到，此问题也在一点点修复。但是以此作为基础，免流的手段可以说层出不穷，虽然也在一个个失效。但似乎如同道高一尺魔高一丈般，免流的技术却从未中断。尤其各大互联网套餐的出现，让这淡出视野的东西又浮现出来。当然在这个家家有宽带处处有wifi的今天，还玩免流的是真不多了。玩也不是图省那点流量，就是想装装13。\n\n附：联通大王卡动态免流脚本，需要手机获取root权限，使用RE文件管理器，复制到系统/system/xbin目录执行即可\n` https://lanzous.com/iat0glg`\n\n[^1]:https://imququ.com/post/the-proxy-connection-header-in-http-request.html ","comments":true,"categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://blog.ahulearn.com/tags/%E9%9A%8F%E7%AC%94/"},{"name":"计网","slug":"计网","permalink":"http://blog.ahulearn.com/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"Typora配合hexo编写文章","date":"2020-03-13T04:00:00.000Z","path":"2020/03/13/Typora配合hexo编写文章/","raw":"---\ntitle: Typora配合hexo编写文章\ndate: 2020-03-13 12:00:00\ntags:\n - 入门实践\n - 配置相关\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\n---\n\n### 图像插入设置\n\n* 主要涉及Typora的两个参数设置\n  * 图片根目录设置\n    * 既告诉Typora哪个文件夹作为网站的根目录\n  * 图片复制路径\n    * 既图片插入时，自动复制图片到指定路径，如此上传至空间，才能生成正确的url\n\n+ 设置图像根目录\n  \n  + 以hexo根目录下的source文件夹为例\n  + 该文件夹中的内容会上传至web根目录，因此此文件相当于网站的根目录\n  + 而文章所在目录为source文件夹下的_post文件夹, 根目录在文章的上级目录\n  + 因此设置图片根目录为`..`\n  + 既在标题栏添加此内容：`typora-root-url: ..`\n  + ![typera_setting2](/img/typera_setting2.JPG)\n  \n  + 设置图片目录\n  \n    + 设置source文件夹下的img文件夹，为图片所在文件夹\n    + 因为img在source文件夹下，既在文章的上级目录下的img文件夹下\n    + 因此设置图片目录为`..\\img`\n  \n    * 既在标题连添加此内容：`typora-copy-images-to: ..\\img`\n  \n* 注意事项：**以上设置只能采用相对路径**\n\n<!--more-->\n\n  + Typora换行Enter键自动添加一个空行，Shift+Enter普通换行。\n\n### hexo 设置\n\n* 无需进行设置\n\n  * 说明一下hexo的目录结构\n  * hexo根目录下需要关注的有以下几个文件：\n    * source/\n      * 资源文件夹，用来存储生成页面的资源文件，图片文章等\n    * themes/\n      * 主题文件夹，也就是网站皮肤，每个主题也有一个source/文件夹，作用同根目录的source/文件夹\n    * public/\n      * 根据source/文件夹生成的最终会上传至服务器的文件\n    * _config.yml\n      * hexo配置文件\n  \n  ","comments":true,"categories":[],"tags":[{"name":"入门实践","slug":"入门实践","permalink":"http://blog.ahulearn.com/tags/%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/"},{"name":"配置相关","slug":"配置相关","permalink":"http://blog.ahulearn.com/tags/%E9%85%8D%E7%BD%AE%E7%9B%B8%E5%85%B3/"}]},{"title":"特权指令、访管指令、陷入指令、广义指令","date":"2020-01-18T12:38:31.000Z","path":"2020/01/18/特权指令、访管指令、陷入指令、广义指令/","raw":"---\ntitle: 特权指令、访管指令、陷入指令、广义指令\ndate: 2020-01-18 20:38:31\ntags:\n - CS\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\n---\n\n对操作系统、计算机组成原理入门具有一定指导意义，对计算机考研知识理解具有一定辅助作用，对工作中的实际应用可能基本没用。\n\n+ 特权指令\n\n○ 从指令系统（指令集）角度定义，在指令系统中拥有用于管理硬件和整个系统安全的指令，让程序随意使用具有极高危险性。不得在用户态（目态）执行，只能在核心态（管态）执行，用户态程序如果运行特权指令将发生异常，并切换到管态由操作系统接管cpu。所以用户程序不得使用特权指令，需要执行特权指令需要使用防管指令，进入核心态。\n\n<!--more-->\n\n + 访管指令\n\n○ 同样从指令集的角度定义，或者说从硬件角度（cpu状态）。防管指令，是用户程序自愿进管的指令（进管同时也意味着程序放弃cpu的控制权），该指令本身属于非特权指令，可在用户态执行，执行后进入核心态。核心态是通过cpu置相应标志表明当前处于核心态。cpu进入核心态后可以执行指令集中的所有指令（包括特权指令和非特权指令，但不执行访管指令）。\n\n+ 陷入指令\n\n○ 原则上可看作访管指令，但是从操作系统的角度定义的。访管强调的是cpu从用户态切换到了核心态，可以执行指令集中的所有指令。而陷入（自陷、陷阱）指令强调程序从用户程序从用户台切换到内核态(以下简称切换到操作系统)，陷入指令即汇编中的中断指令。执行陷入指令程序会中断，跳转到中断服务程序（操作系统的代码）。所以访管强调的是可以执行特权指令，陷入强调的是进程放弃cpu，交还给操作系统。其实核心态和操作系统是不可分割的：道理很显然，进入核心态（管态），必然需要“跳转”到操作系统，不然区分用户态和核心态就没有了意义，如果程序执行完访管指令后，只是进入了管态，之后仍然执行自身的代码，那用户程序将可以为所欲为，显然不能允许。另一方面，如果cpu跳转到了操作系统，没有进入管态，那操作系统也无法执行特权指令，不能管理整个机器，显然也不行（当然也存在操作系统一部分运行在用户态，一部分（即内核）运行在管态，此时操作系统获取cpu控制权后不一定是处于核心态）。所以管态就是运行操作系统(内核代码)，访管指令本质上就是一条陷入（中断）指令。\n\n+ 广义指令（系统调用）\n\n○ 系统调用，从操作系统的角度定义的。指用户程序需要借助操作系统来完成的特定操作，通过陷入指令可以进行系统调用。系统调用是一段代码而不是一条代码，在高级语言层面可能表现为一条，比如c语言的系统调用write()，在汇编层面这条语句包括，初始化相关参数和寄存器，执行陷入（中断）指令，跳转到中断服务程序执行，中断返回。之所以需要系统调用是因为用户程序不能执行特权指令，所以当需要完成特权指令才能做的特定操作，必须通过系统调用由操作系统完成。但系统调用一词并非强调程序不能使用特权指令，即不强调“需要”操作系统服务，仅仅强调“希望”让操作系统服务，表达的含义不是\"不能\"而是\"不需要\"，即目标操作用户程序不需要自己做，直接调用操作系统即可完成，进行系统调用时也并非一定为了执行特权指令，也可能相关操作过于复杂，或者用户程序自身难以实现（有权做但做起来麻烦），而操作系统刚好给出了相应的接口供直接使用。\n\n+ 库函数\n\n○ 操作系统提供的函数，供用户程序直接调用，简化程序的编写。编程时调用库函数直接使用操作系统已经实现的功能即可。与系统调用有些相似，不过库函数调用可以在用户态执行(不需要执行特权指令时)，和普通的函数调用应该并没有什么区别。无需用户态切换到核心态，执行中断服务程序等一些操作。是对系统调用“不需要做”这一概念的推广，另外现在一般用户不直接使用系统调用，而是使用封装好的库函数，由库函数进行系统调用。库函数的意义在于，需要就拿去用，不用再浪费时间了，直接拿大佬已经实现好的来搞。\n\n+ 系统调用和函数调用的区别\n\n○ 系统调用本质上应该也是一种函数调用，只是调用该函数是通过中断方式，INT 指令，进入核心态才能运行。\n\n○ 函数调用通过CALL指令来进行，功能和JMP类似，只是JMP用于跳转指令，而CALL用于调用函数，指令跳转的同时要保存函数调用前下条指令的地址，以保证函数调用完能返回当前指令接着运行。本质上都是修改PC（程序计数器）的值，将下一条指令地址修改成相应指令地址。\n\n○ 而系统调用是通过中断方式，即软件中断/陷入指令INT，执行后通过硬件关中断 保存断点和程序状态字 形成中断服务程序入口地址，之后执行中断服务程序。看起来很像是函数调用，只是系统调用会进入核心态，执行操作系统的代码。\n\n○ 8086汇编语言函数返回\n\n如果是段内调用，使用RET指令返回，从栈中弹出一个字，即IP(指令指针寄存器)\n\n如果是段间调用，使用RETF指令返回，从栈中弹出两个字，即CS（代码段基址寄存器） 和IP\n\n如果是系统调用，使用IREF指令返回，从栈中弹出三个字，即IP CS PSW（程序状态字）","comments":true,"categories":[],"tags":[{"name":"CS","slug":"CS","permalink":"http://blog.ahulearn.com/tags/CS/"}]},{"title":"浅谈对计算机的理解--外设","date":"2020-01-17T12:39:14.000Z","path":"2020/01/17/浅谈对计算机的理解-外设/","raw":"---\ntitle: 浅谈对计算机的理解--外设\ndate: 2020-01-17 20:39:14\ntags:\n - CS\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\n---\n\n首先声明本人非计算机专业，也不玩数码硬件，可以说我下面的内容既不偏向理论也不偏向实际应用。单纯是个外行人对计算机的初步印象，只做个人笔记，当然写在公开领域，自然避免不了外人看到，所以事先声明，以免误导各位。\n\n**1）硬件**\n\n提到计算机硬件，首先应该说一说开关。可以说简单的分析，计算机内部就是由一个个的开关组成。或者说就是由开关演化而来的。乍一听，可能很难接受，这种简单东西的组合是怎么认识代码，是怎么运行软件的。\n\n我只能说你这种想法是把人的观点强加给计算机而已，它不过是一堆没有感情的芯片电路，就一铁疙瘩，懂什么代码。它不过是按既定的物理规律运行而已。\n\n甚至从我的角度来看即便是为计算机量身定做二进制也是计算机看不懂的东西，计算机所理解的这一切都是人强加给它的。\n\n这就相当于按下开关，通上电灯它亮了，而你把他看作是灯知道了你按下了开关，然后亮了，而且你还在这好奇，这灯它到底是咋知道我按下了开关的？灯知道个什么玩意，其实这不过是看待问题的角度本身强加给了它意义，计算机和灯本质上也并无差别。抛开人强加给它的意义，会更容易来理解计算机。\n\n下面来简析一下计算机的基本结构，此处的计算机不以任何现实机器为依据，单纯是对各种计算机抽象出来的一种通用机器模型。\n\n该机器应由 **(1)cpu**  **(2)内存**  和 **(3)外设 **构成，更细致的分：cpu由**(1)控制器**和**(2)运算器**构成，内存既**(3)存储器、主存**，外设既**(4)输入设备**和**(5)输出设备**。\n\n<!--more-->\n\n此处仅对输入输出设备仅稍作说明，之后的文章会涉及计算机的核心部分既软件部分。由上面的说明可知计算机除了控制器、运算器、存储器，其它设备均为外设，例如磁盘 显示器 键盘鼠标等。计算机对外设的操作都可以抽象为读写，既输入是读输出是写。而怎么读怎么写可以认为是外设的事，计算机可以把它们看做相同的。比如数据写入磁盘，计算机就是吧10数据写过去，磁盘的控制器把数据转为磁盘上的磁极偏转，而这个转换过程是磁盘自己的事，磁盘自己的硬件和驱动进行控制。显示器的画面显示也不过是计算机向显示器写入数据而已，显示器的控制器(GPU)将数据转为图像，这个过程也是个显示器自己的事，例如最原始的荧光屏靠电子射击屏幕显示画面，而电子的的坐标数据可以通过是cpu写过去。将坐标转为具体的像素点，控制器可以用高中物理带电粒子在磁场中的运动将这个单纯的数据转为在屏幕上的物理位置。\n\n另一方面，外设不能和cpu直接通信，因为外设都是物理量，磁盘是磁、话筒是磁、键盘敲击的动作，这些量cpu是不能直接输入输出的，必须经过传感器等将所有非电量转为电量，之后调制解调，数模转换等一系列操作转为cpu数字电路能直接操作的数电信号。cpu和外设通信都是通过设备控制器作为中介，这些转换操作可以看做是设备控制器完成的，cpu操作设备控制器，设备控制器操作具体的外设。操作不同的外设只是对设备控制器进行不同的操作，这种结构也让cpu对外设的操作可以统一抽象为读写操作。读写的数据可能是想读写入外设的，也可能是控制设备控制器的。\n\n当然不同的外设读写的内容肯定不同，同一种内容对于不同的外设意义也不同，设备控制器怎么去读写也不同，这些由都驱动程序具体来控制。\n\n驱动程序是和硬件直接相关的，属于最接近底层的软件，用于控制外设，个人认为操作系统就可以看做cpu和内存的广义上的驱动，或者更底层的bios看做cpu和内存的驱动，只不过一般的驱动用于驱动设备，操作系统或bios驱动cpu。","comments":true,"categories":[],"tags":[{"name":"CS","slug":"CS","permalink":"http://blog.ahulearn.com/tags/CS/"}]},{"title":"IPV4地址划分详解","date":"2020-01-17T12:04:43.000Z","path":"2020/01/17/IPV4地址划分详解/","raw":"---\ntitle: IPV4地址划分详解\ndate: 2020-01-17 20:04:43\ntags:\n - 计网\ntypora-root-url: ..\ntypora-copy-images-to: ..\\img\n---\n\n1\\.  概述：\n-----------\n\n早期网络分配是只能以网段为单位进行(可能是出于路由简单的目的，网段类似电话号区号)。类比到电话4位区号，7位座机号，共11位。当电话呼叫时，线路进行转接的时候只需看区号就可以直接把电话接到某个地区，地区再看座机号接到具体某一户。这样一来转接过程各自分工让电话接通变得更加简单。网络通信也是类似，ip地址总共32位（二进制），但是网络号（区号）和主机号（座机号）不像11位电话那样始终固定为4位7位。\n\nip的划分稍微复杂一点，其划分原则为：ip地址中若第一位为0，则网络号8位，主机号24位，被称为A类地址。若第一位为1第二位为0，则网络号16位，主机号16位，被称为B类地址。若第一二位为1第三位为0，则网络号24位，主机号8位，被称为C类地址。早期网络并非个人使用，而是科研机构军工学校企业等使用，故ip的分配也是以网络号为单位，而不是以单个ip为单位来售卖。类比到电话就是，直接区号分配给你，而不是分配手机号。机构的用户多就购买一个A类网段，约可以连16M(2^24，主机号24位)台电脑，人少就购买B类网段，约可以连64k(2^16)台电脑，更少则购买C类网段，约可以连256(2^8)台电脑。分配到网段后，该网端的ip供机构自由分配给机构内的电脑，且网络运营商只负责将发往该网段的数据转发给该机构。至于该数据是属于哪台主机，由机构自己负责路由。\n\n<!--more-->\n\n----\n\n2\\. 网络划分细节：\n------------------------\n\n**1\\.  A类地址：**\n\n1.0.0.0－126.255.255.255\n(**0**0000001 00000000 00000000 00000000 ~ **0**1111110 11111111 11111111 11111111）\n\nip地址第一位为0，前8位为网络号，标识网段，后24位为主机号，标识主机。\n这里可以看到ip地址第一位为0的网段中，A类地址缺少了两个网段，这两个网段分别是：\n(1) 0.0.0.0－0.255.255.255，即 \n(**0**0000000 00000000 00000000 00000000 ~ **0**0000000 11111111 11111111 11111111)\n该网段前八位网络号全0表示本网络。其中后24位主机号全0的ip表示本主机。所以0.0.0.0表示本网络上的本主机，也就是指本机自己，一般用于路由器指定默认路由端口。网络号(前八位)全0的其他地址似乎没有用处，按道理应该指本网络的其他主机，但实测并非如此。\n\n(2) 127.0.0.0－127.255.255.255，即\n(**0**1111111 00000000 00000000 00000000 ~ **0**1111111 11111111 11111111 11111111)\n127网络为保留地址，作为环路自检地址，也就是指本机自身，一般用于测试tcp/ip工作栈是否正常。目的地址以127开头的环回地址不会出现在网络上，只能在主机内部，人话也就是只能自己发给自己，用于测试自身软硬件配置是否正常。\n\n另外A类地址中还有一段私有地址和一段保留地址：\n  （1）A类私有地址(同时也是保留地址)：\n    10.0.0.0－10.255.255.255\n\n  （2）A类保留地址：\n    100.64.0.0－100.127.255.255\n\n关于私有地址和保留地址下面会详细介绍, ABC各类地址都会留一段作为私有地址。\n\n--------\n\n**2\\. B类地址：**\n\n128.0.0.0－191.255.255.255\n(**10**000000 00000000 00000000 00000000 ~ **10**111111 11111111 11111111 11111111)\nip地址前两位为10，前16位为网络号，标识网段，后16位为主机号，标识主机。\n\nB类私有地址(同时也是保留地址)\n    172.16.0.0－172.31.255.255\n\nB类一段已指定用途、稍微特殊点的地址（但可无视此特殊性）\n    169.254.0.0－169.254.255.255，用于使用DHCP协议的主机，当出现某种错误导致无法分配地址时，就自动随机生成一个在此范围地址。\n\n**3\\. C类地址：**\n\n192.0.0.0 - 223.255.255.255\n(**110**00000 00000000 00000000 00000000 ~ **110**11111 11111111 11111111 11111111)\nip地址前三位为110，前24位为网络号，后8位为主机号。\nC类私有地址(同时也是保留地址)\n    192.168.0.0－192.168.255.255\n\n----\n\n前三类是网络划分的重点，后面两类使用较少。\n\n**4\\. D类地址：**\n\n组播(多播)地址，ip前四位为 1110 ，224.0.0.0～239.255.255.255\n(**1110**0000 00000000 00000000 00000000 ~ **1110**1111 11111111 11111111 11111111)\n组播地址前4位固定位**1110**，可变化的有28位，故组播地址有2^28个。  \n\n硬件(MAC)组播：即把多播ip地址转为硬件组播MAC地址交付给局域网内的组播组成员。以太网硬件组播地址范围是01:00:5E:00:00:00 ~ 01:00:5E:7F:FF:FF(十六进制)\n\n前25位为0000 0001 : 0000 0000 : 0101 1110 : 0\n后23位可供分配地址0000000 : 00000000 : 00000000到1111111 : 11111111 : 11111111。硬件组播MAC地址后23位直接映射ip组播地址的后23位，故组播ip地址和硬件MAC地址不是一一映射(D类ip地址可变位有28位)。因此主机收到数据链路层的组播数据报，需要由ip层进行过滤可能不属于本主机的数据报。例如主机在收听组播频道224.0.64.32，但在数据链路层由于ip地址224.128.64.32对应的组播MAC地址相同，因此也可能会收到224.128.64.32的数据报，需要在网络层根据ip过滤。\n\n**5\\. E类地址：**\n\nip地址前四位为1111,地址保留至今，未使用。\n(**1111**0000 00000000 00000000 00000000 - **1111**1111 11111111 11111111 11111111)\n网络号全1:主机号全1,即255.255.255.255表示受限(有限/本地)广播。\n一般用于当主机还不知道自己的ip或者子网掩码时，使用此地址进行广播通信，请求DHCP分配地址。\n\nDHCP请求过程：\n  1）广播DHCP服务器发现报文 \n  2）DHCP服务器应答，广播 DHCP提供报文 \n  3）主机接受DHCP服务器给的配置，广播DHCP请求报文 （广播的目的表明自己接受了谁的DHCP应答，存在多个DHCP服务器时，其他服务器可以得知自己提供的ip并没有被采纳）\n  4）DHCP服务器广播DHCP确认信息。\n\n**6\\. 私有地址：**\n\n私有地址只能用于局域网，不用于广域网，即不能直接用于和Internet通信。通信需要通过网关利用nat协议将私有地址转为公网地址，私有地址目的是用于保护内部网络，是出于网络安全考虑的。该概念ipv6依然保留，私有网络方便个人建立自己的个人网络，无需向网络供应商申请ip，就可以对内部提供各种服务。当不想和Internet连接，只希望内部访问时使用私有地址。\n\n**其实和保留地址基本相同**\n\n7\\. 保留地址：包括所有私有地址，同时又增加100网段下的一段地址，保留地址的目的应该出于缓解ipv4地址紧缺。由于保留地址(包括私有地址)不会出现在Internet上，这些地址不用来标识Internet上唯一的主机，而能用来标识本地网络上的唯一一台主机。因此可用于和本地的主机通信。当这台主机不需要和Internet通信时，就可以分配保留地址(私网地址)。这一设定，使得同一个保留地址，所有人都能使用，可极大的缓解ipv4地址紧缺。\n\n而且事实上用保留地址的主机也可以通过一定方式和Internet通信，当需要与Internet上的主机通信时，通过网关的nat协议将保留地址转为公网地址即可。保留地址类似老大老二这种称呼，虽然每家都有老大老二，但在自己家老大老二能标识唯一一个人，而且这个称呼只在自己家用。家里面就户主有名字，当老大老二想和外人交流时，就把内容告诉户主，户主去交流，同时户主收到别人告诉自己的信息，会判断是否是给老大老二的，如果是就转告给老大老二，当然这个判断并不难实现，但并非单纯网络层能解决，此处不在细谈。","comments":true,"categories":[],"tags":[{"name":"计网","slug":"计网","permalink":"http://blog.ahulearn.com/tags/%E8%AE%A1%E7%BD%91/"}]},{"title":"解决Windows各种dll缺失报错","date":"2019-10-22T18:14:27.000Z","path":"2019/10/23/彻底解决Windows各种dll缺少错误问题/","raw":"---\ntitle: 解决Windows各种dll缺失报错\ndate: 2019-10-23 02:14:27\ntags:\n - 随笔\n - 踩坑记录\n---\n\n\n1. 动态链接库简单理解就是在软件装入内存时才进行动态的链接，与程序链接成完整的可执行文件。\n    * 简单明了的说明就是，和软件主体组装到一块，动态链接库多是一些模块化可复用的代码，实现了一些频繁使用，或者难以实现的操作，供程序直接调用。减少开发人员的工作量，同时动态库在需要执行时才调入内存，一个库可用供多个进程同时使用，可以降低内存占中。\n\t* 另一方面，因为操作系统很多底层的系统调用操作或者频繁使用的操作，每个软件都要用，而且这些操作可能还比较危险，直接交给软件实现也存在一些风险。所以系统自带了很多动态链接库文件，编程人员需要使用相关功能，直接调用系统的链接文件即可。\n\n----\n\n2. 于是就会出现很多软件运行时提示缺少dll文件的情况，因为软件使用的dll文件，系统中并不一定有，或者对应的dll版本不一样。\n\n<!--more-->\n\n----\n\n3. 下面正式说明解决方案了，切忌不要提醒缺什么dll文件，就下载什么dll。\n    * 首先版本选择就很复杂，全靠运气，其次软件运行可能缺的不止这一个dll文件，而每次运行它只能发现一个报错一次，一次次运行然后一个个下肯定不现实。\n    * 微软的动态链接库全部包含在一个叫**Microsoft Visual C++ 20xx Redistributable**的软件包中，正常来讲一个软件安装的时候应该要检查电脑中是否已经安装了该软件，版本是否满足自己的需求，不满足应该给用户发出警告的。\n    * 但是事实是很少有软件这么做，都是直接安装，缺少文件只能在运行时出错才发现。\n\n----\n\n4. 可以自己下载软件包安装，软件[下载地址](https://visualstudio.microsoft.com/zh-hans/vs/older-downloads/) https://visualstudio.microsoft.com/zh-hans/vs/older-downloads/.   在该页面下，选择**可再发行组件和生成工具**，提供2010,2012,2013,2019四个版本，其中2019是包含2015和2017。\n    * 推荐一劳永逸的全部安装，能省去不少麻烦，如果不想全装，可以根据dll缺失的具体报错信息下载对应版本。\n\t* 错误信息中dll文件的数字 120 140 160理论上分别对应2013版，2015版，2017版，不排除有些偏差。\n    * x86是32位的，x64是64位的。建议全部安装，毕竟现在依然有电脑也运行着一些32位的软件。\n\n----\n<sub>Over</sub><sup>'</sup>\n","comments":true,"categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://blog.ahulearn.com/tags/%E9%9A%8F%E7%AC%94/"},{"name":"踩坑记录","slug":"踩坑记录","permalink":"http://blog.ahulearn.com/tags/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"}]},{"title":"hexo避坑小结","date":"2019-10-13T17:41:45.000Z","path":"2019/10/14/hexo避坑小结/","raw":"---\ntitle: hexo避坑小结\ndate: 2019-10-14 01:41:45\ntags:\n - 随笔\n - 踩坑记录\n - 入门实践\n---\n\n## 简单记录一下搭建过程\n+ 启动（可能需要安装python）\n   + `hexo init / hexo init <dir>` 此为hexo初始化，后加目录名则创建文件夹，将博客搭建环境部署在此文件夹下；否则将环境部署在当前文件夹下，故如果初始化不加文件夹，请手动创建一个文件夹后，在该文件夹下执行此命令。\n+ 远程部署\n   + 安装hexo-deployer-git，此为将hexo部署到github的插件，安装时若报错，提示缺eslint，则直接安装eslint即可，'npm install  hexo-deployer-git --save',另外可能是hexo-deployer-git没有创建软链接，手动创建即可：'sudo ln -s /usr/local/<nodejs安装目录>/lib/node_modules/hexo-deployer-git /usr/bin/hexo-deployer-git'.\n+ 标签\n   + 注意hexo配置文件中每个':'后都有一个空格' '，不要忘记，其次标签'tags:'多标签不可在用','隔开的形式，而是分行来写，各行之前均有一个' - '。例如\n\n```\ntags:\n - 随笔\n - 踩坑记录\n```\n+ 目录分析\n   + source 下是资源文件，其中的文件会直接上传到服务器根目录,创建如两个文件移动到该文件夹。\n   + 创建文件 CNAME （全部大写）此为域名解析文件，如果不想绑定自己的域名那就不要创建，文件内容填写自己的域名，例如：'blog.ahulearn.com'。\n   + 创建 README.md，移动到source文件夹下,同时在根目录配置文件_config.yml下添加内容skip_render: \"README.md\"。\n   + 主题目录下同有source和source-src也会上传到根目录，应将和当前使用主题相关的资源比如图片等放入此文件夹。\n","comments":true,"categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://blog.ahulearn.com/tags/%E9%9A%8F%E7%AC%94/"},{"name":"入门实践","slug":"入门实践","permalink":"http://blog.ahulearn.com/tags/%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/"},{"name":"踩坑记录","slug":"踩坑记录","permalink":"http://blog.ahulearn.com/tags/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"}]},{"title":"MathJax","date":"2019-06-30T14:42:17.000Z","path":"2019/06/30/MathJax/","raw":"---\ntitle: MathJax\ndate: 2019-06-30 22:42:17\ntags: \n - 随笔\n - 学习笔记\n---\n\n### 基本数学公式语法(of MathJax)[^queto1]\n\n[^queto1]: CSDN: [作者: ethmery](https://blog.csdn.net/ethmery/article/details/50670297)\n\n## 概述\n在markdown中输入数学公式需要LaTaX语法的支持。\n## 基本语法\n### 呈现位置\n+ 正文（inline）中的LaTeX公式用`$...$`定义\n   + 例句为：`$\\sun_{i=0}^N \\int_{a}^{b} g(t,i)\\text{d}t$`\n   + 显示为：$\\sum_{i=0}^N \\int_{a}^{b} g(t,i)\\text{d}t$\n+ 单独显示（display）的LaTeX公式用`$$...$$`定义，此时公式居中独立成块显示\n   + 例句为：`$$\\sum_{i=0}^N \\int_{a}^{b} g(i,t)\\text{d}t$$`\n   + 显示为：$$\\sum_{i=0}^N \\int_{a}^{b} g(i,t)\\text{d}t$$\n+ *下列描述语句中若非特别指出均省略`$`*\n\n<!--more-->\n\n### 希腊字母\n\n显示|命令|显示|命令\n:-:|:-:|:-:|:-:\n$\\alpha$|\\alpha|$\\beta$|\\beta\n$\\gamma$|\\gamma|$\\delta$|\\delta\n$\\epsilon$|\\epslion|$\\zeta$|\\zeta\n\n-若需要大写希腊字母，将命令首字母大写即可\n-`\\Gamma`显示为$\\Gamma$\n-若需要斜体希腊字母，将命令前加上前缀`var`即可\n-`varGamma`显示为$\\varGamma$\n\n### 字母修饰\n#### 上下标\n+ 上标：`^`\n+ 下标：`_`\n+ 举例：`C_n^2`显示为$C_n^2$\n#### 矢量\n+ `\\vec a`显示为$\\vec a$\n+ `\\overrightarrow{xy}`显示为$\\overrightarrow{xy}$\n#### 字体\n+ Typewriter:`\\mathtt{A}`显示为$\\mathtt{A}$\n   + $\\mathtt{ABCDEFGHIJKLMNOPQRSTUVWXYZ}$\n#### 分组\n+ 使用`{}`将具有相同等级的内容扩入其中，成组处理\n+ 举例：`10^{10}`显示为$10^{10}$, 而`10^10`显示为$10^10$\n#### 括号\n+ 小括号：`()`显示为$()$\n+ 中括号：`[]`显示为$[]$\n+ 尖括号：`\\langle,\\rangle`显示为$\\langle\\rangle$\n   + 此处与分组符号`{}`相区别，使用转义字符`\\`\n+ 使用`\\left(`和`\\right)`使符号大小与相邻的公式自适应；该语法适用于所有括号类型\n   + `(\\frac{x}{y})`显示为$(\\frac{x}{y})$\n   + 而`\\left(\\frac{x}{y}\\right)`显示为$\\left(\\frac{x}{y}\\right)$\n#### 求和、极限与积分\n+ 求和：`sum`\n   + 举例：`\\sum_{i=1}^n{a_i}`显示为$\\sum_{i=1}^n{a_i}$\n+ 极限：`\\to`\n   +举例： `\\lim_{x\\to 0}`显示为$\\lim_{x\\to 0}$\n+ 积分：`\\int`\n   + 举例：`\\int_0^\\infty{f(x)dx}`显示为$\\int_0^\\infty{f(x)dx}$\n\n#### 分式和根式\n\n+ 分式（fractions）:`\\frac{公式1}{公式2}`显示为$\\frac{公式1}{公式2}$\n+ 根式：`\\sqrt[x]{y+2}`显示为$\\sqrt[x]{y+2}$\n#### 特殊函数\n+ `\\函数名`\n+ 举例：`\\sin x`,`\\ln x`,`\\max(A,B,C)`显示为$\\sin x，\\ln x，\\max(A,B,C)$\n#### 特殊符号\n\n显示|命令\n:-:|:-:\n$\\infty$|\\infty\n$\\cup$|\\cup\n$\\cap$|\\cap\n\n\n#### 空格\n+ LaTeX语法本身会忽略空格的存在\n+ 小空格：`a\\ b`显示为$a\\ b$\n+ 4格空格：`a\\quad b`显示为$a\\quad b$\n\n### 矩阵\n#### 基本语法\n#### 矩阵边框\n#### 省略元素\n#### 阵列\n#### 方程组\n\n\n## 流程图\n\n\n```flow\nst=>start: 开始\nop=>operation: 操作\ncond=>condition: 是或否?\ne=>end: 结束\nst->op->cond\ncond(yes)->e\ncond(no)->op\n```","comments":true,"categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://blog.ahulearn.com/tags/%E9%9A%8F%E7%AC%94/"},{"name":"学习笔记","slug":"学习笔记","permalink":"http://blog.ahulearn.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"Markdown第一篇文章","date":"2019-06-01T05:34:07.000Z","path":"2019/06/01/Markdown第一篇文章/","raw":"---\ntitle: Markdown第一篇文章\ndate: 2019-06-01 13:34:07\ntags: \n\t- 随笔 \n\t- 学习笔记\n\n---\n[TOC]\n\n# 介绍\n\n这是第一次使用markdown来写文章\n\n## 基本语法\n`*`来表示强调，一颗 `*`*斜体、*两颗 `**` **粗体**、三颗 `***` ***粗斜体***\n\n> 块级引用\n> 使用> 来标识\n\n或者使用ESC 下方的\\`来标识,块内引用三个点\n\n```\n这是块级引用\n这是块级引用\n```\n\n    使用四个空格来表示块级引用\n    效果同上方\n\n行内引用同样使用 \\` 键，使用一个，效果如下：`这是一段行内引用`\n\n<!--more-->\n## 文本样式修改\n\n使用`=`和`~`可以改变文本样式，`=` 背景色 `==`强调，`~` ~~删除~~符号\n\n上下标\n2`<sup>10</sup>` 会变为为2<sup>10</sup>,`H<sub>2<sub>O` 会变为为H<sub>2</sub>O\n\n## 注释 链接 脚注 图片\n\n注释使用\\*[],这是一个 注释\n\n*[这是一个注释]: 悬停后现实此注释\n\n使用超链接有三种方式\n[内部链接](http://ahulearn.com), 格式\n\n```\n[内部链接](http://ahulearn.com)\n```\n\n[外部链接][1], 格式\n\n```\n[外部连接][1]\n[1]: http://ahulearn.com\n```\n\n\n\n[1]:http://ahulearn.com#\t\"个人博客\"\n图片在的链接的基础上增加了一个'！'，同样存在内部引用，![内部引用](https://avatar.csdn.net/7/7/B/1_ralf_hx163com.jpg#pic_center \"内部引用\")和外部引用。\n![外部引用][2]\n\n[2]:https://avatar.csdn.net/7/7/B/1_ralf_hx163com.jpg#pic_center\t\" 外部引用 \"\n\n脚注用来注明引用来源格式为`[^n]`\n\n例如：markdown语法我主要从 csdn[^1] 网站学习\n\n[^1]: csdn 博客系统使用markdown语法发布文章\n\n简单的表格\n\n姓名|学号|性别\n:-:|:-|-:\n：-：居中对其|：-左对齐|-：右对齐\n小华|H6345|男\n小云|B6782|女\n小明|D21316|未知\n小华|B314537|其他\n\n自定义列表\n\n: 条目1\n: 条目2\n: 条目3\n\n-[]计划任务：使用\\-[]标记\n\n-[x]完成人物：使用\\-[x]标记\n\n无序列表:注意\\-和文字间的空格\n\n- 第一章\n - 第一节\n - 第二节\n- 第二章\n - 第一节\n   - (1)\n   - (2)\n\n有序列表\n\n1. 项目1\n2. 项目2\n3. 项目3\n\n","comments":true,"categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://blog.ahulearn.com/tags/%E9%9A%8F%E7%AC%94/"},{"name":"学习笔记","slug":"学习笔记","permalink":"http://blog.ahulearn.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"Hello World","date":"2019-05-30T04:00:00.000Z","path":"2019/05/30/hello-world/","raw":"---\ntitle: Hello World\ndate: 2019-05-30 12:00:00\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n\n","comments":true,"categories":[],"tags":[]}]