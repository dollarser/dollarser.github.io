<!DOCTYPE html><html lang="zh" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>从零开始的深度学习 | 遗世独立</title><meta name="author" content="神火不知灭"><meta name="copyright" content="神火不知灭"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="从零开始的深度学习 主要内容：  安装NVIDIA GPU驱动 安装CUDA Toolkit 安装cuDNN 安装Conda(附带python) 安装PyTorch 安装TensorFlow  一、工具介绍   NVIDIA GPU驱动：nvidia-smi是nvidia 的系统管理接口，一般安装NVIDIA GPU驱动后即可使用。   CUDA  Toolkit：CUDA（Compute Uni">
<meta property="og:type" content="article">
<meta property="og:title" content="从零开始的深度学习">
<meta property="og:url" content="http://blog.sunlingzhang.com/2021/07/28/default/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/index.html">
<meta property="og:site_name" content="遗世独立">
<meta property="og:description" content="从零开始的深度学习 主要内容：  安装NVIDIA GPU驱动 安装CUDA Toolkit 安装cuDNN 安装Conda(附带python) 安装PyTorch 安装TensorFlow  一、工具介绍   NVIDIA GPU驱动：nvidia-smi是nvidia 的系统管理接口，一般安装NVIDIA GPU驱动后即可使用。   CUDA  Toolkit：CUDA（Compute Uni">
<meta property="og:locale">
<meta property="og:image" content="http://blog.sunlingzhang.com/admin_head.jpg">
<meta property="article:published_time" content="2021-07-28T10:46:00.000Z">
<meta property="article:modified_time" content="2026-02-12T10:34:06.981Z">
<meta property="article:author" content="神火不知灭">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="随笔">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://blog.sunlingzhang.com/admin_head.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "从零开始的深度学习",
  "url": "http://blog.sunlingzhang.com/2021/07/28/default/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/",
  "image": "http://blog.sunlingzhang.com/admin_head.jpg",
  "datePublished": "2021-07-28T10:46:00.000Z",
  "dateModified": "2026-02-12T10:34:06.981Z",
  "author": [
    {
      "@type": "Person",
      "name": "神火不知灭",
      "url": "http://blog.sunlingzhang.com"
    }
  ]
}</script><link rel="shortcut icon" href="/favicon.ico"><link rel="canonical" href="http://blog.sunlingzhang.com/2021/07/28/default/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=5.5.4"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.13.0/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '从零开始的深度学习',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 8.1.1"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/admin_head.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">64</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">64</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">3</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/"><i class="fa-fw fas fa-keyboard"></i><span> 入门实践</span></a></div><div class="menus_item"><a class="site-page" href="/tags/%E9%9A%8F%E7%AC%94/"><i class="fa-fw fas fa-edit"></i><span> 随笔</span></a></div><div class="menus_item"><a class="site-page" href="/tags/paper/"><i class="fa-fw fal fa-paperclip"></i><span> 论文解读</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-book"></i><span> 计算机</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/algorithm/"><i class="fa-fw fas fa-code"></i><span> 算法</span></a></li><li><a class="site-page child" href="/data-structure/"><i class="fa-fw fas fa-terminal"></i><span> 数据结构</span></a></li><li><a class="site-page child" href="/operation-system/"><i class="fa-fw fas fa-desktop"></i><span> 操作系统</span></a></li><li><a class="site-page child" href="/computer-composition/"><i class="fa-fw fas fa-microchip"></i><span> 计算机组成原理</span></a></li><li><a class="site-page child" href="/network/"><i class="fa-fw fas fa-network-wired"></i><span> 计算机网络</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-book"></i><span> 页面</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 编程语言</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/tags/Java/"><i class="fa-fw fas fa-music"></i><span> Java</span></a></li><li><a class="site-page child" href="/tags/Python/"><i class="fa-fw fas fa-video"></i><span> Python</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">遗世独立</span></a><a class="nav-page-title" href="/"><span class="site-name">从零开始的深度学习</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/"><i class="fa-fw fas fa-keyboard"></i><span> 入门实践</span></a></div><div class="menus_item"><a class="site-page" href="/tags/%E9%9A%8F%E7%AC%94/"><i class="fa-fw fas fa-edit"></i><span> 随笔</span></a></div><div class="menus_item"><a class="site-page" href="/tags/paper/"><i class="fa-fw fal fa-paperclip"></i><span> 论文解读</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-book"></i><span> 计算机</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/algorithm/"><i class="fa-fw fas fa-code"></i><span> 算法</span></a></li><li><a class="site-page child" href="/data-structure/"><i class="fa-fw fas fa-terminal"></i><span> 数据结构</span></a></li><li><a class="site-page child" href="/operation-system/"><i class="fa-fw fas fa-desktop"></i><span> 操作系统</span></a></li><li><a class="site-page child" href="/computer-composition/"><i class="fa-fw fas fa-microchip"></i><span> 计算机组成原理</span></a></li><li><a class="site-page child" href="/network/"><i class="fa-fw fas fa-network-wired"></i><span> 计算机网络</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-book"></i><span> 页面</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 编程语言</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/tags/Java/"><i class="fa-fw fas fa-music"></i><span> Java</span></a></li><li><a class="site-page child" href="/tags/Python/"><i class="fa-fw fas fa-video"></i><span> Python</span></a></li></ul></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">从零开始的深度学习</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2021-07-28T10:46:00.000Z" title="Created 2021-07-28 18:46:00">2021-07-28</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2026-02-12T10:34:06.981Z" title="Updated 2026-02-12 18:34:06">2026-02-12</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><h2 id="从零开始的深度学习">从零开始的深度学习</h2>
<h3 id="主要内容：">主要内容：</h3>
<ul>
<li>安装NVIDIA GPU驱动</li>
<li>安装CUDA Toolkit</li>
<li>安装cuDNN</li>
<li>安装Conda(附带python)</li>
<li>安装PyTorch</li>
<li>安装TensorFlow</li>
</ul>
<h1>一、工具介绍</h1>
<ul>
<li>
<p>NVIDIA GPU驱动：nvidia-smi是nvidia 的系统管理接口，一般安装NVIDIA GPU驱动后即可使用。</p>
</li>
<li>
<p>CUDA  Toolkit：CUDA（Compute Unified Device Architecture），是NVIDIA推出的运算平台，AMD也有类似的平台 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/67940936">ROCm</a>，但并不成熟。 CUDA™是一种由NVIDIA推出的通用并行计算架构，该架构使GPU能够解决复杂的计算问题。 它包含了CUDA指令集架构（ISA）以及GPU内部的并行计算引擎。</p>
</li>
<li>
<p>cuDNN：NVIDIA cuDNN是用于深度神经网络的GPU加速库。它强调性能、易用性和低内存开销。NVIDIA cuDNN可以集成到更高级别的机器学习框架中，如Tensorflow、pytorch等。简单的插入式设计可以让开发人员专注于设计和实现神经网络模型，而不是简单调整性能，同时还可以在GPU上实现高性能现代并行计算。</p>
</li>
<li>
<p>Conda：Conda 是一个开源的软件包管理系统和环境管理系统，用于安装多个版本的软件包及其依赖关系，并在它们之间轻松切换。</p>
<ul>
<li>简单来说就是可以创建多个虚拟环境，各个虚拟环境互不干扰，在每个环境中可以装一个版本的python，以及各种版本的软件包。</li>
</ul>
</li>
<li>
<p>PyTorch：PyTorch是一个开源的Python机器学习库，提供两个高级功能：1、具有强大的GPU加速的张量计算（如NumPy）。2、包含自动求导系统的深度神经网络。</p>
</li>
<li>
<p>TensorFlow：TensorFlow™是一个基于数据流编程（dataflow programming）的符号数学系统，被广泛应用于各类机器学习（machine learning）算法的编程实现，其前身是谷歌的神经网络算法库DistBelief。</p>
</li>
</ul>
<p>总结：NVIDIA GPU驱动、CUDA  Toolkit、cuDNN作用是使用NVIDIA进行GPU加速，如果只使用CPU或AMD显卡则不需要。Conda方便后面环境配置和软件管理。PyTorch和TensorFlow是两个不同的深度学习框架，PyTorch学术界使用较为广泛，方便简单，易于上手。TensorFlow工业界使用较为广泛，泛用性好，被更多框架和平台支持。</p>
<span id="more"></span>
<h1>二、环境配置</h1>
<h2 id="2-1、GPU相关-可选">2.1、GPU相关(可选)</h2>
<p>如果电脑GPU不是NVIDIA，则只能使用CPU，无法进行本小节的配置；是NVIDIA GPU，但只想使用CPU，也无需本小节的配置。建议初学者初期只使用CPU。</p>
<h3 id="2-1-1、Windows">2.1.1、Windows</h3>
<h4 id="1-下载安装NVIDIA-GPU驱动">1. 下载安装NVIDIA GPU驱动</h4>
<p>检查自己是否安装：打开cmd命令行，输入nvidia-smi，回车键运行，能运行成功说明已经正常安装。</p>
<p><img src="/img/deeplearnning/1626923540260-01a20532-61d1-4ccf-ad49-7ab7a9a1bd3e.png" alt="image.png"></p>
<p>其中Driver Version是驱动版本号，CUDA Version可能是支持的CUDA最高版本，并不是当前运行的CUDA版本。<br>
​</p>
<ol>
<li>查看显卡型号</li>
</ol>
<blockquote>
<p>查看显卡：右键桌面 我的电脑(此电脑)-&gt;属性-&gt;设备管理器-&gt;显示适配器-&gt;查看显卡型号<br>
如果桌面没有 我的电脑：右键桌面空白处-&gt;个性化-&gt;主题-&gt;桌面图标设置-&gt;勾选计算机</p>
</blockquote>
<p>此处我的显卡是 NVIDIA Quadro K620<br>
<img src="/img/deeplearnning/1626922174812-9c98f866-fd11-4dbb-af94-96d6c5ab8b4a.png" alt="image.png"></p>
<ol start="2">
<li>根据显卡型号下载驱动</li>
</ol>
<p>下载地址：</p>
<p><img src="/img/deeplearnning/1626922481409-847b8c4c-37cd-47e8-9402-c1057132bd60.png" alt="image.png"></p>
<p>根据型号选择对应驱动，点击搜索。跳转到下载页面下载即可。</p>
<ol start="3">
<li>安装NVIDIA GPU驱动</li>
</ol>
<p>点击安装程序，选择安装包解压路径</p>
<p><img src="/img/deeplearnning/1626922952946-d05b52fc-be34-4f70-a453-4a1ea46f3022.png" alt="image.png"></p>
<p>选项自定义安装</p>
<p><img src="/img/deeplearnning/1626923043333-624706c6-b04d-4c0a-a48c-114865466caa.png" alt="image.png"></p>
<p>选择要安装的组件，GPU加速只安装图形驱动程序即可；其他RTX桌面管理、HD音频驱动程序根据自己需要安装。</p>
<p><img src="/img/deeplearnning/1626923702530-1d77b684-c711-4302-9c7e-77402ad6580f.png" alt="image.png"></p>
<p>重启，检查nvidia-smi命令是否可以运行<br>
​</p>
<h4 id="2-下载安装CUDA-Toolkit">2. 下载安装CUDA Toolkit</h4>
<p>根据NVIDIA驱动版本选择对应的CUDA下载，CUDA与NVIDIA版本对应关系如下：<br>
官网文档：<a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html">https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html</a></p>
<table>
<thead>
<tr>
<th><strong>CUDA Toolkit</strong></th>
<th><strong>Linux x86_64 Driver Version</strong></th>
<th><strong>Windows x86_64 Driver Version</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>CUDA 11.0.3 Update 1</td>
<td>&gt;= 450.51.06</td>
<td>&gt;= 451.82</td>
</tr>
<tr>
<td>CUDA 11.0.2 GA</td>
<td>&gt;= 450.51.05</td>
<td>&gt;= 451.48</td>
</tr>
<tr>
<td>CUDA 11.0.1 RC</td>
<td>&gt;= 450.36.06</td>
<td>&gt;= 451.22</td>
</tr>
<tr>
<td>CUDA 10.2.89</td>
<td>&gt;= 440.33</td>
<td>&gt;= 441.22</td>
</tr>
<tr>
<td>CUDA 10.1 (10.1.105 general release, and updates)</td>
<td>&gt;= 418.39</td>
<td>&gt;= 418.96</td>
</tr>
<tr>
<td>CUDA 10.0.130</td>
<td>&gt;= 410.48</td>
<td>&gt;= 411.31</td>
</tr>
<tr>
<td>CUDA 9.2 (9.2.148 Update 1)</td>
<td>&gt;= 396.37</td>
<td>&gt;= 398.26</td>
</tr>
<tr>
<td>CUDA 9.2 (9.2.88)</td>
<td>&gt;= 396.26</td>
<td>&gt;= 397.44</td>
</tr>
<tr>
<td>CUDA 9.1 (9.1.85)</td>
<td>&gt;= 390.46</td>
<td>&gt;= 391.29</td>
</tr>
<tr>
<td>CUDA 9.0 (9.0.76)</td>
<td>&gt;= 384.81</td>
<td>&gt;= 385.54</td>
</tr>
</tbody>
</table>
<p>官网下载地址：<a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-toolkit-archive">https://developer.nvidia.com/cuda-toolkit-archive</a><br>
选择合适的版本，目前10.x版本使用较多。</p>
<p><img src="/img/deeplearnning/1627188144095-d086aecb-e266-4350-bd01-fbd2b6c57089.png" alt="image.png"></p>
<p>之后选择操作系统(Windows)，指令集架构(x86_64)，系统版本(Win10)，安装类型(本地安装local)</p>
<p><img src="/img/deeplearnning/1626925437436-616aaf36-063d-4663-ba2f-32f3361d52a6.png" alt="image.png"></p>
<p>选择完成后，点击下方的 <strong>Base Installer</strong> 下载安装；Base Installer下面的Patch补丁包可以不下载安装(可选)。</p>
<p><img src="/img/deeplearnning/1627188233034-81c0314b-72a4-431d-bd03-b48fee0072fd.png" alt="image.png"></p>
<p>双击下载的安装包，选择解压路径，安装完成解压内容会自动删除；<br>
解压完成，开始安装，选择自定义安装：</p>
<p><img src="/img/deeplearnning/1627189662948-b0e28f95-2933-47cb-8bc2-343a72114871.png" alt="image.png"></p>
<p>取消Driver components，即不安装驱动，前面已经安装。</p>
<p><img src="/img/deeplearnning/1627189724918-d20dada7-4fc1-487d-9cad-b79b1c7700fc.png" alt="image.png"></p>
<p>选择安装路径并记住路径</p>
<p><img src="/img/deeplearnning/1627189839445-f9165a2b-a301-42c8-b9ba-fa1a275b72f9.png" alt="image.png"></p>
<p>安装完成，运行 <code>nvcc -V </code> ，能够正常执行，则说明安装成功。</p>
<p><img src="/img/deeplearnning/1627190048859-d1c1e901-844d-4a81-b92a-64906ad04312.png" alt="image.png"></p>
<h4 id="3-下载cuDNN">3. 下载cuDNN</h4>
<p>官网下载地址：<a target="_blank" rel="noopener" href="https://developer.nvidia.com/rdp/cudnn-archive">https://developer.nvidia.com/rdp/cudnn-archive</a> (下载需要注册NVIDIA账号)<br>
根据CUDA版本选择cuDNN：</p>
<p><img src="/img/deeplearnning/1627188965824-2ae40dad-970c-4446-8609-9561377db062.png" alt="image.png"></p>
<p>下载完成后解压只有一个cuda文件夹，文件夹下包含三个子文件夹：</p>
<p><img src="/img/deeplearnning/1627190180934-dacd03b6-3071-497f-a748-e880732c79e2.png" alt="image.png"></p>
<p>将三个子文件夹中的文件，分别复制到CUDA Toolkit安装路径下对应的文件夹中</p>
<ul>
<li>cuDNN中bin目录下的文件移动到 CUDA 的 bin 目录中</li>
<li>cuDNN目录中的 include 中的文件移动到 CUDA 的 include 目录中</li>
<li>cuDNN目录中的 lib 中的文件移动到 CUDA 的 lib 目录中</li>
</ul>
<p><img src="/img/deeplearnning/1627190473794-5b37df52-3f7b-486b-a16e-bbb87d03e29d.png" alt="image.png"></p>
<p><strong>复制完成，验证是否成功</strong><br>
通过NVIDIA提供的 deviceQuery.exe 和 bandwidthTest.exe 来查看GPU的状态，两者均在安装目录的 extras\demo_suite文件夹中</p>
<p><img src="/img/deeplearnning/1627190810521-8c4fb784-d1db-40bc-b424-b6496849f5b6.png" alt="image.png"></p>
<p>执行返回 <code>Result = PASS</code> 说明安装成功。</p>
<h3 id="2-1-2、Linux">2.1.2、Linux</h3>
<h4 id="1-安装NVIDIA-GPU驱动">1. 安装NVIDIA GPU驱动</h4>
<p>如果你使用Linux，我相信你应该有一定的基础，由于目前手上没有Linux设备，这里不再演示。<br>
安装过程，可参考知乎专栏：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/59618999">https://zhuanlan.zhihu.com/p/59618999</a></p>
<h4 id="2-安装CUDA-Toolkit">2. 安装CUDA  Toolkit</h4>
<p>官网下载地址：<a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-toolkit-archive">https://developer.nvidia.com/cuda-toolkit-archive</a><br>
根据系统和NVIDIA驱动版本，选择合适的CUDA。</p>
<p><img src="/img/deeplearnning/1627191718067-cc5fb4ab-be49-4061-b6b2-77e86217accb.png" alt="image.png"></p>
<p>选择完成后，下方给出下载安装指令，执行 <strong>Base Installer</strong> 进行下载安装；Base Installer下面的Patch补丁包可以不下载安装(可选)。</p>
<p><img src="/img/deeplearnning/1627191952417-ffcec4b7-acbf-4f1a-a3a4-e8e50ce18f86.png" alt="image.png"></p>
<p>这里的下载命令是：<br>
<code>​wget https://developer.download.nvidia.com/compute/cuda/10.2/Prod/local_installers/cuda_10.2.89_440.33.01_linux.run</code><br>
安装命令是：<br>
<code>sudo sh cuda_10.2.89_440.33.01_linux.run</code><br>
如果没有root权限，可以安装在用户目录，此时安装命令：<br>
<code>sh cuda_10.2.89_440.33.01_linux.run --silent --toolkit --toolkitpath=$HOME/cuda_10.2 --installpath=$HOME/cuda_10.2</code><br>
​</p>
<p>安装完成设置环境变量：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 编辑用户目录下的.bashrc文件</span></span><br><span class="line"><span class="built_in">cd</span> ~</span><br><span class="line">vim .bashrc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加如下内容</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$HOME</span>/cuda_10.2/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=<span class="variable">$LD_LIBRARY_PATH</span>:<span class="variable">$HOME</span>/cuda_10.2/lib64</span><br><span class="line"></span><br><span class="line"><span class="comment"># 激活环境变量</span></span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>测试是否安装成功：<br>
<code>nvcc -V</code><br>
可以正常执行说明安装成功。</p>
<h4 id="3-下载cuDNN-2">3. 下载cuDNN</h4>
<p>官网下载地址：<a target="_blank" rel="noopener" href="https://developer.nvidia.com/rdp/cudnn-archive">https://developer.nvidia.com/rdp/cudnn-archive</a> (下载需要注册NVIDIA账号)<br>
根据CUDA版本选择cuDNN</p>
<p><img src="/img/deeplearnning/1627192799774-a12d4021-87b5-44aa-a317-c4ce1f8276b8.png" alt="image.png"></p>
<p>安装cuDNN</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 解压cuDNN</span></span><br><span class="line">tar -zxvf cudnn-10.2.tgz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将cuDNN文件复制到CUDA Toolkit安装目录中</span></span><br><span class="line"><span class="built_in">cp</span> cuda/include/cudnn.h ~/cuda_10.2/include/</span><br><span class="line"><span class="built_in">cp</span> cuda/lib64/libcudnn* ~/cuda_10.2/lib64/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 赋予执行权限</span></span><br><span class="line"><span class="built_in">chmod</span> a+r ~/cuda_10.2/include/cudnn.h</span><br><span class="line"><span class="built_in">chmod</span> a+r ~/cuda_10.2/lib64/libcudnn*</span><br></pre></td></tr></table></figure>
<h2 id="2-2、安装Conda">2.2、安装Conda</h2>
<p>conda分为anaconda和miniconda。anaconda是包含一些常用包的版本，miniconda则是精简版，需要什么装什么，这里介绍miniconda的安装。<br>
官网地址：<a target="_blank" rel="noopener" href="https://docs.conda.io/en/latest/miniconda.html">https://docs.conda.io/en/latest/miniconda.html</a></p>
<h3 id="2-2-1、安装">2.2.1、安装</h3>
<p>进入官网：</p>
<ul>
<li>Windows installers一栏就是Windows安装包</li>
<li>Linux installers一栏就是Linux安装包</li>
</ul>
<p>选择对应的操作系统和conda版本即可。<br>
一般安装MiniConda3，python版本无所谓，3.x以上都可以，后面可以根据需要自行更改。<br>
​</p>
<p>安装完成后，检测是否正常：<code>conda info -e</code></p>
<h3 id="2-2-2、配置">2.2.2、配置</h3>
<p>执行如下命令，配置Miniconda</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置国内镜像清华源，下载加速</span></span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge </span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</span><br><span class="line">conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/main/</span><br><span class="line">conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 其他</span></span><br><span class="line">conda config --<span class="built_in">set</span> show_channel_urls <span class="built_in">yes</span></span><br><span class="line">conda config --<span class="built_in">set</span> ssl_verify <span class="literal">false</span></span><br></pre></td></tr></table></figure>
<h3 id="2-2-3、常用命令参数">2.2.3、常用命令参数</h3>
<ul>
<li>查看虚拟环境： <code>conda info -e</code></li>
<li>激活虚拟环境：<code>conda activate myTorch</code>
<ul>
<li>activate 后是虚拟环境名</li>
</ul>
</li>
<li>退出虚拟环境： <code>conda deactivate</code></li>
<li>删除虚拟环境：<code>conda remove -n 虚拟环境名 --all</code></li>
<li>安装某个软件到当前虚拟环境：<code>conda install 包名 -y</code></li>
<li>卸载当前虚拟环境中的某个软件包：<code>conda uninstall 包名 -y</code></li>
<li>安装某个软件包到指定虚拟环境中：<code>conda install -n 虚拟环境名 包名 -y</code></li>
<li>卸载指定虚拟环境中的某个软件包：<code>conda uninstall -n 虚拟环境名 包名 -y</code></li>
</ul>
<h2 id="2-3、安装PyTorch">2.3、安装PyTorch</h2>
<p>PyTorch的安装分为GPU版和CPU版，使用官网命令安装和手动安装需要注意选择。<br>
​</p>
<ul>
<li>创建虚拟环境：<code>conda create -n myTorch python=3.6.9</code>
<ul>
<li>-n 后接的myTorch是自定义的虚拟环境名，自己随便起名；python=3.6.9指定该虚拟环境下使用的python版本。</li>
</ul>
</li>
<li>激活环境：<code>conda activate myTorch</code></li>
</ul>
<p>之后的安装都在此虚拟环境下进行！</p>
<h3 id="2-3-1-官网命令安装PyTorch">2.3.1 官网命令安装PyTorch</h3>
<p>官网地址：</p>
<p><img src="/img/deeplearnning/1627458601473-137e2c3a-2acb-4f76-b6c8-984202664357.png" alt="image.png"></p>
<p>选择PyTorch版本(1.9.0)，操作系统版本(Windows)，包管理器(Conda)，语言(Language)，计算平台(CUDA 10.2)<br>
得到安装命令：<code>conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch</code><br>
命令中 <code>-c</code> 后接的是官方默认源，如果比较慢，可以使用清华源(ps：好像也不快，经常下载失败)：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda config --add channels  https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</span><br><span class="line">conda install pytorch torchvision torchaudio cudatoolkit=10.2</span><br></pre></td></tr></table></figure>
<p>同理包管理选择pip也可以：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install torch==1.9.0+cu102 torchvision==0.10.0+cu102 torchaudio===0.9.0 -f https://download.pytorch.org/whl/torch_stable.html</span><br></pre></td></tr></table></figure>
<p>这里可以看到使用pip安装，需要显式的指定pytorch和torchvison、torchaudio的版本。<br>
​</p>
<h3 id="2-3-2-手动安装PyTorch">2.3.2 手动安装PyTorch</h3>
<p>手动安装是为了解决自动下载安装总是由于网络问题失败的问题。<br>
安装前需要下载需要的包，地址：</p>
<ul>
<li>官网：<a target="_blank" rel="noopener" href="https://download.pytorch.org/whl/torch_stable.html">https://download.pytorch.org/whl/torch_stable.html</a></li>
<li>清华：<a target="_blank" rel="noopener" href="https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple/torch/">https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple/torch/</a>、<a target="_blank" rel="noopener" href="https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple/torch/">https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple/torchvision/</a></li>
</ul>
<p>手动安装，最值得注意的是选择torch和torchvision的版本对应关系。</p>
<blockquote>
<p>pytrch=1.4、torchvision=0.5<br>
pytorch=1.6、torchvision=0.7<br>
torch=1.9、torchvision=0.10<br>
其他版本可以自行百度</p>
</blockquote>
<p>以官网为例，访问上述地址，可以看到需要的whl包文件。</p>
<p><img src="/img/deeplearnning/1627461859068-c9297fbf-b7ad-4646-8173-d6af03c9a312.png" alt="image.png"></p>
<p><img src="/img/deeplearnning/1627461797313-853bb9e2-8ed5-4dc7-9580-ce22a6f05ae1.png" alt="image.png"></p>
<p>软件包格式：<code>设备(cpu/gpu)-软件包名-包版本-python版本-操作系统_处理器</code></p>
<ul>
<li>如果使用的是cpu那么就选cpu版本，如果适用gpu那么需要根据安装的cuda版本选择，比如安装了cuda10.2就选择cu102。</li>
<li>如果使用的python版本是3.6.x就选择cp36-cp36m，其他版本对应选择即可。</li>
<li>如果操作系统是Windows，就选择win；如果是linux就选择linux。</li>
<li>处理器架构目前基本都是64位，amd64和x86_64相同都是64位。</li>
</ul>
<p>使用下载工具下载对应的torch和torchvision，下载完成使用pip命令安装。<br>
假如下载的文件分别为：torchvision-0.5.0+cpu-cp37-cp37m-win_amd64.whl、torch-1.4.0+cpu-cp37-cp37m-win_amd64.whl：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install ./torchvision-0.5.0+cpu-cp37-cp37m-win_amd64.whl</span><br><span class="line">pip install ./torch-1.4.0+cpu-cp37-cp37m-win_amd64.whl</span><br></pre></td></tr></table></figure>
<h2 id="2-4、安装TensorFlow">2.4、安装TensorFlow</h2>
<p>TensorFlow的安装也分为GPU版和CPU版，CPU版本安装较简单；但如果安装GPU版，则需要满足与cuDNN和CUDA的关系。否则可能无法使用GPU加速。<br>
另外TensorFlow 1.x 和 2.x 变动较大，建议安装 2.x 版本，相对简单易用。<br>
​</p>
<h3 id="2-4-1-CPU版本安装">2.4.1 CPU版本安装</h3>
<p>使用pip直接输入以下命令：<br>
<code>pip install 'tensorflow==2.2.0' -i [http://pypi.doubanio.com/simple/](http://pypi.doubanio.com/simple/) --trusted-host pypi.doubanio.com</code><br>
其中 2.2.0是版本号，-i 后指定安装源，–trusted-host 表示信任安装源，防止无法下载。<br>
​</p>
<h3 id="2-4-2-GPU版本安装">2.4.2 GPU版本安装</h3>
<p>命令与cpu版本类似，但需要保证TensorFlow版本与cuDNN和CUDA版本对应：<br>
<code>pip install 'tensorflow-gpu==2.2.0' -i [http://pypi.doubanio.com/simple/](http://pypi.doubanio.com/simple/) --trusted-host pypi.doubanio.com</code><br>
只需要在tensorflow后加上-gpu即会下载gpu版本。<br>
​</p>
<p>下方是官网给出的对应关系：</p>
<ul>
<li>Linux GPU</li>
</ul>
<table>
<thead>
<tr>
<th>版本</th>
<th>Python 版本</th>
<th>编译器</th>
<th>构建工具</th>
<th>cuDNN</th>
<th>CUDA</th>
</tr>
</thead>
<tbody>
<tr>
<td>tensorflow-2.4.0</td>
<td>3.6-3.8</td>
<td>GCC 7.3.1</td>
<td>Bazel 3.1.0</td>
<td>8.0</td>
<td>11.0</td>
</tr>
<tr>
<td>tensorflow-2.3.0</td>
<td>3.5-3.8</td>
<td>GCC 7.3.1</td>
<td>Bazel 3.1.0</td>
<td>7.6</td>
<td>10.1</td>
</tr>
<tr>
<td>tensorflow-2.2.0</td>
<td>3.5-3.8</td>
<td>GCC 7.3.1</td>
<td>Bazel 2.0.0</td>
<td>7.6</td>
<td>10.1</td>
</tr>
<tr>
<td>tensorflow-2.1.0</td>
<td>2.7、3.5-3.7</td>
<td>GCC 7.3.1</td>
<td>Bazel 0.27.1</td>
<td>7.6</td>
<td>10.1</td>
</tr>
<tr>
<td>tensorflow-2.0.0</td>
<td>2.7、3.3-3.7</td>
<td>GCC 7.3.1</td>
<td>Bazel 0.26.1</td>
<td>7.4</td>
<td>10.0</td>
</tr>
<tr>
<td>tensorflow_gpu-1.15.0</td>
<td>2.7、3.3-3.7</td>
<td>GCC 7.3.1</td>
<td>Bazel 0.26.1</td>
<td>7.4</td>
<td>10.0</td>
</tr>
<tr>
<td>tensorflow_gpu-1.14.0</td>
<td>2.7、3.3-3.7</td>
<td>GCC 4.8</td>
<td>Bazel 0.24.1</td>
<td>7.4</td>
<td>10.0</td>
</tr>
<tr>
<td>tensorflow_gpu-1.13.1</td>
<td>2.7、3.3-3.7</td>
<td>GCC 4.8</td>
<td>Bazel 0.19.2</td>
<td>7.4</td>
<td>10.0</td>
</tr>
<tr>
<td>tensorflow_gpu-1.12.0</td>
<td>2.7、3.3-3.6</td>
<td>GCC 4.8</td>
<td>Bazel 0.15.0</td>
<td>7</td>
<td>9</td>
</tr>
<tr>
<td>tensorflow_gpu-1.11.0</td>
<td>2.7、3.3-3.6</td>
<td>GCC 4.8</td>
<td>Bazel 0.15.0</td>
<td>7</td>
<td>9</td>
</tr>
<tr>
<td>tensorflow_gpu-1.10.0</td>
<td>2.7、3.3-3.6</td>
<td>GCC 4.8</td>
<td>Bazel 0.15.0</td>
<td>7</td>
<td>9</td>
</tr>
<tr>
<td>tensorflow_gpu-1.9.0</td>
<td>2.7、3.3-3.6</td>
<td>GCC 4.8</td>
<td>Bazel 0.11.0</td>
<td>7</td>
<td>9</td>
</tr>
<tr>
<td>tensorflow_gpu-1.8.0</td>
<td>2.7、3.3-3.6</td>
<td>GCC 4.8</td>
<td>Bazel 0.10.0</td>
<td>7</td>
<td>9</td>
</tr>
<tr>
<td>tensorflow_gpu-1.7.0</td>
<td>2.7、3.3-3.6</td>
<td>GCC 4.8</td>
<td>Bazel 0.9.0</td>
<td>7</td>
<td>9</td>
</tr>
<tr>
<td>tensorflow_gpu-1.6.0</td>
<td>2.7、3.3-3.6</td>
<td>GCC 4.8</td>
<td>Bazel 0.9.0</td>
<td>7</td>
<td>9</td>
</tr>
<tr>
<td>tensorflow_gpu-1.5.0</td>
<td>2.7、3.3-3.6</td>
<td>GCC 4.8</td>
<td>Bazel 0.8.0</td>
<td>7</td>
<td>9</td>
</tr>
<tr>
<td>tensorflow_gpu-1.4.0</td>
<td>2.7、3.3-3.6</td>
<td>GCC 4.8</td>
<td>Bazel 0.5.4</td>
<td>6</td>
<td>8</td>
</tr>
<tr>
<td>tensorflow_gpu-1.3.0</td>
<td>2.7、3.3-3.6</td>
<td>GCC 4.8</td>
<td>Bazel 0.4.5</td>
<td>6</td>
<td>8</td>
</tr>
<tr>
<td>tensorflow_gpu-1.2.0</td>
<td>2.7、3.3-3.6</td>
<td>GCC 4.8</td>
<td>Bazel 0.4.5</td>
<td>5.1</td>
<td>8</td>
</tr>
<tr>
<td>tensorflow_gpu-1.1.0</td>
<td>2.7、3.3-3.6</td>
<td>GCC 4.8</td>
<td>Bazel 0.4.2</td>
<td>5.1</td>
<td>8</td>
</tr>
<tr>
<td>tensorflow_gpu-1.0.0</td>
<td>2.7、3.3-3.6</td>
<td>GCC 4.8</td>
<td>Bazel 0.4.2</td>
<td>5.1</td>
<td>8</td>
</tr>
</tbody>
</table>
<ul>
<li>Windows GPU</li>
</ul>
<table>
<thead>
<tr>
<th>版本</th>
<th>Python 版本</th>
<th>编译器</th>
<th>构建工具</th>
<th>cuDNN</th>
<th>CUDA</th>
</tr>
</thead>
<tbody>
<tr>
<td>tensorflow_gpu-2.4.0</td>
<td>3.6-3.8</td>
<td>MSVC 2019</td>
<td>Bazel 3.1.0</td>
<td>8.0</td>
<td>11.0</td>
</tr>
<tr>
<td>tensorflow_gpu-2.3.0</td>
<td>3.5-3.8</td>
<td>MSVC 2019</td>
<td>Bazel 3.1.0</td>
<td>7.6</td>
<td>10.1</td>
</tr>
<tr>
<td>tensorflow_gpu-2.2.0</td>
<td>3.5-3.8</td>
<td>MSVC 2019</td>
<td>Bazel 2.0.0</td>
<td>7.6</td>
<td>10.1</td>
</tr>
<tr>
<td>tensorflow_gpu-2.1.0</td>
<td>3.5-3.7</td>
<td>MSVC 2019</td>
<td>Bazel 0.27.1-0.29.1</td>
<td>7.6</td>
<td>10.1</td>
</tr>
<tr>
<td>tensorflow_gpu-2.0.0</td>
<td>3.5-3.7</td>
<td>MSVC 2017</td>
<td>Bazel 0.26.1</td>
<td>7.4</td>
<td>10</td>
</tr>
<tr>
<td>tensorflow_gpu-1.15.0</td>
<td>3.5-3.7</td>
<td>MSVC 2017</td>
<td>Bazel 0.26.1</td>
<td>7.4</td>
<td>10</td>
</tr>
<tr>
<td>tensorflow_gpu-1.14.0</td>
<td>3.5-3.7</td>
<td>MSVC 2017</td>
<td>Bazel 0.24.1-0.25.2</td>
<td>7.4</td>
<td>10</td>
</tr>
<tr>
<td>tensorflow_gpu-1.13.0</td>
<td>3.5-3.7</td>
<td>MSVC 2015 update 3</td>
<td>Bazel 0.19.0-0.21.0</td>
<td>7.4</td>
<td>10</td>
</tr>
<tr>
<td>tensorflow_gpu-1.12.0</td>
<td>3.5-3.6</td>
<td>MSVC 2015 update 3</td>
<td>Bazel 0.15.0</td>
<td>7.2</td>
<td>9.0</td>
</tr>
<tr>
<td>tensorflow_gpu-1.11.0</td>
<td>3.5-3.6</td>
<td>MSVC 2015 update 3</td>
<td>Bazel 0.15.0</td>
<td>7</td>
<td>9</td>
</tr>
<tr>
<td>tensorflow_gpu-1.10.0</td>
<td>3.5-3.6</td>
<td>MSVC 2015 update 3</td>
<td>Cmake v3.6.3</td>
<td>7</td>
<td>9</td>
</tr>
<tr>
<td>tensorflow_gpu-1.9.0</td>
<td>3.5-3.6</td>
<td>MSVC 2015 update 3</td>
<td>Cmake v3.6.3</td>
<td>7</td>
<td>9</td>
</tr>
<tr>
<td>tensorflow_gpu-1.8.0</td>
<td>3.5-3.6</td>
<td>MSVC 2015 update 3</td>
<td>Cmake v3.6.3</td>
<td>7</td>
<td>9</td>
</tr>
<tr>
<td>tensorflow_gpu-1.7.0</td>
<td>3.5-3.6</td>
<td>MSVC 2015 update 3</td>
<td>Cmake v3.6.3</td>
<td>7</td>
<td>9</td>
</tr>
<tr>
<td>tensorflow_gpu-1.6.0</td>
<td>3.5-3.6</td>
<td>MSVC 2015 update 3</td>
<td>Cmake v3.6.3</td>
<td>7</td>
<td>9</td>
</tr>
<tr>
<td>tensorflow_gpu-1.5.0</td>
<td>3.5-3.6</td>
<td>MSVC 2015 update 3</td>
<td>Cmake v3.6.3</td>
<td>7</td>
<td>9</td>
</tr>
<tr>
<td>tensorflow_gpu-1.4.0</td>
<td>3.5-3.6</td>
<td>MSVC 2015 update 3</td>
<td>Cmake v3.6.3</td>
<td>6</td>
<td>8</td>
</tr>
<tr>
<td>tensorflow_gpu-1.3.0</td>
<td>3.5-3.6</td>
<td>MSVC 2015 update 3</td>
<td>Cmake v3.6.3</td>
<td>6</td>
<td>8</td>
</tr>
<tr>
<td>tensorflow_gpu-1.2.0</td>
<td>3.5-3.6</td>
<td>MSVC 2015 update 3</td>
<td>Cmake v3.6.3</td>
<td>5.1</td>
<td>8</td>
</tr>
<tr>
<td>tensorflow_gpu-1.1.0</td>
<td>3.5</td>
<td>MSVC 2015 update 3</td>
<td>Cmake v3.6.3</td>
<td>5.1</td>
<td>8</td>
</tr>
<tr>
<td>tensorflow_gpu-1.0.0</td>
<td>3.5</td>
<td>MSVC 2015 update 3</td>
<td>Cmake v3.6.3</td>
<td>5.1</td>
<td>8</td>
</tr>
</tbody>
</table>
<p>注：其实TensorFlow 2.x 以后不再区分CPU版和GPU版，上述两个命令只在 1.x 版本有区别。</p>
<h3 id="2-4-3-手动下载地址">2.4.3 手动下载地址</h3>
<p><a target="_blank" rel="noopener" href="https://pypi.org/project/tensorflow/#files">https://pypi.org/project/tensorflow/#files</a><br>
手动下载后，pip安装即可，注意python版本、操作系统和处理器架构。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install tensorflow-2.2.0-cp36-cp36m-win_amd64.whl</span><br></pre></td></tr></table></figure></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="http://blog.sunlingzhang.com">神火不知灭</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="http://blog.sunlingzhang.com/2021/07/28/default/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">http://blog.sunlingzhang.com/2021/07/28/default/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E9%9A%8F%E7%AC%94/">随笔</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></div><div class="post-share"><div class="social-share" data-image="/admin_head.jpg" data-sites="facebook,x,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2021/08/05/Python/Python%E5%85%A5%E9%97%A8/" title="Python入门"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">Python入门</div></div><div class="info-2"><div class="info-item-1">1、环境配置 python作为脚本语言，只需要一个python解释器就可以直接编写代码和运行。 但是为了方便我们通常会使用IDE(集成开发环境)或轻量级的文本编辑器进行开发。 这里首先介绍使用最简单的python编辑器编写代码，以及使用VS Code、Jupyter开发。  1.1 安装python解释器 这里推荐安装Conda,Conda是极其方便且强大的包管理器，安装后自带python解释器，同时为以后开发带来极大的便利。如果只想安装python解释器可以从下方地址下载： 官网Windows下载：https://www.python.org/downloads/windows/ 1.2、安装Conda conda分为anaconda和miniconda。anaconda是包含一些常用包的版本，miniconda则是精简版，需要什么装什么，这里介绍miniconda的安装。 官网地址：https://docs.conda.io/en/latest/miniconda.html 1.2.1、安装 进入官网：https://docs.conda.io/en/latest/minic...</div></div></div></a><a class="pagination-related" href="/2021/05/21/Paper/Attention%20Is%20All%20You%20Need/" title="Attention Is All You Need"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">Attention Is All You Need</div></div><div class="info-2"><div class="info-item-1">Transformer 注意力就是您所需要的 [TOC] 会议： NeurIPS 2017 论文地址：https://arxiv.org/abs/1706.03762 摘要 主流的序列转换模型多是基于复杂的循环或卷积神经网络，网络包括编码器和解码器。性能最好的模型还通过注意机制连接编码器和解码器。我们提出了一个新的简单且完全基于注意力机制的网络结构，Transformer，摒弃了循环和卷积。在两个机器翻译任务上的实验表明，这些模型具有更高的并行性，更少的训练时间。我们的模型在WMT 2014 Englishto-German 的翻译任务中达到28.4 BLEU，比现有的最佳结果（包括集成模型）提高了2 BLEU以上。在WMT 2014 English-to-French翻译任务中，我们的模型在8个GPU上训练3.5天后，达到了新的单模型BLEU 41.8的最新分数，这只相当于文献中最佳模型训练成本的一小部分。通过将Transformer成功地应用于大规模和有限训练数据下的英语选区分析，证明了Transformer具有良好的泛化能力。  1 简介 循环神经网络，特别是长-短期记忆(...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2024/03/11/default/Generative%20Adversarial%20Nets/" title="Generative Adversarial Networks"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-11</div><div class="info-item-2">Generative Adversarial Networks</div></div><div class="info-2"><div class="info-item-1">Generative Adversarial Networks(GAN神经网络) [TOC] 摘要 本文提出了一个新的基于对抗的网络框架，主要包含两个模型。一个是生成模型G，用于获取整个数据分布；另一个是判别模型D，用于判别数据是来自真实数据还是生成数据。生成模型尽可能让判别模型犯错。判别模型试图找到一个函数，使得判别模型在真实的数据上得分较高，在生成模型的数据上得分较低。  介绍 GAN网络由两个模型组成：生成模型G和判别模型D。生成模型G的目标是生成尽可能接近真实数据的数据，判别模型D的目标是判别数据是来自真实数据还是生成数据。 生成模型G通过一个随机过程生成数据，判别模型D试图判别数据是否来自真实数据。判别模型D有一个输出值，表示数据来自真实数据的概率。判别模型D有一个目标函数，使得判别模型在真实的数据上得分较高，在生成模型的数据上得分较低。 生成模型G有一个目标函数，使得判别模型在生成模型的数据上得分较低，在真实的数据上得分较高。 生成模型G和判别模型D交替更新，生成模型G的目标函数和判别模型D的目标函数相互对抗。 方法  GAN网络可以应用在图像生成、语音生成等领域。 ...</div></div></div></a><a class="pagination-related" href="/2020/01/17/default/IPV4%E5%9C%B0%E5%9D%80%E5%88%92%E5%88%86%E8%AF%A6%E8%A7%A3/" title="IPV4地址划分详解"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2020-01-17</div><div class="info-item-2">IPV4地址划分详解</div></div><div class="info-2"><div class="info-item-1">1.  概述： 早期网络分配是只能以网段为单位进行(可能是出于路由简单的目的，网段类似电话号区号)。类比到电话4位区号，7位座机号，共11位。当电话呼叫时，线路进行转接的时候只需看区号就可以直接把电话接到某个地区，地区再看座机号接到具体某一户。这样一来转接过程各自分工让电话接通变得更加简单。网络通信也是类似，ip地址总共32位（二进制），但是网络号（区号）和主机号（座机号）不像11位电话那样始终固定为4位7位。 ip的划分稍微复杂一点，其划分原则为：ip地址中若第一位为0，则网络号8位，主机号24位，被称为A类地址。若第一位为1第二位为0，则网络号16位，主机号16位，被称为B类地址。若第一二位为1第三位为0，则网络号24位，主机号8位，被称为C类地址。早期网络并非个人使用，而是科研机构军工学校企业等使用，故ip的分配也是以网络号为单位，而不是以单个ip为单位来售卖。类比到电话就是，直接区号分配给你，而不是分配手机号。机构的用户多就购买一个A类网段，约可以连16M(2^24，主机号24位)台电脑，人少就购买B类网段，约可以连64k(2^16)台电脑，更少则购买C类网段，约可以连2...</div></div></div></a><a class="pagination-related" href="/2020/03/28/default/%E6%95%B0%E6%8D%AE%E6%B5%81%E9%87%8F%E8%AF%B7%E6%B1%82%E5%A4%B4%E5%88%86%E6%9E%90/" title="移动数据流量请求头分析"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2020-03-28</div><div class="info-item-2">移动数据流量请求头分析</div></div><div class="info-2"><div class="info-item-1">1. http协议请求头 12345[method] [uri] [version]\r\nHost: www.example.com\r\nConnection: keep-alive\r\n...\r\n 1.1 第一行的字段为请求的：方法，资源地址，协议版本 http协议常用的请求方法[method]为  GET：用于向服务器请求数据； POST: 用于向服务器提交数据； CONNECT: 用于隧道代理; HEAD: 用于向服务器请求报头;  资源地址[uri]：一般为URL中去掉域名后剩下的那部分，即浏览器地址栏网址中域名之后的内容。 http协议版本[version]: 目前主流版本有HTTP/1.0和HTTP/1.1。 http请求头中的的换行用的是\r\n, 而非Linux中的换行符\n。以下为一个真实请求头的示例  GET /index.html HTTP/1.1 Host: www.example.com Connection: keep-alive   1.2 Host字段为请求的主机域名 早期没有虚拟主机的概念，一台服务器有一个主机名。因此规定在请求头的第一...</div></div></div></a><a class="pagination-related" href="/2025/04/16/Python/pytorch-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-CTCLoss/" title="损失函数-CTCLoss"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-16</div><div class="info-item-2">损失函数-CTCLoss</div></div><div class="info-2"><div class="info-item-1">什么是CTCLoss？ CTC (Connectionist Temporal Classification) 是一种用于序列到序列学习的损失函数，特别适用于输入和输出长度不固定的场景。它在语音识别、手写体识别等任务中应用广泛。CTC 的核心思想是通过引入一个“空白”符号（blank token），允许模型对不定长的输入序列生成不定长的输出序列，同时避免了对输入和输出进行显式的对齐操作。 传统的序列标注方法通常需要将输入和输出进行严格的对齐（例如，逐帧标注），而 CTC 允许模型自动学习输入和输出之间的对齐关系，从而大大简化了训练过程。   CTCLoss 的工作原理 1. 输入与输出的关系  输入是一个不定长的序列，比如语音信号或手写笔迹的时间序列。 输出是一个较短的目标序列，比如文本转录结果。 输入和输出的长度可能不同，且没有明确的对齐关系。  2. 引入空白符号 CTC 引入了一个特殊的“空白”符号（通常记作 - 或 blank），表示某个时间步没有对应的输出。空白符号在最终的输出中会被移除。 3. 路径的概念 CTC 将输入序列到输出序列的所有可能对齐方式称为“路径”。例...</div></div></div></a><a class="pagination-related" href="/2019/10/14/default/hexo%E9%81%BF%E5%9D%91%E5%B0%8F%E7%BB%93/" title="hexo避坑小结"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2019-10-14</div><div class="info-item-2">hexo避坑小结</div></div><div class="info-2"><div class="info-item-1">简单记录一下搭建过程  启动（可能需要安装python）  hexo init / hexo init &lt;dir&gt; 此为hexo初始化，后加目录名则创建文件夹，将博客搭建环境部署在此文件夹下；否则将环境部署在当前文件夹下，故如果初始化不加文件夹，请手动创建一个文件夹后，在该文件夹下执行此命令。   远程部署  安装hexo-deployer-git，此为将hexo部署到github的插件，安装时若报错，提示缺eslint，则直接安装eslint即可，‘npm install  hexo-deployer-git --save’,另外可能是hexo-deployer-git没有创建软链接，手动创建即可：‘sudo ln -s /usr/local/&lt;nodejs安装目录&gt;/lib/node_modules/hexo-deployer-git /usr/bin/hexo-deployer-git’.   标签  注意hexo配置文件中每个’:‘后都有一个空格’ '，不要忘记，其次标签’tags:‘多标签不可在用’,‘隔开的形式，而是分行来写，各行之前均有一个’...</div></div></div></a><a class="pagination-related" href="/2025/08/05/Python/pytorch-%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/" title="pytorch-常用激活函数"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-05</div><div class="info-item-2">pytorch-常用激活函数</div></div><div class="info-2"><div class="info-item-1">激活函数的原则：  单调函数（或有极小一部分不单调） 非线性函数 具有良好的梯度    1. Sigmoid 函数 Sigmoid 是早期神经网络中常用的激活函数，其数学表达式为： f(x)=11+e−xf(x) = \frac{1}{1 + e^{-x}} f(x)=1+e−x1​  优点：输出值在 (0, 1) 区间内，适合用于二分类问题的概率预测。 缺点：容易出现梯度消失问题，计算量相对较大。  2. Tanh（双曲正切）函数 Tanh 的数学表达式如下： f(x)=tanh⁡(x)=ex−e−xex+e−x f(x) = \tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}  f(x)=tanh(x)=ex+e−xex−e−x​  优点：将输入值压缩到 (-1, 1)，对于后续的优化过程较为友好。 缺点：与 Sigmoid 类似，两端的导数接近于零，可能导致梯度消失问题。  3. ReLU（修正线性单元） ReLU 是当前深度学习中最常用的激活函数之一，定义为： f(x)=max⁡(0,x) f(x) = \max(0, x)  f(x...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/admin_head.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">神火不知灭</div><div class="author-info-description">日常记录学习用博客，仅用来练习使用</div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">64</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">64</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/dollarser"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">技术笔记，日常记录</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.</span> <span class="toc-text">从零开始的深度学习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E5%86%85%E5%AE%B9%EF%BC%9A"><span class="toc-number">1.1.</span> <span class="toc-text">主要内容：</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">一、工具介绍</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">二、环境配置</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1%E3%80%81GPU%E7%9B%B8%E5%85%B3-%E5%8F%AF%E9%80%89"><span class="toc-number">3.1.</span> <span class="toc-text">2.1、GPU相关(可选)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-1%E3%80%81Windows"><span class="toc-number">3.1.1.</span> <span class="toc-text">2.1.1、Windows</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85NVIDIA-GPU%E9%A9%B1%E5%8A%A8"><span class="toc-number">3.1.1.1.</span> <span class="toc-text">1. 下载安装NVIDIA GPU驱动</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85CUDA-Toolkit"><span class="toc-number">3.1.1.2.</span> <span class="toc-text">2. 下载安装CUDA Toolkit</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E4%B8%8B%E8%BD%BDcuDNN"><span class="toc-number">3.1.1.3.</span> <span class="toc-text">3. 下载cuDNN</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-2%E3%80%81Linux"><span class="toc-number">3.1.2.</span> <span class="toc-text">2.1.2、Linux</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E5%AE%89%E8%A3%85NVIDIA-GPU%E9%A9%B1%E5%8A%A8"><span class="toc-number">3.1.2.1.</span> <span class="toc-text">1. 安装NVIDIA GPU驱动</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E5%AE%89%E8%A3%85CUDA-Toolkit"><span class="toc-number">3.1.2.2.</span> <span class="toc-text">2. 安装CUDA  Toolkit</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E4%B8%8B%E8%BD%BDcuDNN-2"><span class="toc-number">3.1.2.3.</span> <span class="toc-text">3. 下载cuDNN</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2%E3%80%81%E5%AE%89%E8%A3%85Conda"><span class="toc-number">3.2.</span> <span class="toc-text">2.2、安装Conda</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-1%E3%80%81%E5%AE%89%E8%A3%85"><span class="toc-number">3.2.1.</span> <span class="toc-text">2.2.1、安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-2%E3%80%81%E9%85%8D%E7%BD%AE"><span class="toc-number">3.2.2.</span> <span class="toc-text">2.2.2、配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-3%E3%80%81%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%8F%82%E6%95%B0"><span class="toc-number">3.2.3.</span> <span class="toc-text">2.2.3、常用命令参数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3%E3%80%81%E5%AE%89%E8%A3%85PyTorch"><span class="toc-number">3.3.</span> <span class="toc-text">2.3、安装PyTorch</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-1-%E5%AE%98%E7%BD%91%E5%91%BD%E4%BB%A4%E5%AE%89%E8%A3%85PyTorch"><span class="toc-number">3.3.1.</span> <span class="toc-text">2.3.1 官网命令安装PyTorch</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-2-%E6%89%8B%E5%8A%A8%E5%AE%89%E8%A3%85PyTorch"><span class="toc-number">3.3.2.</span> <span class="toc-text">2.3.2 手动安装PyTorch</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-4%E3%80%81%E5%AE%89%E8%A3%85TensorFlow"><span class="toc-number">3.4.</span> <span class="toc-text">2.4、安装TensorFlow</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-1-CPU%E7%89%88%E6%9C%AC%E5%AE%89%E8%A3%85"><span class="toc-number">3.4.1.</span> <span class="toc-text">2.4.1 CPU版本安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-2-GPU%E7%89%88%E6%9C%AC%E5%AE%89%E8%A3%85"><span class="toc-number">3.4.2.</span> <span class="toc-text">2.4.2 GPU版本安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-3-%E6%89%8B%E5%8A%A8%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80"><span class="toc-number">3.4.3.</span> <span class="toc-text">2.4.3 手动下载地址</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/12/Python/Claude_Code/" title="Claude Code应用指南">Claude Code应用指南</a><time datetime="2026-02-12T09:30:00.000Z" title="Created 2026-02-12 17:30:00">2026-02-12</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/12/Python/MuSGD/" title="MuSGD优化器">MuSGD优化器</a><time datetime="2026-02-12T09:00:00.000Z" title="Created 2026-02-12 17:00:00">2026-02-12</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/11/Python/pytorch-%E5%B8%B8%E7%94%A8%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" title="深度学习常用损失函数">深度学习常用损失函数</a><time datetime="2026-02-11T10:00:00.000Z" title="Created 2026-02-11 18:00:00">2026-02-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/10/Python/%E4%BD%8E%E7%A7%A9%E8%BF%91%E4%BC%BC/" title="矩阵相关">矩阵相关</a><time datetime="2026-02-10T10:00:00.000Z" title="Created 2026-02-10 18:00:00">2026-02-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/02/10/Python/Muon%E4%BC%98%E5%8C%96%E5%99%A8/" title="Muon优化器">Muon优化器</a><time datetime="2026-02-10T09:00:00.000Z" title="Created 2026-02-10 17:00:00">2026-02-10</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 - 2026 By 神火不知灭</span><span class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 8.1.1</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.5.4</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=5.5.4"></script><script src="/js/main.js?v=5.5.4"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex@0.16.28/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex@0.16.28/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>